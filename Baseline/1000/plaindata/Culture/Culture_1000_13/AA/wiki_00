{"id": "38979885", "url": "https://en.wikipedia.org/wiki?curid=38979885", "title": "\"Holy...\"", "text": "\"Holy...\"\n\n\"Holy…!\" (for example \"Holy cow!\", \"Holy mackerel!\" or \"Holy smoke!\") is an exclamation of surprise used mostly in English-speaking countries.\n\nRobin of the \"Batman\" TV series is noted for his many catchphrase \"Holy…\" exclamations. The lines in the 1960s TV series were uttered by Burt Ward who played Robin, who delivered the exclamations in a nasal voice. Many of the camp quips are directly related to the plot; for example, \"Holy Graf Zeppelin!\" is uttered by Robin upon seeing an aerial balloon.\n\nAccording to New York wellness expert Scott A. Morofsky, Robin would \"inevitably refer to an intense experience with a loud, 'Holy... Batman, what do we do now?'\". Bradley J. Ricca, comic book scholar at Case Western Reserve University, suggests that: \"Robin exists as a media entity inextricably linked with Batman and shares nearly as much ubiquity in American culture\". He considers Robin's famous \"Holy...\" catchphrases to have been grossly overused in the series, popularizing it in the American vernacular. Cartoons such as \"The Super Friends\" continued to make use of Robin and his catchphrases, \"spouting 'Holy' in front of every noun imaginable\" and Robin's exclamations still remain closely associated with his character in popular culture.\n\nAmerican author David Shields notes how much in contrast Robin's \"Holy...\" outbursts, his alliteration and assonance, his fast riffs\" were to the laconic Batman. According to film critics Deborah Cartmell and Imelda Whelehan, Robin's quip \"Holey Rusted Metal!\" in \"Batman Forever\" was an \"explicit in-joke\". Camp humour, through Robin's exclamations and other circumstances in the Batman series, have led some commentators to speculate on homosexual undertones in the relationship between Batman and Robin. Image Entertainment paid homage to Robin's quips with the title \"Batman: Holy Batmania\" in a 2004 2-disc DVD release containing four documentaries discussing the sixties TV series. The DVD title is the name of one of the documentaries itself.\n\n\n"}
{"id": "232680", "url": "https://en.wikipedia.org/wiki?curid=232680", "title": "Action fiction", "text": "Action fiction\n\nAction fiction is the literary genre that includes spy novels, adventure stories, tales of terror and intrigue (\"cloak and dagger\"), and mysteries. This kind of story utilizes suspense, the tension that is built up when the reader wishes to know how the conflict between the protagonist and antagonist is going to be resolved or what the solution to the puzzle of a thriller is.\n\nAction fiction is a form of genre fiction whose subject matter is characterized by emphasis on exciting action sequences. This does not always mean they exclude character development or story-telling. Action fiction is related to other forms of fiction, including action films, action games and analogous media in other formats such as manga and anime. It includes martial arts action, extreme sports action, car chases and vehicles, suspense action, and action comedy, with each focusing in more detail on its own type and flavor of action. It is usually possible to tell from the creative style of an action sequence, the emphasis of an entire work, so that, for example, the style of a combat sequence will indicate whether the entire work can be classified as action adventure, or a martial work. Action is mainly defined by a central focus on any kind of exciting movement.\n\n"}
{"id": "50944285", "url": "https://en.wikipedia.org/wiki?curid=50944285", "title": "Animal epithet", "text": "Animal epithet\n\nAn animal epithet is a name used to label a person or group, by association with some perceived quality of an animal. Epithets may be formulated as similes, explicitly comparing people with the named animal, or as metaphors, directly naming people as animals. Animal epithets may be pejorative, readily giving offence, and they are sometimes used in political campaigns. One English epithet, lamb, is always used positively.\n\nAnimal similes and metaphors have been used since classical times, for example by Homer and Virgil, to heighten effects in literature, and to sum up complex concepts concisely.\n\nSurnames that name animals are found in different countries. They may be metonymic, naming a person's profession, generally in the Middle Ages; toponymic, naming the place where a person lived; or nicknames, comparing the person favourably or otherwise with the named animal.\n\nIn the cultures of ancient Greece and ancient Rome, animal stereotypes grew until by the time of Virgil, animal epithets could be applied to anything from an abstract concept like love or fear, to a whole civilisation. An author could use an animal's name to emphasise a theme or to provide an overview of a complex epic tale. For example, Homer uses animal similes in the \"Iliad\" and the \"Odyssey\", where the lion symbolises qualities such as bravery. This leads up to the lion simile at the end of the \"Odyssey\", where in Book 22 Odysseus kills all Penelope's suitors. In the \"Iliad\", Homer compares the Trojans to stridulating grasshoppers, which the classicist Gordon Lindsay Campbell believes to imply that they make a lot of noise but are weaker and less determined than they think. In the \"Aeneid\", Book 4, Virgil compares the world of Dido, queen of Carthage, with a colony of ants. Campbell argues that Dido's people are hardworking, strong, unfailingly loyal, organised, and self-regulating: just the sort of world that the hero Aeneas would like to create. But, Campbell argues, the simile also suggests that Carthage's civilisation is fragile and insignificant, and could readily be destroyed.\n\nAnimal epithets may be pejorative, indeed in some cultures highly offensive. Epithets are sometimes used in political campaigns; in 1890, the trades unionist Chummy Fleming marched with a group of unemployed people through the streets of Melbourne, displaying a banner with the message \"Feed on our flesh and blood you capitalist hyenas: it is your funeral feast\". On the other side of the ideological divide, the Cuban government described the revolutionary Che Guevara as a \"communist rat\" in 1958. Epithets are not limited to mammals; for instance, comparing someone to a snail means they are (extremely) slow, while calling them a slug implies they are lazy and loathsome. Frog is pejorative for French people in English, from the use of frogs' legs in French cuisine.\n\nEdmund Leach argued in a classic 1964 paper that animal epithets are insulting when the animal in question is taboo, making its name suitable for use as an obscenity. For example, Leach argues that calling a person \"a son of a bitch\" or \"you swine\" means that the \"animal name itself is credited with potency\".\n\nIn 1976, John Halverson argued that Leach's argument about taboos was \"specious\", and his \"categorisation of animals in terms of 'social distance' and edibility is inconsistent in itself and corresponds neither to reality nor to the scheme of social distance and human sexuality it is claimed to parallel\". Halverson disputed the association of animal epithets with potency, noting that calling a timid person a mouse, or a person who does not face reality an ostrich, or a silly person a goose, does not mean that these names are potent, taboo, or sacred.\n\nTimothy Jay argues, citing Leach, that the use of animal epithets as insults is partly down to taboos on eating pets or unfamiliar wild animals, and partly down to our stereotypes of animals' habits, such as that pigs \"are dirty, fat, and eat filth\". Jay further cites Sigmund Freud's view that obscenities that name animals, such as cow, cock, dog, pig, and bitch, gain their power by reducing people to animals.\n\nThe use of metaphors from zoology, such as referring to politicians as rats or hyenas, is what the linguistic researcher Aida Sakalauskaite calls \"zoometaphors\" and Grzegorz A. Kleparski calls \"zoosemy\", the use of metaphors from zoology. In each of three different languages, English, German, and Lithuanian, the most common animal categories are farmyard animals (40% in English), Canidae (including dog and wolf, 6% in English), and birds (10% in English). Grammatically, metaphor, as in \"sly fox\", is not the only option: speakers may also use simile, as in \"deaf as an ass\". In German, 92% of animal epithets are metaphors, 8% similes, whereas in English, 53% are similes, 47% metaphors.\n\nThe Hungarian linguists Katalin Balogné Bérces and Zsuzsa Szamosfalvi found in a preliminary survey of Serbian usage that the most commonly used \"animal vocatives\" were, in order, 1. pig, 2. chick(en), 3. dog/puppy, 4. cow, 5. monkey, 6. hen, 7. rat, 8. turkey, 9. mouse, 10. snake, 11. cat/kitten, 12. fox, 13. lamb, 14. vixen, 15. worm. Of these, using the classification devised by Sabina Halupka-Resetar, and Biljana Radic, lamb was always used positively; cow and vixen referred to a person's appearance; pig indicated a person's eating habits; calling someone a fox or a turkey related to their intelligence, or lack of it; and names like cat, snake, worm, monkey, dog, mouse, chicken, lamb and rat were used to indicate a person's character.\n\nSome English surnames from the Middle Ages name animals. These have different origins. Some, like Pigg (1066), Hogg (1079) and Hoggard, Hogarth (1279) are metonyms for a swineherd, while Oxer (1327) similarly denotes an oxherd and Shepherd (1279 onwards) means as it sounds a herder of sheep.\n\nSurnames that mention animals can also be toponymic, the names Horscroft, Horsfall, Horsley and Horstead for example all denoting people who came from these villages associated with horses. The surname Horseman (1226 onwards) on the other hand is a metonym for a rider, mounted warrior, or horse-dealer, while the surnames Horse and Horsnail could either be nicknames or metonyms for workers with horses and shoers of horses respectively.\n\nSome surnames, like Bird, dating from 1193 onwards, with variants like Byrd and Bride, are most likely nicknames for a birdlike person, though they may also be metonyms for a birdcatcher; but Birdwood is toponymic, for a person who lived by a wood full of birds. Eagle from 1230 is a nickname from the bird, while Weasel, Wessel from 1193 and Stagg from 1198 are certainly nicknames from those animals. It is not always easy to tell whether a nickname was friendly, humorous or negative, but the surname Stallion, with variants Stallan, Stallen and Stallon, (1202 onwards) is certainly pejorative, meaning \"a begetter, a man of lascivious life\".\n\nSurnames behave in similar ways in other languages; for example in France, surnames can be toponymic, metonymic, or may record nicknames (\"sobriquets\"). Poisson (Fish) is a metonym for a fishmonger or fisherman. Loiseau (The bird) and Lechat (The cat) are nicknames, Lechat indicating either a flexible man or a hypocrite, Loiseau suggesting a lightly-built birdlike person. In Sweden, the surname Falk (Falcon) is common; it is found among Swedish nobility from 1399.\n\n"}
{"id": "55505034", "url": "https://en.wikipedia.org/wiki?curid=55505034", "title": "Aramaic studies", "text": "Aramaic studies\n\nAramaic studies is the study of the Aramaic language and Syriac Christianity. A specialist in Aramaic studies is known as a Aramaicist. British, French, and German scholars of the 18th and 19th centuries who were involved in the study of Syriac/Aramaic language and literature were commonly known by the designation Syriacist (a scholar of Syriac studies, at a time when the Syriac language was little understood outside Assyrian, Syriac Christian and Maronite Christian communities. In Germany the field of study is distinguished between \"Aramaistik\" (Aramaic studies) and \"Neuaramaistik\" (Neo-Aramaic (Syriac) studies).\n\nAramaic studies is the term used at the University of Oxford, University of Leiden, and University of Detroit Mercy. At some other universities, Aramaic studies are mostly incorporated into a more 'general' field of studies, such as Eastern Christianity at the School of Oriental and African Studies, University of London, as Eastern Christianity at Duke University, or as Semitic studies at the Freie Universität Berlin. Most students learn the Aramaic language and Syriac language within a biblical studies program.\n\nAramaic academic journals include the annual \"Aramaic Studies\", a leading journal for Aramaic language and literature published by Brill Academic Publishers. The journal incorporates the previous \"Journal for the Aramaic Bible\" for a more inclusive scope, to include all aspects of Aramaic language and literature, even when not, or only indirectly, related to Biblical texts.\n\n"}
{"id": "39272508", "url": "https://en.wikipedia.org/wiki?curid=39272508", "title": "Artist's impression", "text": "Artist's impression\n\nAn artist's impression or artist's interpretation is the representation of an object or a scene created by an artist, when no other accurate representation is available. It could be an image, a sound, a video or a model. Artist's impressions are often created to represent concepts and objects that cannot be seen by the naked eye; that are very big, very small, in the past, in the future, fictional, or otherwise abstract in other ways. For example, in architecture, artists' impressions are used to showcase the design of planned buildings and associated landscape. Artists' impressions are particularly prominent in space art.\n\n"}
{"id": "47127", "url": "https://en.wikipedia.org/wiki?curid=47127", "title": "Baby boomers", "text": "Baby boomers\n\nBaby boomers (also known as boomers) are the demographic cohort following the Silent Generation and preceding Generation X. There are varying timelines defining the start and the end of this cohort; demographers and researchers typically use birth years starting from the early- to mid-1940s and ending anywhere from 1960 to 1964.\n\nThe term \"baby boomer\" is also used in a cultural context, so it is difficult to achieve broad consensus of a precise date definition. Different people, organizations, and scholars have varying opinions on who is a baby boomer, both chronologically and culturally. Some define \"baby boomers\" as those born between 1946 and 1964. \n\nBaby boomers are associated with a rejection or redefinition of traditional values. Many commentators, however, have disputed the extent of that rejection, noting the widespread continuity of values with older and younger generations. In Europe and North America, boomers are widely associated with privilege, as many grew up in a time of widespread government subsidies in post-war housing and education, and increasing affluence.\n\nAs a group, baby boomers were the wealthiest, most active, and most physically fit generation up to the era in which they arrived, and were amongst the first to grow up genuinely expecting the world to improve with time. They were also the generation that received peak levels of income; they could therefore reap the benefits of abundant levels of food, apparel, retirement programs, and sometimes even \"midlife crisis\" products. The increased consumerism for this generation has been regularly criticized as excessive.\n\nOne feature of the boomers was that they have tended to think of themselves as a special generation, very different from those that had come before or that has come afterward. In the 1960s, as the relatively large numbers of young people became teenagers and young adults, they, and those around them, created a very specific rhetoric around their cohort, and the changes they were bringing about. This rhetoric had an important impact in the self perceptions of the boomers, as well as their tendency to define the world in terms of generations, which was a relatively new phenomenon. The baby boom has been described variously as a \"shockwave\" and as \"the pig in the python\".\n\nThe term \"Generation Jones\" is sometimes used to describe those born roughly between 1954 and 1964. The term is typically used to refer to the later years of the Baby boomer cohort and the early years of Generation X.\n\nThe term baby boom refers to a noticeable increase in the birth rate. The post-war population increase was described as a \"boom\" by various newspaper reporters, including Sylvia F. Porter in a column for the May 4, 1951, edition of the \"New York Post\", based on the increase in the population of the U.S. of 2,357,000 in 1950. The first recorded use of \"baby boomer\" is in a January 1963 \"Daily Press\" article describing a massive surge of college enrollments approaching as the oldest boomers were coming of age.\n\nVarious authors have delimited the baby boom period differently. Landon Jones, in his book \"Great Expectations: America and the Baby Boom Generation\" (1980), defined the span of the baby-boom generation as extending from 1943 through 1960, when annual births increased over 4,000,000. Authors William Strauss and Neil Howe, well known for their generational theory, define the social generation of Boomers as that cohort born from 1943 to 1960, who were too young to have any personal memory of World War II, but old enough to remember the postwar American High.\n\nPew Research Center defines baby boomers as being born between 1946 and 1964. In the U.S., the generation can be segmented into two broadly defined cohorts: The Leading-Edge Baby Boomers are individuals born between 1946 and 1955, those who came of age during the Vietnam War era. This group represents slightly more than half of the generation, or roughly 38,002,000 people of all races. The other half of the generation was born between 1956 and 1964. Called Late Boomers, or Trailing-Edge Boomers, this second cohort includes about 37,818,000 individuals, according to \"Live Births by Age and Mother and Race, 1933–98\", published by the Centers for Disease Control's National Center for Health Statistics.\n\nAn ongoing battle for \"generational ownership\" has motivated a handful of marketing mavens and cultural commentators to coin and/or promote their own terms for sub‑segments of the baby-boomer generation. These monikers include, but are not limited to, \"golden boomers,\" \"generation Jones,\" \"alpha boomers,\" \"hippies,\" \"yippies,\" \"yuppies,\" \"zoomers,\" and \"cuspers.\"\n\nIn Ontario, Canada, one attempt to define the boom came from David Foot, author of \"Boom, Bust and Echo: Profiting from the Demographic Shift in the 21st century\" (1997). He defines a Canadian boomer as someone born from 1947 to 1966, the years that more than 400,000 babies were born. However, he acknowledges that is a demographic definition, and that culturally it may not be as clear-cut.\n\nDoug Owram argues that the Canadian boom took place from 1942 to 1960, but that culturally boomers everywhere were born between the late war years and about 1955 or 1956. He notes that those born in the years before the actual boom were often the most influential people among boomers; for example, musicians such as The Beatles, Bob Dylan, and The Rolling Stones, as well as writers like Jack Kerouac and Allen Ginsberg, who were either slightly or vastly older than the boomer generation. Those born in the 1960s might feel disconnected from the cultural identifiers of the earlier boomers.\n\nBernard Salt places the Australian baby boom between 1943 and 1960, while the Australian Bureau of Statistics defines the boom as 1946 to 1964.\n\n76 million Americans were born between 1946 and 1964, representing a cohort that is significant in size alone. In 2004, the British baby boomers held 80% of the UK's wealth and bought 80% of all high-end cars, 80% of cruises and 50% of skincare products.\n\nIn addition to the size of the group, Steve Gillon has suggested that one thing that sets the baby boomers apart from other generational groups is the fact that \"almost from the time they were conceived, Boomers were dissected, analyzed, and pitched to by modern marketers, who reinforced a sense of generational distinctiveness.\" This is supported by the articles of the late 1940s identifying the increasing number of babies as an economic boom, such as a 1948 \"Newsweek\" article whose title proclaimed \"Babies Mean Business\", or a 1948 \"Time\" magazine article called \"Baby Boom.\"\n\nThe age wave theory suggests an economic slowdown when the boomers started retiring during 2007–2009. Projections for the aging U.S. workforce suggest that by 2020, 25% of employees will be at least 55 years old.\n\nThe Baby Boomers came into being the largest voting demographic in the early 1980s, a period which ushered in a long running trend of rapidly increasing income inequality. From 1979-2007, those receiving the highest 1 percentile of incomes saw their already large incomes increase by 278% while those in the middle at the 40th-60th percentiles saw a 35% increase. Since 1980, after the vast majority of Baby Boomer college goers graduated, the cost of college has been increased by over 600% (inflation adjusted).\n\nA survey found that nearly a third of baby boomer multimillionaires polled in the United States would prefer to pass on their inheritance to charities rather than pass it down to their children. Fifty-seven percent of these boomers believed it was important for each generation to earn their own money; fifty four percent believed it was more important to invest in their children while they were growing up.\n\nBoomers grew up at a time of dramatic social change. In the United States, that change marked the generation with a strong cultural cleavage, between the proponents of change and the more conservative individuals. Some analysts believe this cleavage played out politically since the time of the Vietnam War to the mid‑2000s, to some extent defining the political landscape and division in the country. Starting in the 1980s, the boomers became more conservative, many of them regretting the cultural changes they brought in their youth.\n\nIn 1993, \"Time\" magazine reported on the religious affiliations of baby boomers. Citing Wade Clark Roof, a sociologist at the University of California at Santa Barbara, the articles stated that about 42% of baby boomers were dropouts from formal religion, 33% had never strayed from church, and 25% of boomers were returning to religious practice. The boomers returning to religion were \"usually less tied to tradition and less dependable as church members than the loyalists. They are also more liberal, which deepens rifts over issues like abortion and homosexuality.\"\n\nThe early and mid-boomers were coming of age at the same time across the world, so that they experienced events like Beatlemania and Woodstock, organizing against the Vietnam War, or fighting and dying in the same war. Boomers in Italy were dressing in mod clothes and \"buying the world a Coke.\" Boomers in India were seeking new philosophical discoveries. Some American boomers in Canada had found a new home after escaping the draft. Canadian Boomers were organizing support for Pierre Trudeau. It is precisely because of these experiences that many believe those born in the second half of the birth boom belong to another generation, as events that defined their coming of age have little in common with leading or core boomers.\nPolitically, early Boomers in the United States tend to be Democrats, while later boomers tend to be Republicans.\n\nThe baby boomers found that their music, most notably rock and roll, was another expression of their generational identity. Transistor radios were personal devices that allowed teenagers to listen to The Beatles, the Motown Sound, and other new musical directions and artists.\n\nIn the west, baby boomers comprised the first generation to grow up with the television; some popular Boomer-era shows included \"Howdy Doody\", \"The Mickey Mouse Club\", \"Captain Video\", \"The Soupy Sales Show\", \"The Brady Bunch\", \"Gilligan's Island\", \"The Twilight Zone\", \"Batman\", \"Rowan and Martin's Laugh-In\", \"Star Trek\", \"The Ed Sullivan Show\", \"All in the Family\" and \"Happy Days\".\n\nIn the 1985 study of U.S. generational cohorts by Schuman and Scott, a broad sample of adults was asked, \"What world events over the past 50 years were especially important to them?\" For the baby boomers the results were:\n\nSome debate exists regarding the generational identity of those born from 1961 to 1964, as some demographers and researchers consider these individuals to be part of the younger demographic cohort, Generation X.\n\nThe density of Baby Boomers can put a strain on Medicare. According to the American Medical Student Association, the population of individuals over the age of 65 will increase by 73 percent between 2010 and 2030, meaning one in five Americans will be a senior citizen.\n\n, it was reported that, as a generation, boomers had tended to avoid discussions and long-term planning for their demise. However, beginning at least as early as that year, there has been a growing dialogue on how to manage aging and end-of-life issues as the generation ages. In particular, a number of commentators have argued that Baby Boomers are in a state of denial regarding their own aging and death and are leaving an undue economic burden on their children for their retirement and care. According to the 2011 Associated Press and LifeGoesStrong.com surveys:\nIn 2009, the earliest baby boomers (If someone uses Strauss and Howe's range of 1943-1960) reached a common retirement age in the United States: 66 years.\n\nAn indication of the importance put on the impact of the boomer was the selection by \"TIME\" magazine of the Baby Boom Generation as its 1966 \"Man of the Year.\" As Claire Raines points out in \"Beyond Generation X\", \"never before in history had youth been so idealized as they were at this moment.\" When Generation X came along it had much to live up to according to Raines.\n\nBoomers are often associated with the counterculture of the 1960s, the civil rights movement, and the \"second-wave\" feminist cause of the 1970s. Conversely, many trended in moderate to conservative directions opposite to the counterculture, especially those making professional careers in the military (officer and enlisted), law enforcement, business, blue collar trades, and Republican Party politics. They are also associated with the spending trends and narcissism of the \"Me\" generation.\n\nPeople often take it for granted that each succeeding generation will be \"better off\" than the one before it. When Generation X came along just after the boomers, they would be the first generation to enjoy a lesser quality of life than the generation preceding it.\n\nBaby boomers continue to have a significant effect on politics, as the United States presidential election, 2016 came down to two controversial candidates in Hillary Clinton and Donald Trump, both boomers, with a majority of Trump's support coming from the Baby Boomer generation. Three American presidents were born in 1946: Bill Clinton, George W. Bush and Donald Trump.\n\nWithin the UK, numerous Baby Boomers have served as major party leaders, including four prime ministers (John Major, Tony Blair, Gordon Brown, and Theresa May), and five leaders of the opposition (Neil Kinnock, Margaret Beckett, Tony Blair, Iain Duncan Smith and Jeremy Corbyn).\n\n\n\n"}
{"id": "17252167", "url": "https://en.wikipedia.org/wiki?curid=17252167", "title": "Beast of Dean", "text": "Beast of Dean\n\nThe Beast of Dean is an animal said to live, or to have once lived, in the Forest of Dean, Gloucestershire, England. It was originally thought to resemble a wild boar (\"Sus scrofa\"), but abnormally large in size. At that time of its first sightings, wild boar were extinct in Britain.\n\nFarmers from the village of Parkend undertook an expedition to capture and kill the creature, in 1802 but found nothing. The animal they were hunting was reported to be a boar large enough to fell trees and hedges.\n\nBeginning in the early 1990's a number of Phantom cats were sighted in the Forest of Dean. The identity of these \"Black Panthers\" was thrown into further confusion in 2002 when a large Wild Boar with black fur was killed in a collision along the A40 near the town of Over.\n\nIn the science-fiction television series \"Primeval\", the Beast of Dean turns out to be a gorgonopsid that arrived in the present day through a wormhole leading to the Permian period.\n"}
{"id": "31721334", "url": "https://en.wikipedia.org/wiki?curid=31721334", "title": "Counter-flows", "text": "Counter-flows\n\nCounter-flow (also referred as contra-flow) is the movement of cultures from one place to another brought by mobile subjects (migrants) that can have a positive or negative impact or effect on society. It is no longer from \"the west to the rest\", but a two-way movement. Counter-flows can be seen through the media such as telenovelas (soap operas) and through gangs such as the Mara Salvatrucha (MS-13) from El Salvador. Daya Kishan Thussu defines contra-flow as:\n\nUnlike transculturation, counter-flows (or contra-flow) is not the mixing or meshing of two cultures. Rather, contra-flow is about the movement of cultures, like a two-way traffic lane, where individuals are said to live \"between cultures\". The term contra-flow originated from the preceding peripheries of global media industries, designated \"sub-altern flows\". More importantly, contra-flows emerged because of the global mass media reversing the dominant Western, First World direction, in other words it is no longer from \"the West to the rest\", It can also be said that counter-flows originated because of colonization and later on because of diaspora.\n\nColonization brought a new language and religious beliefs to the Americas. On the one hand, a new way of living was taken in by the indigenous people, but on the other, they retained part of their language that is still used today such as the words \"maize\" and \"aguacate\", among others. Additionally, just like the indigenous people, colonizers acquired something from the colonized; they brought back with them goods from the Americans such as potatoes and corn. Through colonization, we can see counter-flows being born and take action because of the consumption, fluidity, and flexibility of culture in both directions, from the colonizer to the colonized and vice versa.\n\nContra or counter-flows, through media, have had a positive and negative impact on migrant communities. As mentioned before, counter-flows is the movement of culture, not only one way but a two-way movement. Furthermore, media is a major source of communication and information that reaches hundreds of homes across the country. The term counter-flows is especially applied and seen in the Latino communities located all throughout the United States.\n\nA positive example of contra-flow media are telenovelas or soap operas. Telenovelas have become global because of the leading producers of telenovelas such as Televisa in Mexico, Venevision in Venezuela, and Globo TV in Brazil, reaching hundreds of homes all around the globe. Through these leading networks, migrant communities are able to obtain information and watch entertainment shows from their native land.\n\n\"Yo Soy Betty La Fea\", a telenovela originally from Colombia, has become a success not only in its native country but in more than seventy countries in three different continents. In the United States, for example, the telenovela aired on the Telemundo network for Latino communities in the United States. After its grand success, other United States networks became interested in creating or remaking the telenovela by naming it \"Ugly Betty\", but for an English-speaking audience. However, the producers of \"Ugly Betty\" made sure to still maintain the plot and some of the main characteristics from the original \"Yo Betty La Fea\" telenovela to retain the Hispanic fans and audience. By maintaining some of the characteristics, producers hope that the English-speaking Latino communities are able to relate with the main character, Betty, because of the fact that she is a Latino woman living in the United States with an immigrant father.\n\n\"Yo Soy Betty La Fea\" is a great example of contra-flow media because of the increasing exportation of telenovelas to the United States and other countries not familiar or culturally similar to Latin America. \"Ugly Betty\" also shows the reverse media imperialism which is \"the term focused on the one-way flow of information from the United States to the rest of the world with complete disregard for the importance of counter-flows generated by television exporters in other parts of the world\".\n\nLa Mara Salvatrucha is a negative example of counter-flow. This Latin gang originated from Los Angeles California after Salvadoran migrants left their country in the early 1980s due to the civil war. La Mara Salvatrucha (or MS-13) has a reputation of being the world's most dangerous gang. The flow of La Mara Salvatrucha gang members between the United States and El Salvador has created a transnational empire of power and control supported by violence. Members from MS-13 keep in constant contact with members in El Salvador. Among the criminal activities that they operate in both the US an El Salvador are robbery, muggings, extortion, drug trafficking, the distribution of weapons, human trafficking and murder. They are protective with their business empire while keeping in touch through technology. According to Tina Strickland the gang members stay in contact by \"using disposable cell phones and the Internet, both of which are readily available at low cost\". Many of the members do not have technological skills, but there are programs that help them navigate.\n\nThrough technology, the media has exposed society to issues that are occurring around the world. The media does not hesitate to expose violence through the news, Internet and newspaper magazines. The printing industry and images are a navigation chain to reach out to the world, and La Mara has been on top of the negative exposure. La Mara's exposure to the world has created fear among society. The gang’s history has appeared in different airings, from Fox News Channel, and \"Gangland\" on the History Channel. According to Strickland, \"Deportations have helped create an 'unending chain' of gang members moving between the U.S. and Central America. ... it's a merry-go-round\". Till this day the Salvadoran gang MS-13 is still considered a transnational group through their back and forth movement.\n\nSubaltern flows: This idea is mentioned by Daya Kishan Thussu in his 2012 article \"Mapping Global Media Flow and Contra-Flow\". He described the subaltern flows as \"originators of transnational media flows have a strong regional presence but are also aimed at audiences outside their primary constituency.\" To better describe \"subaltern flows\", he mentioned the CCTV-9 as an example. CCTV-9 is an English language network of China Central Television broadcasting since 2011 because the official language used there is English. The potential viewers of CCTV-9 are in two major groups, the foreigner in China and the overseas Chinese. As Daya Kishan Thussu argued in 2012: \"the expansion of CCTV-9, reflects the recognition by the Beijing authorities of the importance of the English language as the key to success for global commerce and communication and their strategy to bring Chinese public diplomacy to a global audience.\"\n\nDominant flows: Daya Kishan Thussu explained this idea in his article \"Mapping Global Media Flow and Contra-Flow\" as \"the US-led Western media, both online and offline, and in various forms –information, infotainment and entertainment – are global in their reach and influence.\" He also provides three examples of \"dominant media flows\" in his article which is media from the United States that \"available across the global\"; media from Britain which is a \"major presence in global media, particularly in the field of news and current affairs\"; and Japanese animation which is \"the only non-Western genre\". These are all considered as major dominant media flows that have extended their influence in a global content.\n"}
{"id": "16039879", "url": "https://en.wikipedia.org/wiki?curid=16039879", "title": "Cultural Alliance of Greater Washington", "text": "Cultural Alliance of Greater Washington\n\nThe Cultural Alliance of Greater Washington (CAGW) works to increase appreciation, support, and resources for arts and culture in the Greater Washington DC region, United States. With over 300 member organizations, the CAGW programming includes:\n\n"}
{"id": "1502499", "url": "https://en.wikipedia.org/wiki?curid=1502499", "title": "Cultural capital", "text": "Cultural capital\n\nIn sociology, cultural capital consists of the social assets of a person (education, intellect, style of speech and dress, etc.) that promote social mobility in a stratified society. Cultural capital functions as a social-relation within an economy of practices (system of exchange), and comprises all of the material and symbolic goods, without distinction, that society considers rare and worth seeking. As a social relation within a system of exchange, cultural capital includes the accumulated cultural knowledge that confers social status and power.\n\nIn \"Cultural Reproduction and Social Reproduction\" (1977), Pierre Bourdieu and Jean-Claude Passeron presented \"cultural capital\" to conceptually explain the differences among the levels of performance and academic achievement of children within the educational system of France in the 1960s; and further developed the concept in the essay \"The Forms of Capital\" (1985) and in the book \"The State Nobility: Élite Schools in the Field of Power\" (1996).\n\nIn the sociological essay, \"The Forms of Capital\" (1985), Pierre Bourdieu identifies three categories of capital:\n\n\nThere are three types of cultural capital: (i) Embodied capital; (ii) Objectified capital; and (iii) Institutionalised capital:\n\n\nThe cultural capital of a person is linked to his or her habitus (embodied disposition and tendencies) and field (social positions), which are configured as a social-relation structure. The field is the place of social position that is constituted by the conflicts that occur when social groups endeavour to establish and define what is cultural capital, within a given social space; therefore, depending upon the social field, one type of cultural capital can simultaneously be legitimate and illegitimate. In that way, the legitimization (societal recognition) of a type of cultural capital can be arbitrary and derived from symbolic capital.\n\nThe habitus of a person is composed of the intellectual dispositions inculcated to him or her by family and the familial environment, and are manifested according to the nature of the person. As such, the social formation of a person's habitus is influenced by family, by objective changes in social class, and by social interactions with other people in daily life; moreover, the habitus of a person also changes when he or she changes social positions within the field.\n\nThe concept of cultural capital has received widespread attention all around the world, from theorists and researchers alike. It is mostly employed in relation to the education system, but on the odd occasion has been used or developed in other discourses. Use of Bourdieu's cultural capital can be broken up into a number of basic categories. First, are those who explore the theory as a possible means of explanation or employ it as the framework for their research. Second, are those who build on or expand Bourdieu's theory. Finally, there are those who attempt to disprove Bourdieu's findings or to discount them in favour of an alternative theory. The majority of these works deal with Bourdieu's theory in relation to education, only a small number apply his theory to other instances of inequality in society.\n\nThose researchers and theorists who explore or employ Bourdieu's theory use it in a similar way as it was articulated by Bourdieu. They usually apply it uncritically, and depending on the measurable indicators of cultural capital and the fields within which they measure it, Bourdieu's theory either works to support their argument totally, or in a qualified way.. These works to help portray the usefulness of Bourdieu's concept in analysing (mainly educational) inequality but they do not add anything to the theory.\n\nOne work which does employ Bourdieu's work in an enlightening way is that of Emirbayer & Williams (2005) who use Bourdieu's notion of fields and capital to examine the power relations in the field of social services, particularly homeless shelters. The authors talk of the two separate fields that operate in the same geographic location (the shelter) and the types of capital that are legitimate and valued in each. Specifically they show how homeless people can possess \"staff-sanctioned capital\" or \"client-sanctioned capital\" (2005:92) and show how in the shelter, they are both at the same time, desirable and undesirable, valued and disparaged, depending on which of the two fields they are operating in. Although the authors do not clearly define staff-sanctioned and client-sanctioned capital as cultural capital, and state that usually the resources that form these two capitals are gathered from a person's life as opposed to their family, it can be seen how Bourdieu's theory of cultural capital can be a valuable theory in analyzing inequality in any social setting.\n\nA number of works expand Bourdieu's theory of cultural capital in a beneficial manner, without deviating from Bourdieu's framework of the different forms of capital. In fact, these authors can be seen to explore unarticulated areas of Bourdieu's theory as opposed to constructing a new theory. For instance, Stanton-Salazar & Dornbusch (1995:121) examine how those people with the desired types of cultural (and linguistic) capital in a school transform this capital into \"instrumental relations\" or social capital with institutional agents who can transmit valuable resources to the person, furthering their success in the school. They state that this is simply an elaboration of Bourdieu's theory. Similarly, Dumais (2002) introduces the variable of gender to determine the ability of cultural capital to increase educational achievement. The author shows how gender and social class interact to produce different benefits from cultural capital. In fact in Distinction (1984:107), Bourdieu states \"sexual properties are as inseparable from class properties as the yellowness of lemons is inseparable from its acidity\". He simply did not articulate the differences attributable to gender in his general theory of reproduction in the education system.\n\nOn the other hand, two authors have introduced new variables into Bourdieu's concept of cultural capital. Emmison & Frow's (1998) work centers on an exploration of the ability of Information Technology to be considered a form of cultural capital. The authors state that \"a familiarity with, and a positive disposition towards the use of bourgeoisie technologies of the information age can be seen as an additional form of cultural capital bestowing advantage on those families that possess them\". Specifically computers are \"machines\" (Bourdieu, 1986:47) that form a type of objectified cultural capital, and the ability to use them is an embodied type of cultural capital. This work is useful because it shows the ways in which Bourdieu's concept of cultural capital can be expanded and updated to include cultural goods and practices which are progressively more important in determining achievement both in the school and without.\n\nHage uses Bourdieu's theory of cultural capital to explore multiculturalism and racism in Australia. His discussion around race is distinct from Bourdieu's treatment of migrants and their amount of linguistic capital and habitus. Hage actually conceives of \"whiteness\" (in Dolby, 2000:49) as being a form of cultural capital. 'White' is not a stable, biologically determined trait, but a \"shifting set of social practices\" (Dolby, 2000:49). He conceptualizes the nation as a circular field, with the hierarchy moving from the powerful center (composed of 'white' Australians) to the less powerful periphery (composed of the 'others'). The 'others' however are not simply dominated, but are forced to compete with each other for a place closer to the centre. This use of Bourdieu's notion of capital and fields is extremely illuminating to understand how people of non-Anglo ethnicities may try and exchange the cultural capital of their ethnic background with that of 'whiteness' to gain a higher position in the hierarchy. It is especially useful to see it in these terms as it exposes the arbitrary nature of what is \"Australian\", and how it is determined by those in the dominant position (mainly 'white' Australians). In a path-breaking study, Bauder (2006) uses the notions of habitus and cultural capital to explain the situation of migrants in the labor market and society.\n\nIn the article \"Against School\" (2003), the retired teacher John Taylor Gatto addresses education in modern schooling. The relation of cultural capital can be linked to \"Principles of Secondary Education\" (1918), by Alexander Inglis, which indicates how American schooling is what like Prussian schooling in the 1820s. The objective was to divide children into sections, by distributing them by subject, by age, and by test score. Inglis introduces six basic functions for modern schooling; functions three, four, and five are related to cultural capital, and describe the manner in which schooling enforces the cultural capital of each child, from a young age. Functions three, four, and five are: 3. Diagnosis and direction:\nSchool is meant to determine the proper social role of each student, by logging mathematic and anecdotal evidence into cumulative records. 4. Differentiation: Once the social role of a student is determined, the children are sorted by role and trained only as merited for his or her social destination. 5. Selection: This refers to Darwin's theory of natural selection applied to \"the favored races\".\n\nThe idea is to help American society, by consciously attempting to improve the breeding stock. Schools are meant to tag the socially unfit with poor grades, remedial-schooling placement, and other notable social punishments that their peers will then view and accept them as intellectually inferior, and effectively bar them from the reproductive (sexual, economic, and cultural) sweepstakes of life. That was the purpose of petty humiliation in school: \"It was the dirt down the drain.\" The three functions are directly related to cultural capital, because through schooling children are discriminated by social class and cognitively placed into the destination that will make them fit to sustain that social role. That is the path leading to their determined social class; and, during the fifth function, they will be socially undesirable to the privileged children, and so kept in a low social stratum.\n\nPaul DiMaggio expands on Bourdieu's view on cultural capital and its influence on education saying: \"Following Bourdieu, I measure high school students' cultural capital using self-reports of involvement in art, music, and literature.\" In his journal article titled Cultural Capital and School Success: The Impact of Status Culture Participation on the Grades of U.S. High School Students in the \"American Sociological Review\".\n\nIn the US, Richard A. Peterson and A Simkus (1992) extended the cultural capital theory, exclusively on (secondary) analysis of survey data on Americans, in 'How musical tastes mark occupational status groups', with the term \"cultural omnivores\" as a particular higher status section in the US that has broader cultural engagements and tastes spanning an eclectic range from highbrow arts to popular culture. Originally, it was Peterson (1992) who coined the term 'cultural omnivore' to address an anomaly observed in the evidence revealed by his work with Simkus (Peterson and Simkus, 1992) which showed that people of higher social status, contrary to elite-mass models of cultural taste developed by French scholars with French data, were not averse to participation in activities associated with popular culture. The work rejected the universal adaptation of the cultural capital theory, especially in the 20th century in advanced post-industrialist societies like the United States.\n\nIn the UK, Louise Archer and colleagues (2015) developed the concept of science capital. The concept of science capital draws from the work of Bourdieu, in particular his studies focusing on the reproduction of social inequalities in society. Science capital is made up of science related cultural capital and social capital as well as habitus. It encapsulates the various influences that a young person's life experiences can have on their science identity and participation in science-related activities. The empirical work on science capital builds from a growing body of data into students' aspirations and attitudes to science, including ASPIRES and Enterprising Science. The concept of science capital was developed as a way to understand why these science-related resources, attitudes and aspirations led some children to pursue science, while others did not. The concept provides policy makers and practitioners with a useful framework to help understand what shapes young people's engagement with (and potential resistance to) science.\n\nBourdieu's theory has been expanded to reflect modern forms of cultural capital, such as internet memes. Studies conducted by Asaf Nissenbaum and Limor Shifman on the topic of internet memes; utilised the website 4chan to analyse how these memes can be seen as forms of cultural capital. Discourse demonstrates the different forums and mediums that memes can be expressed through, such as different 'boards' on 4chan. \n\nCriticisms of Bourdieu's concept have been made on many grounds, including a lack of conceptual clarity. Perhaps due to this lack of clarity, researchers have operationalised the concept in diverse ways, and have varied in their conclusions. While some researchers may be criticised for using measures of cultural capital which focus only on certain aspects of 'highbrow' culture, this is a criticism which could also be leveled at Bourdieu's own work. Several studies have attempted to refine the measurement of cultural capital, in order to examine which aspects of middle-class culture actually have value in the education system.\n\nIt has been observed that Bourdieu's theory, and in particular his notion of habitus, is entirely deterministic, leaving no place for individual agency or even individual consciousness. Although Bourdieu claimed to have transcended the dichotomy of structure and agency, this is not necessarily convincing. For example, the Oxford academic John Goldthorpe has long argued that:\n\nBourdieu has also been criticised for his lack of consideration of gender. Kanter (in Robinson & Garnier, 1986) point out the lack of interest in gender inequalities in the labour market in Bourdieu's work. \nHowever, Bourdieu addressed the topic of gender head-on in his 2001 book \"Masculine Domination\". Bourdieu stated on the first page of the prelude in this book that he considered masculine domination to be a prime example of symbolic violence.\n\n\n"}
{"id": "424789", "url": "https://en.wikipedia.org/wiki?curid=424789", "title": "Cultural history", "text": "Cultural history\n\nCultural history combines the approaches of anthropology and history to look at popular cultural traditions and cultural interpretations of historical experience. It examines the records and narrative descriptions of past matter, encompassing the continuum of events (occurring in succession and leading from the past to the present and even into the future) pertaining to a culture.\n\nCultural history records and interprets past events involving human beings through the social, cultural, and political milieu of or relating to the arts and manners that a group favors. Jacob Burckhardt (1818–1897) helped found cultural history as a discipline. Cultural history studies and interprets the record of human societies by denoting the various distinctive ways of living built up by a group of people under consideration. Cultural history involves the aggregate of past cultural activity, such as ceremony, class in practices, and the interaction with locales.\n\nCultural history overlaps in its approaches with the French movements of \"histoire des mentalités\" (Philippe Poirrier, 2004) and the so-called new history, and in the U.S. it is closely associated with the field of American studies. As originally conceived and practiced by 19th Century Swiss historian Jakob Burckhardt with regard to the Italian Renaissance, cultural history was oriented to the study of a particular historical period in its entirety, with regard not only for its painting, sculpture and architecture, but for the economic basis underpinning society, and the social institutions of its daily life as well. Echoes of Burkhardt's approach in the 20th century can be seen in Johan Huizinga's \"The Waning of the Middle Ages\" (1919).\n\nMost often the focus is on phenomena shared by non-elite groups in a society, such as: carnival, festival, and public rituals; performance traditions of tale, epic, and other verbal forms; cultural evolutions in human relations (ideas, sciences, arts, techniques); and cultural expressions of social movements such as nationalism. Also examines main historical concepts as power, ideology, class, culture, cultural identity, attitude, race, perception and new historical methods as narration of body. Many studies consider adaptations of traditional culture to mass media (television, radio, newspapers, magazines, posters, etc.), from print to film and, now, to the Internet (culture of capitalism). Its modern approaches come from art history, Annales, Marxist school, microhistory and new cultural history.\n\nCommon theoretical touchstones for recent cultural history have included: Jürgen Habermas's formulation of the public sphere in \"The Structural Transformation of the Bourgeois Public Sphere\"; Clifford Geertz's notion of 'thick description' (expounded in, for example, \"The Interpretation of Cultures\"); and the idea of memory as a cultural-historical category, as discussed in Paul Connerton's \"How Societies Remember\".\n\nThe area where new-style cultural history is often pointed to as being almost a paradigm is the 'revisionist' history of the French Revolution, dated somewhere since François Furet's massively influential 1978 essay \"Interpreting the French Revolution\". The 'revisionist interpretation' is often characterised as replacing the allegedly dominant, allegedly Marxist, 'social interpretation' which locate the causes of the Revolution in class dynamics. The revisionist approach has tended to put more emphasis on 'political culture'. Reading ideas of political culture through Habermas' conception of the public sphere, historians of the Revolution in the past few decades have looked at the role and position of cultural themes such as gender, ritual, and ideology in the context of pre-revolutionary French political culture.\n\nHistorians who might be grouped under this umbrella are Roger Chartier, Robert Darnton, Patrice Higonnet, Lynn Hunt, Keith Baker, Joan Landes, Mona Ozouf and Sarah Maza. Of course, these scholars all pursue fairly diverse interests, and perhaps too much emphasis has been placed on the paradigmatic nature of the new history of the French Revolution. Colin Jones, for example, is no stranger to cultural history, Habermas, or Marxism, and has persistently argued that the Marxist interpretation is not dead, but can be revivified; after all, Habermas' logic was heavily indebted to a Marxist understanding. Meanwhile, Rebecca Spang has also recently argued that for all its emphasis on difference and newness, the 'revisionist' approach retains the idea of the French Revolution as a watershed in the history of (so-called) modernity, and that the problematic notion of 'modernity' has itself attracted scant attention.\n\n\"Cultural studies\" is an academic discipline popular among a diverse group of scholars. It combines political economy, geography, sociology, social theory, literary theory, film/video studies, cultural anthropology, philosophy, and art history/criticism to study cultural phenomena in various societies. Cultural studies researchers often concentrate on how a particular phenomenon relates to matters of ideology, nationality, ethnicity, social class, and/or gender. The term was coined by Richard Hoggart in 1964 when he founded the Birmingham Centre for Contemporary Cultural Studies. It has since become strongly associated with Stuart Hall, who succeeded Hoggart as Director.\n\n\n\n"}
{"id": "9216811", "url": "https://en.wikipedia.org/wiki?curid=9216811", "title": "Cultural retention", "text": "Cultural retention\n\nCultural retention is the act of retaining the culture of a specific ethnic group of people, especially when there is reason to believe that the culture, through inaction, may be lost. Many African-American, European and Asian organizations have cultural retention programs in place.\n\n"}
{"id": "3689246", "url": "https://en.wikipedia.org/wiki?curid=3689246", "title": "Culture of Grenada", "text": "Culture of Grenada\n\nGrenada's French colonists brought along their culture, as did the African slaves they brought across the Atlantic for agricultural work. The combination of these cultures is what you will find on this island. Indians have also influenced the island culture in more recent years. \n\nWith the passing of the Slave Trade Act 1807 by the British Parliament and the subsequent Abolishing of Slavery, indentured labor from India was procured at a very large scale. \n\nThe first ship, named \"Nickor Jeremiah\", departed from Calcutta, India on January 27, 1857 and arrived a few months later on May 1. In all 3,206 East Indians arrived in Grenada by 1885. Only 380 of them returned to India. The Indians made many contributions to Grenada. Indian Arrival Day was celebrated in 2007 on the 150th anniversary, for the first time since the centenary celebration in 1957.\n\nThe Indians later on assimilated with the existing Africans, Europeans and other ethnicities intermarrying with each other. This very much influenced the culture and cuisine of Grenada.\n\nSpecial dishes reflect the cultural diversity of Grenada. The national dish, Oil Down is a combination of breadfruit, coconut milk, turmeric (misnamed saffron), dumplings, callaloo (taro leaves), and salted meat such as saltfish (cod), smoked herring or salt beef. It's often cooked in a large pot commonly referred to by locals as a karhee, or curry pot. Popular street foods include aloo pie, doubles, and dal puri served wrapped around a curry, commonly goat, and bakes and fish cakes. Sweets include kurma, guava cheese, fudge or barfi, tamarind balls, rum, raisin ice cream, currant rolls, and Grenadian spice cake. \n\nMusic plays a huge part in Grenadian culture, with the annual Carnival competition generating new soca and calypso material in August. The rest of the time soca, calypso, and reggae are the mainstay on the minibuses competing for the loudest, and unfortunately, sometimes fastest bus service. Zouk music has also been imported to Grenada from other French Caribbean islands recently. Other local celebrations include the National Dance Festival and Independence Day.\n\n"}
{"id": "2233449", "url": "https://en.wikipedia.org/wiki?curid=2233449", "title": "Culture of Togo", "text": "Culture of Togo\n\nTogo's culture reflects the influences of its 37 tribal ethnic groups, the largest and most influential of which are the Ewe, Mina, and Kabye. French is the official language of Togo, but many native African languages are spoken there as well. Despite the influence of Western religion, more than half of the people of Togo follow native animistic practices and beliefs.\n\nEwe statuary is characterized by its famous statuettes which illustrate the worship of the twins, the \"ibéji\". Sculptures and hunting trophies were used rather than the more ubiquitous African masks. The wood-carvers of Kloto are famous for their \"chains of marriage\": two characters are connected by rings drawn from only one piece of wood.\n\nThe dyed fabric batiks of the artisanal center of Kloto represent stylized and colored scenes of ancient everyday life. The loincloths used in the ceremonies of the tisserands of Assahoun are famous. Works of the painter Sokey Edorh are inspired by the immense arid extents, swept by the harmattan, and where the laterite keeps the prints of the men and the animals. The plastics technician Paul Ahyi is internationally recognized today. He practises the \"zota\", a kind of pyroengraving, and his monumental achievements decorate Lomé.\n\n\n"}
{"id": "8128", "url": "https://en.wikipedia.org/wiki?curid=8128", "title": "Dialect", "text": "Dialect\n\nThe term dialect (from Latin , , from the Ancient Greek word , , \"discourse\", from , , \"through\" and , , \"I speak\") is used in two distinct ways to refer to two different types of linguistic phenomena:\n\n\nFor example, most of the various regional Romance languages of Italy, often colloquially referred to as Italian \"dialects\", are, in fact, not \"actually\" derived from modern standard Italian, but rather evolved from Vulgar Latin separately and individually from one another and independently of standard Italian, long prior to the diffusion of a national standardized language throughout what is now Italy. These various Latin-derived regional languages are, therefore, in a linguistic sense, not truly \"dialects\" or varieties of the standard Italian language, but are instead better defined as their own separate languages. Conversely, with the spread of standard Italian throughout Italy in the 20th century, regional versions or varieties of standard Italian have developed, generally as a mix of national standard Italian with a substratum of local regional languages and local accents. While \"dialect\" levelling has increased the number of standard Italian speakers and decreased the number of speakers of other languages native to Italy, Italians in different regions have developed variations of standard Italian particular to their region. These variations on standard Italian, known as regional Italian, would thus more appropriately be called \"dialects\" in accordance with the first linguistic definition of \"dialect\", as they are in fact derived partially or mostly from standard Italian.\n\nA dialect is distinguished by its vocabulary, grammar, and pronunciation (phonology, including prosody). Where a distinction can be made only in terms of pronunciation (including prosody, or just prosody itself), the term \"accent\" may be preferred over \"dialect\". Other types of speech varieties include jargons, which are characterized by differences in lexicon (vocabulary); slang; patois; pidgins; and argots. The particular speech patterns used by an individual are termed an idiolect.\n\nA \"standard dialect\" (also known as a standardized dialect or \"standard language\") is a dialect that is supported by institutions. Such institutional support may include government recognition or designation; presentation as being the \"correct\" form of a language in schools; published grammars, dictionaries, and textbooks that set forth a correct spoken and written form; and an extensive formal literature that employs that dialect (prose, poetry, non-fiction, etc.). There may be multiple standard dialects associated with a single language. For example, Standard American English, Standard British English, Standard Canadian English, Standard Indian English, Standard Australian English, and Standard Philippine English may all be said to be standard dialects of the English language.\n\nA nonstandard dialect, like a standard dialect, has a complete vocabulary, grammar, and syntax, but is usually not the beneficiary of institutional support. Examples of a nonstandard English dialect are Southern American English, Western Australian English, New York English, New England English, Mid-Atlantic American or Philadelphia / Baltimore English, Scouse, Brummie, Cockney, and Tyke. The Dialect Test was designed by Joseph Wright to compare different English dialects with each other.\n\nThere is no universally accepted criterion for distinguishing two different languages from two dialects (i.e. varieties) of the same language. A number of rough measures exist, sometimes leading to contradictory results. The distinction is therefore subjective and depends upon the user's frame of reference. For example, there has been discussion about whether or not the Limón Creole English should be considered \"a kind\" of English or a different language. This creole is spoken in the Caribbean coast of Costa Rica (Central America) by descendants of Jamaican people. The position that Costa Rican linguists support depends upon which University they represent.\n\nThe most common, and most purely linguistic, criterion is that of mutual intelligibility: two varieties are said to be dialects of the same language if being a speaker of one variety confers sufficient knowledge to understand and be understood by a speaker of the other; otherwise, they are said to be different languages. However, this definition becomes problematic in the case of dialect continua, in which it may be the case that dialect B is mutually intelligible with both dialect A and dialect C but dialects A and C are not mutually intelligible with each other. In this case, the criterion of mutual intelligibility makes it impossible to decide whether A and C are dialects of the same language or not. The mutual intelligibility criterion also flounders in cases in which a speaker of dialect X can understand a speaker of dialect Y, but not vice versa.\n\nAnother occasionally used criterion for discriminating dialects from languages is the sociolinguistic notion of linguistic authority. According to this definition, two varieties are considered dialects of the same language if (under at least some circumstances) they would defer to the same authority regarding some questions about their language. For instance, to learn the name of a new invention, or an obscure foreign species of plant, speakers of Westphalian and East Franconian German might each consult a German dictionary or ask a German-speaking expert in the subject.\nThus these varieties are said to be dependent on, or heteronomous with respect to, Standard German, which is said to be autonomous.\nIn contrast, speakers in the Netherlands of Low Saxon varieties similar to Westphalian would instead consult a dictionary of Standard Dutch.\nSimilarly, although Yiddish is classified by linguists as a language in the Middle High German group of languages, a Yiddish speaker would consult a different dictionary in such a case.\n\nWithin this framework, W. A. Stewart defined a \"language\" as an autonomous variety together with all the varieties that are heteronomous with respect to it, noting that an essentially equivalent definition had been stated by Charles A. Ferguson and John J. Gumperz in 1960.\nSimilarly, a heteronomous variety may be considered a \"dialect\" of a language defined in this way.\nIn these terms, Danish and Norwegian, though mutually intelligible to a large degree, are considered separate languages.\nIn the framework of Heinz Kloss, these are described as languages by \"ausbau\" (development) rather than by \"abstand\" (separation).\n\nIn other situations, a closely related group of varieties possess considerable (though incomplete) mutual intelligibility, but none dominates the others.\nTo describe this situation, the editors of the \"Handbook of African Languages\" introduced the term \"dialect cluster\".\nDialect clusters were treated as classificatory units at the same level as languages.\nA similar situation, but with a greater degree of mutual unintelligibility, has been termed a \"language cluster\".\n\nIn many societies, however, a particular dialect, often the sociolect of the elite class, comes to be identified as the \"standard\" or \"proper\" version of a language by those seeking to make a social distinction and is contrasted with other varieties. As a result of this, in some contexts, the term \"dialect\" refers specifically to varieties with low social status. In this secondary sense of \"dialect\", language varieties are often called \"dialects\" rather than \"languages\":\n\nThe status of \"language\" is not solely determined by linguistic criteria, but it is also the result of a historical and political development. Romansh came to be a written language, and therefore it is recognized as a language, even though it is very close to the Lombardic alpine dialects. An opposite example is the case of Chinese, whose variations such as Mandarin and Cantonese are often called dialects and not languages in China, despite their mutual unintelligibility.\n\nModern nationalism, as developed especially since the French Revolution, has made the distinction between \"language\" and \"dialect\" an issue of great political importance. A group speaking a separate \"language\" is often seen as having a greater claim to being a separate \"people\", and thus to be more deserving of its own independent state, while a group speaking a \"dialect\" tends to be seen not as \"a people\" in its own right, but as a sub-group, part of a bigger people, which must content itself with regional autonomy. The distinction between language and dialect is thus inevitably made at least as much on a political basis as on a linguistic one, and can lead to great political controversy or even armed conflict.\n\nThe Yiddish linguist Max Weinreich published the expression, \"A shprakh iz a dialekt mit an armey un flot\" (: \"A language is a dialect with an army and navy\") in \"YIVO Bleter\" 25.1, 1945, p. 13. The significance of the political factors in any attempt at answering the question \"what is a language?\" is great enough to cast doubt on whether any strictly linguistic definition, without a socio-cultural approach, is possible. This is illustrated by the frequency with which the army-navy aphorism is cited.\n\nBy the definition most commonly used by linguists, any linguistic variety can be considered a \"dialect\" of \"some\" language—\"everybody speaks a dialect\". According to that interpretation, the criteria above merely serve to distinguish whether two varieties are dialects of the \"same\" language or dialects of \"different\" languages.\n\nThe terms \"language\" and \"dialect\" are not necessarily mutually exclusive, although it is often perceived to be. Thus there is nothing contradictory in the statement \"the \"language\" of the Pennsylvania Dutch is a dialect of German\".\n\nThere are various terms that linguists may use to avoid taking a position on whether the speech of a community is an independent language in its own right or a dialect of another language. Perhaps the most common is \"variety\"; \"lect\" is another. A more general term is \"languoid\", which does not distinguish between dialects, languages, and groups of languages, whether genealogically related or not.\n\nWhen talking about the German language, the term German dialects is only used for the traditional regional varieties. That allows them to be distinguished from the regional varieties of modern standard German.\n\nThe German dialects show a wide spectrum of variation. Some of them are not mutually intelligible. German dialectology traditionally names the major dialect groups after Germanic tribes from which they were assumed to have descended.\n\nThe extent to which the dialects are spoken varies according to a number of factors: In Northern Germany, dialects are less common than in the South. In cities, dialects are less common than in the countryside. In a public environment, dialects are less common than in a familiar environment.\n\nThe situation in Switzerland and Liechtenstein is different from the rest of the German-speaking countries. The Swiss German dialects are the default everyday language in virtually every situation, whereas standard German is only spoken in education, partially in media, and with foreigners not possessing knowledge of Swiss German. Most Swiss German speakers perceive standard German to be a foreign language.\n\nThe Low German varieties spoken in Germany are often counted among the German dialects. This reflects the modern situation where they are roofed by standard German. This is different from the situation in the Middle Ages when Low German had strong tendencies towards an ausbau language.\n\nThe Frisian languages spoken in Germany are excluded from the German dialects.\n\nItaly is home to a vast array of native regional minority languages, most of which are Romance-based and have their own local variants. These regional languages are often referred to colloquially or in non-linguistic circles as Italian \"dialects\", or \"dialetti\" (standard Italian for \"dialects\"). However, the majority of the regional languages in Italy are in fact not actually \"dialects\" of standard Italian in the strict linguistic sense, as they are not derived from modern standard Italian but instead evolved locally from Vulgar Latin independent of standard Italian, with little to no influence from what is now known as \"standard Italian.\" They are therefore better classified as individual languages rather than \"dialects.\"\n\nIn addition to having evolved, for the most part, separately from one another and with distinct individual histories, the Latin-based regional Romance languages of Italy are also better classified as separate languages rather than true \"dialects\" due to the often high degree in which they lack mutual intelligibility. Though mostly mutually unintelligible, the exact degree to which the regional Italian languages are mutually unintelligible varies, often correlating with geographical distance or geographical barriers between the languages, with some regional Italian languages that are closer in geographical proximity to each other or closer to each other on the dialect continuum being more or less mutually intelligible. For instance, a speaker of purely Eastern Lombard, a language in Northern Italy's Lombardy region that includes the Bergamasque dialect, would have severely limited mutual intelligibility with a purely standard Italian speaker and would be nearly completely unintelligible to a speaker of a pure Sicilian language variant. Due to Eastern Lombard's status as a Gallo-Italic language, an Eastern Lombard speaker may, in fact, have more mutual intelligibility with a Occitan, Catalan, or French speaker than with a standard Italian or Sicilian language speaker. Meanwhile, a Sicilian language speaker would have a greater degree of mutual intelligibility with a speaker of the more closely related Neapolitan language, but far less mutual intelligibility with a person speaking Sicilian Gallo-Italic, a language that developed in isolated Lombard emigrant communities on the same island as the Sicilian language.\n\nModern standard Italian itself is heavily based on the Latin-derived Florentine Tuscan language. The Tuscan-based language that would eventually become modern standard Italian had been used in poetry and literature since at least the 12th century, and it first spread throughout Italy among the educated upper class through the works of authors such as Dante Alighieri, Giovanni Boccaccio, Niccolò Machiavelli, and Petrarch. Dante's Florentine-Tuscan literary Italian thus slowly became the language of the literate and upper class in Italy, and it spread throughout the peninsula as the \"lingua franca\" among the Italian educated class as well as Italian traveling merchants. The economic prowess and cultural and artistic importance of Tuscany in the Late Middle Ages and the Renaissance further encouraged the diffusion of the Florentine-Tuscan Italian throughout Italy and among the educated and powerful, though local and regional languages remained the main languages of the common people.\n\nDuring the Risorgimento, proponents of Italian republicanism and Italian nationalism, such as Alessandro Manzoni, stressed the importance of establishing a uniform national language in order to better create an Italian national identity. With the unification of Italy in the 1860s, standard Italian became the official national language of the new Italian state, while the various unofficial regional languages of Italy gradually became regarded as subordinate \"dialects\" to Italian, increasingly associated negatively with lack of education or provincialism. However, at the time of the Italian Unification, standard Italian still existed mainly as a literary language, and only 2.5% of Italy's population could speak standard Italian.\n\nIn the early 20th century, the vast conscription of Italian men from all throughout Italy during World War I is credited with facilitating the diffusion of standard Italian among less educated Italian men, as these men from various regions with various regional languages were forced to communicate with each other in a common tongue while serving in the Italian military. With the eventual spread of the radio and television throughout Italy and the establishment of public education, Italians from all regions were increasingly exposed to standard Italian, while literacy rates among all social classes improved. Today, the majority of Italians are able to speak standard Italian, though many Italians still speak their regional language regularly or as their primary day-to-day language, especially at home with family or when communicating with Italians from the same town or region. However, to some Italians, speaking a regional language, especially in a formal setting or outside of one's region, may carry a stigma or negative connotations associated with being lower class, uneducated, boorish, or overly informal.\n\nItalians in different regions today may also speak regional varieties of standard Italian, or regional Italian dialects, which, unlike the majority of languages of Italy, are actually dialects of standard Italian rather than separate languages. A regional Italian dialect is generally standard Italian that has been heavily influenced or mixed with local or regional native languages and accents.\n\nThe languages of Italy are primarily Latin-based Romance languages, with the most widely spoken languages falling within the Italo-Dalmatian language family. This wide category includes:\n\nAside from the more common Italo-Dalmatian Romance languages in Italy, other native languages in Italy include: \n\nThe Sardinian language is considered to be its own Romance language family, separate not only from Italian and the wider Italo-Dalmatian family but from all the other Neo-Latin families; it is often subdivided into the Campidanese and Logudorese dialects. The Corsican-related Gallurese and Sassarese which are also spoken in Sardinia, on the other hand, are often considered closely related to or derived from Tuscan and are therefore fully part of the Italo-Dalmatian languages. Furthermore, the Gallo-Romance language of Ligurian and the Catalan Algherese dialect are also spoken in Sardinia, respectively in Carloforte/Calasetta and Alghero.\n\nThe classification of speech varieties as dialects or languages and their relationship to other varieties of speech can be controversial and the verdicts inconsistent. English and Serbo-Croatian illustrate the point. English and Serbo-Croatian each have two major variants (British and American English, and Serbian and Croatian, respectively), along with numerous other varieties. For political reasons, analyzing these varieties as \"languages\" or \"dialects\" yields inconsistent results: British and American English, spoken by close political and military allies, are almost universally regarded as varieties of a single language, whereas the national standards of Serbia and Croatia, which are closer to each other than some local vernacular dialects of Serbo-Croatian are to themselves, differing to a similar extent as the formal varieties of English, are treated by some linguists from the region as distinct languages, largely because the two countries oscillate from being brotherly to being bitter enemies. (The Serbo-Croatian language article deals with this topic much more fully.)\n\nSimilar examples abound. Macedonian, although largely mutually intelligible with Bulgarian, certain dialects of Serbo-Croatian and to a lesser extent the rest of the South Slavic dialect continuum, is considered by Bulgarian linguists to be a Bulgarian dialect, in contrast with the contemporary international view and the view in the Republic of Macedonia, which regards it as a language in its own right. Nevertheless, before the establishment of a literary standard of Macedonian in 1944, in most sources in and out of Bulgaria before the Second World War, the southern Slavonic dialect continuum covering the area of today's Republic of Macedonia were referred to as Bulgarian dialects.\n\nIn Lebanon, a part of the Christian population considers \"Lebanese\" to be in some sense a distinct language from Arabic and not merely a dialect. During the civil war Christians often used Lebanese Arabic officially, and sporadically used the Latin script to write Lebanese, thus further distinguishing it from Arabic. All Lebanese laws are written in the standard literary form of Arabic, though parliamentary debate may be conducted in Lebanese Arabic.\n\nIn Tunisia, Algeria, and Morocco, the Darijas (spoken North African languages) are sometimes considered more different from other Arabic dialects. Officially, North African countries prefer to give preference to the Literary Arabic and conduct much of their political and religious life in it (adherence to Islam), and refrain from declaring each country's specific variety to be a separate language, because Literary Arabic is the liturgical language of Islam and the language of the Islamic sacred book, the Qur'an. Although, especially since the 1960s, the Darijas are occupying an increasing use and influence in the cultural life of these countries. Examples of cultural elements where Darijas' use became dominant include: theatre, film, music, television, advertisement, social media, folk-tale books and companies' names.\n\nThe Modern Ukrainian language has been in common use since the late 17th century, associated with the establishment of the Cossack Hetmanate. In the 19th century, the Tsarist Government of the Russian Empire claimed that Ukrainian was merely a dialect of Russian and not a language on its own. According to these claims, the differences were few and caused by the conquest of western Ukraine by the Polish-Lithuanian Commonwealth. However, in reality the dialects in Ukraine were developing independently from the dialects in the modern Russia for several centuries, and as a result they differed substantially.\n\nFollowing the signing of the Brest-Litovsk Treaty, the German Empire briefly gained control over Ukraine during World War I, but was eventually defeated by the Entente, with major involvement by the Ukrainian Bolsheviks. After Bolsheviks managed to conquer the rest of Ukraine from the Ukrainian People's Republic and the Whites, Ukraine became part of the USSR, whence a process of Ukrainization was begun, with encouragement from Moscow. However, in the late 1920s - early 1930s, the process started to reverse. Witnessing the Ukrainian cultural revival spurred by the ukrainization in the early 1290s, and fearing that it might lead to an independence movement, Moscow started to remove from power and in some cases physically eliminate the public proponents of ukrainization. The appointment of Pavel Postyshev as the secretary of the Communist Party of Ukraine marked the end of ukrainization, and the opposite process of russification started. After World War II, citing Ukrainian collaboration with Nazi Germany in an attempt to gain independence as the reason, Moscow changed its policy towards repression of the Ukrainian language.\n\nToday the boundaries of the Ukrainian language to the Russian language are still not drawn clearly, with an intermediate dialect between them, called Surzhyk, developing in Ukraine.\n\nThere have been cases of a variety of speech being deliberately reclassified to serve political purposes. One example is Moldovan. In 1996, the Moldovan parliament, citing fears of \"Romanian expansionism\", rejected a proposal from President Mircea Snegur to change the name of the language to Romanian, and in 2003 a Moldovan–Romanian dictionary was published, purporting to show that the two countries speak different languages. Linguists of the Romanian Academy reacted by declaring that all the Moldovan words were also Romanian words; while in Moldova, the head of the Academy of Sciences of Moldova, Ion Bărbuţă, described the dictionary as a politically motivated \"absurdity\".\n\nUnlike languages that use alphabets to indicate their pronunciation, Chinese characters have developed from logograms that do not always give hints to their pronunciation. Although the written characters have remained relatively consistent for the last two thousand years, the pronunciation and grammar in different regions have developed to an extent that the varieties of the spoken language are often mutually unintelligible. As a series of migration to the south throughout the history, the regional languages of the south, including Gan, Xiang, Wu, Min, Yue and Hakka often show traces of Old Chinese or Middle Chinese. From the Ming dynasty onward, Beijing has been the capital of China and the dialect spoken in Beijing has had the most prestige among other varieties. With the founding of the Republic of China, Standard Mandarin was designated as the official language, based on the spoken language of Beijing. Since then, other spoken varieties are regarded as \"fangyan\" (regional speech). Cantonese is still the most commonly-used language in Guangzhou, Hong Kong, Macau and among some overseas Chinese communities, whereas Hokkien has been accepted in Taiwan as an important local language alongside Mandarin.\n\nOne language, Interlingua, was developed so that the languages of Western civilization would act as its dialects. Drawing from such concepts as the international scientific vocabulary and Standard Average European, linguists developed a theory that the modern Western languages were actually dialects of a hidden or latent language. Researchers at the International Auxiliary Language Association extracted words and affixes that they considered to be part of Interlingua's vocabulary. In theory, speakers of the Western languages would understand written or spoken Interlingua immediately, without prior study, since their own languages were its dialects. This has often turned out to be true, especially, but not solely, for speakers of the Romance languages and educated speakers of English. Interlingua has also been found to assist in the learning of other languages. In one study, Swedish high school students learning Interlingua were able to translate passages from Spanish, Portuguese, and Italian that students of those languages found too difficult to understand. It should be noted, however, that the vocabulary of Interlingua extends beyond the Western language families.\n\n\n"}
{"id": "11725949", "url": "https://en.wikipedia.org/wiki?curid=11725949", "title": "Feminization (sociology)", "text": "Feminization (sociology)\n\nIn sociology, feminization is the shift in gender roles and sex roles in a society, group, or organization towards a focus upon the feminine. It can also mean the incorporation of women into a group or a profession that was once dominated by men. \n\n\nDefining the term \"feminization\" can be complicated due to its meaning being unstable, as it can be portrayed as either a social process or as a critique of a process. Feminization has two basic meanings. The first concerns a person who was not initially feminine but becomes feminine later in their life through the perceptions of both the individual and those around them. According to gender theorist Judith Butler, a person's gender is not solely an act of will or self-description, as it is also shaped by the people who describe, categorize, and treat the person according to their own perceptions of their gender. The second meaning of the term feminization describes when a person who originally had feminine qualities begins to incorporate more feminine attributes into their personality in some way, shape, or form. The term has often been used to describe females, however over time it shifted to where the term can be used to describe the process of someone or something becoming more feminine by adopting feminine qualities.\n\nWomen are more likely than men to live below the poverty line, a phenomenon known as the feminization of poverty. The 2015 poverty rates for men and women in the U.S. were 10% and 15% respectively. Women are less likely to pursue advanced degrees and tend to have low paying jobs. It has been argued that even with the same level of education and occupational role, women earn much less than men, although other sources have disputed the idea of a wage gap in American society.\n\nFeminization of the labor force in present day associations is inescapable in that females make up half of the labor force and the revelation of them as a potential profitable asset. Post war there has been almost a movement of women flowing into the workforce in the North America and Europe economies with women making considerable advances in balancing the workforce when comparing women and men's job status and pay rates. \n\nFeminists of the modern day living wage movement began in Baltimore, Maryland in the early 1990's right in the very heart and depths of the struggling urban poor. Around this same time, Baltimore churches became involved in providing the poor with needed social services. Even though national prosperity and rising stock markets seemed to be showing growth, more and more full-time workers were relying on soup kitchens, low-income housing assistance, and thrift store purchases for clothing. Their jobs did not pay enough to keep families above the poverty line. Whole communities became known as the \"working poverty.\"\n"}
{"id": "11393", "url": "https://en.wikipedia.org/wiki?curid=11393", "title": "Four Noble Truths", "text": "Four Noble Truths\n\nThe Four Noble Truths refer to and express the basic orientation of Buddhism in a short expression: we crave and cling to impermanent states and things, which are \"dukkha\", \"incapable of satisfying\" and painful. This craving keeps us caught in \"samsara\", the endless cycle of repeated \"bhava\" (\"becoming\") and \"jāti\" (literally: \"birth\", interpreted as rebirth), and the continued \"dukkha\" that comes with it. There is, however, a way to end this cycle, namely by attaining \"nirvana\", cessation of craving, whereafter birth and the accompanying \"dukkha\" will no longer arise again. This can be accomplished by following the eightfold path, restraining oneself, cultivating discipline and wholesome states, and practicing mindfulness and \"dhyana\".\n\nIn short form, the four truths are \"dukkha\", \"samudaya\" (\"arising,\" \"coming together\"), \"nirodha\" (\"cessation,\" \"confinement\"), and \"marga\", the path leading to cessation. As the \"Four Noble Truths\" (Sanskrit: \"catvāri āryasatyāni\"; Pali: \"cattāri ariyasaccāni\"), they are \"the truths of the Noble Ones,\" the truths or realities which are understood by the \"worthy ones\" who have attained nirvana.\n\nIn the \"sutras\", Buddhist religious texts, the four truths have both a symbolic and a propositional function. They represent the awakening and liberation of the Buddha, but also the possibility of liberation for all sentient beings, describing how release from craving is to be reached. In the Pali canon scriptures, the four truths appear in a \"network of teachings,\" as part of \"the entire \"dhamma\" matrix,\" which have to be taken together. They provide a conceptual framework for introducing and explaining Buddhist thought, which has to be personally understood or \"experienced\". \n\nThe function of the four truths, and their importance, developed over time, when \"prajna\", or \"liberating insight,\" came to be regarded as liberating in itself, instead of or in addition to the practice of \"dhyana\", meditation. This \"liberating insight\" gained a prominent place in the sutras, and the four truths came to represent this liberating insight, as part of the enlightenment story of the Buddha.\n\nThe four truths became of central importance in the Theravada tradition of Buddhism, which holds to the idea that insight into the four truths is liberating in itself. They are less prominent in the Mahayana tradition, which sees the higher aims of insight into \"sunyata\", emptiness, and following the Bodhisattva path as central elements in their teachings and practice. The Mahayana tradition reinterpreted the four truths to explain how a liberated being can still be \"pervasively operative in this world.\" Beginning with the exploration of Buddhism by western colonialists in the 19th century and the development of Buddhist modernism, they came to be often presented in the west as the central teaching of Buddhism.\n\nThe four truths are best known from their presentation in the \"Dhammacakkappavattana Sutta\" text, which contains two sets of the four truths, while various other sets can be found in the Pali Canon, a collection of scriptures in the Theravadan Buddhist tradition. According to the Buddhist tradition, the \"Dhammacakkappavattana Sutta\", \"Setting the Wheel of Dhamma in Motion,\" contains the first teachings that the Buddha gave after attaining full awakening, and liberation from rebirth. According to L. S. Cousins, many scholars are of the view that \"this discourse was identified as the first sermon of the Buddha only at a later date,\" and according to professor of religion Carol S. Anderson the four truths may originally not have been part of this sutta, but were later added in some versions. Within this discourse, the four noble truths are given as follows (\"bhikkus\" is normally translated as \"Buddhist monks\"):\nAccording to this sutra, with the complete comprehension of these four truths release from \"samsara\", the cycle of rebirth, was attained:\nThe comprehension of these four truths by his audience leads to the opening of the \"Dhamma Eye\", that is, the attainment of right vision:\nAccording to K. R. Norman, the Pali canon contains various shortened forms of the four truths, the \"mnemonic set,\" which were \"intended to remind the hearer of the full form of the NTs.\" The earliest form of the mnemonic set was \"dukkham samudayo nirodho magga,\" without the reference to the Pali terms \"sacca\" or \"arya\", which were later added to the formula. The four mnemonic terms can be translated as follows:\n\nThis full set, which is most commonly used in modern expositions, contains grammatical errors, pointing to multiple sources for this set and translation problems within the ancient Buddhist community. Nevertheless, they were considered correct by the Pali tradition, which didn't correct them. According to K.R. Norman, the basic set is as follows:\n\nAccording to L.S. Cousins, the four truths are not restricted to the well-known form where \"dukkha\" is the subject. Other forms take \"the world, the arising of the world\" or \"the āsavas, the arising of the āsavas\" as their subject. According to Cousins, \"the well-known form is simply shorthand for all of the forms.\" \"The world\" refers to the saṅkhāras, that is, all compounded things, or to the six sense spheres.\n\nThe various terms all point to the same basic idea of Buddhism, as described in five skandhas and twelve nidānas: sense-contact with objects leads to sensation, perception, Saṅkhāra ('inclinations', c.q. craving etc.), and consciousness. The \"Twelve Nidānas\" describe how this also leads to rebirth: from sensation comes craving, from craving comes karma, from karma comes rebirth. The aim of the Buddhist path is to reverse this causal chain: when there is no (response to) sensation, there is no craving, no karma, no rebirth.\n\nThe Pali terms \"ariya sacca\" (Sanskrit: \"arya satya\") are commonly translated as \"noble truths\". This translation is a convention started by the earliest translators of Buddhist texts into English. According to K.R. Norman, this is just one of several possible translations. According to Paul Williams,\nThe term \"arya\" was later added to the four truths. The term \"ariya\" (Sanskrit: \"arya\") can be translated as \"noble\", \"not ordinary\", \"valuable\", \"precious\". \"pure\", Paul Williams:\nThe term \"sacca\" (Sanskrit: \"satya\") is a central term in Indian thought and religion. It is typically translated as \"truth\"; but it also means \"that which is in accord with reality\", or \"reality\". According to Rupert Gethin, the four truths are \"four 'true things' or 'realities' whose nature, we are told, the Buddha finally understood on the night of his awakening.\" They function as \"a convenient conceptual framework for making sense of Buddhist thought.\" According to K.R. Norman, probably the best translation is \"the truth[s] of the noble one (the Buddha).\" It is a statement of how things are seen by a Buddha, how things really are when seen correctly. It is the truthful way of seeing, Through not seeing things this way, and behaving accordingly, we suffer.\n\nAccording to Anderson, the four truths have both a symbolic and a propositional function:\nAs a symbol, they refer to the possibility of awakening, as represented by the Buddha, and are of utmost importance:\nAs a proposition, they are part of the matrix or \"network of teachings,\" in which they are \"not particularly central,\" but have an equal place next to other teachings, describing how release from craving is to be reached. A long recognized feature of the Theravada canon is that it lacks an \"overarching and comprehensive structure of the path to \"nibbana\".\" The sutras form a network or matrix, and the four truths appear within this \"network of teachings,\" which have to be taken together. Within this network, \"the four noble truths are one doctrine among others and are not particularly central,\" but are a part of \"the entire \"dhamma\" matrix.\" The four noble truths are be set and learnt in that network, learning \"how the various teachings intersect with each other,\" and refer to the various Buddhist techniques, which are all explicitly and implicitly part of the passages which refer to the four truths. According to Anderson,\nAs a proposition, the four truths defy an exact definition, but refer to and express the basic orientation of Buddhism: clinging and craving to temporary states and things is ultimately unsatisfactory and painful, \"dukkha\", and sustains \"samsara\", the repeated cycle of \"bhava\" (becoming, habitual tendencies) and \"jāti\" (\"birth,\" interpreted as either rebirth, the coming to be of a new existence; or as the arising of the sense of self as a mental phenomenon).\nBy following the Buddhist path, craving and clinging can be confined, peace of mind and real happiness\ncan be attained, and the repeated cycle of repeated becoming and birth will be stopped.\nThe truth of \"dukkha\", \"incapable of satisfying,\" \"painful,\" is the basic insight that life in this \"mundane world,\"\" with its clinging and craving to impermanent states and things\" is \"dukkha\", unsatisfactory and painful. We expect happiness from states and things which are impermanent, and therefore cannot attain real happiness.\n\nThe truth of \"samudaya\", \"arising,\" \"coming together,\" or \"dukkha-samudaya\", the origination or arising of \"dukkha\", is the truth that repeated life in this world, and its associated \"dukkha\" arises, or continues, with taṇhā, \"thirst,\" craving for and clinging to these impermanent states and things.\n\nThe truth of \"nirodha\", cessation, or \"dukkha-nirodha\", the cessation of \"dukkha\", is the truth that \"dukkha\" ceases, or can be confined, when craving and clinging cease or are confined, and nirvana is attained. \"Nirvana\" refers to the moment of attainment itself, and the resulting peace of mind and happiness (\"khlesa-nirvana\"), but also to the final dissolution of the five skandhas at the time of death (\"skandha-nirvana\" or \"parinirvana\"); in the Theravada-tradition, it also refers to a transcendental reality which is \"known at the moment of awakening.\" According to Gethin, \"modern Buddhist usage tends to restrict 'nirvāṇa' to the awakening experience and reserve 'parinirvāṇa' for the death experience. When \"nirvana\" is attained, no more karma is being produced, and rebirth and dissatisfaction will no longer arise again. Cessation is \"nirvana\", \"blowing out,\" and peace of mind. Joseph Goldstein explains:\nThe truth of \"magga\", refers to the path to the cessation of, or liberation from \"dukkha\". By following the Noble Eightfold Path, to \"moksha\", liberation, restraining oneself, cultivating discipline, and practicing mindfulness and meditation, one starts to disengage from craving and clinging to impermanent states and things, and rebirth and dissatisfaction will be ended. The term \"path\" is usually taken to mean the Noble Eightfold Path, but other versions of \"the path\" can also be found in the Nikayas. The Theravada tradition regards insight into the four truths as liberating in itself.\n\nThe well-known eightfold path consists of the understanding that this world is fleeting and unsatisfying, and how craving keeps us tied to this fleeting world; a friendly and compassionate attitude to others; a correct way of behaving; mind-control, which means not feeding on negative thoughts, and nurturing positive thoughts; constant awareness of the feelings and responses which arise; and the practice of \"dhyana\", meditation. The tenfold path adds the right (liberating) insight, and liberation from rebirth.\n\nThe four truths are to be internalised, and understood or \"experienced\" personally, to turn them into a lived reality.\n\nThe four truths describe \"dukkha\" and its ending as a means to reach peace of mind in this life, but also as a means to end rebirth.\n\nAccording to Geoffrey Samuel, \"the Four Noble Truths [...] describe the knowledge needed to set out on the path to liberation from rebirth.\" By understanding the four truths, one can stop this clinging and craving, attain a pacified mind, and be freed from this cycle of rebirth and redeath. Patrick Olivelle explains that moksha is a central concept in Indian religions, and \"literally means freedom from samsara.\" Melvin E. Spiro further explains that \"desire is the cause of suffering because desire is the cause of rebirth.\" When desire ceases, rebirth and its accompanying suffering ceases. Peter Harvey explains:\nThe last sermon, the \"Maha-parinibbana Sutta\" (Last Days of the Buddha, Digha Nikaya 16)\", states it as follows:\nAccording to Bhikkhu Buddhadasa, \"birth\" does refer not to physical birth and death, but to the birth and death of our self-concept, the \"emergence of the ego\". According to Buddhadhasa,\nSome contemporary teachers tend to explain the four truths psychologically, by taking \"dukkha\" to mean mental anguish in addition to the physical pain of life, and interpreting the four truths as a means to attain happiness in this life. In the contemporary Vipassana movement that emerged out of the Theravada Buddhism, freedom and the \"pursuit of happiness\" have become the main goals, not the end of rebirth, which is hardly mentioned in their teachings.\n\nYet, though freedom and happiness is a part of the Buddhist teachings, these words refer to something different in traditional Asian Buddhism. According to Fronsdal, \"when Asian teachers do talk about freedom, it is primarily in reference to what one is free from—that is, from greed, hate, delusion, grasping, attachment, wrong view, self, and most significantly, rebirth\". \"Nibbana\" is the final freedom, and it has no purpose beyond itself. In contrast, freedom in the creative modern interpretation of Four Noble Truths and the Eightfold Path means living happily and wisely, \"without drastic changes in lifestyle\". Such freedom and happiness is not the goal of Four Noble Truths and related doctrines within traditional Buddhism, but the vipassana teachings in the West make no reference to traditional Theravada doctrines, instead they present only the pragmatic and experiential goals in the form of therapy for the audience's current lives. The creative interpretations are driven in part because the foundational premises of Buddhism do not make sense to audiences outside of Asia. According to Spiro, \"the Buddhist message is not simply a psychological message,\" but an eschatological message.\n\nAccording to Anderson, \"the four truths are recognized as perhaps the most important teaching of the Buddha.\" Yet, as early as 1935 Caroline Rhys Davids wrote that for a teaching so central to Theravada Buddhism, it was missing from critical passages in the Pali canon. According to Gethin, the four truths and the eightfold path are only two lists of \"literally hundreds of similar lists covering the whole range of the theory and practice of ancient Buddhism.\" The position of the four truths within the canon raises questions, and has been investigated throughout the 19th and 20th century.\n\nAccording to academic scholars, inconsistencies in the oldest texts may reveal developments in the oldest teachings. While the Theravada-tradition holds that the Sutta Pitaka is \"the definitive recension of the Buddha-word,\" and Theravadins argue that it is likely that the sutras date back to the Buddha himself, in an unbroken chain of oral transmission, academic scholars have identified many of such inconsistencies, and tried to explain them. Information of the oldest teachings of Buddhism, such as on the Four Noble Truths, has been obtained by analysis of the oldest texts and these inconsistencies, and are a matter of ongoing discussion and research.\n\nAccording to Bronkhorst, the four truths may already have been formulated in earliest Buddhism, but did not have the central place they acquired in later buddhism. According to Anderson, only by the time of the commentaries, in the fifth century CE, did the four truths come to be identified in the Theravada tradition as the central teaching of the Buddha. According to Anderson,\nAccording to Feer and Anderson, the four truths probably entered the Sutta Pitaka from the Vinaya, the rules for monastic order. They were first added to enlightenment-stories which contain the Four Jhanas, replacing terms for \"liberating insight\". From there they were added to the biographical stories of the Buddha.\n\nScholars have noted inconsistencies in the presentations of the Buddha's enlightenment, and the Buddhist path to liberation, in the oldest sutras. They offer that these inconsistencies show that the Buddhist teachings evolved, either during the lifetime of the Buddha, or thereafter. According to the Japanese scholar Ui, the four truths are not the earliest representation of the Buddha's enlightenment. Instead, they are a rather late theory on the content of the Buddha's enlightenment. According to Vetter and Bronkhorst, the earliest Buddhist path consisted of a set of practices which culminate in the practice of \"dhyana\", leading to a calm of mind and awareness (mindfulness) which according to Vetter \"is\" the liberation which is being sought. Later on, \"liberating insight\" came to be regarded as equally liberating. This \"liberating insight\" came to be exemplified by \"prajna\", or the insight in the \"four truths,\" but also by other elements of the Buddhist teachings. According to Vetter and Bronkhorst, this growing importance of \"liberating insight\" was a response to other religious groups in India, which held that a liberating insight was indispensable for \"moksha\", liberation from rebirth. This change is reflected in the canon, where, according to Bronkhorst,\nAccording to Vetter and Bonkhorst, the ideas on what exactly constituted this \"liberating insight\" was not fixed but developed over time. According to Bronkhorst, in earliest Buddhism the four truths did not serve as a description of \"liberating insight\". Initially the term \"prajna\" served to denote this \"liberating insight.\" Later on, \"prajna\" was replaced in the suttas by the \"four truths.\" This happened in those texts where practicing the four jhanas preceded the attainment of \"liberating insight,\" and where this practice of the four jhanas then culminates in \"liberating insight.\" This \"liberating insight\" came to be defined as \"insight into the four truths,\" which is presented as the \"liberating insight\" which constituted the awakening, or \"enlightenment\" of the Buddha. When he understood these truths he was \"enlightened\" and liberated, as reflected in Majjhima Nikaya 26:42: \"his taints are destroyed by his seeing with wisdom.\"\n\nBronkhorst points to an inconsistency, noting that the four truths refer here to the eightfold path as the means to gain liberation, while the attainment of insight into the four truths is portrayed as liberating in itself. According to Bronkhorst, this is an inconsistency which reveals a change which took place over time in the composition of the sutras. An example of this substitution, and its consequences, is Majjhima Nikaya 36:42-43, which gives an account of the awakening of the Buddha.\n\nAccording to Schmithausen, the four truths were superseded by \"pratityasamutpada\", and still later, in the Hinayana schools, by the doctrine of the non-existence of a substantial self or person.. Schmithausen further states that still other descriptions of this \"liberating insight\" exist in the Buddhist canon:\nIn contrast, Thanissaro Bikkhu presents the view that the four truths, pratityasamutpada and anatta are inextricably intertwined .\n\nIn their symbolic function, the sutras present the insight into the four truths as the culmination of the Buddh's path to awakening. In the \"Vinayapitaka\" and the \"Sutta-pitaka\" they have the same symbolic function, in a reenactment by his listeners of the Buddha's awakening by attaining the \"dhamma-eye\". In contrast, here this insight serves as the starting point to path-entry for his audience. These sutras present a repeated sequence of events:\n\nYet, in other sutras, where the four truths have a propositional function, the comprehension of the four truths destroys the corruptions. They do so in combination with the practice of the \"jhanas\" and the attainment of the divine eye, with which past lives and the working of rebirth are being seen.\n\nAccording to Anderson, following Schmithausen and Bronkhorst, these two presentations give two different models of the path to liberation, reflecting their function as a symbol and as a proposition. Most likely, the four truths were first associated with the culmination of the path in the destruction of the \"āsavās\", where they substituted the unspecified \"liberating insight\"; as the canon developed, they became more logically associated with the beginning of the Buddhist path.\n\nAccording to Anderson there is a strong tendency within scholarship to present the four truths as the most essential teaching of Buddhism. According to Anderson, the four truths have been simplified and popularized in western writings, due to \"the colonial project of gaining control over Buddhism.\" According to Crosby, the Buddhist teachings are reduced to a \"simple, single rationalized account,\" which has parallels in the reinterpretation of the Buddha in western literature.\n\nThe presentation of the four truths as one of the most important teachings of the Buddha \"has been [done] to reduce the four noble truths to a teaching that is accessible, pliable, and therefore readily appropriated by non-Buddhists.\" There is a great variety of teachings in the Buddhist literature, which may be bewildering for those who are unaware of this variety. The four truths are easily accessible in this regard, and are \"readily [understood] by those outside the Buddhist traditions.\" For example Walpola Rahula's \"What the Buddha Taught\", a widely used introductory text for non-Buddhists, uses the four truths as a framework to present an overview of the Buddhist teachings.\n\nAccording to Harris, the British in the 19th century crafted new representations of Buddhism and the Buddha. 19th century missionaries studied Buddhism, to be more effective in their missionary efforts. The Buddha was de-mystified, and reduced from a \"superhuman\" to a \"compassionate, heroic human,\" serving \"western historical method and the missionary agenda of situating the Buddha firmly below the divine.\" The four truths were discovered by the British by reading the Buddhist texts, and were not immediately granted the central position they later received.\n\nThe writings of British missionaries show a growing emphasis on the four truths as being central to Buddhism, with somewhat different presentations of them. This colonial project had a strong influence on some strands of Buddhism, culminating in socalled Protestant Buddhism, which incorporated several essentially Protestant attitudes regarding religion, such as the emphasis on written texts. According to Gimello, Rahula's book is an example of this Protestant Budhism, and \"was created in an accommodating response to western expectations, and in nearly diametrical opposition to Buddhism as it had actually been practised in traditional Theravada.\"\n\nHendrik Kern proposed in 1882 that the model of the four truths may be an analogy with classical Indian medicine, in which the four truths function as a medical diagnosis, and the Buddha is presented as a physician. Kern's analogy became rather popular, but \"there is not sufficient historical evidence to conclude that the Buddha deliberately drew upon a clearly defined medical model for his fourfold analysis of human pain.\"\n\nAccording to Anderson, those scholars who did not place the four truths at the center of Buddhism, either \"located the four truths in a fuller reading of the Theravada canon and the larger context of South Asian literature,\" or \"located the teaching within an experience of Buddhism as practiced in a contemporary setting.\" According to Anderson, \"these autors suggest a more complex reading of the four noble truths than those who locate the teaching as the key to or as a crucial element within the grand scheme of Buddhism.\"\n\nThe developing Buddhist tradition inserted the four truths, using various formulations, at various sutras. They are being used both as a symbol of all dhammas and the Buddha's awakening, and as a set of propositions which function within a matrix of teachings. According to Anderson, there is no single way to understand the teachings; one teaching may be used to explain another teaching, and vice versa. The teachings form a network, which should be apprehended as such to understand how the various teachings intersect with each other.\n\nThe \"Mahasaccaka Sutta\" (\"The Greater Discourse to Saccaka\", Majjhima Nikaya 36) gives one of several versions of the Buddha's way to liberation. He attains the three knowledges, namely knowledge of his former lifes, knowledge of death and rebirth, and knowledge of the destruction of the taints, the Four Noble Truths. After going through the four dhyanas, and gaining the first two knowledges, the story proceeds:\nBronkhorst dismisses the first two knowledges as later additions, and proceeds to notice that the recognition of the intoxicants is modelled on the four truths. According to Bronkhorst, those are added the bridge the original sequence of \"I directed my mind to the knowledge of the destruction of the intoxicants. My mind was liberated\", which was interrupted by the addition of the four truths. Bronkhorst points out that those do not fit here, since the four truths culminate in the knowledge of the path to be followed, while the Buddha himself is already liberated at that point.\n\nAccording to the Buddhist tradition, the first talk of Gautama Buddha after he attained enlightenment is recorded in the \"Dhammacakkappavattana Sutta\" (\"Setting in Motion the Wheel of Dhamma\", Samyutta Nikaya 56.11). The \"Dhammacakkappavattana Sutta\" provides details on three stages in the understanding of each truth, for a total of twelve insights. The three stages for understanding each truth are:\n\nThese three stages of understanding are emphasized particularly in the Theravada tradition, but they are also recognized by some contemporary Mahayana teachers.\n\nAccording to Cousins, many scholars are of the view that \"this discourse was identified as the first sermon of the Buddha only at a later date.\" According to Stephen Batchelor, the \"Dhammacakkappavattana Sutta\" contains incongruities, and states that\nAccording to Bronkhorst this \"first sermon\" is recorded in several sutras, with important variations. In the Vinaya texts, and in the \"Dhammacakkappavattana Sutta\" which was influenced by the Vinaya texts, the four truths are included, and Kondañña is enlightened when the \"vision of Dhamma\" arises in him: \"whatever is subject to origination is all subject to cessation.\" Yet, in the \"Ariyapariyesanā Sutta\" (\"The Noble Search\", Majjhima Nikaya 26) the four truths are not included, and the Buddha gives the five ascetics personal instructions in turn, two or three of them, while the others go out begging for food. The versions of the \"first sermon\" which include the four truths, such as the \"Dhammacakkappavattana Sutta\", omit this instruction, showing that\nAccording to Bronkhorst, this indicates that the four truths were later added to earlier descriptions of liberation by practicing the four dhyanas, which originally was thought to be sufficient for the destruction of the arsavas. Anderson, following Norman, also thinks that the four truths originally were not part of this sutta, and were later added in some versions.\n\nAccording to Bronkhorst, the \"twelve insights\" are probably also a later addition, born out of unease with the substitution of the general term \"prajna\" for the more specific \"four truths\".\n\nAccording to the Buddhist tradition, the \"Maha-parinibbana Sutta\" (Last Days of the Buddha, Digha Nikaya 16) was given near the end of the Buddha's life. This sutta \"gives a good general idea of the Buddha's Teaching:\"\n\nThe \"Maha-salayatanika Sutta\", Majjhima Nikaya 149:3 plus 149:9, give an alternative presentation of the four truths:\n\nThe Ekavyāvahārika sect emphasized the transcendence of the Buddha, asserting that he was eternally enlightened and essentially non-physical. According to the Ekavyāvahārika, the words of the Buddha were spoken with one transcendent meaning, and the Four Noble Truths are to be understood simultaneously in one moment of insight. According to the Mahīśāsaka sect, the Four Noble Truths should be meditated upon simultaneously.\n\nAccording to Carol Anderson, the four truths have \"a singular position within the Theravada canon and tradition.\" The Theravada tradition regards insight in the four truths as liberating in itself. As Walpola Rahula states, \"when the Truth is seen, all the forces which feverishly produce the continuity of samsara in illusion become calm and incapable of producing any more karma-formations [...] he is free from [...] the 'thirst' for becoming.\" This liberation can be attained in one single moment, when the four truths are understood together. Within the Theravada tradition, great emphasis is placed upon reading and contemplating \"The Discourse That Sets Turning the Wheel of Truth\", and other suttas, as a means to study the four noble truths and put them into practice. For example, Ajahn Sumedho states: \nWithin the Theravada-tradition, three different stances on \"nirvana\" and the question what happens with the \"Arhat\" after death can be found. \"Nirvana\" refers to the cessation of the defilements and the resulting peace of mind and happiness (\"khlesa-nirvana\"); to the final dissolution of the five skandhas at the time of death (\"skandha-nirvana\" or \"parinirvana\"); and to a transcendental reality which is \"known at the moment of awakening.\" According to Gethin, \"modern Buddhist usage tends to restrict 'nirvāṇa' to the awakening experience and reserve 'parinirvāṇa' for the death experience. According to Geisler and Amano, in the \"minimal Theravada interpretation\", \"nirvana\" is a psychological state, which ends with the dissolution of the body and the total extinction of existence. According to Geisler and Amano, the \"orthodox Theravada interpretation\" is that nirvana is a transcendent reality with which the self unites. According to Bronkhorst, while \"Buddhism preached liberation in this life, i.e. before death,\" there was also a tendency in Buddhism to think of liberation happening after death. According to Bronkhorst, this \nAccording to Walpola Rahula, the cessation of \"dukkha\" is \"nirvana\", the \"summum bonum\" of Buddhism, and is attained in this life, not when one dies. \"Nirvana\" is \"perfect freedom, peace, tranquility and happiness,\" and \"Absolute Truth,\" which simply \"is\". Jayatilleke also speaks of \"the attainment of an ultimate reality.\" According to Bhikkhu Bodhi, the \"elimination of craving culminates not only in the extinction of sorrow, anguish and distress, but in the unconditioned freedom of nibbana, which is won with the ending of reapeated rebirth.\"\n\nAccording to Spiro, most (lay) Theravada Buddhists do not aspire for \"nirvana\" and total extinction, but for a pleasurable rebirth in heaven. According to Spiro, this presents a \"serious conflict\" since the Buddhist texts and teaching \"describe life as suffering and hold up nirvana as the \"summum bonum.\"\" In response to this deviation, \"monks and others emphasize that the hope for nirvana is the only legitimate action for Buddhist action.\" Nevertheless, according to Spiro most Burmese lay Buddhists do not aspire for the extinction of existence which is \"nirvana\".\n\nAccording to B.R. Ambedkar, the Indian Buddhist Dalit leader, the four truths were not part of the original teachings of the Buddha, but a later aggregation, due to Hindu influences. According to Ambedkar, total cessation of suffering is an illusion; yet, the Buddhist Middle Path aims at the reduction of suffering and the maximizing of happiness, balancing both sorrow and happiness.\n\nThe four truths are less prominent in the Mahayana traditions, which emphasize insight into Śūnyatā and the Bodhisattva path as a central elements in their teachings. If the sutras in general are studied at all, it is through various Mahayana commentaries.\n\nAccording to Makransky the Mahayana Bodhisattva ideal created tensions in the explanation of the four truths. In the Mahayana view, a fully enlightened Buddha does not leave \"samsara\", but remains in the world out of compassion for all sentient beings. The four truths, which aim at ending \"samsara\", do not provide a doctrinal basis for this view, and had to be reinterpreted. In the old view, \"klesas\" and \"karma\" are the cause of prolonged existence. According to Makransky, \"[t]o remove those causes was, at physical death, to extinguish one's conditioned existence, hence to end forever one's participation in the world (Third Truth).\" According to Makransky, the question of how a liberated being can still be \"pervasively operative in this world\" has been \"a seminal source of ongoing doctrinal tension over Buddhahood throughout the history of the Mahayana in India and Tibet.\"\n\nAtisha, in his \"Bodhipathapradīpa\" (\"A Lamp for the Path to Awakening\"), which forms the basis for the Lamrim tradition, discerns three levels of motivation for Buddhist practitioners. At the beginning level of motivation, one strives toward a better life in \"samsara\". At the intermediate level, one strives to a liberation from existence in samsara and the end of all suffering. At the highest level of motivation, one strives after the liberation of all living beings. In his commentary on the text, Tsenshap Serkong Rinpoche explains that the four truths are to be meditated upon as a means of practice for the intermediate level.\n\nAccording to Geshe Tashi Tsering, within Tibetan Buddhism, the four noble truths are studied as part of the Bodhisattva path. They are explained in Mahayana commentaries such as the \"Abhisamayalamkara\", a summary of and commentary on the Prajna Paramitra sutras, where they form part of the lower Hinayana teachings. The truth of the path (the fourth truth) is traditionally presented according to a progressive formula of five paths, rather than as the eightfold path presented in Theravada. According to Tsering, the study of the four truths is combined with the study of the sixteen characteristics of the four noble truths.\n\nSome contemporary Tibetan Buddhist teachers have provided commentary on the \"Dhammacakkappavattana Sutta\" and the noble eightfold path when presenting the dharma to Western students.\n\nNichiren Buddhism is based on the teaching of the Japanese priest and teacher Nichiren, who believed that the Lotus Sūtra contained the essence of all of Gautama Buddha's teachings. The third chapter of the Lotus Sutra states that the Four Noble Truths was the early teaching of the Buddha, while the Dharma of the Lotus is the \"most wonderful, unsurpassed great Dharma.\" The teachings on the four noble truths are a provisional teaching, which Shakyamuni Buddha taught according to the people’s capacity, while the Lotus Sutra is a direct statement of Shakyamuni’s own enlightenment.\n\nFor many western Buddhists, the rebirth doctrine in the Four Noble Truths teaching is a problematic notion. According to Lamb, \"Certain forms of modern western Buddhism [...] see it as purely mythical and thus a dispensable notion.\" According to Coleman, the focus of most vipassana students in the west \"is mainly on meditation practice and a kind of down-to-earth psychological wisdom.\" According to Damien Keown, westerners find \"the ideas of karma and rebirth puzzling.\" According to Gowans, many Western followers and people interested in exploring Buddhism are skeptical and object to the belief in karma and rebirth foundational to the Four Noble Truths. According to Konik,\nAccording to Keown, it is possible to reinterpret the Buddhist doctrines such as the Four Noble Truths, since the final goal and the answer to the problem of suffering is nirvana, and not rebirth. Some Western interpreters have proposed what is sometimes referred to as \"naturalized Buddhism\". It is devoid of rebirth, karma, nirvana, realms of existence, and other concepts of Buddhism, with doctrines such as the Four Noble Truths reformulated and restated in modernistic terms. This \"deflated secular Buddhism\" stresses compassion, impermanence, causality, selfless persons, no Boddhisattvas, no nirvana, no rebirth, and a naturalists approach to well-being of oneself and others.\n\nAccording to Melford Spiro, this approach undermines the Four Noble Truths, for it does not address the existential question for the Buddhist as to \"why live? why not commit suicide, hasten the end of \"dukkha\" in current life by ending life\". In traditional Buddhism, rebirth continues the \"dukkha\" and the path to cessation of \"dukkha\" isn't suicide, but the fourth reality of the Four Noble Truths. The \"naturalized Buddhism\", according to Gowans, is a radical revision to traditional Buddhist thought and practice, and it attacks the structure behind the hopes, needs and rationalization of the realities of human life to traditional Buddhists in East, Southeast and South Asia. According to Keown, it may not be necessary to believe in some of the core Buddhist doctrines to be a Buddhist, but the rebirth, karma, realms of existence and cyclic universe doctrines underpin the Four Noble Truths in Buddhism.\n\nTraditional Buddhist scholars disagree with these modernist Western interpretations. Bhikkhu Bodhi, for example, states that rebirth is an integral part of the Buddhist teachings as found in the sutras, despite the problems that \"modernist interpreters of Buddhism\" seem to have with it. Thanissaro Bhikkhu, as another example, rejects the \"modern argument\" that \"one can still obtain all the results of the practice without having to accept the possibility of rebirth.\" He states, \"rebirth has always been a central teaching in the Buddhist tradition.\"\n\nAccording to Owen Flanagan, the Dalai Lama states that \"Buddhists believe in rebirth\" and that this belief has been common among his followers. However, the Dalai Lama's belief, adds Flanagan, is more sophisticated than ordinary Buddhists, because it is not the same as reincarnation--rebirth in Buddhism is envisioned as happening without the assumption of an \"atman, self, soul\", but rather through a \"consciousness conceived along the anatman lines\". The doctrine of rebirth is considered mandatory in Tibetan Buddhism, and across many Buddhist sects.\n\nAccording to Christopher Gowans, for \"most ordinary Buddhists, today as well as in the past, their basic moral orientation is governed by belief in karma and rebirth\". Buddhist morality hinges on the hope of well being in this lifetime or in future rebirths, with nirvana (enlightenment) a project for a future lifetime. A denial of karma and rebirth undermines their history, moral orientation and religious foundations. According to Keown, most Buddhists in Asia do accept these traditional teachings, and seek better rebirth.\n\nThe Navayana, a modernistic interpretation of Buddhism by the Indian leader B. R. Ambedkar, rejected much of traditional Buddhism, including the Four Noble Truths, karma and rebirth, thus turning his new religion into a Marxist-oriented vehicle for class struggle and social action. According to Ambedkar, Four Noble Truths was \"the invention of wrong-headed monks\".\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "8715248", "url": "https://en.wikipedia.org/wiki?curid=8715248", "title": "Four Treasures of the Study", "text": "Four Treasures of the Study\n\nFour Treasures of the Study, Four Jewels of the Study or Four Friends of the Study is an expression used to denote the brush, ink, paper and ink stone used in Chinese and other East Asian calligraphic traditions. The name appears to originate in the time of the Southern and Northern Dynasties (420–589 AD).\n\nChinese culture is very fond of four word couplets, and the Four Treasures is another example: \"文房四寶: 筆、墨、紙、硯,\" (Pinyin: \"wén fáng sì bǎo: bǐ, mò, zhǐ, yàn\") \"The four jewels of the study: Brush, Ink, Paper, Inkstone.\" In the couplet mentioned, each of the Treasures is referred to by a single epithet; however, each of these are usually known by a compound name (\"i.e.\" The Brush: 毛筆, literally \"\"hair brush/pen\"). The individual treasures have a \"treasured\" form, each being produced in certain areas of China as a speciality for those scholars who would use them.These are called the 4 SPECIAL Treasures of the Study.\n\n The brush () is the oldest Four Treasures member, with archaeological evidence dating to Zhou dynasty (1045 BC–256 BC) illustrations on ancient bones. The oldest brush so far dates to Han dynasty (202 BC–220 AD). Brushes are generally made from animal hair, or —in certain situations—the first hair taken from a baby's head (said to bring good luck in the Imperial examinations). Brush handles are commonly constructed from bamboo, but special brushes may have handles of sandalwood, jade, carved bone/ivory, or other precious materials.\n\nModern brushes are primarily white goat hair (羊毫), black rabbit hair (紫毫), yellow weasel hair (黄鼠毫/狼毫), or a combination mix. Ancient brushes, and some of the more valuable ones available on the market may be made with the hair of any number of different types of animals. Each type of hair has a specific ink capacity, giving distinct brush strokes. Different brushes are used for different styles of calligraphy and writing.\n\nBrushes are classed as soft (軟毫), mixed (兼毫) or hard (硬毫). Hair is laboriously sorted by softness, hardness, thickness, & length, then bundled for specific uses. The most famous and highly prized brushes are a mix of yellow weasel, goat and rabbit hair, known as Húbǐ (湖筆); highly prized since the Ming dynasty (late 14th century) they are currently made in Shanlian (善琏), a town in the Nanxun District, prefecture-level city of Huzhou, of Zhejiang province (浙江).\n\nThe Inkstick (Chinese: 墨 pinyin: \"\") is an artificial ink developed during the Han dynasty. These first writing inks were based on naturally occurring minerals like graphite and vermilion; earliest inks were probably liquids and not preserved. Modern inksticks are generally made of soots from one of three different sources, including lacquer soot, pine soot, and oil soot. Soots are collected, then mixed with glue. Higher quality inksticks also use powdered spices and herbs, adding to aroma and providing some protection to the ink itself. The glue, soot, and spice mixture is then pressed into shape and allowed to dry. This process can take 6 weeks, depending on an inkstick's dimensions.\n\nThe best ink sticks are fine grained and have a light, slightly ringing sound when tapped. They are often decorated with poems, calligraphy, or bas relief, and painted. These particular articles are highly collectable, and often acquired like stamps. The inksticks in highest regard, known as Huīmò (徽墨), contain musk, borneol and other precious aromatics of Chinese medicine. They are still produced today in Shexian (歙县) in Anhui province (安徽).\n\nPaper (Chinese: \"traditional\" 紙, \"simplified\" 纸; Pinyin: \"\") was first developed in China in the first decade of 100 AD. Previous to its invention, bamboo slips and silks were used for writing material. Several methods of paper production developed over the centuries in China. However, the paper which was considered of highest value was that of the Jingxian (泾县) in Anhui province.\n\nThis particular form of paper, known as Xuānzhǐ (宣紙), is soft, fine-textured, moth resistant, has a high tensile strength, and remarkable longevity for such a product – so much so that it has a reputation for lasting \"1,000 years\". The quality of the paper depends on the processing methods used to produce it. Paper may be unprocessed, half processed or processed. The processing determines how well ink or paint is absorbed into the fibre of the paper, as well as the stiffness of the paper itself. Unprocessed papers are very absorbent and quite malleable, whereas processed papers are far more resistant to absorption and are stiffer.\n\nThe inkstone (Chinese: \"traditional\" 硯 or 硯臺; \"simplified\" 砚 or 砚台; Pinyin: \"\" or \"yàn tái\") is used to grind the ink stick into powder. This powder is then mixed with water in a well in the inkstone in order to produce usable ink for calligraphy. The most ideal water for use in ink is slightly salty. Ink was first prepared using a mortar and pestle, but with the advent of inksticks this method slowly vanished. The stone used is generally of a relatively fine whetstone type.\n\nThe earliest known inkstones date back to the Han dynasty. The production of inkstones reached its zenith in the Tang and Song dynasties with inkstones becoming extremely intricate works of art. The most highly sought-after inkstones originated in four different locations in China. Duanshi stones (端石硯) from Duanxi in Guangdong, She stones (歙硯) from Shexian in Anhui, Taohe stones (洮河硯) from the Tao River in South Gansu and Chengni ceramic stones (澄泥硯) which are manufactured by a process which is said to have been developed in Luoyang in Henan.\n\nClassical scholars had more than just the Four treasures in their studies. The other \"Treasures\" include the brush-holder (笔架), brush-hanger (笔挂), paperweights (镇纸), the brush-rinsing pot (笔洗), and the seal (圖章) and seal-ink (印泥).\n\nFor painting, Chinese pigments are also used.\n\n"}
{"id": "1189936", "url": "https://en.wikipedia.org/wiki?curid=1189936", "title": "French maid", "text": "French maid\n\nFrench maid is a strongly modified style of servant's dress that evolved from typical housemaid's black-and-white afternoon uniforms of 19th-century France (and their later use by stereotypical soubrette characters in burlesque dramas and bedroom farces). Some styles are conservative while others are revealing. The French maid costume is often used in cosplay, sexual roleplaying, and uniform fetishism. Depending on design details, some forms can be classified as lingerie.\n\nThough not strict to historically accurate uniforms, the French maid outfit has an easily recognizable pattern and black-and white theme that remains the template for other forms of the costume.\n\nThe typical French maid costume includes:\n\nOptional accessories depend on design and context:\n\nThe outfits are frequently worn to costume parties (fancy dress), and also used in drama/theater.\n\n"}
{"id": "154273", "url": "https://en.wikipedia.org/wiki?curid=154273", "title": "G.I. Generation", "text": "G.I. Generation\n\nThe G.I. Generation (also known as the WWII Generation or The Greatest Generation in the United States or the Federation Generation in Australia) is the demographic cohort following the Lost Generation. There are no precise dates for when this cohort starts or ends; demographers and researchers typically use the early 1900s as starting birth years and ending birth years in the mid-1920s.\n\nThis generation experienced much of their youth during rapid technological innovation (radio, telephone) amidst growing levels of worldwide income inequality and a soaring economy. After the Stock Market crashed, this generation experienced profound economic and social turmoil, which eventually culminated in World War II.\n\nDemographers William Stauss and Neil Howe coined the term \"G.I. Generation\" in their 1991 book \"Generations: The History of America's Future\" and use 1901–1924 as birth years. The initials \"G.I.\" of \"G.I. Generation\" is military terminology referring to \"Government Issue\" or \"General Issue\". This cohort is also referred to as the \"World War II Generation\".\n\nMcCrindle Research expanded on Howe's work and uses the term \"Federation Generation\" to describe Australian members of this cohort, born between 1901–1924, \"a time of peace when Australia finally secured nationhood\" who came of age during The Great Depression and WWII and experienced post-war prosperity in midlife.\n\nPew Research Center defines this cohort as being born from 1901 to 1927.\n\nThe term \"The Greatest Generation\", which is a term sometimes used to refer to the US members of this cohort, comes from the title of 1998 book by American journalist Tom Brokaw. In the book, Brokaw profiled American members of this generation who came of age during the Great Depression and went on to fight in World War II, as well as those who contributed to the war effort on the home front. Brokaw wrote that these men and women fought not for fame or recognition, but because it was the \"right thing to do.\"\n\nSample members include Walt Disney, Charles Lindberg, John Steinbeck. Notable actors Bob Hope, Katharine Hepburn, Sidney Poitier and John Wayne. U.S. presidents were Lyndon B. Johnson, Ronald Reagan, Richard Nixon, Gerald Ford, John F. Kennedy, Jimmy Carter and George H. W. Bush. The American automobile executive best known for making the development of Ford Mustang and Pinto cars Lee Iacocca and theoretical physicist and professor of physics Robert Oppenheimer.\n\nProminent international peers include George Orwell, Leonid Brezhnev, Willy Brandt and Ferdinand Marcos.\n\n"}
{"id": "501118", "url": "https://en.wikipedia.org/wiki?curid=501118", "title": "Hermit kingdom", "text": "Hermit kingdom\n\nThe term hermit kingdom can be used to refer to any country, organization or society which willfully walls itself off, either metaphorically or physically, from the rest of the world - The country of North Korea is a prime example of a hermit kingdom.\n\nKorea in the age of Joseon dynasty was the subject of the first use of the term, in William Elliot Griffis' 1882 book \"Corea: The Hermit Nation\", and Korea was frequently described as a hermit kingdom until 1905 when it became a protectorate of Japan. The term is still commonplace throughout Korea and it is often used by Koreans themselves to describe pre-modern Korea. Today, the term is often applied to North Korea in news and social media, and in 2009 it was used by United States former Secretary of State Hillary Clinton. \n"}
{"id": "7873885", "url": "https://en.wikipedia.org/wiki?curid=7873885", "title": "History by period", "text": "History by period\n\nThis history by period summarizes significant eras in the history of the world, from the ancient world to the present day.\n\nAncient history refers to the time period in which scientists have found the earliest remains of human activity, approximately 60,000 BC. It ends with the fall of several significant empires, such as the Western Roman Empire in the Mediterranean, the Han Dynasty in China, and the Gupta Empire in India, collectively around 650 AD.\n\nThe Bronze Age is the time period in which humans around the world began to use bronze as a major metal in tools. It is generally accepted as starting around 3600 BC and ending with the advent of iron in 1000 BC.\n\nThe Iron Age is often called Antiquity or the Classical Era, but these periods more commonly refer to only one region. It begins around 1000 BC with the widespread use of iron in tools. It is often accepted to end at approximately 650 AD, with the fall of the aforementioned major civilizations.\n\nNote that BC and BCE refer to the same time period. BCE is an abbreviation for Before Common Era, and BC for Before Christ. AD is Anno Domini, and CE is Common Era. This is done in order to standardize time periods across the world (ISO 8601).\n\nThe Postclassical Era, also referred to as the Medieval period or, for Europe, the Middle Ages, begins around 500 CE after the fall of major civilizations, covering the advent of Islam. The period ends around 1450–1500, with events like the rise of moveable-type printing in Europe, the voyages of Christopher Columbus, and the Ottoman Empire's conquest of Constantinople.\n\n\nThe Modern Period covers human history from the creation of a more global network (i.e. the discovery of the Americas by Europeans) to present day.\n\nThe Early Modern Period is the first third of the Modern Period and is often used with the parent categorization. It starts with the invention of the printing press, covering the voyage of Christopher Columbus in 1492 and, more generally, the establishment of a more global network. It ends in 1750 with the beginning of British industrialization.\n\nThe Age of Revolution is a less commonly used period, but appropriately covers the time between the early modern and contemporary. It begins around 1750 with European industrialization and is marked by several political revolutions. It ends around 1945, with the relative advancement of industrialization in Europe, the United States, Japan, and Russia, and the beginning of World War II.\n\n\nThe Contemporary Period generally covers history still in living memory, approximately 100 years behind the current year. However, for all intents and purposes, the period will be used here as spanning from the second world war in 1945 to present day, as it is considered separate from the past eras and the newest stage of world history.\n\n\n\n"}
{"id": "37360538", "url": "https://en.wikipedia.org/wiki?curid=37360538", "title": "Human interactions with insects", "text": "Human interactions with insects\n\nHuman interactions with insects include both a wide variety of uses, whether practical such as for food, textiles, and dyestuffs, or symbolic, as in art, music, and literature, and negative interactions including serious damage to crops and extensive efforts to eliminate insect pests. \n\nAcademically, the interaction of insects and society has been treated in part as cultural entomology, dealing mostly with \"advanced\" societies, and in part as ethnoentomology, dealing mostly with \"primitive\" societies, though the distinction is weak and not based on theory. Both academic disciplines explore the parallels, connections and influence of insects on human populations, and vice versa. They are rooted in anthropology and natural history, as well as entomology, the study of insects. Other cultural uses of insects, such as biomimicry, do not necessarily lie within these academic disciplines.\n\nMore generally, people make a wide range of uses of insects, both practical and symbolic. On the other hand, attitudes to insects are often negative, and extensive efforts are made to kill them. The widespread use of insecticides has failed to exterminate any insect pest, but has caused resistance to commonly-used chemicals in a thousand insect species.\n\nPractical uses include as food, in medicine, for the valuable textile silk, for dyestuffs such as carmine, in science, where the fruit fly is an important model organism in genetics, and in warfare, where insects were successfully used in the Second World War to spread disease in enemy populations. One insect, the honey bee, provides honey, pollen, royal jelly, propolis and an anti-inflammatory peptide, melittin; its larvae too are eaten in some societies. Medical uses of insects include maggot therapy for wound debridement. Over a thousand protein families have been identified in the saliva of blood-feeding insects; these may provide useful drugs such as anticoagulants, vasodilators, antihistamines and anaesthetics.\n\nSymbolic uses include roles in art, in music (with many songs featuring insects), in film, in literature, in religion, and in mythology. Insect costumes are used in theatrical productions and worn for parties and carnivals.\n\nCulture consists of the social behaviour and norms found in human societies and transmitted through social learning. Cultural universals in all human societies include expressive forms like art, music, dance, ritual, religion, and technologies like tool usage, cooking, shelter, and clothing. The concept of material culture covers physical expressions such as technology, architecture and art, whereas immaterial culture includes principles of social organization, mythology, philosophy, literature, and science. This article describes the roles played by insects in human culture so defined.\n\nEthnoentomology developed from the 19th century with early works by authors such as Alfred Russel Wallace (1852) and Henry Walter Bates (1862). Hans Zinsser's \"classic\" \"Rats, Lice and History\" (1935) showed that insects were an important force in human history. Writers like William Morton Wheeler, Maurice Maeterlinck, and Jean Henri Fabre described insect life and communicated their meaning to people \"with imagination and brilliance\". Frederick Simon Bodenheimer's \"Insects as Human Food\" (1951) drew attention to the scope and potential of entomophagy, and showed a positive aspect of insects. Food is the most studied topic in ethnoentomology, followed by medicine and beekeeping.\n\nIn 1968, claimed cultural entomology as a branch of insect studies, in a review of the roles insects played in folklore and culture including religion, food, medicine and the arts. In 1984, Charles Hogue covered the field in English and from 1994 to 1997, Hogue's \"The Cultural Entomology Digest\" served as a forum on the field. Hogue argued that \"Humans spend their intellectual energies in three basic areas of activity: surviving, using practical learning (the application of technology); seeking pure knowledge through inductive mental processes (science); and pursuing enlightenment to taste a pleasure by aesthetic exercises that may be referred to as the \"humanities.\" Entomology has long been concerned with survival (economic entomology) and scientific study (academic entomology), but the branch of investigation that addresses the influence of insects (and other terrestrial Arthropoda, including arachnids and myriapods) in literature, language, music, the arts, interpretive history, religion, and recreation has only become recognized as a distinct field through Schimitschek's work.\nHogue set out the boundaries of the field by saying: \"The narrative history of the science of entomology is not part of cultural entomology, while the influence of insects on general history would be considered cultural entomology.\" He added: \"Because the term \"cultural\" is narrowly defined, some aspects normally included in studies of human societies are excluded.\"\n\nDarrell Addison Posey, noting that the boundary between cultural entomology and ethnoentomology is difficult to draw, cites Hogue as limiting cultural entomology to the influence of insects on \"the essence of humanity as expressed in the arts and humanities\". Posey notes further that cultural anthropology is usually restricted to the study of \"advanced\", industrialised, and literate societies, whereas ethnoentomology studies \"the entomological concerns of 'primitive' or 'noncivilized' societies\". Posey states at once that the division is artificial, complete with an unjustified us/them bias. Brian Morris similarly criticises the way that anthropologists treat non-Western attitudes to nature as monadic and spiritualist, and contrast this \"in gnostic fashion\" with a simplistic treatment of Western, often 17th century, mechanistic attitude. Morris considers this \"quite unhelpful, if not misleading\", and offers instead his own research into the multiple ways that the people of Malawi relate to insects and other animals: \"pragmatic, intellectual, realist, practical, aesthetic, symbolic and sacramental.\"\n\nThe Millennium Ecosystem Assessment (MEA) report 2005 defines ecosystem services as benefits people obtain from ecosystems, and distinguishes four categories, namely provisioning, regulating, supporting, and cultural. A fundamental tenet is that a few species of arthropod are well understood for their influence on humans (such as honeybees, ants, mosquitoes, and spiders). However, insects offer ecological goods and services. The Xerces Society calculates the economic impact of four ecological services rendered by insects: pollination, recreation (i.e. \"the importance of bugs to hunting, fishing, and wildlife observation, including bird-watching\"), dung burial, and pest control. The value has been estimated at $153 billion worldwide. As the ant expert E. O. Wilson observed: \"If all mankind were to disappear, the world would regenerate back to the rich state of equilibrium that existed ten thousand years ago. If insects were to vanish, the environment would collapse into chaos.\" A Nova (TV Series) segment on the American Public Broadcasting Service framed the relationship with insects in an urban context: \"We humans like to think that we run the world. But even in the heart of our great cities, a rival superpower thrives ... These tiny creatures live all around us in vast numbers, though we hardly even notice them. But in many ways, it is they who really run the show. \"The Washington Post\" stated: \"We are flying blind in many aspects of preserving the environment, and that's why we are so surprised when a species like the honeybee starts to crash, or an insect we don't want, the Asian tiger mosquito or the fire ant, appears in our midst. In other words: Start thinking about the bugs.\"\n\n \nHuman attitudes toward insects are often negative, reinforced by sensationalism in the media. This has produced a society that attempts to eliminate insects from daily life. For example, nearly 75 million pounds of broad-spectrum insecticides are manufactured and sold each year for use in American homes and gardens. Annual revenues from insecticide sales to homeowners exceeded $450 million in 2004. Out of the roughly a million species of insects described so far, not more than 1,000 can be regarded as serious pests, and less than 10,000 (about 1%) are even occasional pests. Yet not one species of insect has been permanently eradicated through the use of pesticides. Instead, at least 1,000 species have developed field resistance to pesticides, and extensive harm has been done to beneficial insects including pollinators such as bees.\n\nDuring the Cold War, the Warsaw Pact countries launched a widespread war against the potato beetle, blaming the introduction of the species from America on the CIA, demonising the species in propaganda posters, and urging children to gather the beetles and kill them.\n\nEntomophagy is the eating of insects. Many insects are considered a culinary delicacy in some societies around the world, and Frederick Simon Bodenheimer's \"Insects as Human Food\" (1951) drew attention to the scope and potential of entomophagy, but the practice is uncommon and even taboo in other societies. Sometimes insects are considered suitable only for the poor in the third world, but in 1975 Victor Meyer-Rochow suggested that insects could help ease global future food shortages and advocated a change in western attitudes towards cultures in which insects were appreciated as a food item. P.J. Gullan and P.S. Cranston felt that the remedy for this may be marketing of insect dishes as suitably exotic and costly to make them acceptable. They also note that some societies in sub-Saharan Africa prefer caterpillars to beef, while Chakravorty et al. (2011) point out that food insects (highly appreciated in North-East India) are more expensive than meat. The economics, i.e., the costs involved collecting food insects and the money earned through the sale of such insects, have been studied in a Laotian setting by Meyer-Rochow et al. (2008). In Mexico, ant larvae and Corixid water boatman eggs are sought out as a form of caviar by gastronomes. In Guangdong, water beetles fetch a high enough price for these insects to be farmed. Especially high prices are fetched in Thailand for the giant water bug \"Lethocerus indicus\".\n\nInsects used in food include honey bee larvae and pupae, mopani worms, silkworms, Maguey worms, Witchetty grubs, crickets, grasshoppers and locusts. In Thailand, there are 20,000 farmers rearing crickets, producing some 7,500 tons per year.\n\nInsects have been used medicinally in cultures around the world, often according to the Doctrine of Signatures. Thus, the femurs of grasshoppers, which were said to resemble the human liver, were used to treat liver ailments by the indigenous peoples of Mexico. The doctrine was applied in both Traditional Chinese Medicine (TCM) and in Ayurveda. TCM uses arthropods for various purposes; for example, centipede is used to treat tetanus, seizures, and convulsions, while the Chinese Black Mountain Ant, \"Polyrhachis vicina\", is used as a cure all, especially by the elderly, and extracts have been examined as a possible anti-cancer agent. Ayurveda uses insects such as Termite for conditions such as ulcers, rheumatic diseases, anaemia, and pain. The Jatropha leaf miner's larvae are used boiled to induce lactation, reduce fever, and soothe the gastrointestinal tract. In contrast, the traditional insect medicine of Africa is local and unformalised. The indigenous peoples of Central America used a wide variety of insects medicinally. Mayans used Army ant soldiers as living sutures. The venom of the Red harvester ant was used to cure rheumatism, arthritis, and poliomyelitis via the immune reaction produced by its sting. Boiled \"silkworm\" pupae were taken to treat apoplexy, aphasy, bronchitis, pneumonia, convulsions, haemorrhages, and frequent urination.\n\nHoney bee products are used medicinally in apitherapy across Asia, Europe, Africa, Australia, and the Americas, despite the fact that the honey bee was not introduced to the Americas until the colonization by Spain and Portugal. They are by far the most common medical insect product both historically and currently, and the most frequently referenced of these is honey. It can be applied to skin to treat excessive scar tissue, rashes, and burns, and as an eye poultice to treat infection. Honey is taken for digestive problems and as a general health restorative. It is taken hot to treat colds, cough, throat infections, laryngitis, tuberculosis, and lung diseases. Apitoxin (honey bee venom) is applied via direct stings to relieve arthritis, rheumatism, polyneuritis, and asthma. Propolis, a resinous, waxy mixture collected by honeybees and used as a hive insulator and sealant, is often consumed by menopausal women because of its high hormone content, and it is said to have antibiotic, anesthetic, and anti-inflammatory properties. Royal jelly is used to treat anaemia, gastrointestinal ulcers, arteriosclerosis, hypo- and hypertension, and inhibition of sexual libido. Finally Bee bread, or bee pollen, is eaten as a generally health restorative, and is said to help treat both internal and external infections. One of the major peptides in bee venom, Melittin, has the potential to treat inflammation in sufferers of Rheumatoid arthritis and Multiple sclerosis.\n\nThe rise of antibiotic resistant infections has sparked pharmaceutical research for new resources, including into arthropods.\n\nMaggot therapy uses blowfly larvae to perform wound-cleaning debridement.\n\nCantharidin, the blister-causing oil found in several families of beetles described by the vague common name Spanish fly has been used as an aphrodisiac in some societies.\n\nBlood-feeding insects like ticks, horseflies, and mosquitoes inject multiple bioactive compounds into their prey. These insects have long been used by practitioners of Eastern Medicine to prevent blood clot formation or thrombosis, suggesting possible applications in scientific medicine. Over 1280 protein families have been associated with the saliva of blood feeding organisms, including inhibitors of platelet aggregation, ADP, arachidonic acid, thrombin, PAF, anticoagulants, vasodilators, vasoconstrictors, antihistamines, sodium channel blockers, complement inhibitors, pore formers, inhibitors of angiogenesis, anaesthetics, AMPs and microbial pattern recognition molecules, and parasite enhancers/activators.\n\nInsects play an important role in biological research. Because of its small size, short generation time and high fecundity, the common fruit fly \"Drosophila melanogaster\" was selected as a model organism for studies of the genetics of higher eukaryotes. \"D. melanogaster\" has been an essential part of studies into principles like genetic linkage, interactions between genes, chromosomal genetics, evolutionary developmental biology, animal behaviour and evolution. Because genetic systems are well conserved among eukaryotes, understanding basic cellular processes like DNA replication or transcription in fruit flies helps scientists to understand those processes in other eukaryotes, including humans. The genome of \"D. melanogaster\" was sequenced in 2000, reflecting the fruit fly's important role in biological research. 70% of the fly genome is similar to the human genome, supporting the Darwinian theory of evolution from a single origin of life.\n\nSome hemipterans are used to produce dyestuffs such as carmine (also called cochineal). The scale insect \"Dactylopius coccus\" produces the brilliant red-coloured carminic acid to deter predators. Up to 100,000 scale insects are needed to make a kilogram (2.2 lbs) of cochineal dye.\n\nA similarly enormous number of lac bugs are needed to make a kilogram of shellac, a brush-on colourant and wood finish. Additional uses of this traditional product include the waxing of citrus fruits to extend their shelf-life, and the coating of pills to moisture-proof them, provide slow-release or mask the taste of bitter ingredients.\n\nKermes is a red dye from the dried bodies of the females of a scale insect in the genus \"Kermes\", primarily \"Kermes vermilio\". \"Kermes\" are native to the Mediterranean region, living on the sap of the Kermes oak. They were used as a red dye by the ancient Greeks and Romans. The kermes dye is a rich red, and has good colour fastness in silk and wool.\n\nInsect attributes are sometimes mimicked in architecture, as at the Eastgate Centre, Harare, which uses passive cooling, storing heat in the morning and releasing it in the warm parts of the day. The target of this piece of biomimicry is the structure of the mounds of termites such as \"Macrotermes michaelseni\" which effectively cool the nests of these social insects. The properties of the Namib desert beetle's exoskeleton, in particular its wing-cases (elytra) which have bumps with hydrophilic (water-attracting) tips and hydrophobic (water-shedding) sides, have been mimicked in a film coating designed for the British Ministry of Defence, to capture water in arid regions.\n\nSilkworms, the caterpillars and pupae of the moth \"Bombyx mori\", have been reared to produce silk in China from the Neolithic Yangshao period onwards, c. 5000 BC. Production spread to India by 140 AD. The caterpillars are fed on mulberry leaves. The cocoon, produced after the fourth moult, is covered with a continuous filament of the silk protein, fibroin, gummed together with sericin. In the traditional process, the gum is removed by soaking in hot water, and the silk is then unwound from the cocoon and reeled. Filaments are spun together to make silk thread. Commerce in silk between China and countries to its west began in ancient times, with silk known from an Egyptian mummy of 1070 BC, and later to the ancient Greeks and Romans. The silk road leading west from China was opened in the second century AD, helping to drive trade in silk and other goods.\n\nThe use of insects for warfare may have been attempted in the Middle Ages or earlier, but was first systematically researched by several nations during the twentieth century. It was put into practice by the Japanese army's Unit 731 in attacks on China during the Second World War, killing almost 500,000 Chinese people with fleas infected with plague and flies infected with cholera. Also in the Second World War, the Germans explored the use of Colorado beetles to destroy enemy potato crops. During the Cold War, the US Army considered using yellow fever mosquitoes to attack Soviet cities.\n\nInsects have appeared in mythology around the world from ancient times. Among the insect groups featuring in myths are the bee, butterfly, cicada, fly, dragonfly, praying mantis and scarab beetle. Scarab beetles held religious and cultural symbolism in Old Egypt, Greece and some shamanistic Old World cultures. The ancient Chinese regarded cicadas as symbols of rebirth or immortality. In the \"Homeric Hymn to Aphrodite\", the goddess Aphrodite retells the legend of how Eos, the goddess of the dawn, requested Zeus to let her lover Tithonus live forever as an immortal. Zeus granted her request, but, because Eos forgot to ask him to also make Tithonus ageless, Tithonus never died, but he did grow old. Eventually, he became so tiny and shriveled that he turned into the first cicada.\n\nIn an ancient Sumerian poem, a fly helps the goddess Inanna when her husband Dumuzid is being chased by \"galla\" demons. Flies also appear on Old Babylonian seals as symbols of Nergal, the god of death and fly-shaped lapis lazuli beads were often worn by many different cultures in ancient Mesopotamia, along with other kinds of fly-jewellery. The Akkadian \"Epic of Gilgamesh\" contains allusions to dragonflies, signifying the impossibility of immortality.\n\nAmongst the Arrernte Aborigines of Australia, honey ants and witchety grubs served as personal clan totems. In the case of the San bushmen of the Kalahari, it is the praying mantis which holds much cultural significance including creation and zen-like patience in waiting.\n\nInsects feature in folklore around the world. In China, farmers traditionally regulated their crop planting according to the Awakening of the Insects, when temperature shifts and monsoon rains bring insects out of hibernation. Most \"Awakening\" customs are related to eating snacks like pancakes, parched beans, pears, and fried corn, symbolizing harmful insects in the field.\n\nIn the Great Lakes region of the United States, there is an annual Woollybear Festival that has been celebrated for over 40 years. The larvae of the species \"Pyrrharctia isabella\" (commonly known as the Isabella Tiger moth), with their 13 distinct segments of black and reddish-brown, have the reputation in common folklore of being able to forecast the coming winter weather.\n\nThere is a common misconception that cockroaches are serious vectors of disease, but while they can carry bacteria they do not travel far, and have no bite or sting. Their shells contain a protein, arylphorin, implicated in asthma and other respiratory conditions.\n\nMany people believe the urban myth that the daddy longlegs Opiliones have the most poisonous bite in the spider world, but that the fangs are too small to penetrate human skin. This is untrue on several counts. None of the known species of harvestmen have venom glands; their chelicerae are not hollowed fangs but grasping claws that are typically very small and definitely not strong enough to break human skin.\n\nIn Japan, the emergence of fireflies and rhinoceros beetles signify the anticipated changing of the seasons.\n\nIn the Brazilian Amazon, members of the Tupí–Guaraní language family have been observed using \"Pachycondyla commutata\" ants during female rite-of-passage ceremonies, and prescribing the sting of \"Pseudomyrmex\" spp. for fevers and headaches.\n\nThe red harvester ant \"Pogonomyrmex californicus\" has been widely used by natives of Southern California and Northern Mexico for hundreds of years in ceremonies conducted to help tribe members acquire spirit helpers through hallucination. During the ritual, young men are sent away from the tribe and consume large quantities of live, unmasticated ants under the supervision of an elderly member of the tribe. Ingestion of ants should lead to a prolonged state of unconsciousness, where dream helpers appear and serve as allies to the dreamer for the rest of his life.\n\nBoth the symbolic form and the actual body of insects have been used to adorn humans in ancient and modern times. A recurrent theme for ancient cultures in Europe and the Near East regarded the sacred image of a bee or human with insect features. Often referred to as the bee \"goddess\", these images were found in gems and stones. An onyx gem from Knossos (ancient Crete) dating to approximately 1500 BC illustrates a Bee goddess with bull horns above her head. In this instance, the figure is surrounded by dogs with wings, most likely representing Hecate and Artemis – gods of the underworld, similar to the Egyptian gods Akeu and Anubis.\n\nBeetlewing art is an ancient craft technique using iridescent beetle wings practiced traditionally in Thailand, Myanmar, India, China and Japan. Beetlewing pieces are used as an adornment to paintings, textiles and jewelry. Different species of metallic wood-boring beetle wings were used depending on the region, but traditionally the most valued were those from beetles belonging to the genus Sternocera. The practice comes from across Asia and Southeast Asia, especially Thailand, Myanmar, Japan, India and China. In Thailand beetlewings were preferred to decorate clothing (shawls and Sabai cloth) and jewellery in former court circles.\n\nThe Canadian entomologist C.H. Curran's 1945 book, \"Insects of the Pacific World\", noted women from India and Sri Lanka, who kept 1 1/2 inch long, iridescent greenish coppery beetles of the species \"Chrysochroa ocellata\" as pets. These living jewels were worn on festive occasions, probably with a small chain attached to one leg anchored to the clothing to prevent escape. Afterwards, the insects were bathed, fed, and housed in decorative cages. Living jewelled beetles have also been worn and kept as pets in Mexico.\n\nButterflies have long inspired humans with their life cycle, color, and ornate patterns. The novelist Vladimir Nabokov was also a renowned butterfly expert. He published and illustrated many butterfly species, stating:\n\n\"I discovered in nature the nonutilitarian delights that I sought in art. Both were a form of magic, both were games of intricate enchantment and deception.\"\n\nIt was the aesthetic complexity of insects that led Nabokov to reject natural selection.\n\nThe naturalist Ian MacRae writes of butterflies:\n\n\"... the animal is at once awkward, flimsy, strange, bouncy in flight, yet beautiful and immensely sympathetic; it is painfully transient, albeit capable of extreme migrations and transformations. Images and phrases such as \"kaleidoscopic instabilities,\" \"oxymoron of similarities,\" \"rebellious rainbows,\" \"visible darkness\" and \"souls of stone\" have much in common. They bring together the two terms of a conceptual contradiction, thereby facilitating the mixing of what should be discrete and mutually exclusive categories ... In positing such questions, butterfly science, an inexhaustible, complex, and finely nuanced field, becomes not unlike the human imagination, or the field of literature itself. In the natural history of the animal, we begin to sense its literary and artistic possibilities.\"\n\nThe photographer Kjell Sandved spent 25 years documenting all 26 characters of the Latin alphabet using the wing patterns of butterflies and moths as \"The Butterfly Alphabet\".\n\nIn 2011, the artist Anna Collette created over 10,000 individual ceramic insects at Nottingham Castle, \"Stirring the Swarm.\" Reviews of the exhibit offered a compelling narrative for Cultural Entomology: \"the unexpected use of materials, dark overtones, and the straightforward impact of thousands of tiny multiples within the space. The exhibition was at once both exquisitely beautiful and deeply repulsive, and this strange duality was fascinating.\"\n\nThe Ancient Greek playwright Aeschylus has a gadfly pursue and torment Io, a maiden associated with the moon, watched constantly by the eyes of the herdsman Argus, associated with all the stars: \"Io: Ah! Hah! Again the prick, the stab of gadfly-sting! O earth, earth, hide, the hollow shape—Argus—that evil thing—the hundred-eyed.\" William Shakespeare, inspired by Aeschylus, has Tom o'Bedlam in \"King Lear\", \"Whom the foul fiend hath led through fire and through flame, through ford and whirlpool, o'er bog and quagmire\", driven mad by the constant pursuit. In \"Antony and Cleopatra\", Shakespeare similarly likens Cleopatra's hasty departure from the Actium battlefield to that of a cow chased by a gadfly.\nH. G. Wells introduced giant wasps in his 1904 novel \"The Food of the Gods and How It Came to Earth\", making use of the newly discovered growth hormones to lend plausibility to his science fiction.\nLafcadio Hearn's essay \"Butterflies\" analyses the treatment of the butterfly in Japanese literature, both prose and poetry. He notes that these often allude to Chinese tales, such as of the young woman that the butterflies took to be a flower. He translates 22 Japanese Haiku poems about butterflies, including one by the Haiku master Matsuo Bashō, said to suggest happiness in springtime: \"Wake up! Wake up!—I will make thee my comrade, thou sleeping butterfly.\"\n\nThe novelist Vladimir Nabokov was the son of a professional lepidopterist, and was interested in butterflies himself. He wrote his novel \"Lolita\" while travelling on his annual butterfly-collection trips in the western United States. He eventually became a leading lepidopterist. This is reflected in his fiction, where for example \"The Gift\" devotes two whole chapters (of five) to the tale of a father and son on a butterfly expedition.\n\nHorror films involving insects, sometimes called \"big bug movies\", include the pioneering 1954 \"Them!\", featuring giant ants mutated by radiation, and the 1957 \"The Deadly Mantis\".\n\n\"The Far Side\", a newspaper cartoon, has been used by professor of Michael Burgett as a teaching tool in his entomology class; \"The Far Side\" and its author Gary Larson have been acknowledged by biologist Dale H. Clayton his colleague for \"the enormous contribution\" Larson has made to their field through his cartoons.\n\nThe \"Flight of the Bumblebee\" was written by Nikolai Rimsky-Korsakov, in 1899–1900, as part of his opera, \"The Tale of Tsar of Saltan\". The piece is one of the most recognizable pieces in classical composition. The bumblebee in the story is a prince who has been transformed into an insect so that he can fly off to visit his father. The play upon which the opera was based – written by Alexandr Pushkin – originally had two more insect themes: the Flight of the Mosquito and the Flight of the Fly.\n\nThe Hungarian composer Béla Bartók explained in his diary that he was attempting to depict the desperate attempts to escape of a fly caught in a cobweb in his piece \"From the Diary of a Fly, for piano (Mikrokosmos Vol. 6/142)\".\n\nThe jazz musician and philosophy professor David Rothenberg plays duets with singing insects including cicadas, crickets, and beetles.\n\nIn astronomy, constellations named after arthropods include the zodiacal Scorpius, the scorpion, and Musca, the fly, also known as Apis, the bee, in the deep southern sky. Musca, the only recognised insect constellation, was named by Petrus Plancius in 1597.\n\n\"The Bug Nebula\", also called \"The Butterfly Nebula\", is a more recent discovery. Known as NGC 6302 is one of the brightest and most popular stars in the universe – popular in that its features draw the attention of a lot of researchers. It happens to be located in the Scorpius constellation. It is perfectly bipolar, and until recently, the central star was unobservable, clouded by gas, but estimated to be one of the hottest in the galaxy – 200,000 degrees Fahrenheit, perhaps 35 times hotter than our Sun.\n\nThe honey bee played a central role in the cosmology of the Mayan people. The stucco figure at the temples of Tulum known as \"Ah Mucen Kab\" – the Diving Bee God – bears resemblance to the insect in the Codex Tro-Cortesianus identified as a bee. Such reliefs might have indicated towns and villages that produce honey. Modern Mayan authorities say the figure also have a connection to modern cosmology. Mayan mythology expert Migel Angel Vergara relates that the Mayans held a belief that bees came from Venus, the \"Second Sun.\" The relief might be indicative of another \"insect deity\", that of Xux Ex, the Mayan \"wasp star.\" The Mayan embodied Venus in the form of the god Kukulkán (also known as or related to Gukumatz and Quetzalcoatl in other parts of Mexico), Quetzalcoatl is a Mesoamerican deity whose name in Nahuatl means \"feathered serpent\". The cult was the first Mesoamerican religion to transcend the old Classic Period linguistic and ethnic divisions. This cult facilitated communication and peaceful trade among peoples of many different social and ethnic backgrounds. Although the cult was originally centered on the ancient city of Chichén Itzá in the modern Mexican state of Yucatán, it spread as far as the Guatemalan highlands.\n\nBee and other insect costumes are worn in a variety of countries for parties, carnivals and other celebrations.\n\nOvo is an insect-themed production by the world renowned Canadian entertainment company Cirque du Soleil. The show looks at the world of insects and its biodiversity where they go about their daily lives until a mysterious egg appears in their midst, as the insects become awestruck about this iconic object that represents the enigma and cycles of their lives. The costuming was a fusion of arthropod body types blended with superhero armour. Liz Vandal, the lead costume designer, has a special affinity for the world of the insect:\n\nThe Webby award-winning video series \"Green Porno\" was created to showcase the reproductive habits of insects. Jody Shapiro and Rick Gilbert were responsible for translating the research and concepts that Isabella Rossellini envisioned into the paper and paste costumes which directly contribute to the series' unique visual style. The film series was driven by the creation of costumes to translate scientific research into \"something visual and how to make it comical.\"\n\n\n\n"}
{"id": "15220", "url": "https://en.wikipedia.org/wiki?curid=15220", "title": "Imprecise language", "text": "Imprecise language\n\nOften, informal, spoken language, \"everyday language\" is less precise than any more formal or academic languages.\n\nLanguage might be said to be imprecise because it exhibits one or more of the following features:\n\nWhile imprecise language is not desirable in various scientific fields, it may be helpful, illustrative or discussion-stimulative in other contexts. Imprecision in a discourse may or may not be the intention of the author(s) or speaker(s). The role of imprecision may depend on audience, end goal, extended context and subject matter. Relevant players and real stakes will also bear on truth-grounds of statements.\n"}
{"id": "21740823", "url": "https://en.wikipedia.org/wiki?curid=21740823", "title": "Ivy Day (United States)", "text": "Ivy Day (United States)\n\nIvy Day is an annual ceremony in which an ivy stone is placed on either a residential, academic or administrative building or ground to commemorate academic excellence. The ceremony is most known for being practiced among older colleges in the Northeastern United States. It is most associated with the Ivy League and a group of small liberal arts college known as the Little Ivies. Some institutions announce members of Phi Beta Kappa and specialized honor designations for students. Some classes donate to the college, in the form gates, facades, and door outlines, by inscribing or creating their own version of symbolic icons of the college's seal or other prominent insignia. The ivy stones are usually decorated with the graduation date and a symbol that represents the college as a whole or the class as a whole. The most common ivy stone is one-by-two feet and is usually made out of workable stone.\n\nOn occasion students have featured prominent alumni on their class ivy stones or have selected to feature an engraving of a member of their graduating class. Since 1873 at the University of Pennsylvania and since 1879 at Bates College, students have unveiled class ivy stones at the annual ivy day preceding commencement. Students may also have a selective procession prior to the official commencement walk to honor each stone being placed on the buildings. On some occasions students plant ivy in front or on the side of their ivy stones. Princeton University also places class ivy stones on the walls of its buildings, a few days prior to their commencement. Students are known to give speeches at Ivy Day to commemorate their time and work at the college. Select medical schools also participate in Ivy Day prior to their White Coat Ceremony.\n"}
{"id": "35079368", "url": "https://en.wikipedia.org/wiki?curid=35079368", "title": "Junior Ambassador", "text": "Junior Ambassador\n\nJunior Ambassador is an international cultural exchange and relations organization. Junior Ambassador manages international cultural exchange programs, which are certified by government organizations to train young global leaders(youth ambassadors).\n\nThe purpose of the program of Junior Ambassador is to train youth global cultural representatives, who could lead the generation of 21st Century cultural diplomacy and contribute to the happiness and development of mankind with much knowledge and love for mankind. The purpose of the Junior Ambassador program is to train youth ambassadors who would lead 21st century cultural diplomacy and contribute to the happiness and development of mankind. Since the 26th UNESCO General Conference has adopted ‘Seoul Agenda: Goals for Cultural Art Exchange’, which was mainly led by the government of Republic of Korea, practicing cultural diversity, intercultural dialogue, and sustainable development became significant issues. To practice UNESCO’s educational ideology, Junior Ambassador’s object is to train 21st Century style leaders, who comprehend about the movement of global cultural flow and lead exchange of cultural art.\n\nBritish Council, ATOUT France, ENIT Italia, Switzerland embassy and Switzerland tourism are participating as partners of the Junior Ambassador program. These global partners assist in designing the program, co-hosting cultural activities and issuing the letter of credence.\n\nJunior Ambassador manages many programs as below.\n\n"}
{"id": "21669080", "url": "https://en.wikipedia.org/wiki?curid=21669080", "title": "KAIROS Prize", "text": "KAIROS Prize\n\nThe KAIROS Prize has been awarded to European artists and scholars from the fields of visual and performing arts, music, architecture, design, film, photography, literature and journalism since 2007 by the Alfred Toepfer Foundation in Hamburg. It is endowed with a sum of 75,000 Euro.\n\nSource: Alfred Toepfer Foundation\n\n"}
{"id": "57204677", "url": "https://en.wikipedia.org/wiki?curid=57204677", "title": "Kyrgyz literature", "text": "Kyrgyz literature\n\nThe history of Kyrgyz literature dates to the early 19th century, from the poems of Moldo Nïyaz to stories written in \"Old Kyrgyz\". It is an important facet of the culture of Kyrgyzstan. Kyrgyz literature is not only written, but also spoken, and passed down from generation to generation. Much of the literature in Kyrgyzstan is poetry.\n\n\n\n"}
{"id": "17524", "url": "https://en.wikipedia.org/wiki?curid=17524", "title": "Language", "text": "Language\n\nLanguage is a system that consists of the development, acquisition, maintenance and use of complex systems of communication, particularly the human ability to do so; and a language is any specific example of such a system.\n\nThe scientific study of language is called linguistics. Questions concerning the philosophy of language, such as whether words can represent experience, have been debated at least since Gorgias and Plato in ancient Greece. Thinkers such as Rousseau have argued that language originated from emotions while others like Kant have held that it originated from rational and logical thought. 20th-century philosophers such as Wittgenstein argued that philosophy is really the study of language. Major figures in linguistics include Ferdinand de Saussure and Noam Chomsky.\n\nEstimates of the number of human languages in the world vary between 5,000 and 7,000. However, any precise estimate depends on a partly arbitrary distinction between languages and dialects. Natural languages are spoken or signed, but any language can be encoded into secondary media using auditory, visual, or tactile stimuli – for example, in whistling, signed, or braille. This is because human language is modality-independent. Depending on philosophical perspectives regarding the definition of language and meaning, when used as a general concept, \"language\" may refer to the cognitive ability to learn and use systems of complex communication, or to describe the set of rules that makes up these systems, or the set of utterances that can be produced from those rules. All languages rely on the process of semiosis to relate signs to particular meanings. Oral, manual and tactile languages contain a phonological system that governs how symbols are used to form sequences known as words or morphemes, and a syntactic system that governs how words and morphemes are combined to form phrases and utterances.\n\nHuman language has the properties of productivity and displacement, and relies entirely on social convention and learning. Its complex structure affords a much wider range of expressions than any known system of animal communication. Language is thought to have originated when early hominins started gradually changing their primate communication systems, acquiring the ability to form a theory of other minds and a shared intentionality. This development is sometimes thought to have coincided with an increase in brain volume, and many linguists see the structures of language as having evolved to serve specific communicative and social functions. Language is processed in many different locations in the human brain, but especially in Broca's and Wernicke's areas. Humans acquire language through social interaction in early childhood, and children generally speak fluently by approximately three years old. The use of language is deeply entrenched in human culture. Therefore, in addition to its strictly communicative uses, language also has many social and cultural uses, such as signifying group identity, social stratification, as well as social grooming and entertainment.\n\nLanguages evolve and diversify over time, and the history of their evolution can be reconstructed by comparing modern languages to determine which traits their ancestral languages must have had in order for the later developmental stages to occur. A group of languages that descend from a common ancestor is known as a language family. The Indo-European family is the most widely spoken and includes languages as diverse as English, Russian and Hindi; the Sino-Tibetan family includes Mandarin, Bodo and the other Chinese languages, and Tibetan; the Afro-Asiatic family includes Arabic, Somali, and Hebrew; the Bantu languages include Swahili, and Zulu, and hundreds of other languages spoken throughout Africa; and the Malayo-Polynesian languages include Indonesian, Malay, Tagalog, and hundreds of other languages spoken throughout the Pacific. The languages of the Dravidian family, spoken mostly in Southern India, include Tamil Telugu and Kannada. Academic consensus holds that between 50% and 90% of languages spoken at the beginning of the 21st century will probably have become extinct by the year 2100.\n\nThe English word \"language\" derives ultimately from Proto-Indo-European \"\" \"tongue, speech, language\" through Latin \"lingua\", \"language; tongue\", and Old French \"language\". The word is sometimes used to refer to codes, ciphers, and other kinds of artificially constructed communication systems such as formally defined computer languages used for computer programming. Unlike conventional human languages, a formal language in this sense is a system of signs for encoding and decoding information. This article specifically concerns the properties of natural human language as it is studied in the discipline of linguistics.\n\nAs an object of linguistic study, \"language\" has two primary meanings: an abstract concept, and a specific linguistic system, e.g. \"French\". The Swiss linguist Ferdinand de Saussure, who defined the modern discipline of linguistics, first explicitly formulated the distinction using the French word \"langage\" for language as a concept, \"langue\" as a specific instance of a language system, and \"parole\" for the concrete usage of speech in a particular language.\n\nWhen speaking of language as a general concept, definitions can be used which stress different aspects of the phenomenon. These definitions also entail different approaches and understandings of language, and they also inform different and often incompatible schools of linguistic theory. Debates about the nature and origin of language go back to the ancient world. Greek philosophers such as Gorgias and Plato debated the relation between words, concepts and reality. Gorgias argued that language could represent neither the objective experience nor human experience, and that communication and truth were therefore impossible. Plato maintained that communication is possible because language represents ideas and concepts that exist independently of, and prior to, language.\n\nDuring the Enlightenment and its debates about human origins, it became fashionable to speculate about the origin of language. Thinkers such as Rousseau and Herder argued that language had originated in the instinctive expression of emotions, and that it was originally closer to music and poetry than to the logical expression of rational thought. Rationalist philosophers such as Kant and Descartes held the opposite view. Around the turn of the 20th century, thinkers began to wonder about the role of language in shaping our experiences of the world – asking whether language simply reflects the objective structure of the world, or whether it creates concepts that it in turn imposes on our experience of the objective world. This led to the question of whether philosophical problems are really firstly linguistic problems. The resurgence of the view that language plays a significant role in the creation and circulation of concepts, and that the study of philosophy is essentially the study of language, is associated with what has been called the linguistic turn and philosophers such as Wittgenstein in 20th-century philosophy. These debates about language in relation to meaning and reference, cognition and consciousness remain active today.\n\nOne definition sees language primarily as the mental faculty that allows humans to undertake linguistic behaviour: to learn languages and to produce and understand utterances. This definition stresses the universality of language to all humans, and it emphasizes the biological basis for the human capacity for language as a unique development of the human brain. Proponents of the view that the drive to language acquisition is innate in humans argue that this is supported by the fact that all cognitively normal children raised in an environment where language is accessible will acquire language without formal instruction. Languages may even develop spontaneously in environments where people live or grow up together without a common language; for example, creole languages and spontaneously developed sign languages such as Nicaraguan Sign Language. This view, which can be traced back to the philosophers Kant and Descartes, understands language to be largely innate, for example, in Chomsky's theory of Universal Grammar, or American philosopher Jerry Fodor's extreme innatist theory. These kinds of definitions are often applied in studies of language within a cognitive science framework and in neurolinguistics.\n\nAnother definition sees language as a formal system of signs governed by grammatical rules of combination to communicate meaning. This definition stresses that human languages can be described as closed structural systems consisting of rules that relate particular signs to particular meanings. This structuralist view of language was first introduced by Ferdinand de Saussure, and his structuralism remains foundational for many approaches to language.\n\nSome proponents of Saussure's view of language have advocated a formal approach which studies language structure by identifying its basic elements and then by presenting a formal account of the rules according to which the elements combine in order to form words and sentences. The main proponent of such a theory is Noam Chomsky, the originator of the generative theory of grammar, who has defined language as the construction of sentences that can be generated using transformational grammars. Chomsky considers these rules to be an innate feature of the human mind and to constitute the rudiments of what language is. By way of contrast, such transformational grammars are also commonly used to provide formal definitions of language are commonly used in formal logic, in formal theories of grammar, and in applied computational linguistics. In the philosophy of language, the view of linguistic meaning as residing in the logical relations between propositions and reality was developed by philosophers such as Alfred Tarski, Bertrand Russell, and other formal logicians.\n\nYet another definition sees language as a system of communication that enables humans to exchange verbal or symbolic utterances. This definition stresses the social functions of language and the fact that humans use it to express themselves and to manipulate objects in their environment. Functional theories of grammar explain grammatical structures by their communicative functions, and understand the grammatical structures of language to be the result of an adaptive process by which grammar was \"tailored\" to serve the communicative needs of its users.\n\nThis view of language is associated with the study of language in pragmatic, cognitive, and interactive frameworks, as well as in sociolinguistics and linguistic anthropology. Functionalist theories tend to study grammar as dynamic phenomena, as structures that are always in the process of changing as they are employed by their speakers. This view places importance on the study of linguistic typology, or the classification of languages according to structural features, as it can be shown that processes of grammaticalization tend to follow trajectories that are partly dependent on typology. In the philosophy of language, the view of pragmatics as being central to language and meaning is often associated with Wittgenstein's later works and with ordinary language philosophers such as J.L. Austin, Paul Grice, John Searle, and W.O. Quine.\n\nA number of features, many of which were described by Charles Hockett and called design features set human language apart from other known systems of communication, such as those used by non-human animals.\n\nCommunication systems used by other animals such as bees or apes are closed systems that consist of a finite, usually very limited, number of possible ideas that can be expressed. In contrast, human language is open-ended and productive, meaning that it allows humans to produce a vast range of utterances from a finite set of elements, and to create new words and sentences. This is possible because human language is based on a dual code, in which a finite number of elements which are meaningless in themselves (e.g. sounds, letters or gestures) can be combined to form an infinite number of larger units of meaning (words and sentences). However, one study has demonstrated that an Australian bird, the chestnut-crowned babbler, is capable of using the same acoustic elements in different arrangements to create two functionally distinct vocalizations. Additionally, pied babblers have demonstrated the ability to generate two functionally distinct vocalisations composed of the same sound type, which can only be distinguished by the number of repeated elements.\n\nSeveral species of animals have proved to be able to acquire forms of communication through social learning: for instance a bonobo named Kanzi learned to express itself using a set of symbolic lexigrams. Similarly, many species of birds and whales learn their songs by imitating other members of their species. However, while some animals may acquire large numbers of words and symbols, none have been able to learn as many different signs as are generally known by an average 4 year old human, nor have any acquired anything resembling the complex grammar of human language.\n\nHuman languages also differ from animal communication systems in that they employ grammatical and semantic categories, such as noun and verb, present and past, which may be used to express exceedingly complex meanings. Human language is also unique in having the property of recursivity: for example, a noun phrase can contain another noun phrase (as in \"<nowiki>the chimpanzee]'s lips]</nowiki>\") or a clause can contain another clause (as in \"<nowiki>[I see [the dog is running</nowiki>\"). Human language is also the only known natural communication system whose adaptability may be referred to as \"modality independent\". This means that it can be used not only for communication through one channel or medium, but through several. For example, spoken language uses the auditive modality, whereas sign languages and writing use the visual modality, and braille writing uses the tactile modality.\n\nHuman language is also unique in being able to refer to abstract concepts and to imagined or hypothetical events as well as events that took place in the past or may happen in the future. This ability to refer to events that are not at the same time or place as the speech event is called \"displacement\", and while some animal communication systems can use displacement (such as the communication of bees that can communicate the location of sources of nectar that are out of sight), the degree to which it is used in human language is also considered unique.\n\nTheories about the origin of language differ in regard to their basic assumptions about what language is. Some theories are based on the idea that language is so complex that one cannot imagine it simply appearing from nothing in its final form, but that it must have evolved from earlier pre-linguistic systems among our pre-human ancestors. These theories can be called continuity-based theories. The opposite viewpoint is that language is such a unique human trait that it cannot be compared to anything found among non-humans and that it must therefore have appeared suddenly in the transition from pre-hominids to early man. These theories can be defined as discontinuity-based. Similarly, theories based on the generative view of language pioneered by Noam Chomsky see language mostly as an innate faculty that is largely genetically encoded, whereas functionalist theories see it as a system that is largely cultural, learned through social interaction.\n\nChomsky is one prominent proponent of a discontinuity-based theory of human language origins. He suggests that for scholars interested in the nature of language, \"talk about the evolution of the language capacity is beside the point.\" Chomsky proposes that perhaps \"some random mutation took place [...] and it reorganized the brain, implanting a language organ in an otherwise primate brain.\" Though cautioning against taking this story literally, Chomsky insists that \"it may be closer to reality than many other fairy tales that are told about evolutionary processes, including language.\"\n\nContinuity-based theories are held by a majority of scholars, but they vary in how they envision this development. Those who see language as being mostly innate, for example psychologist Steven Pinker, hold the precedents to be animal cognition, whereas those who see language as a socially learned tool of communication, such as psychologist Michael Tomasello, see it as having developed from animal communication in primates: either gestural or vocal communication to assist in cooperation. Other continuity-based models see language as having developed from music, a view already espoused by Rousseau, Herder, Humboldt, and Charles Darwin. A prominent proponent of this view is archaeologist Steven Mithen. Stephen Anderson states that the age of spoken languages is estimated at 60,000 to 100,000 years and that: Researchers on the evolutionary origin of language generally find it plausible to suggest that language was invented only once, and that all modern spoken languages are thus in some way related, even if that relation can no longer be recovered ... because of limitations on the methods available for reconstruction.\n\nBecause language emerged in the early prehistory of man, before the existence of any written records, its early development has left no historical traces, and it is believed that no comparable processes can be observed today. Theories that stress continuity often look at animals to see if, for example, primates display any traits that can be seen as analogous to what pre-human language must have been like. And early human fossils can be inspected for traces of physical adaptation to language use or pre-linguistic forms of symbolic behaviour. Among the signs in human fossils that may suggest linguistic abilities are: the size of the brain relative to body mass, the presence of a larynx capable of advanced sound production and the nature of tools and other manufactured artifacts.\n\nIt was mostly undisputed that pre-human australopithecines did not have communication systems significantly different from those found in great apes in general. However, a 2017 study on Ardipithecus ramidus challenges this belief. Scholarly opinions vary as to the developments since the appearance of the genus \"Homo\" some 2.5 million years ago. Some scholars assume the development of primitive language-like systems (proto-language) as early as \"Homo habilis\" (2.3 million years ago) while others place the development of primitive symbolic communication only with \"Homo erectus\" (1.8 million years ago) or \"Homo heidelbergensis\" (0.6 million years ago), and the development of language proper with Anatomically Modern \"Homo sapiens\" with the Upper Paleolithic revolution less than 100,000 years ago.\n\nThe study of language, linguistics, has been developing into a science since the first grammatical descriptions of particular languages in India more than 2000 years ago, after the development of the Brahmi script. Modern linguistics is a science that concerns itself with all aspects of language, examining it from all of the theoretical viewpoints described above.\n\nThe academic study of language is conducted within many different disciplinary areas and from different theoretical angles, all of which inform modern approaches to linguistics. For example, descriptive linguistics examines the grammar of single languages, theoretical linguistics develops theories on how best to conceptualize and define the nature of language based on data from the various extant human languages, sociolinguistics studies how languages are used for social purposes informing in turn the study of the social functions of language and grammatical description, neurolinguistics studies how language is processed in the human brain and allows the experimental testing of theories, computational linguistics builds on theoretical and descriptive linguistics to construct computational models of language often aimed at processing natural language or at testing linguistic hypotheses, and historical linguistics relies on grammatical and lexical descriptions of languages to trace their individual histories and reconstruct trees of language families by using the comparative method.\n\nThe formal study of language is often considered to have started in India with Pāṇini, the 5th century BC grammarian who formulated 3,959 rules of Sanskrit morphology. However, Sumerian scribes already studied the differences between Sumerian and Akkadian grammar around 1900 BC. Subsequent grammatical traditions developed in all of the ancient cultures that adopted writing.\n\nIn the 17th century AD, the French Port-Royal Grammarians developed the idea that the grammars of all languages were a reflection of the universal basics of thought, and therefore that grammar was universal. In the 18th century, the first use of the comparative method by British philologist and expert on ancient India William Jones sparked the rise of comparative linguistics. The scientific study of language was broadened from Indo-European to language in general by Wilhelm von Humboldt. Early in the 20th century, Ferdinand de Saussure introduced the idea of language as a static system of interconnected units, defined through the oppositions between them.\n\nBy introducing a distinction between diachronic and synchronic analyses of language, he laid the foundation of the modern discipline of linguistics. Saussure also introduced several basic dimensions of linguistic analysis that are still fundamental in many contemporary linguistic theories, such as the distinctions between syntagm and paradigm, and the Langue-parole distinction, distinguishing language as an abstract system (\"langue\"), from language as a concrete manifestation of this system (\"parole\").\n\nIn the 1960s, Noam Chomsky formulated the generative theory of language. According to this theory, the most basic form of language is a set of syntactic rules that is universal for all humans and which underlies the grammars of all human languages. This set of rules is called Universal Grammar; for Chomsky, describing it is the primary objective of the discipline of linguistics. Thus, he considered that the grammars of individual languages are only of importance to linguistics insofar as they allow us to deduce the universal underlying rules from which the observable linguistic variability is generated.\n\nIn opposition to the formal theories of the generative school, functional theories of language propose that since language is fundamentally a tool, its structures are best analyzed and understood by reference to their functions. Formal theories of grammar seek to define the different elements of language and describe the way they relate to each other as systems of formal rules or operations, while functional theories seek to define the functions performed by language and then relate them to the linguistic elements that carry them out. The framework of cognitive linguistics interprets language in terms of the concepts (which are sometimes universal, and sometimes specific to a particular language) which underlie its forms. Cognitive linguistics is primarily concerned with how the mind creates meaning through language.\n\nSpeaking is the default modality for language in all cultures. The production of spoken language depends on sophisticated capacities for controlling the lips, tongue and other components of the vocal apparatus, the ability to acoustically decode speech sounds, and the neurological apparatus required for acquiring and producing language. The study of the genetic bases for human language is at an early stage: the only gene that has definitely been implicated in language production is FOXP2, which may cause a kind of congenital language disorder if affected by mutations.\n\n The brain is the coordinating center of all linguistic activity; it controls both the production of linguistic cognition and of meaning and the mechanics of speech production. Nonetheless, our knowledge of the neurological bases for language is quite limited, though it has advanced considerably with the use of modern imaging techniques. The discipline of linguistics dedicated to studying the neurological aspects of language is called neurolinguistics.\n\nEarly work in neurolinguistics involved the study of language in people with brain lesions, to see how lesions in specific areas affect language and speech. In this way, neuroscientists in the 19th century discovered that two areas in the brain are crucially implicated in language processing. The first area is Wernicke's area, which is in the posterior section of the superior temporal gyrus in the dominant cerebral hemisphere. People with a lesion in this area of the brain develop receptive aphasia, a condition in which there is a major impairment of language comprehension, while speech retains a natural-sounding rhythm and a relatively normal sentence structure. The second area is Broca's area, in the posterior inferior frontal gyrus of the dominant hemisphere. People with a lesion to this area develop expressive aphasia, meaning that they know what they want to say, they just cannot get it out. They are typically able to understand what is being said to them, but unable to speak fluently. Other symptoms that may be present in expressive aphasia include problems with fluency, articulation, word-finding, word repetition, and producing and comprehending complex grammatical sentences, both orally and in writing. Those with this aphasia also exhibit ungrammatical speech and show inability to use syntactic information to determine the meaning of sentences. Both expressive and receptive aphasia also affect the use of sign language, in analogous ways to how they affect speech, with expressive aphasia causing signers to sign slowly and with incorrect grammar, whereas a signer with receptive aphasia will sign fluently, but make little sense to others and have difficulties comprehending others' signs. This shows that the impairment is specific to the ability to use language, not to the physiology used for speech production.\n\nWith technological advances in the late 20th century, neurolinguists have also incorporated non-invasive techniques such as functional magnetic resonance imaging (fMRI) and electrophysiology to study language processing in individuals without impairments.\n\nSpoken language relies on human physical ability to produce sound, which is a longitudinal wave propagated through the air at a frequency capable of vibrating the ear drum. This ability depends on the physiology of the human speech organs. These organs consist of the lungs, the voice box (larynx), and the upper vocal tract – the throat, the mouth, and the nose. By controlling the different parts of the speech apparatus, the airstream can be manipulated to produce different speech sounds.\n\nThe sound of speech can be analyzed into a combination of segmental and suprasegmental elements. The segmental elements are those that follow each other in sequences, which are usually represented by distinct letters in alphabetic scripts, such as the Roman script. In free flowing speech, there are no clear boundaries between one segment and the next, nor usually are there any audible pauses between words. Segments therefore are distinguished by their distinct sounds which are a result of their different articulations, and they can be either vowels or consonants. Suprasegmental phenomena encompass such elements as stress, phonation type, voice timbre, and prosody or intonation, all of which may have effects across multiple segments.\n\nConsonants and vowel segments combine to form syllables, which in turn combine to form utterances; these can be distinguished phonetically as the space between two inhalations. Acoustically, these different segments are characterized by different formant structures, that are visible in a spectrogram of the recorded sound wave (See illustration of Spectrogram of the formant structures of three English vowels). Formants are the amplitude peaks in the frequency spectrum of a specific sound.\n\nVowels are those sounds that have no audible friction caused by the narrowing or obstruction of some part of the upper vocal tract. They vary in quality according to the degree of lip aperture and the placement of the tongue within the oral cavity. Vowels are called \"close\" when the lips are relatively closed, as in the pronunciation of the vowel (English \"ee\"), or \"open\" when the lips are relatively open, as in the vowel (English \"ah\"). If the tongue is located towards the back of the mouth, the quality changes, creating vowels such as (English \"oo\"). The quality also changes depending on whether the lips are rounded as opposed to unrounded, creating distinctions such as that between (unrounded front vowel such as English \"ee\") and (rounded front vowel such as German \"ü\").\n\nConsonants are those sounds that have audible friction or closure at some point within the upper vocal tract. Consonant sounds vary by place of articulation, i.e. the place in the vocal tract where the airflow is obstructed, commonly at the lips, teeth, alveolar ridge, palate, velum, uvula, or glottis. Each place of articulation produces a different set of consonant sounds, which are further distinguished by manner of articulation, or the kind of friction, whether full closure, in which case the consonant is called \"occlusive\" or \"stop\", or different degrees of aperture creating \"fricatives\" and \"approximants\". Consonants can also be either \"voiced or unvoiced\", depending on whether the vocal cords are set in vibration by airflow during the production of the sound. Voicing is what separates English in \"bus\" (unvoiced sibilant) from in \"buzz\" (voiced sibilant).\n\nSome speech sounds, both vowels and consonants, involve release of air flow through the nasal cavity, and these are called \"nasals\" or \"nasalized\" sounds. Other sounds are defined by the way the tongue moves within the mouth: such as the l-sounds (called \"laterals\", because the air flows along both sides of the tongue), and the r-sounds (called \"rhotics\") that are characterized by how the tongue is positioned relative to the air stream.\n\nBy using these speech organs, humans can produce hundreds of distinct sounds: some appear very often in the world's languages, whereas others are much more common in certain language families, language areas, or even specific to a single language.\n\nWhen described as a system of symbolic communication, language is traditionally seen as consisting of three parts: signs, meanings, and a code connecting signs with their meanings. The study of the process of semiosis, how signs and meanings are combined, used, and interpreted is called semiotics. Signs can be composed of sounds, gestures, letters, or symbols, depending on whether the language is spoken, signed, or written, and they can be combined into complex signs, such as words and phrases. When used in communication, a sign is encoded and transmitted by a sender through a channel to a receiver who decodes it.\nSome of the properties that define human language as opposed to other communication systems are: the arbitrariness of the linguistic sign, meaning that there is no predictable connection between a linguistic sign and its meaning; the duality of the linguistic system, meaning that linguistic structures are built by combining elements into larger structures that can be seen as layered, e.g. how sounds build words and words build phrases; the discreteness of the elements of language, meaning that the elements out of which linguistic signs are constructed are discrete units, e.g. sounds and words, that can be distinguished from each other and rearranged in different patterns; and the productivity of the linguistic system, meaning that the finite number of linguistic elements can be combined into a theoretically infinite number of combinations.\n\nThe rules by which signs can be combined to form words and phrases are called syntax or grammar. The meaning that is connected to individual signs, morphemes, words, phrases, and texts is called semantics. The division of language into separate but connected systems of sign and meaning goes back to the first linguistic studies of de Saussure and is now used in almost all branches of linguistics.\n\nLanguages express meaning by relating a sign form to a meaning, or its content. Sign forms must be something that can be perceived, for example, in sounds, images, or gestures, and then related to a specific meaning by social convention. Because the basic relation of meaning for most linguistic signs is based on social convention, linguistic signs can be considered arbitrary, in the sense that the convention is established socially and historically, rather than by means of a natural relation between a specific sign form and its meaning.\n\nThus, languages must have a vocabulary of signs related to specific meaning. The English sign \"dog\" denotes, for example, a member of the species \"Canis familiaris\". In a language, the array of arbitrary signs connected to specific meanings is called the lexicon, and a single sign connected to a meaning is called a lexeme. Not all meanings in a language are represented by single words. Often, semantic concepts are embedded in the morphology or syntax of the language in the form of grammatical categories.\n\nAll languages contain the semantic structure of predication: a structure that predicates a property, state, or action. Traditionally, semantics has been understood to be the study of how speakers and interpreters assign truth values to statements, so that meaning is understood to be the process by which a predicate can be said to be true or false about an entity, e.g. \"<nowiki>[x [is y]]\" or \"[x [does y]]</nowiki>\". Recently, this model of semantics has been complemented with more dynamic models of meaning that incorporate shared knowledge about the context in which a sign is interpreted into the production of meaning. Such models of meaning are explored in the field of pragmatics.\n\nDepending on modality, language structure can be based on systems of sounds (speech), gestures (sign languages), or graphic or tactile symbols (writing). The ways in which languages use sounds or signs to construct meaning are studied in phonology. The study of how humans produce and perceive vocal sounds is called phonetics. In spoken language, meaning is produced when sounds become part of a system in which some sounds can contribute to expressing meaning and others do not. In any given language, only a limited number of the many distinct sounds that can be created by the human vocal apparatus contribute to constructing meaning.\n\nSounds as part of a linguistic system are called phonemes. Phonemes are abstract units of sound, defined as the smallest units in a language that can serve to distinguish between the meaning of a pair of minimally different words, a so-called minimal pair. In English, for example, the words \"bat\" and \"pat\" form a minimal pair, in which the distinction between and differentiates the two words, which have different meanings. However, each language contrasts sounds in different ways. For example, in a language that does not distinguish between voiced and unvoiced consonants, the sounds and (if they both occur) could be considered a single phoneme, and consequently, the two pronunciations would have the same meaning. Similarly, the English language does not distinguish phonemically between aspirated and non-aspirated pronunciations of consonants, as many other languages like Korean and Hindi do: the unaspirated in \"spin\" and the aspirated in \"pin\" are considered to be merely different ways of pronouncing the same phoneme (such variants of a single phoneme are called allophones), whereas in Mandarin Chinese, the same difference in pronunciation distinguishes between the words 'crouch' and 'eight' (the accent above the á means that the vowel is pronounced with a high tone).\n\nAll spoken languages have phonemes of at least two different categories, vowels and consonants, that can be combined to form syllables. As well as segments such as consonants and vowels, some languages also use sound in other ways to convey meaning. Many languages, for example, use stress, pitch, duration, and tone to distinguish meaning. Because these phenomena operate outside of the level of single segments, they are called suprasegmental. Some languages have only a few phonemes, for example, Rotokas and Pirahã language with 11 and 10 phonemes respectively, whereas languages like Taa may have as many as 141 phonemes. In sign languages, the equivalent to phonemes (formerly called cheremes) are defined by the basic elements of gestures, such as hand shape, orientation, location, and motion, which correspond to manners of articulation in spoken language.\n\nWriting systems represent language using visual symbols, which may or may not correspond to the sounds of spoken language. The Latin alphabet (and those on which it is based or that have been derived from it) was originally based on the representation of single sounds, so that words were constructed from letters that generally denote a single consonant or vowel in the structure of the word. In syllabic scripts, such as the Inuktitut syllabary, each sign represents a whole syllable. In logographic scripts, each sign represents an entire word, and will generally bear no relation to the sound of that word in spoken language.\n\nBecause all languages have a very large number of words, no purely logographic scripts are known to exist. Written language represents the way spoken sounds and words follow one after another by arranging symbols according to a pattern that follows a certain direction. The direction used in a writing system is entirely arbitrary and established by convention. Some writing systems use the horizontal axis (left to right as the Latin script or right to left as the Arabic script), while others such as traditional Chinese writing use the vertical dimension (from top to bottom). A few writing systems use opposite directions for alternating lines, and others, such as the ancient Maya script, can be written in either direction and rely on graphic cues to show the reader the direction of reading.\n\nIn order to represent the sounds of the world's languages in writing, linguists have developed the International Phonetic Alphabet, designed to represent all of the discrete sounds that are known to contribute to meaning in human languages.\n\nGrammar is the study of how meaningful elements called \"morphemes\" within a language can be combined into utterances. Morphemes can either be \"free\" or \"bound\". If they are free to be moved around within an utterance, they are usually called \"words\", and if they are bound to other words or morphemes, they are called affixes. The way in which meaningful elements can be combined within a language is governed by rules. The rules for the internal structure of words are called morphology. The rules of the internal structure of phrases and sentences are called \"syntax\".\n\nGrammar can be described as a system of categories and a set of rules that determine how categories combine to form different aspects of meaning. Languages differ widely in whether they are encoded through the use of categories or lexical units. However, several categories are so common as to be nearly universal. Such universal categories include the encoding of the grammatical relations of participants and predicates by grammatically distinguishing between their relations to a predicate, the encoding of temporal and spatial relations on predicates, and a system of grammatical person governing reference to and distinction between speakers and addressees and those about whom they are speaking.\n\nLanguages organize their parts of speech into classes according to their functions and positions relative to other parts. All languages, for instance, make a basic distinction between a group of words that prototypically denotes things and concepts and a group of words that prototypically denotes actions and events. The first group, which includes English words such as \"dog\" and \"song\", are usually called nouns. The second, which includes \"run\" and \"sing\", are called verbs. Another common category is the adjective: words that describe properties or qualities of nouns, such as \"red\" or \"big\". Word classes can be \"open\" if new words can continuously be added to the class, or relatively \"closed\" if there is a fixed number of words in a class. In English, the class of pronouns is closed, whereas the class of adjectives is open, since an infinite number of adjectives can be constructed from verbs (e.g. \"saddened\") or nouns (e.g. with the -like suffix, as in \"noun-like\"). In other languages such as Korean, the situation is the opposite, and new pronouns can be constructed, whereas the number of adjectives is fixed.\n\nWord classes also carry out differing functions in grammar. Prototypically, verbs are used to construct predicates, while nouns are used as arguments of predicates. In a sentence such as \"Sally runs\", the predicate is \"runs\", because it is the word that predicates a specific state about its argument \"Sally\". Some verbs such as \"curse\" can take two arguments, e.g. \"Sally cursed John\". A predicate that can only take a single argument is called \"intransitive\", while a predicate that can take two arguments is called \"transitive\".\n\nMany other word classes exist in different languages, such as conjunctions like \"and\" that serve to join two sentences, articles that introduce a noun, interjections such as \"wow!\", or ideophones like \"splash\" that mimic the sound of some event. Some languages have positionals that describe the spatial position of an event or entity. Many languages have classifiers that identify countable nouns as belonging to a particular type or having a particular shape. For instance, in Japanese, the general noun classifier for humans is \"nin\" (人), and it is used for counting humans, whatever they are called:\n\nFor trees, it would be:\n\nIn linguistics, the study of the internal structure of complex words and the processes by which words are formed is called morphology. In most languages, it is possible to construct complex words that are built of several morphemes. For instance, the English word \"unexpected\" can be analyzed as being composed of the three morphemes \"un-\", \"expect\" and \"-ed\".\n\nMorphemes can be classified according to whether they are independent morphemes, so-called roots, or whether they can only co-occur attached to other morphemes. These bound morphemes or affixes can be classified according to their position in relation to the root: \"prefixes\" precede the root, suffixes follow the root, and infixes are inserted in the middle of a root. Affixes serve to modify or elaborate the meaning of the root. Some languages change the meaning of words by changing the phonological structure of a word, for example, the English word \"run\", which in the past tense is \"ran\". This process is called \"ablaut\". Furthermore, morphology distinguishes between the process of inflection, which modifies or elaborates on a word, and the process of derivation, which creates a new word from an existing one. In English, the verb \"sing\" has the inflectional forms \"singing\" and \"sung\", which are both verbs, and the derivational form \"singer\", which is a noun derived from the verb with the agentive suffix \"-er\".\n\nLanguages differ widely in how much they rely on morphological processes of word formation. In some languages, for example, Chinese, there are no morphological processes, and all grammatical information is encoded syntactically by forming strings of single words. This type of morpho-syntax is often called isolating, or analytic, because there is almost a full correspondence between a single word and a single aspect of meaning. Most languages have words consisting of several morphemes, but they vary in the degree to which morphemes are discrete units. In many languages, notably in most Indo-European languages, single morphemes may have several distinct meanings that cannot be analyzed into smaller segments. For example, in Latin, the word \"bonus\", or \"good\", consists of the root \"bon-\", meaning \"good\", and the suffix -\"us\", which indicates masculine gender, singular number, and nominative case. These languages are called \"fusional languages\", because several meanings may be fused into a single morpheme. The opposite of fusional languages are agglutinative languages which construct words by stringing morphemes together in chains, but with each morpheme as a discrete semantic unit. An example of such a language is Turkish, where for example, the word \"evlerinizden\", or \"from your houses\", consists of the morphemes, \"ev-ler-iniz-den\" with the meanings \"house-plural-your-from\". The languages that rely on morphology to the greatest extent are traditionally called polysynthetic languages. They may express the equivalent of an entire English sentence in a single word. For example, in Persian the single word \"nafahmidamesh\" means \"I didn't understand it\" consisting of morphemes \"na-fahm-id-am-esh\" with the meanings, \"negation.understand.past.I.it\". As another example with more complexity, in the Yupik word \"tuntussuqatarniksatengqiggtuq\", which means \"He had not yet said again that he was going to hunt reindeer\", the word consists of the morphemes \"tuntu-ssur-qatar-ni-ksaite-ngqiggte-uq\" with the meanings, \"reindeer-hunt-future-say-negation-again-third.person.singular.indicative\", and except for the morpheme \"tuntu\" (\"reindeer\") none of the other morphemes can appear in isolation.\n\nMany languages use morphology to cross-reference words within a sentence. This is sometimes called \"agreement\". For example, in many Indo-European languages, adjectives must cross-reference the noun they modify in terms of number, case, and gender, so that the Latin adjective \"bonus\", or \"good\", is inflected to agree with a noun that is masculine gender, singular number, and nominative case. In many polysynthetic languages, verbs cross-reference their subjects and objects. In these types of languages, a single verb may include information that would require an entire sentence in English. For example, in the Basque phrase \"ikusi nauzu\", or \"you saw me\", the past tense auxiliary verb \"n-au-zu\" (similar to English \"do\") agrees with both the subject (you) expressed by the \"n\"- prefix, and with the object (me) expressed by the – \"zu\" suffix. The sentence could be directly transliterated as \"see you-did-me\"\n\nAnother way in which languages convey meaning is through the order of words within a sentence. The grammatical rules for how to produce new sentences from words that are already known is called syntax. The syntactical rules of a language determine why a sentence in English such as \"I love you\" is meaningful, but \"*love you I\" is not. Syntactical rules determine how word order and sentence structure is constrained, and how those constraints contribute to meaning. For example, in English, the two sentences \"the slaves were cursing the master\" and \"the master was cursing the slaves\" mean different things, because the role of the grammatical subject is encoded by the noun being in front of the verb, and the role of object is encoded by the noun appearing after the verb. Conversely, in Latin, both \"Dominus servos vituperabat\" and \"Servos vituperabat dominus\" mean \"the master was reprimanding the slaves\", because \"servos\", or \"slaves\", is in the accusative case, showing that they are the grammatical object of the sentence, and \"dominus\", or \"master\", is in the nominative case, showing that he is the subject.\n\nLatin uses morphology to express the distinction between subject and object, whereas English uses word order. Another example of how syntactic rules contribute to meaning is the rule of inverse word order in questions, which exists in many languages. This rule explains why when in English, the phrase \"John is talking to Lucy\" is turned into a question, it becomes \"Who is John talking to?\", and not \"John is talking to who?\". The latter example may be used as a way of placing special emphasis on \"who\", thereby slightly altering the meaning of the question. Syntax also includes the rules for how complex sentences are structured by grouping words together in units, called phrases, that can occupy different places in a larger syntactic structure. Sentences can be described as consisting of phrases connected in a tree structure, connecting the phrases to each other at different levels. To the right is a graphic representation of the syntactic analysis of the English sentence \"the cat sat on the mat\". The sentence is analyzed as being constituted by a noun phrase, a verb, and a prepositional phrase; the prepositional phrase is further divided into a preposition and a noun phrase, and the noun phrases consist of an article and a noun.\n\nThe reason sentences can be seen as being composed of phrases is because each phrase would be moved around as a single element if syntactic operations were carried out. For example, \"the cat\" is one phrase, and \"on the mat\" is another, because they would be treated as single units if a decision was made to emphasize the location by moving forward the prepositional phrase: \"[And] on the mat, the cat sat\". There are many different formalist and functionalist frameworks that propose theories for describing syntactic structures, based on different assumptions about what language is and how it should be described. Each of them would analyze a sentence such as this in a different manner.\n\nLanguages can be classified in relation to their grammatical types. Languages that belong to different families nonetheless often have features in common, and these shared features tend to correlate. For example, languages can be classified on the basis of their basic word order, the relative order of the verb, and its constituents in a normal indicative sentence. In English, the basic order is SVO: \"The snake(S) bit(V) the man(O)\", whereas for example, the corresponding sentence in the Australian language Gamilaraay would be \"d̪uyugu n̪ama d̪ayn yiːy\" (snake man bit), SOV. Word order type is relevant as a typological parameter, because basic word order type corresponds with other syntactic parameters, such as the relative order of nouns and adjectives, or of the use of prepositions or postpositions. Such correlations are called implicational universals. For example, most (but not all) languages that are of the SOV type have postpositions rather than prepositions, and have adjectives before nouns.\n\nAll languages structure sentences into Subject, Verb, and Object, but languages differ in the way they classify the relations between actors and actions. English uses the nominative-accusative word typology: in English transitive clauses, the subjects of both intransitive sentences (\"I run\") and transitive sentences (\"I love you\") are treated in the same way, shown here by the nominative pronoun \"I\". Some languages, called ergative, Gamilaraay among them, distinguish instead between Agents and Patients. In ergative languages, the single participant in an intransitive sentence, such as \"I run\", is treated the same as the patient in a transitive sentence, giving the equivalent of \"me run\". Only in transitive sentences would the equivalent of the pronoun \"I\" be used. In this way the semantic roles can map onto the grammatical relations in different ways, grouping an intransitive subject either with Agents (accusative type) or Patients (ergative type) or even making each of the three roles differently, which is called the tripartite type.\n\nThe shared features of languages which belong to the same typological class type may have arisen completely independently. Their co-occurrence might be due to universal laws governing the structure of natural languages, \"language universals\", or they might be the result of languages evolving convergent solutions to the recurring communicative problems that humans use language to solve.\n\nWhile humans have the ability to learn any language, they only do so if they grow up in an environment in which language exists and is used by others. Language is therefore dependent on communities of speakers in which children learn language from their elders and peers and themselves transmit language to their own children. Languages are used by those who speak them to communicate and to solve a plethora of social tasks. Many aspects of language use can be seen to be adapted specifically to these purposes. Due to the way in which language is transmitted between generations and within communities, language perpetually changes, diversifying into new languages or converging due to language contact. The process is similar to the process of evolution, where the process of descent with modification leads to the formation of a phylogenetic tree.\n\nHowever, languages differ from biological organisms in that they readily incorporate elements from other languages through the process of diffusion, as speakers of different languages come into contact. Humans also frequently speak more than one language, acquiring their first language or languages as children, or learning new languages as they grow up. Because of the increased language contact in the globalizing world, many small languages are becoming endangered as their speakers shift to other languages that afford the possibility to participate in larger and more influential speech communities.\n\nThe semantic study of meaning assumes that meaning is in a relation between signs and meanings that are firmly established through social convention. However, semantics does not study the way in which social conventions are made and affect language. Rather, when studying the way in which words and signs are used, it is often the case that words have different meanings, depending on the social context of use. An important example of this is the process called deixis, which describes the way in which certain words refer to entities through their relation between a specific point in time and space when the word is uttered. Such words are, for example, the word, \"I\" (which designates the person speaking), \"now\" (which designates the moment of speaking), and \"here\" (which designates the position of speaking). Signs also change their meanings over time, as the conventions governing their usage gradually change. The study of how the meaning of linguistic expressions changes depending on context is called pragmatics. Deixis is an important part of the way that we use language to point out entities in the world. Pragmatics is concerned with the ways in which language use is patterned and how these patterns contribute to meaning. For example, in all languages, linguistic expressions can be used not just to transmit information, but to perform actions. Certain actions are made only through language, but nonetheless have tangible effects, e.g. the act of \"naming\", which creates a new name for some entity, or the act of \"pronouncing someone man and wife\", which creates a social contract of marriage. These types of acts are called speech acts, although they can also be carried out through writing or hand signing.\n\nThe form of linguistic expression often does not correspond to the meaning that it actually has in a social context. For example, if at a dinner table a person asks, \"Can you reach the salt?\", that is, in fact, not a question about the length of the arms of the one being addressed, but a request to pass the salt across the table. This meaning is implied by the context in which it is spoken; these kinds of effects of meaning are called conversational implicatures. These social rules for which ways of using language are considered appropriate in certain situations and how utterances are to be understood in relation to their context vary between communities, and learning them is a large part of acquiring communicative competence in a language.\n\nAll healthy, normally developing human beings learn to use language. Children acquire the language or languages used around them: whichever languages they receive sufficient exposure to during childhood. The development is essentially the same for children acquiring sign or oral languages. This learning process is referred to as first-language acquisition, since unlike many other kinds of learning, it requires no direct teaching or specialized study. In \"The Descent of Man\", naturalist Charles Darwin called this process \"an instinctive tendency to acquire an art\".\n\nFirst language acquisition proceeds in a fairly regular sequence, though there is a wide degree of variation in the timing of particular stages among normally developing infants. From birth, newborns respond more readily to human speech than to other sounds. Around one month of age, babies appear to be able to distinguish between different speech sounds. Around six months of age, a child will begin babbling, producing the speech sounds or handshapes of the languages used around them. Words appear around the age of 12 to 18 months; the average vocabulary of an eighteen-month-old child is around 50 words. A child's first utterances are holophrases (literally \"whole-sentences\"), utterances that use just one word to communicate some idea. Several months after a child begins producing words, he or she will produce two-word utterances, and within a few more months will begin to produce telegraphic speech, or short sentences that are less grammatically complex than adult speech, but that do show regular syntactic structure. From roughly the age of three to five years, a child's ability to speak or sign is refined to the point that it resembles adult language. Studies published in 2013 have indicated that unborn fetuses are capable of language acquisition to some degree.\n\nAcquisition of second and additional languages can come at any age, through exposure in daily life or courses. Children learning a second language are more likely to achieve native-like fluency than adults, but in general, it is very rare for someone speaking a second language to pass completely for a native speaker. An important difference between first language acquisition and additional language acquisition is that the process of additional language acquisition is influenced by languages that the learner already knows.\n\nLanguages, understood as the particular set of speech norms of a particular community, are also a part of the larger culture of the community that speaks them. Languages differ not only in pronunciation, vocabulary, and grammar, but also through having different \"cultures of speaking.\" Humans use language as a way of signalling identity with one cultural group as well as difference from others. Even among speakers of one language, several different ways of using the language exist, and each is used to signal affiliation with particular subgroups within a larger culture. Linguists and anthropologists, particularly sociolinguists, ethnolinguists, and linguistic anthropologists have specialized in studying how ways of speaking vary between speech communities.\n\nLinguists use the term \"varieties\" to refer to the different ways of speaking a language. This term includes geographically or socioculturally defined dialects as well as the jargons or styles of subcultures. Linguistic anthropologists and sociologists of language define communicative style as the ways that language is used and understood within a particular culture.\n\nBecause norms for language use are shared by members of a specific group, communicative style also becomes a way of displaying and constructing group identity. Linguistic differences may become salient markers of divisions between social groups, for example, speaking a language with a particular accent may imply membership of an ethnic minority or social class, one's area of origin, or status as a second language speaker. These kinds of differences are not part of the linguistic system, but are an important part of how people use language as a social tool for constructing groups.\n\nHowever, many languages also have grammatical conventions that signal the social position of the speaker in relation to others through the use of registers that are related to social hierarchies or divisions. In many languages, there are stylistic or even grammatical differences between the ways men and women speak, between age groups, or between social classes, just as some languages employ different words depending on who is listening. For example, in the Australian language Dyirbal, a married man must use a special set of words to refer to everyday items when speaking in the presence of his mother-in-law. Some cultures, for example, have elaborate systems of \"social deixis\", or systems of signalling social distance through linguistic means. In English, social deixis is shown mostly through distinguishing between addressing some people by first name and others by surname, and in titles such as \"Mrs.\", \"boy\", \"Doctor\", or \"Your Honor\", but in other languages, such systems may be highly complex and codified in the entire grammar and vocabulary of the language. For instance, in languages of east Asia such as Thai, Burmese, and Javanese, different words are used according to whether a speaker is addressing someone of higher or lower rank than oneself in a ranking system with animals and children ranking the lowest and gods and members of royalty as the highest.\n\nThroughout history a number of different ways of representing language in graphic media have been invented. These are called writing systems.\n\nThe use of writing has made language even more useful to humans. It makes it possible to store large amounts of information outside of the human body and retrieve it again, and it allows communication across distances that would otherwise be impossible. Many languages conventionally employ different genres, styles, and registers in written and spoken language, and in some communities, writing traditionally takes place in an entirely different language than the one spoken. There is some evidence that the use of writing also has effects on the cognitive development of humans, perhaps because acquiring literacy generally requires explicit and formal education.\n\nThe invention of the first writing systems is roughly contemporary with the beginning of the Bronze Age in the late 4th millennium BC. The Sumerian archaic cuneiform script and the Egyptian hieroglyphs are generally considered to be the earliest writing systems, both emerging out of their ancestral proto-literate symbol systems from 3400–3200 BC with the earliest coherent texts from about 2600 BC. It is generally agreed that Sumerian writing was an independent invention; however, it is debated whether Egyptian writing was developed completely independently of Sumerian, or was a case of cultural diffusion. A similar debate exists for the Chinese script, which developed around 1200 BC. The pre-Columbian Mesoamerican writing systems (including among others Olmec and Maya scripts) are generally believed to have had independent origins.\n\nAll languages change as speakers adopt or invent new ways of speaking and pass them on to other members of their speech community. Language change happens at all levels from the phonological level to the levels of vocabulary, morphology, syntax, and discourse. Even though language change is often initially evaluated negatively by speakers of the language who often consider changes to be \"decay\" or a sign of slipping norms of language usage, it is natural and inevitable.\n\nChanges may affect specific sounds or the entire phonological system. Sound change can consist of the replacement of one speech sound or phonetic feature by another, the complete loss of the affected sound, or even the introduction of a new sound in a place where there had been none. Sound changes can be \"conditioned\" in which case a sound is changed only if it occurs in the vicinity of certain other sounds. Sound change is usually assumed to be \"regular\", which means that it is expected to apply mechanically whenever its structural conditions are met, irrespective of any non-phonological factors. On the other hand, sound changes can sometimes be \"sporadic\", affecting only one particular word or a few words, without any seeming regularity. Sometimes a simple change triggers a chain shift in which the entire phonological system is affected. This happened in the Germanic languages when the sound change known as Grimm's law affected all the stop consonants in the system. The original consonant * became /b/ in the Germanic languages, the previous * in turn became /p/, and the previous * became /f/. The same process applied to all stop consonants and explains why Italic languages such as Latin have \"p\" in words like pater\" and pisces\", whereas Germanic languages, like English, have father\" and fish\".\n\nAnother example is the Great Vowel Shift in English, which is the reason that the spelling of English vowels do not correspond well to their current pronunciation. This is because the vowel shift brought the already established orthography out of synchronization with pronunciation. Another source of sound change is the erosion of words as pronunciation gradually becomes increasingly indistinct and shortens words, leaving out syllables or sounds. This kind of change caused Latin \"mea domina\" to eventually become the French \"madame\" and American English \"ma'am\".\n\nChange also happens in the grammar of languages as discourse patterns such as idioms or particular constructions become grammaticalized. This frequently happens when words or morphemes erode and the grammatical system is unconsciously rearranged to compensate for the lost element. For example, in some varieties of Caribbean Spanish the final /s/ has eroded away. Since Standard Spanish uses final /s/ in the morpheme marking the second person subject \"you\" in verbs, the Caribbean varieties now have to express the second person using the pronoun \"tú\". This means that the sentence \"what's your name\" is \"¿como te llamas?\" in Standard Spanish, but in Caribbean Spanish. The simple sound change has affected both morphology and syntax. Another common cause of grammatical change is the gradual petrification of idioms into new grammatical forms, for example, the way the English \"going to\" construction lost its aspect of movement and in some varieties of English has almost become a full-fledged future tense (e.g. \"I'm gonna\").\n\nLanguage change may be motivated by \"language internal\" factors, such as changes in pronunciation motivated by certain sounds being difficult to distinguish aurally or to produce, or through patterns of change that cause some rare types of constructions to drift towards more common types. Other causes of language change are social, such as when certain pronunciations become emblematic of membership in certain groups, such as social classes, or with ideologies, and therefore are adopted by those who wish to identify with those groups or ideas. In this way, issues of identity and politics can have profound effects on language structure.\n\nOne important source of language change is contact and resulting diffusion of linguistic traits between languages. Language contact occurs when speakers of two or more languages or varieties interact on a regular basis. Multilingualism is likely to have been the norm throughout human history and most people in the modern world are multilingual. Before the rise of the concept of the ethno-national state, monolingualism was characteristic mainly of populations inhabiting small islands. But with the ideology that made one people, one state, and one language the most desirable political arrangement, monolingualism started to spread throughout the world. Nonetheless, there are only 250 countries in the world corresponding to some 6000 languages, which means that most countries are multilingual and most languages therefore exist in close contact with other languages.\n\nWhen speakers of different languages interact closely, it is typical for their languages to influence each other. Through sustained language contact over long periods, linguistic traits diffuse between languages, and languages belonging to different families may converge to become more similar. In areas where many languages are in close contact, this may lead to the formation of language areas in which unrelated languages share a number of linguistic features. A number of such language areas have been documented, among them, the Balkan language area, the Mesoamerican language area, and the Ethiopian language area. Also, larger areas such as South Asia, Europe, and Southeast Asia have sometimes been considered language areas, because of widespread diffusion of specific areal features.\n\nLanguage contact may also lead to a variety of other linguistic phenomena, including language convergence, borrowing, and relexification (replacement of much of the native vocabulary with that of another language). In situations of extreme and sustained language contact, it may lead to the formation of new mixed languages that cannot be considered to belong to a single language family. One type of mixed language called pidgins occurs when adult speakers of two different languages interact on a regular basis, but in a situation where neither group learns to speak the language of the other group fluently. In such a case, they will often construct a communication form that has traits of both languages, but which has a simplified grammatical and phonological structure. The language comes to contain mostly the grammatical and phonological categories that exist in both languages. Pidgin languages are defined by not having any native speakers, but only being spoken by people who have another language as their first language. But if a Pidgin language becomes the main language of a speech community, then eventually children will grow up learning the pidgin as their first language. As the generation of child learners grow up, the pidgin will often be seen to change its structure and acquire a greater degree of complexity. This type of language is generally called a creole language. An example of such mixed languages is Tok Pisin, the official language of Papua New-Guinea, which originally arose as a Pidgin based on English and Austronesian languages; others are Kreyòl ayisyen, the French-based creole language spoken in Haiti, and Michif, a mixed language of Canada, based on the Native American language Cree and French.\n\n\"SIL Ethnologue\" defines a \"living language\" as \"one that has at least one speaker for whom it is their first language\". The exact number of known living languages varies from 6,000 to 7,000, depending on the precision of one's definition of \"language\", and in particular, on how one defines the distinction between languages and dialects. As of 2016, \"Ethnologue\" cataloged 7,097 living human languages. The \"Ethnologue\" establishes linguistic groups based on studies of mutual intelligibility, and therefore often includes more categories than more conservative classifications. For example, the Danish language that most scholars consider a single language with several dialects is classified as two distinct languages (Danish and Jutish) by the \"Ethnologue\".\n\nAccording to the \"Ethnologue\", 389 languages (nearly 6%) have more than a million speakers. These languages together account for 94% of the world's population, whereas 94% of the world's languages account for the remaining 6% of the global population. To the right is a table of the world's 10 most spoken languages with population estimates from the \"Ethnologue\" (2009 figures).\n\nThere is no clear distinction between a language and a dialect, notwithstanding a famous aphorism attributed to linguist Max Weinreich that \"a language is a dialect with an army and navy\". For example, national boundaries frequently override linguistic difference in determining whether two linguistic varieties are languages or dialects. Hakka, Cantonese and Mandarin are, for example, often classified as \"dialects\" of Chinese, even though they are more different from each other than Swedish is from Norwegian. Before the Yugoslav civil war, Serbo-Croatian was considered a single language with two dialects, but now Croatian and Serbian are considered different languages and employ different writing systems. In other words, the distinction may hinge on political considerations as much as on cultural differences, distinctive writing systems, or degree of mutual intelligibility.\n\nThe world's languages can be grouped into language families consisting of languages that can be shown to have common ancestry. Linguists recognize many hundreds of language families, although some of them can possibly be grouped into larger units as more evidence becomes available and in-depth studies are carried out. At present, there are also dozens of language isolates: languages that cannot be shown to be related to any other languages in the world. Among them are Basque, spoken in Europe, Zuni of New Mexico, Purépecha of Mexico, Ainu of Japan, Burushaski of Pakistan, and many others.\n\nThe language family of the world that has the most speakers is the Indo-European languages, spoken by 46% of the world's population. This family includes major world languages like English, Spanish, Russian, and Hindustani (Hindi/Urdu). The Indo-European family achieved prevalence first during the Eurasian Migration Period (c. 400–800 AD), and subsequently through the European colonial expansion, which brought the Indo-European languages to a politically and often numerically dominant position in the Americas and much of Africa. The Sino-Tibetan languages are spoken by 20% of the world's population and include many of the languages of East Asia, including Hakka, Mandarin Chinese, Cantonese, and hundreds of smaller languages.\n\nAfrica is home to a large number of language families, the largest of which is the Niger-Congo language family, which includes such languages as Swahili, Shona, and Yoruba. Speakers of the Niger-Congo languages account for 6.9% of the world's population. A similar number of people speak the Afroasiatic languages, which include the populous Semitic languages such as Arabic, Hebrew language, and the languages of the Sahara region, such as the Berber languages and Hausa.\n\nThe Austronesian languages are spoken by 5.5% of the world's population and stretch from Madagascar to maritime Southeast Asia all the way to Oceania. It includes such languages as Malagasy, Māori, Samoan, and many of the indigenous languages of Indonesia and Taiwan. The Austronesian languages are considered to have originated in Taiwan around 3000 BC and spread through the Oceanic region through island-hopping, based on an advanced nautical technology. Other populous language families are the Dravidian languages of South Asia (among them Kannada Tamil and Telugu), the Turkic languages of Central Asia (such as Turkish), the Austroasiatic (among them Khmer), and Tai–Kadai languages of Southeast Asia (including Thai).\n\nThe areas of the world in which there is the greatest linguistic diversity, such as the Americas, Papua New Guinea, West Africa, and South-Asia, contain hundreds of small language families. These areas together account for the majority of the world's languages, though not the majority of speakers. In the Americas, some of the largest language families include the Quechumaran, Arawak, and Tupi-Guarani families of South America, the Uto-Aztecan, Oto-Manguean, and Mayan of Mesoamerica, and the Na-Dene, Iroquoian, and Algonquian language families of North America. In Australia, most indigenous languages belong to the Pama-Nyungan family, whereas New Guinea is home to a large number of small families and isolates, as well as a number of Austronesian languages.\n\nLanguage endangerment occurs when a language is at risk of falling out of use as its speakers die out or shift to speaking another language. Language loss occurs when the language has no more native speakers, and becomes a \"dead language\". If eventually no one speaks the language at all, it becomes an \"extinct language\". While languages have always gone extinct throughout human history, they have been disappearing at an accelerated rate in the 20th and 21st centuries due to the processes of globalization and neo-colonialism, where the economically powerful languages dominate other languages.\n\nThe more commonly spoken languages dominate the less commonly spoken languages, so the less commonly spoken languages eventually disappear from populations. The total number of languages in the world is not known. Estimates vary depending on many factors. The consensus is that there are between 6,000 and 7,000 languages spoken as of 2010, and that between 50–90% of those will have become extinct by the year 2100. The top 20 languages, those spoken by more than 50 million speakers each, are spoken by 50% of the world's population, whereas many of the other languages are spoken by small communities, most of them with less than 10,000 speakers.\n\nThe United Nations Educational, Scientific and Cultural Organization (UNESCO) operates with five levels of language endangerment: \"safe\", \"vulnerable\" (not spoken by children outside the home), \"definitely endangered\" (not spoken by children), \"severely endangered\" (only spoken by the oldest generations), and \"critically endangered\" (spoken by few members of the oldest generation, often semi-speakers). Notwithstanding claims that the world would be better off if most adopted a single common \"lingua franca\", such as English or Esperanto, there is a consensus that the loss of languages harms the cultural diversity of the world. It is a common belief, going back to the biblical narrative of the tower of Babel in the Old Testament, that linguistic diversity causes political conflict, but this is contradicted by the fact that many of the world's major episodes of violence have taken place in situations with low linguistic diversity, such as the Yugoslav and American Civil War, or the genocide of Rwanda, whereas many of the most stable political units have been highly multilingual.\n\nMany projects aim to prevent or slow this loss by revitalizing endangered languages and promoting education and literacy in minority languages. Across the world, many countries have enacted specific legislation to protect and stabilize the language of indigenous speech communities. A minority of linguists have argued that language loss is a natural process that should not be counteracted, and that documenting endangered languages for posterity is sufficient.\n\n"}
{"id": "4751657", "url": "https://en.wikipedia.org/wiki?curid=4751657", "title": "Lipstick feminism", "text": "Lipstick feminism\n\nLipstick feminism is a variety of third-wave feminism that seeks to embrace traditional concepts of femininity, including the sexual power of women, alongside feminist ideas.\n\nUnlike early feminist campaigns that focused on the basic fundamental rights of women, starting with the Women's Suffrage Movement, lipstick feminism seeks to ascertain that women could still be feminist without ignoring or negating their femininity, particularly in terms of sexuality. During the second wave of feminism, feminists had focused solely on legal and social equality of women and refused to 'embrace' their sexuality; some even abhorred the idea of men and would often take on physical characteristics and persona that was far from what the average woman looked like, thus creating stereotypes of what feminism and feminists looked like. Lipstick feminism, on the other hand, embraces the concepts of womanhood and the female sexuality emitted from a woman's body and the need to embrace sex. Lipstick feminism also seeks to reclaim certain derogatory words and turn them into powerful tools for their cause such as the word 'slut' as seen in the SlutWalk movement. It developed in part as a response to the ideological backlash against radical varieties of second-wave feminism, with the negative stereotypes it generated of the “ugly feminist” or the “anti-sex feminist”; in part the result of the belief that the successes of second-wave feminism had made it possible to reclaim aspects of femininity that had earlier been seen as disempowering, like make-up or stilettos.\n\nLinguistically, lipstick feminism proposed to semantically reclaim, for feminist usage, double-standard insult words, such as “slut”, in order to eliminate the social stigma applied to a woman whose sexual behaviour was \"patriarchically\" interpreted to denote “immoral woman” and libertine.\n\nPhilosophically, lipstick feminism proposes that a woman can be empowered — psychologically, socially, politically – by the wearing of cosmetic make up, sensually-appealing clothes, and the embrace of sexual allure for her own self-image as a confidently sexual being. The rhetoric of choice and empowerment is used to validate such overt sexual practices, because they no longer represent coerced acquiescence to societally established gender roles, such as “the good girl”, “the decent woman”, “the abnegated mother”, “the virtuous sister”, \"et aliæ\".\n\nOther feminists object that the so-called empowerment of lipstick feminism is a philosophic contradiction wherein a woman chooses to sexually objectify herself, and so ceases to be her own woman, in control neither of her self nor of her person. In an ongoing debate, lipstick feminism counter-proposes that the practice of sexual allure is a form of social power in the interpersonal relations between a man and a woman, which may occur in the realms of cultural, social, and gender equality.\n\nStiletto feminism, a more ideologically radical variety of lipstick feminism, sees the postmodern use of fetish fashion as empowering; and extends the argument from the acceptance of makeup, to the validity of women practicing occupations specifically predicated upon female physical beauty, such as working as a striptease dancer or as a pole dancer, as well as flashing or lesbian (girl-on-girl) exhibitionism.\n\n\n\n"}
{"id": "46768799", "url": "https://en.wikipedia.org/wiki?curid=46768799", "title": "List of non-narrative films", "text": "List of non-narrative films\n\nThis is a list of non-narrative feature films.\n\n"}
{"id": "54666819", "url": "https://en.wikipedia.org/wiki?curid=54666819", "title": "Lurish music", "text": "Lurish music\n\nLurish music is referred to an ethno-cultural characteristic of Lurs in the middle-east. The Lurish music enjoys a various and ancient background, and it can be divided into two parts; vocal music and instrumental.\nBased on the songs, the Lurish music is divided into seven sections; \n\nThe most popular Lurish musical instruments include Sorna, Dohol, Tâl (Lurish kamancheh), Tonbak (Tomak), and the common Iranian traditional instruments. Meanwhile, the Lurish kamancheh is the only one that is fundamentally different from other ethnic music instruments.\nThe Lurs select the Mâhur\nas their basic musical step to showcase the magnificence, grandeur and independence of their people.\n\nAfter 1979 revolution of Iran due to intense encounters with musical performances, especially ethnic music, the amount of music participation in different parts of the life of the Lurs was reduced however in the past, cheerful music and lyrics were accompanied with collective dance.\n\n"}
{"id": "18908331", "url": "https://en.wikipedia.org/wiki?curid=18908331", "title": "Mondialogo Engineering Award", "text": "Mondialogo Engineering Award\n\nThe Mondialogo Engineering Award was established by Daimler and UNESCO to encourage cooperation and dialogue between engineering people from different countries and cultures, working together across continents on a joint project activity. The award invites student engineers from universities around the world to apply for Award. It was supported by the World Federation of Engineering Organisations (WFEO), who promoted it to its national members and took part in the judging panel.\nThe scheme has closed with Daimler and UNESCO ending their partnership in 2010. It is not clear if an alternative sponsor or scheme will be created.\n\nThe first round of the competition 2005 ended with a symposium in Berlin while the second round in 2007 ended in Mumbai. In its first round, the Mondialogo Engineering Award brought over 1,700 young engineers from 79 countries together to work on engineering solutions tackling poverty and promoting sustainable development in all regions of the world. While in the second round 3200 students from 89 countries participated.\n\nThe Mondialogo Engineering Award invited engineering students in developing and developed countries to form international teams to create project proposals that address the United Nations Millennium Development to 1) eradicate extreme poverty and hunger; 2) achieve universal primary education; 3) promote gender equality and empower women; 4) reduce child mortality; 5) improve maternal health; 6) combat HIV/AIDS, malaria and other diseases; 7) ensure environmental sustainability; and 8) develop global partnerships for development. Mondialogo encourages proposals that will improve the quality of life in the developing world, particularly poverty eradication and the promotion of sustainable development.\n\nInternational Project Teams eligible to apply for the Mondialogo Engineering Award consisted of two student groups from two higher education establishments, with one group from a developing country and the other from a developed country. The Mondialogo Internet Portal www.mondialogo.org acts as a contact centre for groups to meet each other, aiming to function as a virtual office for inter-group communications. Teams had until April 2009 to develop and design their project proposals. An international jury then assessed the entries and decide on the awarding, which formed part of a festive ceremony in latter 2009. Key factors in the assessment are sustainability, technical quality, feasibility of the project proposals and the quality of the intercultural cooperation between the teams.\n\nThe following criteria were taken into consideration when assessing the final project proposals:\nQuality of project – quality of analysis and understanding of a relevant problem, quality and innovativeness of project idea and design, and quality of presentation of the project proposal \nDegree to which the project addresses the Millennium Development Goals, especially poverty eradication and sustainable social development \nRelevance of project proposal in mitigating negative impacts of climate change \nFeasibility of the proposed project – demonstration of the practicality of implementing the proposed project, and benefit to local community; \nQuality of Dialogue – level of communication within project teams and student groups, balanced involvement of both student groups\n\nTen Mondialogo Engineering Awards of €20,000 went to teams with the top project proposals, with an Honourable Mention and €5,000 earmarked for twenty more teams. Representatives of the 30 finalist project teams (consisting of one member of each student group two members of each International Project Team) were invited to the Mondialogo Engineering Award Symposium. At the Symposium, each team made a presentation of their project proposal, followed by an Award Ceremony where the Mondialogo Engineering Awards and Honourable Mentions were announced. All participating teams that submit project proposals received an official certificate in recognition of their achievements and their commitment to the worldwide exchange of knowledge and intercultural dialogue. Additionally, Daimler and UNESCO publicized the 30 winning projects.\n\nStudents from all fields of engineering were eligible to register for the Mondialogo Engineering Award. All members of the two (or more) student groups must have been officially registered as students at universities, technical colleges or similar institutions through to May 2009. Employees of commercial institutions and companies or students above 35 years of age were not eligible to participate.\n\nMondialogo Web Site\n\n"}
{"id": "718763", "url": "https://en.wikipedia.org/wiki?curid=718763", "title": "Narratology", "text": "Narratology\n\nNarratology is the study of narrative and narrative structure and the ways that these affect our perception. While in principle the word may refer to any systematic study of narrative, in practice its usage is rather more restricted. It is an anglicisation of French \"narratologie\", coined by Tzvetan Todorov (\"Grammaire du Décaméron\", 1969). Narratology is applied retrospectively as well to work predating its coinage. Its theoretical lineage is traceable to Aristotle (\"Poetics\") but modern narratology is agreed to have begun with the Russian Formalists, particularly Vladimir Propp (\"Morphology of the Folktale\", 1928), and Mikhail Bakhtin's theories of heteroglossia, dialogism, and the chronotope first presented in \"The Dialogic Imagination\" (1975).\n\nThe origins of narratology lend to it a strong association with the structuralist quest for a formal system of useful description applicable to any narrative content, by analogy with the grammars used as a basis for parsing sentences in some forms of linguistics. This procedure does not however typify all work described as narratological today; Percy Lubbock's work in point of view (\"The Craft of Fiction\", 1921) offers a case in point.\n\nIn 1966 a special issue of the journal \"Communications\" proved highly influential, becoming considered a program for research into the field and even a manifesto. It included articles by Barthes, Claude Brémond, Genette, Greimas, Todorov and others, which in turn often referred to the works of Vladimir Propp (1895–1970).\n\nJonathan Culler (2001) describes narratology as comprising many strands \nimplicitly united in the recognition that narrative theory requires a distinction between \"story,\" a sequence of actions or events conceived as independent of their manifestation in discourse, and \"discourse,\" the discursive presentation or narration of events.'\nThe Russian Formalists first proposed such a distinction, employing the couplet fabula and sujet. A subsequent succession of alternate pairings has preserved the essential binomial impulse, e.g. \"histoire\"/\"discours\", \"histoire\"/\"récit\", \"story\"/\"plot\". The Structuralist assumption that one can investigate fabula and sujet separately gave birth to two quite different traditions: thematic (Propp, Bremond, Greimas, Dundes, et al.) and modal (Genette, Prince, et al.) narratology. The former is mainly limited to a semiotic formalization of the sequences of the actions told, while the latter examines the manner of their telling, stressing voice, point of view, transformation of the chronological order, rhythm and frequency. Many authors (Sternberg, 1993, Ricoeur, 1984, and Baroni, 2007) have insisted that thematic and modal narratology should not be looked at separately, especially when dealing with the function and interest of narrative sequence and plot.\n\nJames Phelan, editor of \"Narrative\" (the journal of the International Society for the Study of Narrative), has written numerous books and articles on narrative theory (see reference list). With Frederick Luis Aldama, Brian McHale and Robyn Warhol, Phelan directs Project Narrative at The Ohio State University:)\n\nDesignating work as narratological is to some extent dependent more on the academic discipline in which it takes place than any theoretical position advanced. The approach is applicable to any narrative, and in its classic studies, vis-a-vis Propp, non-literary narratives were commonly taken up. Still the term \"narratology\" is most typically applied to literary theory and literary criticism, as well as film theory and (to a lesser extent) film criticism. Atypical applications of narratological methodologies would include sociolinguistic studies of oral storytelling (William Labov) and in conversation analysis or discourse analysis that deal with narratives arising in the course of spontaneous verbal interaction. It also includes the study of videogames, graphic novels, the infinite canvas, and narrative sculptures linked to topology and graph theory.\nHowever, constituent analysis of a type where narremes are considered to be the basic units of narrative structure could fall within the areas of linguistics, semiotics, or literary theory.\n\n\n\n"}
{"id": "4952057", "url": "https://en.wikipedia.org/wiki?curid=4952057", "title": "Nazareth College (New York)", "text": "Nazareth College (New York)\n\nNazareth College is a coeducational, private, religiously independent college in Pittsford, a suburb of Rochester, in the U.S. state of New York. Founded by the Sisters of St. Joseph in 1924, the college offers more than 60 undergraduate majors and 24 graduate programs. Alumni and locals commonly refer to the school as \"Naz\" for short. \n\nAt the request of Bishop Thomas Francis Hickey of Rochester, five Sisters of St. Joseph founded Nazareth College of Rochester in 1924. The first class was composed of 25 young women who began their studies in a large mansion on Lake Avenue in Rochester, New York. The original mansion that housed the college was known as \"the Glass House.\" At that time, the college offered Bachelor of Arts and Bachelor of Science degrees, each with a liberal arts core. In response to increasing enrollment, the college moved to a larger facility in 1928 at 402 Augustine Street.\n\nIn January 1942, the college moved to its present campus on East Avenue in the suburb of Pittsford. In the 1950s, the college responded to the need for graduate study by adding majors and by the 1970s offered programs in teacher education and social work. Study abroad programs and intercollegiate sports were also added in the 1970s. During this time, the college became co-educational and independent of the Roman Catholic Church. \n\nNazareth competed in men’s intercollegiate athletics for the first time in 1977. The official nickname of the sports teams became the Golden Flyers — golden for the Nazareth color, and flyers for the bird-like symbol that is part of the old Nazareth logo. Today, Nazareth supports 25 varsity teams. The most recent sport, added in 2018, is women's ice hockey.\n\nIn the early 2000s, the college purchased adjacent land from the Sisters of St. Joseph, including the former Motherhouse and Infirmary. This acquisition doubled the campus size to its current 150 acres. As a result of support from college benefactors (including Tom Golisano, the founder of Paychex), the Motherhouse became the Golisano Academic Center. The Infirmary became George Hall, a residence hall that also houses a coffeehouse and late night study area. The decade of the 2000s also saw the construction of additional student housing, including Portka Hall, Clock Tower Commons, and the Lyons and Breen apartment buildings.\n\nIn 2003, 30 years after becoming religiously independent, Nazareth College was removed from \"The Official Catholic Directory,\" having been declared no longer a Catholic institution by Rochester Bishop Matthew H. Clark. It was the second time since Pope John Paul II issued Ex Corde Ecclesiae, the apostolic constitution on Catholic universities in 1990, a bishop declared a historically Catholic college or university to be not Catholic.\n\nIn 2012, Nazareth added Peckham Hall, the Integrated Center for Math and Science. Named after lead donors Nancy and Larry Peckham, the $30 million facility supports majors in math and science fields, as well as education programs. It also provides important learning facilities for students in health and human services programs. \nIn 2015, the York Wellness and Rehabilitation Institute opened after an extensive renovation/expansion of Carroll Hall consolidated and doubled the size of the clinics associated with the college's School of Health and Human Services and added collaboration space.\n\nNazareth College is organized into four core schools:\n\nNazareth offers more than 60 four-year undergraduate programs, 20 master's degree programs, a Doctorate of Physical Therapy, and three post-baccalaureate certificate programs. \n\nUndergraduate Majors and Programs\n\nAccounting,\nActing,\nAmerican Studies,\nAnthropology,\nArt Education,\nArt History,\nArt (Studio Art), \nArt (Visual Communication Design),\nBiochemistry,\nBiology,\nBiomedical Sciences,\nBusiness Management,\nChemistry,\nChinese,\nClinical Laboratory Sciences,\nCommunication and Media,\nCommunication Sciences and Disorders (Speech Therapy),\nCommunity Youth Development,\nDance Studies,\nEconomics,\nEducation (Adolescence Education, Early Childhood and Elementary),\nEducation (Special Education),\nEnglish,\nEnvironmental Science and Sustainability,\nFinance,\nFrench,\nGuided Exploration of Majors (for undeclared majors)\nHistory,\nInternational and Global Studies,\nItalian,\nLaw (3+3 with Syracuse U.),\nLegal Studies,\nMarketing,\nMathematics,\nModern Foreign Languages,\nMuseums, Archives, and Public History,\nMusic,\nMusic/Business,\nMusic Composition,\nMusic Education,\nMusic Performance,\nMusic Therapy,\nMusical Theatre,\nNursing,\nNursing Accelerated Weekend R.N. to B.S.,\nOccupational Therapy,\nPeace and Justice,\nPhilosophy,\nPhysical Therapy,\nPolitical Science,\nPsychology,\nPublic Health,\nReligious Studies,\nSocial Science,\nSocial Work,\nSociology,\nSpanish,\nTechnical Production,\nTheatre Arts,\nToxicology,\nUndeclared program,\nWomen and Gender Studies.\n\nGraduate Programs\nAmerican Studies, \nArt Education, \nArt Therapy,\nBusiness Organization and Management, \nEducational Technology Specialist, \nESOL (post-master's certification program),\nHigher Education Student Affairs Administration, \nHuman Resource Development, \nHuman Resource Management, \nInclusive Adolescence Education (to teach grades 7-12), \nInclusive Childhood Education (to teach grades 1-6), \nInclusive Early Childhood Education (to teach birth-grade 2), \nIntegrated Marketing Communications, \nLeadership and Change Management, \nLiteracy Specialist, \nMusic Education, \nMusic Therapy, \nPerformance and Pedagogy, \nPhysical Therapy, \nSocial Work, \nSpeech-Language Pathology, \nTESOL (with and without N.Y. state teaching certification)\n\nCore curriculum\n\nIn 2013, Nazareth College revised its liberal arts core, required for all undergraduates.\n\nFulbright Program at Nazareth\n\nHonors Program\n\nClinton Global Initiative University\n\nIn fall 2013, Nazareth College joined the Clinton Global Initiative University Network (CGI U), a consortium of colleges and universities that support, mentor, and provide seed funding to student leaders who are developing solutions to the world's most pressing challenges. From 2014 to 2017, CGI U selected a total of 26 students from Nazareth College to attend its three-day international conference, based on the strength of the projects they proposed in health, education, youth empowerment, and the environment.\n\n\n\nRenovated in 2009, the Nazareth College Arts Center is a campus venue with spaces including:\n\nThe Nazareth College Arts Center is the home of Bach Children’s Chorus as well as the performance home of Rochester City Ballet and Garth Fagan Dance. The Arts Center houses the Nazareth College departments of Art, Music, and Theatre & Dance.\n\nThe Center for Interfaith Studies and Dialogue (CISD) at Nazareth College was founded in 2005. In 2011, International Institute of Islamic Thought (IIIT) of Herndon, Virginia offered Nazareth a major gift, provided it was matched by local donors. Brian and Jean Hickey matched this gift, resulting in renaming the center the Hickey Center for Interfaith Studies and Dialogue at Nazareth College. The endowed chair of the Center was left to the IIIT, and they selected Dr. Muhammad Shafiq, who was imam of the Islamic Center of Rochester, the Rochester metropolitan area's largest mosque. The Center is part of Nazareth’s College of Arts and Sciences and located in the Golisano Academic Center. Dr. Muhammad Shafiq is the executive director of the Hickey Center for Interfaith Studies and Dialogue and a professor of Islamic and religious studies at the college.\n\nThe Casa Italiana (Italian House) is a center of Italian language, literature, and culture. It serves as a cultural center for the college and the Rochester metropolitan area. Built with the help of the Italian-American community of greater Rochester in 1978, the Casa promotes traditional and contemporary Italian culture, explores the Italian-American experience, and seeks to enhance exchanges between the United States and Italy. The reading room at the Casa provides the college and the community with language and culture resources, and the classroom provides an environment in which students and community members can study the Italian language. Cultural events organized by the Casa include lectures, cooking and language classes, film nights, conferences, concerts, seminars, symposia, bocce tournaments, art shows, and trips to Italy.\nLa Maison Française (French House) is a home converted into a cultural center and residence hall for 13 selected foreign language majors. The French House offers a living environment and resource center for students who wish to immerse themselves in French culture and practice speaking French. La Maison Française also offers a line-up of cultural events throughout the year. Such gatherings, which include French film nights, cultural and historical lectures, reader’s theater showcases, Francophone regional dinners and campus diversity dinners, occur on Thursday evenings and are prepared by the French department and the house residents.\n\nAt the heart of the Spanish program is the Casa Hispana, a lively place where students and community members enjoy films, conversation, art exhibitions, and a variety of events relating to the culture of Spain and the Latin American countries. The Casa also houses the offices of the Spanish program faculty, a library, and classrooms.\n\n\nNazareth's men's and women's athletic teams are members of the National Collegiate Athletic Association's (NCAA) Division III. The Golden Flyers are a member of the Empire 8 Athletic Conference (Empire 8). For men's volleyball, Nazareth is a member of the single-sport United Volleyball Conference and for men's ice hockey, a member of the United Collegiate Hockey Conference. Athletic facilities at Nazareth include the Robert A. Kidera Gymnasium (1,200) and Golden Flyer Stadium (2,200).\n\nMen's sports include basketball, cross country, equestrian, golf, ice hockey, lacrosse, soccer, swimming & diving, tennis, track & field, and volleyball; while women's sports include basketball, cross country, equestrian, field hockey, golf, lacrosse, soccer, softball, swimming & diving, tennis, track & field, volleyball, and dance. The College announced plans to add women's hockey in 2018.\n\nThe Nazareth men's lacrosse team is a three-time NCAA Division III National Champion (1992, 1996, and 1997). The team has also appeared in the NCAA postseason tournament nineteen times. In 2011, the Nazareth men's indoor volleyball team achieved a #1 national ranking and won the Molten Division III National Championship, while in 2013 they finished runner-up in the NCAA Division III championship to Springfield.\n\nNazareth College's traditional rival is St. John Fisher College, just a mile to the north. The annual men's basketball game between the schools is known as \"The Battle of the Beaks.\"\n\nMore than 95 percent of students are involved in community service through academic service-learning, student organizations, athletics, and residence life. Nazareth has an on-campus Center for Civic Engagement to serve as a resource for students, staff and faculty who want to learn and serve in the context of the local, regional, national and global communities. The Center is also a point of contact for community members seeking College involvement with local organizations, programs and projects. The school also has a campus ministry program to connect students to various volunteer organizations. In addition, over 60% of alumni are known to participate regularly in community service. In 2007, the college was named to the President's Higher Education Community Service Honor Roll (with distinction). And in 2013, Nazareth was only one of five schools in the country named to the 2013 President's Higher Education Community Service Honor Roll, the highest honor a college or university can receive, at the federal level, for its commitment to volunteering, service-learning, and civic engagement.\n\nNazareth has more than 33,000 alumni residing in all 50 states and 38 countries around the world.\nNotable Nazareth alumni include:\n\n\nFor more: Annual Events Calendar\n\n"}
{"id": "64073", "url": "https://en.wikipedia.org/wiki?curid=64073", "title": "New World Syndrome", "text": "New World Syndrome\n\nNew World Syndrome is a set of non-communicable diseases brought on by consumption of junk food and a sedentary lifestyle, especially common to the indigenous peoples of the \"New World\" (i.e. of the Americas). Indigenous peoples of Oceania and Circumpolar peoples, and perhaps other populations of Asiatic origin are similarly affected and perhaps genetically predisposed. It is characterized by obesity, heart disease, diabetes, hypertension, and shortened life span.\n\nNew World Syndrome is linked to a change from a traditional diet and exercise to a Western diet and a sedentary lifestyle. Along with the lack of money. Traditional occupations of indigenous people—such as fishing, farming, and hunting—tended to involve constant activity, whereas modern office jobs do not. The introduction of modern transportation such as automobiles also decreased physical exertion. Meanwhile, Western foods which are rich in fat, salt, sugar, and refined starches are also imported into countries. The amount of carbohydrates in diets increases.\n\n\nRelated:\n\n"}
{"id": "20082214", "url": "https://en.wikipedia.org/wiki?curid=20082214", "title": "Obsessive–compulsive disorder", "text": "Obsessive–compulsive disorder\n\nObsessive–compulsive disorder (OCD) is a mental disorder where people feel the need to check things repeatedly, perform certain routines repeatedly (called \"rituals\"), or have certain thoughts repeatedly (called \"obsessions\"). People are unable to control either the thoughts or the activities for more than a short period of time. Common activities include hand washing, counting of things, and checking to see if a door is locked. Some may have difficulty throwing things out. These activities occur to such a degree that the person's daily life is negatively affected. This often takes up more than an hour a day. Most adults realize that the behaviors do not make sense. The condition is associated with tics, anxiety disorder, and an increased risk of suicide.\nThe cause is unknown. There appear to be some genetic components with both identical twins more often affected than both non-identical twins. Risk factors include a history of child abuse or other stress-inducing event. Some cases have been documented to occur following infections. The diagnosis is based on the symptoms and requires ruling out other drug related or medical causes. Rating scales such as the Yale–Brown Obsessive Compulsive Scale (Y-BOCS) can be used to assess the severity. Other disorders with similar symptoms include anxiety disorder, major depressive disorder, eating disorders, tic disorders, and obsessive–compulsive personality disorder.\nTreatment involves counseling, such as cognitive behavioral therapy (CBT), and sometimes antidepressants such as selective serotonin reuptake inhibitors (SSRIs) or clomipramine. CBT for OCD involves increasing exposure to what causes the problems while not allowing the repetitive behavior to occur. While clomipramine appears to work as well as SSRIs, it has greater side effects so is typically reserved as a second line treatment. Atypical antipsychotics may be useful when used in addition to an SSRI in treatment-resistant cases but are also associated with an increased risk of side effects. Without treatment, the condition often lasts decades.\nObsessive–compulsive disorder affects about 2.3% of people at some point in their life. Rates during a given year are about 1.2%, and it occurs worldwide. It is unusual for symptoms to begin after the age of 35, and half of people develop problems before 20. Males and females are affected about equally. In English, the phrase \"obsessive–compulsive\" is often used in an informal manner unrelated to OCD to describe someone who is excessively meticulous, perfectionistic, absorbed, or otherwise fixated.\nOCD can present with a wide variety of symptoms. Certain groups of symptoms usually occur together. These groups are sometimes viewed as dimensions or clusters that may reflect an underlying process. The standard assessment tool for OCD, the Yale–Brown Obsessive Compulsive Scale (Y-BOCS), has 13 predefined categories of symptoms. These symptoms fit into three to five groupings. A meta analytic review of symptom structures found a four factor structure (grouping) to be most reliable. The observed groups included a \"symmetry factor\", a \"forbidden thoughts factor\", a \"cleaning factor\", and a \"hoarding factor\". The \"symmetry factor\" correlated highly with obsessions related to ordering, counting, and symmetry, as well as repeating compulsions. The \"forbidden thoughts factor\" correlated highly with intrusive and distressing thoughts of a violent, religious, or sexual nature. The \"cleaning factor\" correlated highly with obsessions about contamination and compulsions related to cleaning. The \"hoarding factor\" only involved hoarding related obsessions and compulsions, and was identified as being distinct from other symptom groupings.\n\nWhile OCD has been considered a homogenous disorder from a neuropsychological perspective, many of the putative neuropsychological deficits may be due to comorbid disorders. Furthermore, some subtypes have been associated with improvement in performance on certain tasks such as pattern recognition (washing subtype) and spatial working memory (obsessive thought subtype). Subgroups have also been distinguished by neuroimaging findings and treatment response. Neuroimaging studies on this have been too few, and the subtypes examined have differed too much to draw any conclusions. On the other hand, subtype dependent treatment response has been studied, and the hoarding subtype has consistently responded least to treatment.\n\nObsessions are thoughts that recur and persist, despite efforts to ignore or confront them. People with OCD frequently perform tasks, or compulsions, to seek relief from obsession-related anxiety. Within and among individuals, the initial obsessions, or intrusive thoughts, vary in their clarity and vividness. A relatively vague obsession could involve a general sense of disarray or tension accompanied by a belief that life cannot proceed as normal while the imbalance remains. A more intense obsession could be a preoccupation with the thought or image of someone close to them dying or intrusions related to \"relationship rightness\". Other obsessions concern the possibility that someone or something other than oneself—such as God, the Devil, or disease—will harm either the person with OCD or the people or things that the person cares about. Other individuals with OCD may experience the sensation of invisible protrusions emanating from their bodies, or have the feeling that inanimate objects are ensouled.\n\nSome people with OCD experience sexual obsessions that may involve intrusive thoughts or images of \"kissing, touching, fondling, oral sex, anal sex, intercourse, incest, and rape\" with \"strangers, acquaintances, parents, children, family members, friends, coworkers, animals, and religious figures\", and can include \"heterosexual or homosexual content\" with persons of any age. As with other intrusive, unpleasant thoughts or images, some disquieting sexual thoughts at times are normal, but people with OCD may attach extraordinary significance to the thoughts. For example, obsessive fears about sexual orientation can appear to the person with OCD, and even to those around them, as a crisis of sexual identity. Furthermore, the doubt that accompanies OCD leads to uncertainty regarding whether one might act on the troubling thoughts, resulting in self-criticism or self-loathing.\n\nMost people with OCD understand that their notions do not correspond with reality; however, they feel that they must act as though their notions are correct. For example, an individual who engages in compulsive hoarding might be inclined to treat inorganic matter as if it had the sentience or rights of living organisms, while accepting that such behavior is irrational on a more intellectual level. There is a debate as to whether or not hoarding should be considered with other OCD symptoms.\n\nOCD sometimes manifests without overt compulsions, referred to as Primarily Obsessional OCD. OCD without overt compulsions could, by one estimate, characterize as many as 50 percent to 60 percent of OCD cases.\n\nSome people with OCD perform compulsive rituals because they inexplicably feel they have to, while others act compulsively so as to mitigate the anxiety that stems from particular obsessive thoughts. The person might feel that these actions somehow either will prevent a dreaded event from occurring or will push the event from their thoughts. In any case, the individual's reasoning is so idiosyncratic or distorted that it results in significant distress for the individual with OCD or for those around them. Excessive skin picking, hair-pulling, nail biting, and other body-focused repetitive behavior disorders are all on the obsessive–compulsive spectrum. Some individuals with OCD are aware that their behaviors are not rational, but feel compelled to follow through with them to fend off feelings of panic or dread.\n\nSome common compulsions include hand washing, cleaning, checking things (e.g., locks on doors), repeating actions (e.g., turning on and off switches), ordering items in a certain way, and requesting reassurance. Compulsions are different from tics (such as touching, tapping, rubbing, or blinking) and stereotyped movements (such as head banging, body rocking, or self-biting), which usually aren't as complex and aren't precipitated by obsessions. It can sometimes be difficult to tell the difference between compulsions and complex tics. About 10% to 40% of individuals with OCD also have a lifetime tic disorder.\n\nPeople rely on compulsions as an escape from their obsessive thoughts; however, they are aware that the relief is only temporary, that the intrusive thoughts will soon return. Some people use compulsions to avoid situations that may trigger their obsessions. Although some people do certain things over and over again, they do not necessarily perform these actions compulsively. For example, bedtime routines, learning a new skill, and religious practices are not compulsions. Whether or not behaviors are compulsions or mere habit depends on the context in which the behaviors are performed. For example, arranging and ordering DVDs for eight hours a day would be expected of one who works in a video store, but would seem abnormal in other situations. In other words, habits tend to bring efficiency to one's life, while compulsions tend to disrupt it.\n\nIn addition to the anxiety and fear that typically accompanies OCD, sufferers may spend hours performing such compulsions every day. In such situations, it can be hard for the person to fulfil their work, family, or social roles. In some cases, these behaviors can also cause adverse physical symptoms. For example, people who obsessively wash their hands with antibacterial soap and hot water can make their skin red and raw with dermatitis.\n\nPeople with OCD can use rationalizations to explain their behavior; however, these rationalizations do not apply to the overall behavior but to each instance individually. For example, a person compulsively checking the front door may argue that the time taken and stress caused by one more check of the front door is much less than the time and stress associated with being robbed, and thus checking is the better option. In practice, after that check, the person is \"still\" not sure and deems it is \"still\" better to perform one more check, and this reasoning can continue as long as necessary.\n\nThe DSM-V contains three specifiers for the level of insight in OCD. Good or fair insight is characterized by the acknowledgment that obsessive-compulsive beliefs are or may not be true. Poor insight is characterized by the belief that obsessive-complsive beliefs are probably true. Absence of insight make obsessive-compulsive beliefs delusional thoughts, and occurs in about 4% of people with OCD.\n\nSome people with OCD exhibit what is known as \"overvalued ideas\". In such cases, the person with OCD will truly be uncertain whether the fears that cause them to perform their compulsions are irrational or not. After some discussion, it is possible to convince the individual that their fears may be unfounded. It may be more difficult to do ERP therapy on such people because they may be unwilling to cooperate, at least initially. There are severe cases in which the person has an unshakeable belief in the context of OCD that is difficult to differentiate from psychotic disorders.\n\nA 2013 meta-analysis reported that people with OCD to have mild but wide-ranging cognitive deficits; significantly regarding spatial memory, to a lesser extent with verbal memory, fluency, executive function, and processing speed, while auditory attention was not significantly affected. People with OCD show impairment in formulating an organizational strategy for coding information, set-shifting, and motor and cognitive inhibition.\n\nSpecific subtypes of symptom dimensions in OCD have been associated with specific cognitive deficits. For example, the results of one meta-analysis comparing washing and checking symptoms reported that washers outperformed checkers on eight out of ten cognitive tests. The symptom dimension of contamination and cleaning may be associated with higher scores on tests of inhibition and verbal memory.\n\nApproximately 1–2% of children are affected by OCD. Obsessive–compulsive disorder symptoms tend to develop more frequently in children that are 10–14 years of age, with males displaying symptoms at an earlier age and a more severe level than the females. In children, symptoms can be grouped into at least 4 types.\n\nThe cause is unknown. Both environmental and genetic factors are believed to play a role. Risk factors include a history of child abuse or other stress-inducing event.\n\nThere appear to be some genetic components with identical twins more often affected than non-identical twins. Further, individuals with OCD are more likely to have first-degree family members exhibiting the same disorders than do matched controls. In cases where OCD develops during childhood, there is a much stronger familial link in the disorder than cases in which OCD develops later in adulthood. In general, genetic factors account for 45–65% of the variability in OCD symptoms in children diagnosed with the disorder. A 2007 study found evidence supporting the possibility of a heritable risk for OCD.\n\nA mutation has been found in the human serotonin transporter gene, hSERT, in unrelated families with OCD.\n\nA systematic review found that while neither allele was associated with OCD overall, in caucasians the L allele was associated with OCD. Another meta analysis observed an increased risk in those with the homozygous S allele, but found the LS genotype to be inversely associated with OCD.\n\nA genome wide association study found OCD to be linked with SNPs near BTBD3 and two SNPs in DLGAP1 in a trio-based analysis, but no SNP reached significance when analyzed with case-control data.\n\nOne meta analysis found a small but significant association between a polymorphism in SLC1A1 and OCD.\n\nThe relationship between OCD and COMT has been inconsistent, with one meta analysis reporting a significant association, albeit only in men, and another meta analysis reporting no association.\n\nIt has been postulated by evolutionary psychologists that moderate versions of compulsive behavior may have had evolutionary advantages. Examples would be moderate constant checking of hygiene, the hearth or the environment for enemies. Similarly, hoarding may have had evolutionary advantages. In this view OCD may be the extreme statistical \"tail\" of such behaviors, possibly due to a high amount of predisposing genes.\n\nA controversial hypothesis is that some cases of rapid onset of OCD in children and adolescents may be caused by a syndrome connected to Group A streptococcal infections, known as pediatric autoimmune neuropsychiatric disorders associated with streptococcal infections (PANDAS).\n\nA review of studies examining anti-basal ganglia antibodies in OCD found an increased risk of having anti-basal ganglia antibodies in those with OCD versus the general population.\n\nFunctional neuroimaging during symptom provocation has observed abnormal activity in the orbitofrontal cortex, left dorsolateral prefrontal cortex, right premotor cortex, left superior temporal gyrus, globus pallidus externus, hippocampus and right uncus. Weaker foci of abnormal activity were found in the left caudate, posterior cingulate cortex and superior parietal lobule. However, an older meta analysis of functional neuroimaging in OCD reported the only consistent functional neuroimaging findings have been increased activity in the orbital gyrus and head of the caudate nucleus, while ACC activation abnormalities were too inconsistent. A meta analysis comparing affective and non affective tasks observed differences with controls in regions implicated in salience, habit, goal ditected behavior, self-referential thinking and cognitive control. For non affective tasks, hyperactivity was observed in the insula, ACC, and head of the caudate/putamen, while hypoactivity was observed in the medial prefrontal cortex(mPFC) and posterior caudate. Affective tasks were observed to relate to increased activation in the precuneus and posterior cingulate cortex(PCC), while decreased activation was found in the pallidum, ventral anterior thalamus and postetior caudate. The involvement of the cortico-striato-thalamo-cortical loop in OCD as well as the high rates of comorbidity between OCD and ADHD have led some to draw a link in their mechanism. Observed similarities include dysfunction of the anterior cingulate cortex, and prefrontal cortex, as well as shared deficits in executive functions. The involvement of the orbitofrontal cortex and dorsolateral prefrontal cortex in OCD is shared with Bipolar Disorder and may explain their high degree of comorbidity. Decreased volumes of the dorsolateral prefrontal cortex related to executive function has also been observed in OCD.\n\nPeople with OCD evince increased grey matter volumes in bilateral lenticular nuclei, extending to the caudate nuclei, with decreased grey matter volumes in bilateral dorsal medial frontal/anterior cingulate gyri. These findings contrast with those in people with other anxiety disorders, who evince decreased (rather than increased) grey matter volumes in bilateral lenticular / caudate nuclei, as well as decreased grey matter volumes in bilateral dorsal medial frontal/anterior cingulate gyri. Increased white matter volume and decreased fractional anisotropy in anterior midline tracts has been observed in OCD, possibly indicating increased fiber crossings.\n\nGenerally two categories of models for OCD have been postulated, the first involving deficits in executive function, and the second involving deficits in modulatory control. The first category of executive dysfunction is based on the observed structural and functional abnormalities in the dlPFC, striatum, and thalamus. The second category involving dysfunctional modulatory control primarily relies on observed functional and structural differences in the ACC, mPFC and OFC.\n\nOne proposed model suggests that dysfunction in the OFC leads to improper valuation of behaviors and decreased behavioral control, while the observed alterations in amygdala activations leads to exaggerated fears and representations of negative stimuli.\n\nDue to the heterogeneity of OCD symptoms, studies differentiating between symptoms have been performed. Symptom specific neuroimaging abnormalities include the hyperactivity of caudate and ACC in checking rituals, while finding increased activity of cortical and cerebellar regions in contamination related symptoms. Neuroimaging differentiating between content of intrusive thoughts have found differences between aggressive as opposed to taboo thoughts, finding increased connectivity of the amygdala, ventral striatum, and ventromedial prefrontal cortex in aggressive symptoms, while observing increased connectivity between the ventral striatum and insula in sexual/religious intrusive thoughts.\n\nAnother model proposes that affective dysregulation links excessive reliance on habit based action selection with compulsions. This is supported by the observation that those with OCD demonstrate decreased activation of the ventral striatum when anticipating monetary reward, as well as increase functional connectivity between the VS and the OFC. Furthermore, those with OCD demonstrate reduced performance in pavlovian fear extinction tasks, hyper responsiveness in the amygdala to fearful stimuli, and hypo-resonsiveness in the amygdala when exposed to positively valanced stimuli. Stimulation of the nucleus accumbens has also been observed to effectively alleviate both obsessions and compulsions, supporting the role of affective dysregulation in generating both.\n\nFrom the observation of the efficacy of antidepressants in OCD, a serotonin hypothesis of OCD has been formulated. Studies of peripheral markers of serotonin, as well as challenges with proserotonergic compounds have yielded inconsistent results, including evidence pointing towards basal hyperactivity of serotonergic systems. Serotonin receptor and transporter binding studies have yielded conflicting results, including higher and lower serotonin receptor 5-HT2A and serotonin transporter binding potentials that were normalized by treatment with SSRIs. Despite inconsistencies in the types of abnormalities found, evidence points towards dysfunction of serotonergic systems in OCD. Orbitofrontal cortex overactivity is attenuated in people who have successfully responded to SSRI medication, a result believed to be caused by increased stimulation of serotonin receptors 5-HT2A and 5-HT2C. A complex relationship between dopamine and OCD has been observed. Although antipsychotics, which act by antagonizing dopamine receptors may improve some cases of OCD, they frequently exacerbate others. Antipsychotics, in the low doses used to treat OCD, may actually increased the release of dopamine in the prefrontal cortex, through inhibiting autoreceptors. Further complicating things is the efficacy of amphetamines, decreased dopamine transporter activity observed in OCD, and low levels of D2 binding in the striatum. Furthermore, increased dopamine release in the nucleus accumbens after deep brain stimulation correlates with improvement in symptoms, pointing to reduced dopamine release in the striatum playing a role in generating symptoms.\n\nAbnormalities in glutaminergic neurotransmission have implicated in OCD. Findings such as increased cerebrospinal glutamate, less consistent abnormalities observed in neuroimaging studies, and the efficacy of some glutaminergic drugs such as riluzole have implicated glutamate in OCD. OCD has been associated with reduced N-Acetylaspartic acid in the mPFC, which is thought to reflect neuron density or functionality, although the exact interpretation has not been established.\n\nFormal diagnosis may be performed by a psychologist, psychiatrist, clinical social worker, or other licensed mental health professional. To be diagnosed with OCD, a person must have obsessions, compulsions, or both, according to the Diagnostic and Statistical Manual of Mental Disorders (DSM). The Quick Reference to the 2000 edition of the DSM states that several features characterize clinically significant obsessions and compulsions. Such obsessions, the DSM says, are recurrent and persistent thoughts, impulses or images that are experienced as intrusive and that cause marked anxiety or distress. These thoughts, impulses or images are of a degree or type that lies outside the normal range of worries about conventional problems. A person may attempt to ignore or suppress such obsessions, or to neutralize them with some other thought or action, and will tend to recognize the obsessions as idiosyncratic or irrational.\n\nCompulsions become clinically significant when a person feels driven to perform them in response to an obsession, or according to rules that must be applied rigidly, and when the person consequently feels or causes significant distress. Therefore, while many people who do not suffer from OCD may perform actions often associated with OCD (such as ordering items in a pantry by height), the distinction with clinically significant OCD lies in the fact that the person who suffers from OCD \"must\" perform these actions, otherwise they will experience significant psychological distress. These behaviors or mental acts are aimed at preventing or reducing distress or preventing some dreaded event or situation; however, these activities are not logically or practically connected to the issue, or they are excessive. In addition, at some point during the course of the disorder, the individual must realize that their obsessions or compulsions are unreasonable or excessive.\n\nMoreover, the obsessions or compulsions must be time-consuming (taking up more than one hour per day) or cause impairment in social, occupational or scholastic functioning. It is helpful to quantify the severity of symptoms and impairment before and during treatment for OCD. In addition to the peron's estimate of the time spent each day harboring obsessive-compulsive thoughts or behaviors, concrete tools can be used to gauge the people’s condition. This may be done with rating scales, such as the Yale–Brown Obsessive Compulsive Scale (Y-BOCS). With measurements like these, psychiatric consultation can be more appropriately determined because it has been standardized.\n\nOCD is sometimes placed in a group of disorders called the obsessive–compulsive spectrum.\n\nOCD is often confused with the separate condition obsessive–compulsive personality disorder (OCPD). OCD is egodystonic, meaning that the disorder is incompatible with the sufferer's self-concept. Because ego dystonic disorders go against a person's self-concept, they tend to cause much distress. OCPD, on the other hand, is egosyntonic—marked by the person's acceptance that the characteristics and behaviours displayed as a result are compatible with their self-image, or are otherwise appropriate, correct or reasonable.\n\nAs a result, people with OCD are often aware that their behavior is not rational, are unhappy about their obsessions but nevertheless feel compelled by them. By contrast people with OCPD are not aware of anything abnormal; they will readily explain why their actions are rational, it is usually impossible to convince them otherwise, and they tend to derive pleasure from their obsessions or compulsions.\n\nA form of psychotherapy called \"cognitive behavioral therapy\" (CBT) and psychotropic medications are first-line treatments for OCD. Other forms of psychotherapy, such as psychodynamic and psychoanalysis may help in managing some aspects of the disorder, but in 2007 the American Psychiatric Association (APA) noted a lack of controlled studies showing their effectiveness \"in dealing with the core symptoms of OCD\". The fact that many individuals do not seek treatment may be due in part to stigma associated with OCD.\n\nThe specific technique used in CBT is called exposure and response prevention (ERP) which involves teaching the person to deliberately come into contact with the situations that trigger the obsessive thoughts and fears (\"exposure\"), without carrying out the usual compulsive acts associated with the obsession (\"response prevention\"), thus gradually learning to tolerate the discomfort and anxiety associated with not performing the ritualistic behavior. At first, for example, someone might touch something only very mildly \"contaminated\" (such as a tissue that has been touched by another tissue that has been touched by the end of a toothpick that has touched a book that came from a \"contaminated\" location, such as a school.) That is the \"exposure\". The \"ritual prevention\" is not washing. Another example might be leaving the house and checking the lock only once (exposure) without going back and checking again (ritual prevention). The person fairly quickly habituates to the anxiety-producing situation and discovers that their anxiety level drops considerably; they can then progress to touching something more \"contaminated\" or not checking the lock at all—again, without performing the ritual behavior of washing or checking.\n\nERP has a strong evidence base, and it is considered the most effective treatment for OCD. However, this claim was doubted by some researchers in 2000 who criticized the quality of many studies.\n\nIt has generally been accepted that psychotherapy, in combination with psychiatric medication, is more effective than either option alone.\n\nThe medications most frequently used are the selective serotonin reuptake inhibitors (SSRIs). Clomipramine, a medication belonging to the class of tricyclic antidepressants, appears to work as well as SSRIs but has a higher rate of side effects.\n\nSSRIs are a second line treatment of adult obsessive compulsive disorder (OCD) with mild functional impairment and as first line treatment for those with moderate or severe impairment. In children, SSRIs can be considered as a second line therapy in those with moderate-to-severe impairment, with close monitoring for psychiatric adverse effects. SSRIs are efficacious in the treatment of OCD; people treated with SSRIs are about twice as likely to respond to treatment as those treated with placebo. Efficacy has been demonstrated both in short-term (6–24 weeks) treatment trials and in discontinuation trials with durations of 28–52 weeks.\n\nIn 2006, the National Institute of Clinical and Health Excellence (NICE) guidelines recommended antipsychotics for OCD that does not improve with SSRI treatment. For OCD there is tentative evidence for risperidone and insufficient evidence for olanzapine. Quetiapine is no better than placebo with regard to primary outcomes, but small effects were found in terms of YBOCS score. The efficacy of quetiapine and olanzapine are limited by the insufficient number of studies. A 2014 review article found two studies that indicated that aripiprazole was \"effective in the short-term\" and found that \"[t]here was a small effect-size for risperidone or anti-psychotics in general in the short-term\"; however, the study authors found \"no evidence for the effectiveness of quetiapine or olanzapine in comparison to placebo.\" While quetiapine may be useful when used in addition to an SSRI in treatment-resistant OCD, these drugs are often poorly tolerated, and have metabolic side effects that limit their use. None of the atypical antipsychotics appear to be useful when used alone. Another review reported that no evidence supports the use of first generation antipsychotics in OCD.\n\nA guideline by the APA suggested that dextroamphetamine may be considered by itself after more well supported treatments have been tried.\n\nElectroconvulsive therapy (ECT) has been found to have effectiveness in some severe and refractory cases.\n\nSurgery may be used as a last resort in people who do not improve with other treatments. In this procedure, a surgical lesion is made in an area of the brain (the cingulate cortex). In one study, 30% of participants benefitted significantly from this procedure. Deep-brain stimulation and vagus nerve stimulation are possible surgical options that do not require destruction of brain tissue. In the United States, the Food and Drug Administration approved deep-brain stimulation for the treatment of OCD under a humanitarian device exemption requiring that the procedure be performed only in a hospital with specialist qualifications to do so.\n\nIn the United States, psychosurgery for OCD is a treatment of last resort and will not be performed until the person has failed several attempts at medication (at the full dosage) with augmentation, and many months of intensive cognitive–behavioral therapy with exposure and ritual/response prevention. Likewise, in the United Kingdom, psychosurgery cannot be performed unless a course of treatment from a suitably qualified cognitive–behavioral therapist has been carried out.\n\nTherapeutic treatment may be effective in reducing ritual behaviors of OCD for children and adolescents. Similar to the treatment of adults with OCD, CBT stands as an effective and validated first line of treatment of OCD in children. Family involvement, in the form of behavioral observations and reports, is a key component to the success of such treatments. Parental interventions also provide positive reinforcement for a child who exhibits appropriate behaviors as alternatives to compulsive responses. In a recent meta-analysis of evidenced-based treatment of OCD in children, family-focused individual CBT was labeled as \"probably efficacious\", establishing it as one of the leading psychosocial treatments for youth with OCD. After one or two years of therapy, in which a child learns the nature of his or her obsession and acquires strategies for coping, that child may acquire a larger circle of friends, exhibit less shyness, and become less self-critical.\n\nAlthough the causes of OCD in younger age groups range from brain abnormalities to psychological preoccupations, life stress such as bullying and traumatic familial deaths may also contribute to childhood cases of OCD, and acknowledging these stressors can play a role in treating the disorder.\n\nObsessive–compulsive disorder affects about 2.3% of people at some point in their life. Rates during a given year are about 1.2% and it occurs worldwide. It is unusual for symptoms to begin after the age of thirty five and half of people develop problems before twenty. Males and females are affected about equally.\n\nPeople with OCD may be diagnosed with other conditions, as well as or instead of OCD, such as the aforementioned obsessive–compulsive personality disorder, major depressive disorder, bipolar disorder, generalized anxiety disorder, anorexia nervosa, social anxiety disorder, bulimia nervosa, Tourette syndrome, autism spectrum disorder, attention deficit hyperactivity disorder, dermatillomania (compulsive skin picking), body dysmorphic disorder and trichotillomania (hair pulling). More than 50 percent of people experience suicidal tendencies, and 15 percent have attempted suicide. Depression, anxiety and prior suicide attempts increase the risk of future suicide attempts.\n\nIndividuals with OCD have also been found to be affected by delayed sleep phase syndrome at a substantially higher rate than the general public. Moreover, severe OCD symptoms are consistently associated with greater sleep disturbance. Reduced total sleep time and sleep efficiency have been observed in people with OCD, with delayed sleep onset and offset and an increased prevalence of delayed sleep phase disorder.\n\nBehaviorally, there is some research demonstrating a link between drug addiction and the disorder as well. For example, there is a higher risk of drug addiction among those with any anxiety disorder (possibly as a way of coping with the heightened levels of anxiety), but drug addiction among people with OCD may serve as a type of compulsive behavior and not just as a coping mechanism. Depression is also extremely prevalent among people with OCD. One explanation for the high depression rate among OCD populations was posited by Mineka, Watson and Clark (1998), who explained that people with OCD (or any other anxiety disorder) may feel depressed because of an \"out of control\" type of feeling.\n\nSomeone exhibiting OCD signs does not necessarily have OCD. Behaviors that present as (or seem to be) obsessive or compulsive can also be found in a number of other conditions as well, including obsessive–compulsive \"personality\" disorder (OCPD), autism spectrum disorder, disorders where perseveration is a possible feature (ADHD, PTSD, bodily disorders or habit problems) or sub-clinically.\n\nSome with OCD present with features typically associated with Tourette's syndrome, such as compulsions that may appear to resemble motor tics; this has been termed \"tic-related OCD\" or \"Tourettic OCD\".<ref name=\"10.1176/appi.neuropsych.21.1.59\"></ref>\n\nA myth propagated by Sigmund Freud regarding above-average intelligence in OCD was recently refuted.\n\nOCD frequently co-occurs with both bipolar disorder and major depressive disorder. Between 60–80% of those with OCD experience a major depressive episode in their lifetime. Comorbidity rates have been reported at between 19–90% due to methodological differences. Between 9–35% of those with bipolar disorder also have OCD, compared to the 1–2% in the general population. Around 50% of those with OCD experience cyclothymic traits or hypomanic episodes. OCD is also associated with anxiety disorders. Lifetime comorbidity for OCD has been reported at 22% for specific phobia, 18% for social anxiety disorder, 12% for panic disorder, and 30% for generalized anxiety disorder. The comorbidity rate for OCD and ADHD has been reported as high as 51%.\n\nQuality of life is reduced across all domains in OCD. While psychological or pharmacological treatment can lead to a reduction of OCD symptoms and an increase in QoL, symptoms may persist at moderate levels even following adequate treatment courses, and completely symptom-free periods are uncommon. In pediatric OCD, around 40% still have the disorder in adulthood, and around 40% qualify for remission.\n\nIn the seventh century AD, John Climacus records an instance of a young monk plagued by constant and overwhelming \"temptations to blasphemy\" consulting an older monk, who told him, \"My son, I take upon myself all the sins which these temptations have led you, or may lead you, to commit. All I require of you is that for the future you pay no attention to them whatosever.\" \"The Cloud of Unknowing\", a Christian mystical text from the late fourteenth century, recommends dealing with recurring obsessions by first attempting to ignore them, and, if that fails, \"cower under them like a poor wretch and a coward overcome in battle, and reckon it to be a waste of your time for you to strive any longer against them\", a technique now known as \"emotional flooding\".\n\nFrom the 14th to the 16th century in Europe, it was believed that people who experienced blasphemous, sexual or other obsessive thoughts were possessed by the Devil. Based on this reasoning, treatment involved banishing the \"evil\" from the \"possessed\" person through exorcism. The vast majority of people who thought they were possessed by the Devil did not suffer from hallucinations or other \"spectacular symptoms\", but \"complained of anxiety, religious fears, and evil thoughts.\" In 1584, a woman from Kent, England named Mrs. Davie, described by a justice of the peace as \"a good wife\", was nearly burned at the stake after she confessed that she experienced constant, unwanted urges to murder her family.\n\nThe English term obsessive-compulsive comes from the translated term used to describe the first conceptions of OCD by Carl Westphal, \"zwangsvorstellung\". Westphal's description went on to influence Pierre Janet who further documented features of OCD. In the early 1910s, Sigmund Freud attributed obsessive–compulsive behavior to unconscious conflicts that manifest as symptoms. Freud describes the clinical history of a typical case of \"touching phobia\" as starting in early childhood, when the person has a strong desire to touch an item. In response, the person develops an \"external prohibition\" against this type of touching. However, this \"prohibition does not succeed in abolishing\" the desire to touch; all it can do is repress the desire and \"force it into the unconscious\". Freudian psychoanalysis remained the dominant treatment for OCD until the mid-1980s, even though medicinal and therapeutical treatments were known and available, because it was widely thought that these treatments would be detrimental to the effectiveness of the psychotherapy. In the mid-1980s, psychiatry made a sudden \"about-face\" on the subject and began treating OCD primarily through medicine and practical therapy rather than psychoanalysis.\n\nJohn Bunyan (1628–1688), the author of \"The Pilgrim's Progress\", displayed symptoms of OCD (which had not yet been named). During the most severe period of his condition, he would mutter the same phrase over and over again to himself while rocking back and forth. He later described his obsessions in his autobiography \"Grace Abounding to the Chief of Sinners\", stating, \"These things may seem ridiculous to others, even as ridiculous as they were in themselves, but to me they were the most tormenting cogitations.\" He wrote two pamphlets advising those suffering from similar anxieties. In one of them, he warns against indulging in compulsions: \"Have care of putting off your trouble of spirit in the wrong way: by promising to reform yourself and lead a new life, by your performances or duties\".\n\nBritish poet, essayist and lexicographer Samuel Johnson (1709–1784) also suffered from OCD. He had elaborate rituals for crossing the thresholds of doorways, and repeatedly walked up and down staircases counting the steps. He would touch every post on the street as he walked past, only step in the middles of paving stones, and repeatedly perform tasks as though they had not been done properly the first time. The American aviator and filmmaker Howard Hughes is known to have had OCD. Friends of Hughes have also mentioned his obsession with minor flaws in clothing. This was conveyed in \"The Aviator\" (2004), a film biography of Hughes.\n\nMovies and television shows often portray idealized representations of disorders such as OCD. These depictions may lead to increased public awareness, understanding and sympathy for such disorders.\n\n\nThe naturally occurring sugar inositol has been suggested as a treatment for OCD.\n\nNutrition deficiencies may also contribute to OCD and other mental disorders. Vitamin and mineral supplements may aid in such disorders and provide nutrients necessary for proper mental functioning.\n\nμ-Opioids, such as hydrocodone and tramadol, may improve OCD symptoms. Administration of opiate treatment may be contraindicated in individuals concurrently taking CYP2D6 inhibitors such as fluoxetine and paroxetine.\n\nMuch current research is devoted to the therapeutic potential of the agents that affect the release of the neurotransmitter glutamate or the binding to its receptors. These include riluzole, memantine, gabapentin, N-acetylcysteine, topiramate and lamotrigine.\n\n"}
{"id": "19027841", "url": "https://en.wikipedia.org/wiki?curid=19027841", "title": "Open Humanities Press", "text": "Open Humanities Press\n\nOpen Humanities Press is an international open access publishing initiative in the humanities, specializing in critical and cultural theory. OHP's editorial board includes leading scholars such as Alain Badiou, Jonathan Culler, Stephen Greenblatt, Jean-Claude Guédon, J. Hillis Miller, Antonio Negri, Peter Suber and Gayatri Spivak among others.\n\nThe Open Humanities Press (OHP) is a scholar-led publishing initiative founded by Paul Ashton (Australia), Gary Hall (UK), Sigi Jöttkandt (Australia) and David Ottina (US). Its aim is to raise awareness of open access publishing in the humanities and to provide promotional and technical support to open access journals that have been invited by OHP's editorial oversight group to join the collective.\n\nOHP launched in May 2008 with seven open access journals and was named a \"beacon of hope\" by the Public Library of Science. In August, 2009 OHP announced it will begin publishing open access book series edited by senior members of OHP's board. \n\nThe monograph series are:\n\nJournals\n\nOpen Humanities Press also host several open access journals, including the following:\n\n\n"}
{"id": "2110568", "url": "https://en.wikipedia.org/wiki?curid=2110568", "title": "Paraliterature", "text": "Paraliterature\n\nParaliterature comprises written works dismissed as not literary. It includes commercial fiction, popular fiction, pulp fiction, comic books and, most notably, genre fiction with works of science fiction, fantasy, mystery and others.\n\nOn the term \"paraliterature\", Ursula K. Le Guin commented that \"it exists. What I'm saying is that I don't want to \"perpetuate\" this division. So I would always put it in quotes, or do something to show that I'm rejecting a word that I have to use\". \n\n\n"}
{"id": "461415", "url": "https://en.wikipedia.org/wiki?curid=461415", "title": "Peripeteia", "text": "Peripeteia\n\nPeripeteia () is a reversal of circumstances, or turning point. The term is primarily used with reference to works of literature. The Anglicized form of \"peripeteia\" is peripety.\n\nAristotle, in his Poetics, defines peripeteia as \"a change by which the action veers round to its opposite, subject always to our rule of probability or necessity.\" According to Aristotle, peripeteia, along with discovery, is the most effective when it comes to drama, particularly in a tragedy. He wrote that \"The finest form of Discovery is one attended by Peripeteia, like that which goes with the Discovery in Oedipus...\".\n\nAristotle says that peripeteia is the most powerful part of a plot in a tragedy along with discovery. A peripety is the change of the kind described from one state of things within the play to its opposite, and that too in the way we are saying, in the probable or necessary sequence of events. There is often no element like Peripeteia; it can bring forth or result in terror, mercy, or in comedies it can bring a smile or it can bring forth tears (Rizo). This is the best way to spark and maintain attention throughout the various form and genres of drama \"Tragedy imitates good actions and, thereby, measures and depicts the well-being of its protagonist. But in his formal definition, as well as throughout the Poetics, Aristotle emphasizes that\" ... Tragedy is an imitation not only of a complete action, but also of events inspiring fear or pity\" (1452a 1); in fact, at one point Aristotle isolates the imitation of \"actions that excite pity and fear\" as \"the distinctive mark of tragic imitation\" (1452b 30). Pity and fear are effected through reversal and recognition; and these \"most powerful elements of emotional interest in Tragedy-Peripeteia or Reversal of the Situation, and recognition scenes-are parts of the plot (1450a 32). has the shift of the tragic protagonist's fortune from good to bad, which is essential to the plot of a tragedy. It is often an ironic twist. Good uses of Peripeteia are those that especially are parts of a complex plot, so that they are defined by their changes of fortune being accompanied by reversal, recognition, or both\" (Smithson).\n\nPeripeteia includes changes of character, but also more external changes. A character who becomes rich and famous from poverty and obscurity has undergone peripeteia, even if his character remains the same.\n\nWhen a character learns something he had been previously ignorant of, this is normally distinguished from peripeteia as anagnorisis or discovery, a distinction derived from Aristotle's work.\n\nAristotle considered anagnorisis, leading to peripeteia, the mark of a superior tragedy. Two such plays are \"Oedipus Rex\", where the oracle's information that Oedipus had killed his father and married his mother brought about his mother's death and his own blindness and exile, and \"Iphigenia in Tauris\", where Iphigenia realizes that the strangers she is to sacrifice are her brother and his friend, resulting in all three of them escaping Tauris. These plots he considered complex and superior to simple plots without anagnorisis or peripeteia, such as when Medea resolves to kill her children, knowing they are her children, and does so. Aristotle identified \"Oedipus Rex\" as the principal work demonstrating peripety. (See Aristotle's \"Poetics\".)\n\nIn Sophocles' \"Oedipus Rex\", the peripeteia occurs towards the end of the play when the Messenger brings Oedipus news of his parentage. In the play, Oedipus is fated to murder his father and marry his mother. His parents, Laius and Jocasta, try to forestall the oracle by sending their son away to be killed, but he is actually raised by Polybus and his wife, Merope, the rulers of another kingdom. The irony of the Messenger’s information is that it was supposed to comfort Oedipus and assure him that he was the son of Polybus. Unfortunately for Oedipus, the Messenger says, \"Polybus was nothing to you, [Oedipus] that’s why, not in blood\" (Sophocles 1113). The Messenger received Oedipus from one of Laius’ servants and then gave him to Polybus. The plot comes together when Oedipus realizes that he is the son and murderer of Laius as well as the son and husband of Jocasta. Martin M. Winkler says that here, peripeteia and anagnôrisis occur at the same time \"for the greatest possible impact\" because Oedipus has been \"struck a blow from above, as if by fate or the gods. He is changing from the mighty and somewhat arrogant king of Thebes to a figure of woe\" (Winkler 57).\n\nThe instantaneous conversion of Paul on the road to Damascus is a classic example of \"peripeteia\", which Eusebius presented in his \"Life of Constantine\" as a pattern for the equally revelatory conversion of Constantine. Modern biographers of Constantine see his conversion less as a momentary phenomenon than as a step in a lifelong process.\n\nIn \"The Three Apples\", a medieval \"Arabian Nights\", after the murderer reveals himself near the middle of the story, he explains his reasons behind the murder in a flashback, which begins with him going on a journey to find three rare apples for his wife, but after returning finds out she cannot eat them due to her lingering illness. Later at work, he sees a slave passing by with one of those apples claiming that he received it from his girlfriend, a married woman with three such apples her husband gave her. He returns home and demands his wife to show him all three apples, but she only shows him two. This convinces him of her infidelity and he murders her as a result. After he disposes of her body, he returns home where his son confesses that he had stolen one of the apples and that a slave, to whom he had told about his father's journey, had fled with it. The murderer thus realizes his guilt and regrets what he has just done.\n\nThe second use of peripety occurs near the end. After finding out about the culprit behind the murder, the protagonist Ja'far ibn Yahya is ordered by Harun al-Rashid to find the tricky slave within three days, or else he will have Ja'far executed instead. After the deadline has passed, Ja'far prepares to be executed for his failure and bids his family farewell. As he hugs his youngest daughter, he feels a round object in her pocket, which is revealed to be the same apple that the culprit was holding. In the story's twist ending, the daughter reveals that she obtained it from their slave, Rayhan. Ja'far thus realizes that his own slave was the culprit all along. He then finds Rayhan and solves the case, preventing his own execution. That was a plot twist.\n\n\n\n"}
{"id": "25234", "url": "https://en.wikipedia.org/wiki?curid=25234", "title": "Quadrivium", "text": "Quadrivium\n\nThe quadrivium (plural: quadrivia) is the four subjects, or arts, taught after teaching the trivium. The word is Latin, meaning \"four ways\", and its use for the four subjects has been attributed to Boethius or Cassiodorus in the 6th century. Together, the trivium and the quadrivium comprised the seven liberal arts (based on thinking skills), as distinguished from the practical arts (such as medicine and architecture).\n\nThe quadrivium consisted of arithmetic, geometry, music, and astronomy. These followed the preparatory work of the trivium, consisting of grammar, logic, and rhetoric. In turn, the quadrivium was considered preparatory work for the study of philosophy (sometimes called the \"liberal art \"par excellence\"\") and theology.\n\nThese four studies compose the secondary part of the curriculum outlined by Plato in \"The Republic\" and are described in the seventh book of that work (in the order Arithmetic, Geometry, Astronomy, Music). \nThe quadrivium is implicit in early Pythagorean writings and in the \"De nuptiis\" of Martianus Capella, although the term \"quadrivium\" was not used until Boethius, early in the sixth century. As Proclus wrote:\nThe Pythagoreans considered all mathematical science to be divided into four parts: one half they marked off as concerned with quantity, the other half with magnitude; and each of these they posited as twofold. A quantity can be considered in regard to its character by itself or in its relation to another quantity, magnitudes as either stationary or in motion. Arithmetic, then, studies quantities as such, music the relations between quantities, geometry magnitude at rest, spherics [astronomy] magnitude inherently moving.\nAt many medieval universities, this would have been the course leading to the degree of Master of Arts (after the BA). After the MA, the student could enter for bachelor's degrees of the higher faculties (Theology, Medicine or Law). To this day, some of the postgraduate degree courses lead to the degree of Bachelor (the B.Phil and B.Litt. degrees are examples in the field of philosophy).\n\nThe study was eclectic, approaching the philosophical objectives sought by considering it from each aspect of the quadrivium within the general structure demonstrated by Proclus (AD 412–485), namely arithmetic and music on the one hand and geometry and cosmology on the other.\n\nThe subject of music within the quadrivium was originally the classical subject of harmonics, in particular the study of the proportions between the musical intervals created by the division of a monochord. A relationship to music as actually practised was not part of this study, but the framework of classical harmonics would substantially influence the content and structure of music theory as practised in both European and Islamic cultures.\n\nIn modern applications of the liberal arts as curriculum in colleges or universities, the quadrivium may be considered to be the study of number and its relationship to space or time: arithmetic was pure number, geometry was number in space, music was number in time, and astronomy was number in space and time. Morris Kline classified the four elements of the quadrivium as pure (arithmetic), stationary (geometry), moving (astronomy), and applied (music) number.\n\nThis schema is sometimes referred to as \"classical education\", but it is more accurately a development of the 12th- and 13th-century Renaissance with recovered classical elements, rather than an organic growth from the educational systems of antiquity. The term continues to be used by the Classical education movement and at the independent Oundle School, in the United Kingdom.\n\n"}
{"id": "3253", "url": "https://en.wikipedia.org/wiki?curid=3253", "title": "Running amok", "text": "Running amok\n\nRunning amok, sometimes referred to as simply amok or gone amok, also spelled amuk, from the Southeast Asian Austronesian languages (especially Malaysian and Indonesian), is \"an episode of sudden mass assault against people or objects usually by a single individual following a period of brooding that has traditionally been regarded as occurring especially in Malay culture but is now increasingly viewed as psychopathological behavior\". The syndrome of \"Amok\" is found in the \"Diagnostic and Statistical Manual of Mental Disorders\" (DSM-IV TR). The phrase is often used in a less serious manner when describing something that is wildly out of control or causing a frenzy (e.g., a dog tearing up the living room furniture might be termed as \"running amok\").\n\nAmok originated from the Malaysian/Indonesian word \"meng-âmuk\", which when roughly defined means \"to make a furious and desperate charge\". According to Malaysian and Indonesian cultures, amok was rooted in a deep spiritual belief. They believed that amok was caused by the \"hantu belian\", which was an evil tiger spirit that entered one’s body and caused the heinous act. As a result of the belief, those in Indonesian culture tolerated amok and dealt with the after-effects with no ill will towards the assailant.\n\nAlthough commonly used in a colloquial and less-violent sense, the phrase is particularly associated with a specific sociopathic culture-bound syndrome in the cultures of Malaysia, Indonesia and Brunei. In a typical case of \"running amok\", an individual (often male), having shown no previous sign of anger or any inclination to violence, will acquire a weapon (traditionally a sword or dagger, but presently any of a variety of weapons) and in a sudden frenzy, will attempt to kill or seriously injure anyone he encounters and himself. Amok typically takes place in a well populated or crowded area. Amok episodes of this kind normally end with the attacker being killed by bystanders or committing suicide, eliciting theories that amok may be a form of intentional suicide in cultures where suicide is heavily stigmatized. Those who do not commit suicide and are not killed typically lose consciousness, and upon regaining consciousness, claim amnesia.\n\nAn early Western description of the practice appears in the journals of Captain James Cook, a British explorer, who encountered amok firsthand in 1770 during a voyage around the world. Cook writes of individuals behaving in a reckless, violent manner, without cause and \"indiscriminately killing and maiming villagers and animals in a frenzied attack.\"\n\nA widely accepted explanation links amok with male honor (amok by women and children is virtually unknown).\nRunning amok would thus be both a way of escaping the world (since perpetrators were normally killed or committed suicide) and re-establishing one's reputation as a man to be feared and respected.\n\n\"Running amok\" is used to refer to the behavior of someone who, in the grip of strong emotion, obtains a weapon and begins attacking people indiscriminately, often with multiple fatalities. An episode of amok may be triggered by a period of depression or highly aggressive behavior. The slang terms \"going postal\" or \"going ballistic\" are similar in scope.\nPolice describe such an event as a killing spree. If the individual is seeking death an alternate method is often \"suicide by cop\".\n\nAmok is often described as a culture-bound (or culture-specific) syndrome, which is a psychological condition whose manifestation is strongly shaped by cultural factors. Other reported culture-bound syndromes are latah and koro. Amok is also sometimes considered one of the subcategories of dissociative disorders (cross-cultural variant).\n\nIn 1849, amok was officially classified as a psychiatric condition based on numerous reports and case studies that showed the majority of individuals who committed amok were, in some sense, mentally ill. The modern DSM-IV method of classification of mental disorders contains two official types of amok disorder; beramok and amok. Beramok is considered to be the more common of the two and is associated with the depression and sadness resulting from a loss and the subsequent brooding process. Loss includes, but is not limited to, the death of a spouse or loved one, divorce, loss of a job, money, power, etc. Beramok is associated with mental issues of severe depression or other mood disorders. Amok, the rarer form, is believed to stem from rage, insult, or a vendetta against a person, society, or object for a wide variety of reasons. Amok has been more closely associated with psychosis, personality disorders, bipolar disorder, and delusions.\n\nEarly travelers in Asia sometimes describe a kind of military amok, in which soldiers apparently facing inevitable defeat suddenly burst into a frenzy of violence which so startled their enemies that it either delivered victory or at least ensured what the soldier in that culture considered an honourable death.\n\nAn example would be during the Battle of Bukit Chandu in Singapore during WWII when 41 outnumbered soldiers of the Malay Regiment, led by Adnan Saidi, charged and went all out against a 13 000 strong invading Japanese Army. They continued the fight armed with just knives and bayonets for three days before they were finally defeated.\n\nThis form of amok appears to resemble the Germanic \"Berserker\", the \"cafard\" or \"cathard\" (Polynesia), \"mal de pelea\" (Puerto Rico), and \"iich'aa\" (Navaho).\n\nIn contemporary Indonesia, the term \"amok\" (\"amuk\") generally refers not to individual violence, but to frenzied violence by mobs. Indonesians now commonly use the term 'gelap mata' (literally 'darkened eyes') to refer to individual amok. Laurens van der Post experienced the phenomenon in the East Indies and wrote in 1955:\n\nIn the Philippines, \"amok\" also means unreasoning murderous rage by an individual. In 1876, the Spanish governor-general of the Philippines José Malcampo coined the term \"juramentado\" for the behavior (from \"juramentar\" - \"to take an oath\"), surviving into modern Philippine languages as \"huramentado\". It has historically been linked with the Moro people of Mindanao, particularly in the Sulu Archipelago, in connection with societal and cultural pressures.\n\nNorse Berserkers and the Zulu battle trance are two other examples of the tendency of certain groups to work themselves up into a killing frenzy.\n\nAccording to the \"Encyclopædia Britannica\" Eleventh Edition, some notable cases have occurred among the Rajputs. In 1634, the eldest son of the raja of Jodhpur ran amok at the court of Shah Jahan, failing in his attack on the emperor, but killing five of his officials. During the 18th century, again, at Hyderabad (Sind), two envoys, sent by the Jodhpur chief in regard to a quarrel between the two states, stabbed the prince and twenty-six of his suite before they themselves fell.\n\n"}
{"id": "19342760", "url": "https://en.wikipedia.org/wiki?curid=19342760", "title": "Seven Wonders of the Ancient World", "text": "Seven Wonders of the Ancient World\n\nThe Seven Wonders of the World or the Seven Wonders of the Ancient World is a list of remarkable constructions of classical antiquity given by various authors in guidebooks or poems popular among ancient Hellenic tourists. Although the list, in its current form, did not stabilise until the Renaissance, the first such lists of seven wonders date from the 1st-2nd century BC. The original list inspired innumerable versions through the ages, often listing seven entries. Of the original Seven Wonders, only one—the Great Pyramid of Giza (also called the Pyramid of Khufu, after the pharaoh who built it), the oldest of the ancient wonders—remains relatively intact. The Colossus of Rhodes, the Lighthouse of Alexandria, the Mausoleum at Halicarnassus, the Temple of Artemis and the Statue of Zeus were all destroyed. The location and ultimate fate of the Hanging Gardens are unknown, and there is speculation that they may not have existed at all.\n\nThe Greek conquest of much of the known western world in the 4th century BC gave Hellenistic travellers access to the civilizations of the Egyptians, Persians, and Babylonians. Impressed and captivated by the landmarks and marvels of the various lands, these travellers began to list what they saw to remember them.\n\nInstead of \"wonders\", the ancient Greeks spoke of \"theamata\" (θεάματα), which means \"sights\", in other words \"things to be seen\" (Τὰ ἑπτὰ θεάματα τῆς οἰκουμένης [γῆς] \"\"). Later, the word for \"wonder\" (\"thaumata\" θαύματα, \"wonders\") was used. Hence, the list was meant to be the Ancient World's counterpart of a travel guidebook.\n\nThe first reference to a list of seven such monuments was given by Diodorus Siculus. The epigrammist Antipater of Sidon who lived around or before 100 BC, gave a list of seven such monuments, including six of the present list (substituting the walls of Babylon for the lighthouse):\n\nAnother 2nd century BC observer, who claimed to be the mathematician Philo of Byzantium, wrote a short account entitled \"The Seven Sights of the World\". However, the incomplete surviving manuscript only covered six of the supposedly seven places, which agreed with Antipater's list.\n\nEarlier and later lists by the historian Herodotus (484 BC–ca. 425 BC) and the architect Callimachus of Cyrene (ca. 305–240 BC), housed at the Museum of Alexandria, survived only as references.\n\nThe Colossus of Rhodes was the last of the seven to be completed, after 280 BC, and the first to be destroyed, by an earthquake in 226/225 BC. Hence, all seven existed at the same time for a period of less than 60 years.\n\nThe list covered only the sculptural and architectural monuments of the Mediterranean and Middle Eastern regions, which then comprised the known world for the Greeks. Hence, extant sites beyond this realm were not considered as part of contemporary accounts.\n\nThe primary accounts, coming from Hellenistic writers, also heavily influenced the places included in the wonders list. Five of the seven entries are a celebration of Greek accomplishments in the arts and architecture (the exceptions being the Pyramids of Giza and the Hanging Gardens of Babylon).\n\nThe seven wonders on Antipater's list won praises for their notable features, ranging from superlatives of the highest or largest of their types, to the artistry with which they were executed. Their architectural and artistic features were imitated throughout the Hellenistic world and beyond.\n\nThe Greek influence in Roman culture, and the revival of Greco-Roman artistic styles during the Renaissance caught the imagination of European artists and travellers. Paintings and sculptures alluding to Antipater's list were made, while adventurers flocked to the actual sites to personally witness the wonders. Legends circulated to further complement the superlatives of the wonders.\n\nOf Antipater's wonders, the only one that has survived to the present day is the Great Pyramid of Giza. Its brilliant white stone facing had survived intact until around 1300 AD, when local communities removed most of the stonework for building materials. The existence of the Hanging Gardens has not been proven, although theories abound. Records and archaeology confirm the existence of the other five wonders. The Temple of Artemis and the Statue of Zeus were destroyed by fire, while the Lighthouse of Alexandria, Colossus, and tomb of Mausolus were destroyed by earthquakes. Among the artifacts to have survived are sculptures from the tomb of Mausolus and the Temple of Artemis in the British Museum in London.\n\nStill, the listing of seven of the most marvellous architectural and artistic human achievements continued beyond the Ancient Greek times to the Roman Empire, the Middle Ages, the Renaissance and to the modern age. The Roman poet Martial and the Christian bishop Gregory of Tours had their versions. Reflecting the rise of Christianity and the factor of time, nature and the hand of man overcoming Antipater's seven wonders, Roman and Christian sites began to figure on the list, including the Colosseum, Noah's Ark and Solomon's Temple. In the 6th century, a list of seven wonders was compiled by St. Gregory of Tours: the list included the Temple of Solomon, the Pharos of Alexandria and Noah's Ark.\n\nModern historians, working on the premise that the original Seven Ancient Wonders List was limited in its geographic scope, also had their versions to encompass sites beyond the Hellenistic realm—from the Seven Wonders of the \"Ancient World\" to the Seven Wonders of the \"World\". Indeed, the \"seven wonders\" label has spawned innumerable versions among international organizations, publications and individuals based on different themes—works of nature, engineering masterpieces, constructions of the Middle Ages, etc. Its purpose has also changed from just a simple travel guidebook or a compendium of curious places, to lists of sites to defend or to preserve.\n\n\n\n"}
{"id": "12359435", "url": "https://en.wikipedia.org/wiki?curid=12359435", "title": "Souvenir spoon", "text": "Souvenir spoon\n\nA souvenir spoon is a decorative spoon used to signify or hold a memory of a place or event, or to display as a 'trophy' of having been there. The spoons may be made from a number of different materials such as sterling silver, nickel, steel, and in some cases wood. They are often hung on a spoon rack and are typically ornamental, depicting sights, coat of arms, associated characters, etc. The year the spoon was made may be inscribed in the bowl, or on the back. The entire spoon, including the bowl, handle, and finial may be used to convey the theme. The first souvenir spoons in the United States were made in 1890 by Galt & Bros., Inc. of Washington D.C., featuring the profile of George Washington. One year later, a souvenir Salem Witch spoon was made, and sold seven thousand copies. It was created by Daniel Low, a jeweler in Salem, Massachusetts, after he saw souvenir spoons on vacation in Germany. The Witch Spoon is given credit for starting the souvenir spoon hobby in the U.S.\n"}
{"id": "4228181", "url": "https://en.wikipedia.org/wiki?curid=4228181", "title": "Stateless society", "text": "Stateless society\n\nA stateless society is a society that is not governed by a state, or, especially in common American English, has no government. In stateless societies, there is little concentration of authority; most positions of authority that do exist are very limited in power and are generally not permanently held positions; and social bodies that resolve disputes through predefined rules tend to be small. Stateless societies are highly variable in economic organization and cultural practices.\n\nWhile stateless societies were the norm in human prehistory, few stateless societies exist today; almost the entire global population resides within the jurisdiction of a sovereign state. In some regions nominal state authorities may be very weak and wield little or no actual power. Over the course of history most stateless peoples have been integrated into the state-based societies around them.\n\nSome political philosophies, particularly anarchism, consider the state an unwelcome institution and stateless societies the ideal.\n\nIn archaeology, cultural anthropology and history, a stateless society denotes a less complex human community without a state, such as a tribe, a clan, a band society or a chiefdom. The main criterion of \"complexity\" used is the extent to which a division of labor has occurred such that many people are permanently \"specialized\" in particular forms of production or other activity, and depend on others for goods and services through trade or sophisticated reciprocal obligations governed by custom and laws. An additional criterion is population size. The bigger the population, the more relationships have to be reckoned with.\n\nEvidence of the earliest known city-states has been found in ancient Mesopotamia around 3700 BC, suggesting that the history of the state is less than 6,000 years old; thus, for most of human prehistory the state did not exist.\n\nGenerally speaking, the archaeological evidence suggests that the state emerged from stateless communities only when a fairly large population (at least tens of thousands of people) was more or less settled together in a particular territory, and practiced agriculture. Indeed, one of the typical functions of the state is the defense of territory. Nevertheless, there are exceptions: Lawrence Krader for example describes the case of the Tatar state, a political authority arising among confederations of clans of nomadic or semi-nomadic herdsmen.\n\nCharacteristically the state functionaries (royal dynasties, soldiers, scribes, servants, administrators, lawyers, tax collectors, religious authorities etc.) are mainly not self-supporting, but rather materially supported and financed by taxes and tributes contributed by the rest of the working population. This assumes a sufficient level of labor-productivity per capita which at least makes possible a \"permanent\" surplus product (principally foodstuffs) appropriated by the state authority to sustain the activities of state functionaries. Such permanent surpluses were generally not produced on a significant scale in smaller tribal or clan societies.\n\nThe archaeologist Gregory Possehl has argued that there is no evidence that the relatively sophisticated, urbanized Harappan civilization, which flourished from about 2,500 to 1,900 BC in the Indus region, featured anything like a centralized state apparatus. No evidence has yet been excavated locally of palaces, temples, a ruling sovereign or royal graves, a centralized administrative bureaucracy keeping records, or a state religion—all of which are elsewhere usually associated with the existence of a state apparatus.\n\nSimilarly, in the earliest large-scale human settlements of the stone age which have been discovered, such as Çatal Höyük and Jericho, no evidence was found of the existence of a state authority. The Çatal Höyük settlement of a farming community (7,300 BC to circa 6,200 BC) spanned circa 13 hectares (32 acres) and probably had about 5,000 to 10,000 inhabitants.\n\nModern state-based societies regularly pushed out stateless indigenous populations as their settlements expanded.\n\nUncontacted peoples may be considered remnants of prehistoric stateless societies. To varying extents they may be unaware of and unaffected by the states that have nominal authority over their territory.\n\nSome political philosophies consider the state undesirable, and thus consider the formation of a stateless society a goal to be achieved.\n\nA central tenet of anarchism is the advocacy of society without states. The type of society sought for varies significantly between anarchist schools of thought, ranging from extreme individualism to complete collectivism.\n\nIn Marxism, Marx's theory of the state considers that in a post-capitalist society the state, an undesirable institution, would be unnecessary and wither away. A related concept is that of stateless communism, a phrase sometimes used to describe Marx's anticipated post-capitalist society.\n\nAnthropologists have found that social stratification is not the standard among all societies. John Gowdy writes, \"Assumptions about human behaviour that members of market societies believe to be universal, that humans are naturally competitive and acquisitive, and that social stratification is natural, do not apply to many hunter-gatherer peoples.\"\n\nThe economies of stateless agricultural societies tend to focus and organize subsistence agriculture at the community level, and tend to diversify their production rather than specializing in a particular crop.\n\nIn many stateless societies, conflicts between families or individuals are resolved by appealing to the community. Each of the sides of the dispute will voice their concerns, and the community, often voicing its will through village elders, will reach a judgment on the situation. Even when there is no legal or coercive authority to enforce these community decisions, people tend to adhere to them, due to a desire to be held in esteem by the community.\n\n"}
{"id": "57990980", "url": "https://en.wikipedia.org/wiki?curid=57990980", "title": "Symbiosis in fiction", "text": "Symbiosis in fiction\n\nSymbiosis (mutualism) appears in fiction, especially science fiction, as a plot device. It is distinguished from parasitism in fiction, a similar theme, by the mutual benefit to the organisms involved, whereas the parasite inflicts harm on its host.\n\nRelationships between species in early science fiction were often imaginatively parasitic, with the parasites draining the vital energy of their human hosts and taking over their minds, as in Arthur Conan Doyle's 1895 \"The Parasite\".\n\nAfter the Second World War, science fiction moved towards more mutualistic relationships, as in Ted White's 1970 \"By Furies Possessed\"; Brian Stableford argues that White was consciously opposing the xenophobia of Robert Heinlein's 1951 \"The Puppet Masters\" which involved a parasitic relationship close to demonic possession, with a more positive attitude towards aliens. Stableford notes, however, that Octavia Butler's 1984 \"Clay's Ark\" and other of her works such as \"Fledgling\", and Dan Simmons's 1989 \"Hyperion\" take an ambivalent position, in which the aliens may confer powers such as \"Hyperion\"'s ability to regenerate continually—but at a price, in its case an incremental loss of intelligence at each regeneration.\n\nThe Force in the \"Star Wars\" universe is described by the fictional seer Obi-Wan Kenobi as \"an energy field created by all living things\". In \"The Phantom Menace\", Qui-Gon Jinn says microscopic lifeforms called midi-chlorians, inside all living cells, allow characters with enough of these symbionts in their cells to feel and use the Force.\n\nIn Douglas Adams's humorous 1978 \"The Hitchhiker's Guide to the Galaxy\", the Babel fish lives in its human host's ear, feeding on the energy of its host's brain waves, in return translating any language to the host's benefit.\n\n"}
{"id": "3520025", "url": "https://en.wikipedia.org/wiki?curid=3520025", "title": "The American Monomyth", "text": "The American Monomyth\n\nThe American Monomyth is a 1977 book by Robert Jewett and John Shelton Lawrence arguing for the existence and cultural importance of an 'American Monomyth', a variation on the classical monomyth as proposed by Joseph Campbell.\n\nCampbell's monomyth describes a hero's journey: a hero ventures from the normal world into a supernatural one, winning a decisive victory there and returning with a 'boon'. In contrast, Jewett and Lawrence define the American monomyth as:\n\n\"A community in a harmonious paradise is threatened by evil; normal institutions fail to contend with this threat; a selfless superhero emerges to renounce temptations and carry out the redemptive task; aided by fate, his decisive victory restores the community to its paradisiacal condition; the superhero then recedes into obscurity.\"\n\nIn their 2002 book \"The Myth of the American Superhero\" (with Lawrence as first author) and their 2003 book \"Captain America And The Crusade Against Evil: The Dilemma Of Zealous Nationalism\" (with Jewett as first author), the authors extend the thesis by using examples from both American popular culture and the American religious tradition.\n\n\"The American Monomyth\" posits a level of cultural belief in American society that helps to explain the desire in American government to \"save\" the world.\n\n\n"}
{"id": "12649093", "url": "https://en.wikipedia.org/wiki?curid=12649093", "title": "Wannarexia", "text": "Wannarexia\n\nWannarexia, or anorexic yearning,\nis a label applied to someone who claims to have anorexia nervosa, or wishes they did, but does not. These individuals are also called wannarexic, “wanna-be ana” or \"anorexic wannabe\". The neologism \"wannarexia\" is a portmanteau of the latter two terms. It may be used as a pejorative term.\n\nWannarexia is a cultural phenomenon and has no diagnostic criteria, although some wannarexics may be instead diagnosed with eating disorder not otherwise specified (EDNOS). Wannarexia is more commonly, but not always, found in teenage girls who want to be trendy, and is likely caused by a combination of cultural and media influences.\n\nDr. Richard Kreipe states that the distinction between anorexia and wannarexia is that anorexics aren't satisfied by their weight loss, while wannarexics are more likely to derive pleasure from weight loss. Many people who actually suffer from the eating disorder anorexia are angry, offended, or frustrated about wannarexia.\n\nWannarexics may be inspired or motivated by the pro-anorexia, or pro-ana, community that promotes or supports anorexia as a lifestyle choice rather than an eating disorder. Some participants in pro-ana web forums only want to associate with \"real anorexics\" and will shun wannarexics who only diet occasionally, and are not dedicated to the \"lifestyle\" full-time. Community websites for anorexics and bulimics have posted advice to wannarexics saying that they don't want their \"warped perspectives and dangerous behaviour to affect others.\"\n\nKelsey Osgood uses the label in her book \"How To Disappear Completely: On Modern Anorexia\" where she describes wannarexia as “a gateway drug for teenagers”.\n"}
