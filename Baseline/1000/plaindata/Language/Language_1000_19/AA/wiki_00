{"id": "2199641", "url": "https://en.wikipedia.org/wiki?curid=2199641", "title": "Australian Institute of Aboriginal and Torres Strait Islander Studies", "text": "Australian Institute of Aboriginal and Torres Strait Islander Studies\n\nThe Australian Institute of Aboriginal and Torres Strait Islander Studies (AIATSIS) is an independent Australian Government statutory authority. It is a collecting, publishing and research institute and is considered to be Australia's premier resource for information about the cultures and societies of Aboriginal and Torres Strait Islander peoples. The Institute is a leader in ethical research and the handling of culturally sensitive material and holds in its collections many unique and irreplaceable items of cultural, historical and spiritual significance. The collection at AIATSIS has been built through over 50 years of research and engagement with Aboriginal and Torres Strait Islander communities and is now a source of language and culture revitalisation, native title research and family and community history. AIATSIS is located on Acton Peninsula in Canberra, Australian Capital Territory.\n\nIn the late 1950s, there was an increasing focus on the global need for anthropological research into 'disappearing cultures'. This trend was also emerging in Australia in the work of researchers of Aboriginal and Torres Strait Islander peoples, leading to a proposal by W.C. Wentworth MP for the conception of an Australian Institute of Aboriginal Studies (AIAS) in 1959.\n\nThe proposal was made as a submission to Cabinet, and argued for a more comprehensive approach by the Australian Government to the recording of Australian Aboriginal and Torres Strait Islander peoples and cultures.\n\nIn 1960, a Cabinet sub-committee assessed the proposal and formed a working party at the Australian National University (ANU) to consider the viability of the proposal. One of their first actions was to appoint W.E.H. Stanner to organise a conference on the state of Aboriginal Studies in Australia, to be held in 1961 at the ANU.\n\nAcademics and anthropologists in the field of Aboriginal Studies attended the conference, and contributed research papers published in a conference report in 1963. No Aboriginal people were present at the conference.\n\nThe Prime Minister, Robert Menzies appointed an Interim Council in 1961. The role of the Interim Council was to plan for a national Aboriginal research organisation and establish how this organisation would interact with existing research and scientific bodies. The Interim Council was also tasked with immediately developing a programme that would identify and address urgent research needs.\n\nThe Interim Council consisted of 16 members and was chaired by Deputy Vice-Chancellor of the ANU, Professor AD Trendall, officially recognised as the first Chair of the institute now known as AIATSIS.\n\nIn August 1962, a draft constitution for the institute was submitted to the Menzies government, and rejected. The Interim Council completed a revised constitution in July 1963. Amendments to the document included the change from the title ‘director’ to ‘principal’ of the institute.\n\nThis version of the constitution would go on to form the basis for the creation of the new Australian Institute for Aboriginal Studies the following year.\n\nThe Australian Institute of Aboriginal Studies was established as a Statutory authority under an Act of Parliament in June 1964. The mission of the Institute at that time has been described as \"to record language, song, art, material culture, ceremonial life and social structure before those traditions perished in the face of European ways.\"\n\nThis notion is also reflected in the Institute’s official functions, as recorded in the Reading of the Bill in Parliament. These were:\n\nAIAS had a twenty-two member Council, composed mainly of academics, and had a foundation membership of one hundred. The founding Principal of the newly formed institute was Frederick McCarthy, a professional anthropologist and graduate of Sydney University who had spent nearly 30 years working in the field.\n\nThe creation of the AIAS provided an opportunity for greater cross-discipline interaction in fields relating to Aboriginal and Torres Strait Islander studies in Australia.\n\nThe Institute’s founding principal, Fred McCarthy, was an advocate of film as an important part of research methodology as early as his tenure as curator of anthropology at the Australian Museum in Sydney in the 1940s. This was evident in the contributions he made during his involvement in establishing the AIAS and also as its principal, in continuing to support the development of the AIAS Film Unit and championing ethnographic film in global forums.\n\nIn the early years of the AIAS, the Film Unit largely outsourced early filmmaking work to other companies, or worked in collaboration with the Commonwealth Film Unit (as early as 1962). But over the next 30 years, the Film Unit would go on to produce “one of the largest assembly of ethnographic films created in the world”.\n\nIn keeping with the AIAS official function “to publish and to support the publication of the results of research”, a publishing arm of the Institute was established in 1964. Publishing under the name Australian Institute of Aboriginal Studies, the publishing arm released a range of papers and research findings, including in the fields of linguistics, demography, physical anthropology, history and musicology.\n\nThe early work of the AIAS is credited with increasing interaction between academics in different fields, as well as establishing the foundations for the extensive collections AIATSIS holds today. But before 1970, there had never been an Aboriginal or Torres Strait Islander member on the AIAS Council.\n\n\"Money and other resources are in short supply for Aboriginal control of their livelihood, but not, it seems, for discussing it.\" – Eaglehawk and Crow letter, 29 March 1974The 1970s marked a period of change for the AIAS. This began with the appointment of the first Aboriginal member of the AIAS Council in 1970. Phillip Roberts, an Alawa man, served on the Council from September 1970 until June 1972.\n\nThis was followed in 1971 with a second Aboriginal Council member, Senator Neville Bonner, who served on Council until 1974 and for a second term in the late 1970s. And again in 1972, with the appointment of Dick Roughsey to replace Phillip Roberts at the end of his term.\n\nThe appointment of Phillip Roberts to the Council reflected a growing pressure for an increase in Aboriginal representation within the Institute. But the move did not allay the belief held by some Aboriginal activists that the AIAS was engaging in 'tokenism' in the extent to which Aboriginal people were involved in the administration of Aboriginal Studies.\n\nThe changes to the Institute that would take place in the following decade were also influenced by the shifting social and political landscape in Australia. The Aboriginal rights movement was growing and Aboriginal people were demanding a voice on Council, consultation with communities and an increased focus on projects relevant to the needs of Indigenous people.\n\nIn 1972, the Whitlam government was elected. Their policy of Self-determination for Aboriginal people echoed calls for greater Aboriginal involvement in the administration and functions of the AIAS. The new government was also responsible for a significant boost to AIAS funding.\n\nThe appointment of Peter Ucko in 1972 as Principal of the AIAS has since been described as the beginning of an increase in involvement of Aboriginal people in the workings of the Institute.\n\nIn his time as Principal, Ucko was responsible for implementing a policy later labelled “Aboriginalisation”, which was aimed at opening up the Institute to Aboriginal involvement and representation. This policy was influenced by a document circulated in 1974, called the Eaglehawk and Crow letter, which criticised the current model of academic research. The letter asserted that anthropologists \"should not pretend that their studies are objective when the overwhelming factor in the lives of Aborigines is our oppression by the society of which the anthropologist is, to a greater or lesser extent, a part of.\" Its authors called for increased participation of Aboriginal people in the running of the Institute and for greater control over commissioning and funding of research into their cultures.\n\nThe policy and structural changes to the Institute continued throughout the 1970s.\n\nThe Aboriginal Advisory Committee was established in 1975, and consisted of the six Aboriginal members of the AIAS Council. Early recommendations including increased representation of Aboriginal people on committees and the AIAS Council as well as employment at the Institute. The committee was renamed in 1978, to Aboriginal and Torres Strait Islander Advisory Committee.\n\nIn 1975–1976, a category of research grants for Aboriginal researchers was introduced. The emergence of Aboriginal and Torres Strait Islander people filling the role of ‘cultural practitioner’, travelling to the AIAS to provide advice on projects and research being undertaken, was also documented from around 1976 onwards.\n\nThe time Peter Ucko spent as Principal of the AIAS saw a phase of “rapid expansion” for the Institute.\n\nThe AIAS Film Unit that had operated in Sydney until 1973 was re-established in Canberra in 1975. Prominent American-born ethnographic filmmaker David MacDougall was appointed as the Director of this new AIAS Film Unit. With his wife and filmmaking partner Judith, and Kim McKenzie, the Film Unit operated until 1988 when its functions were absorbed back into the Institute.\n\nDuring the MacDougall/McKenzie era, a new style of ethnographic film was explored. One that moved away from film as a scientific record in favour of telling the story of individuals lives. The filmmakers also practised a more collaborative approach to their films, and chose to use translations and subtitles to give direct access to the subjects voice and thoughts rather than the dominant ‘voice of god’ narration style.\n\nOne of the most notable films produced towards the end of this period was \"Waiting for Harry\", a prize-winning film directed by Kim McKenzie with anthropologist Les Hiatt and now considered to exemplify the \"style of collaborative filmmaking\" the Film Unit favoured in their work.\n\nThe power of film to \"influence opinion\" was becoming increasingly recognised and with this, the lack of representation of Aboriginal people telling their own stories. In 1978, a meeting chaired by prominent activist and academic Marcia Langton expressed these concerns, arguing for greater access to film and video in Aboriginal communities, and training in film production by the AIAS.\n\nBy the following year, the AIAS Film Unit had begun to implement a training program and had started employing trainee Aboriginal filmmakers on productions by the early 1980s.\n\nThe AIAS began presenting a biennial Wentworth Lecture in 1978, named as a tribute to W.C. Wentworth for his role in establishing the Institute. The lecture is presented by prominent person with knowledge or experience relating to issues affecting Aboriginal and Torres Strait Islander peoples in Australia today.\n\nThe expansion of the Institute continued into the 1980s. The Aboriginal Studies Press began publishing the Australian Aboriginal Studies Journal in 1983, a peer-reviewed journal aimed at “promoting high-quality research in Australian Indigenous studies.”\n\nIn 1982, the AIAS established a task force that identified the prevailing need for further ‘Aboriginalisation’ of the Institute’s workforce. At the time, there were four Aboriginal staff members, making up around 7% of the total staff. This was followed in 1985 with the creation of the role of Aboriginal Studies Coordination Officer within the AIAS, whose responsibilities involved improving access for Aboriginal people to the research and resources of the Institute.\n\nThe ‘After 200 Years’ project was launched in 1985, aiming to fill some of the gaps in the AIAS photographic collection; particularly images of daily life in the southern, urban parts of Australia. Aboriginal involvement in selecting subject matter, photographing and documenting the collection was a major part of the project. The three-year project culminated in the publication of a book containing hundreds of photographs of Aboriginal and Torres Strait Islander people, and selected by them to represent their community.\n\nThe Rock Art Protection Program (RAPP) commenced in 1986 following a request for such an initiative by the then Minister of Aboriginal Affairs Clyde Holding. The aim of the RAPP was to protect Australian Indigenous rock art. Grants were approved by the Institute to fund various projects related to rock art protection.\n\nThe collections were also expanding, and by 1987 the AIATSIS library encompassed the print collections, a special Bibliographic Section and the Resource Centre (which contained the Institute’s audiovisual materials).\n\nBetween 1987 and 1989, the survival of the AIAS as an independent statutory body was tied to a proposal for a new statutory commission that would take over all aspects of the Aboriginal Affairs portfolio. This commission would become the Aboriginal and Torres Strait Islander Commission (ATSIC), conceived in an Act of Parliament in 1989. The AIAS would not be folded into this commission; instead it would be recreated under a new Act with a new name.\n\nThe Australian Institute of Aboriginal and Torres Strait Islander Studies (AIATSIS) Act was passed by parliament in 1989, replacing the AIAS Act. The newly established AIATSIS had a reduced Council consisting of nine members, with the AIATSIS Act specifying that Aboriginal and Torres Strait Islander people hold a minimum of five of these Council positions.\n\nThe new Act also established a Research Advisory Committee, to assess research applications and advise the Council.\n\nThe Aboriginal Studies Press published their best-selling Aboriginal Australia map in 1996, based on research conducted for the Encyclopaedia of Aboriginal Australia.\n\nIn 2001, the Institute launched a two-year Library Digitisation Pilot Program (LDPP). Among the items digitised, catalogued and made available online were 267 volumes of the Dawn and New Dawn magazines held in the AIATSIS collection. AIATSIS also distributed over 2000 free copies of these magazines on CD-Rom, to Indigenous organisations, schools and libraries in New South Wales.\n\nThroughout this period, AIATSIS continued to undertake projects focused on the digitisation of collection materials, including their holdings of the complete back catalogue of Koori Mail. This involved scanning over 35,000 pages from 500 editions of the newspaper, with searchable copies launched on the AIATSIS website in partnership with Koori Mail in 2011.\n\nAs part of their research functions, AIATSIS also initiated a number of public programs and research related events during this time that are still run today. The Institute has convened the National Indigenous Studies Conference every two years since 2001 and the National Native Title Conference every year since 2002.\n\nThe ‘After 200 Years’ photographic project was revisited in 2014 with an exhibition of images at Parliament House, to coincide with AIATSIS’ 50-year anniversary.\n\nThe Australian Institute of Aboriginal and Torres Strait Islander Studies Act 1989 is a Commonwealth Act of Parliament that establishes the purpose and functions of AIATSIS.\n\nThe main functions of AIATSIS under the Act are:\n\nThe AIATSIS Act 1989 also established a Research Advisory Committee and sets out the framework for the AIATSIS Council; specifying the number of members and the minimum representation of Aboriginal and Torres Strait Islander members on Council.\n\nOther legislation that governs the operations of AIATSIS are the \"Public Governance, Performance and Accountability Act 2013\" and the \"Public Service Act 1999\".\n\nThe Minister for Education and Training is responsible for the Institute, as AIATSIS is part of the portfolio of the Department of Education and Training.\n\nThe AIATSIS Council is a governing body designed to oversee and steer the functions and direction of the Institute. The role and responsibilities of the Council are mandated in the AIATSIS Act 1989 and detailed in the AIATSIS Council Charter.\n\nThe Council consists of nine members, four are elected by the Institute's membership and five appointed by the Minister.\n\nAccording to the AIATSIS Act 1989, one person appointed by the Minister must be a Torres Strait Islander and the four other people appointed by the Minister must be Aboriginal persons or Torres Strait Islanders. The four Council members elected by the Institute’s membership must be members themselves.\n\nCurrent AIATSIS Council Chairperson:\n\nThe first Aboriginal Chairperson of AIATSIS Council:\n\nThe first Aboriginal woman to be Chairperson of AIATSIS Council:\n\nThe Research Advisory Committee (RAC) is responsible for assessing and advising on AIATSIS research projects and programs, including research grants.\n\nThe functions of the Research Advisory Committee are established in the AIATSIS Act, 1989. They are:\n\nThere are twelve members of the RAC. Three Council members are appointed by the Council and eight members of the Institute are elected by the members. The final RAC member is the AIATSIS Principal.\n\nThe Research Ethics Committee (REC) is responsible for advising AIATSIS on the ethics of the research proposals by staff or grantees of AIATSIS, as well as research carried out through the Institute’s external collaborations.\n\nThe roles in the Research Ethics Committee are based on guidelines published by the National Health and Medical Research Council. There are eight members appointed by the AIATSIS Council, with at least four being Aboriginal or Torres Strait Islander people, as follows:\n\n\nThe functions of the REC are governed by the AIATSIS Research Ethics Committee Charter.\n\nThe Native Title Research Advisory Committee (NTRAC) was established by the AIATSIS Council to oversee the work of the Native Title Research Unit and provide advice to the AIATSIS Principal.\n\nThere are ten members of the NTRAC, held by people fulfilling the following criteria:\n\n\nThe NTRAC shares oversight of the quality, independence and ethical research of the Native Title Research Unit with the AIATSIS Council and the Research Ethics Committee.\n\nThe Publishing Advisory Committee (PAC) is responsible for making recommendations to the AIATSIS Principal on the selection of manuscripts for publication by the Aboriginal Studies Press.\n\nManuscripts are first submitted to and read by Aboriginal Studies Press staff and are then subject to peer review by scholars and professionals before being assessed by the PAC.\n\nThe PAC members contribute the following range of skills: academic credentials; Indigenous community and language knowledge; and writing and publishing expertise.\n\nThe Indigenous Caucus is a working group within AIATSIS providing a forum for Aboriginal and Torres Strait Islander staff to meet and discuss workplace issues. The Caucus also provides advice to the AIATSIS Principal, as well as the broader Institute and its Committees.\n\nCaucus also has representatives on the AIATSIS Consultative Committee, a forum for staff and management of the Institute to discuss issues.\n\nThe Indigenous Caucus was revitalised in 2003–2004 and contributed to the development of policies and procedures in that year, notably AIATSIS’ Indigenous Training and Career Development Plan.\n\nIn 2013, the Indigenous Caucus developed a formal Service Charter and elected an Executive consisting of three members.\n\nThe AIATSIS Act sets the organisation the task of conducting, facilitating and promoting research in Aboriginal and Torres Strait Islander Studies and training Indigenous researchers. For over 50 years, AIATSIS has conducted research across a range of areas of study relevant to Indigenous peoples, culture, heritage, knowledge and experiences. This has led to a diverse research history; from languages and archaeological research, land rights and political engagement to contemporary topics in health and commerce.\n\nThe AIATSIS collections not only contain priceless records of Australia’s Indigenous cultural heritage, but provide a significant national and international research infrastructure for research by, for and about Aboriginal and Torres Strait Islander peoples.\n\nAIATSIS is one of Australia’s Publicly Funded Research Agencies, alongside organisations such as CSIRO and the Australian Institute of Marine Science. AIATSIS is Australia's only non-science PFRA.\n\nCurrently AIATSIS undertakes research in six priority areas.\n\n\nAIATSIS publishes the Guidelines for Ethical Research in Australian Indigenous Studies (referred to as GERAIS), a document considered to be the leading ethics guidelines for conducting research in and with Indigenous communities in Australia.\n\nThe guidelines consist of 14 principles. These principles broadly fit under the following themes:\n\n\nThe GERAIS document is required reading for researchers applying for Ethical Clearance for research sponsored by AIATSIS. However, the guidelines are also intended by AIATSIS to inform all research in the field of Indigenous studies.\n\nOriginally published by AIATSIS in 2000, the latest version of the GERAIS document was published in 2012. This update was made to reflect legal and technological developments that had occurred since original publication. In particular, in the area of intellectual property and the rights of Indigenous people in their traditional knowledge and cultural expressions as well as progress in digitisation technologies and data and information management.\n\nThese changes reflect AIATSIS’ support for the importance of research projects involving appropriate ethical conduct and rights protection for both the way data is collected during research and the findings and materials generated through that research.\n\nThe GERAIS document is the first point of reference in the ethical review process researchers must undergo before AIATSIS will sponsor a research project. All research projects are reviewed by the Research Ethics Committee for approval, using the following project documents:\n\n\nIn 2013, AIATSIS was involved in the review of two National Health and Medical Research Council research ethics guidelines relating to Aboriginal and Torres Strait Islander health research.\n\nAIATSIS began undertaking Native Title research activities through the Native Title Research Unit in 1993, following the 1992 Mabo v Queensland High Court decision. Native Title research at AIATSIS is primarily funded through the Department of the Prime Minister and Cabinet but research has also been conducted in partnership with other departments and organisations including the Australian National University, the Australian Conservation Foundation and the Federal Court of Australia.\n\nThe Native Title Research Advisory Committee, the Research Advisory Committee and the AIATSIS Council oversee the work conducted in Native Title and traditional ownership research at AIATSIS.\n\nAIATSIS conducts a range of research projects relating to Native Title and traditional ownership, including Native Title and cultural heritage, Native Title and fresh and sea water, and Prescribed Body Corporates.\n\nThe role of Native Title research at AIATSIS is to monitor outcomes of Native Title and through research and study, provide advice on Native Title policy development. The Institute publishes a range of materials relating to Native Title including books, discussion papers, research reports and a Native Title Newsletter.\n\nAIATSIS also provides a Native Title Research and Access Officer, who is responsible for assisting Native Title claimants to access materials from the AIATSIS collections in support of their claim.\n\nAIATSIS also contributes to Native Title policy and research by co-organising the Annual National Native Title Conference.\n\nAIATSIS publishes a number of resources for anyone wishing to undertake research into their own family history.\n\nThe \"Family History kit\" is aimed at providing the basics for tracing Aboriginal and Torres Strait Islander heritage. It contains guides to AIATSIS’ own resources, including the Aboriginal and Torres Strait Islander Biographical Index (ABI) and digitised collection materials, as well as guides to external resources that may help with family history research.\n\nGeneral guidance is also provided regarding research resources specific to Indigenous family history research, historical name conventions and usage and confirmation of Aboriginal and Torres Strait Islander heritage.\n\nAIATSIS also provides research support to Link-Up case workers and researchers around Australia, who are assisting members of the Stolen Generations to reconnect with their family and heritage.\n\nAIATSIS is the only Commonwealth institution responsible for collecting and maintaining materials documenting the oral and visual traditions and histories of Australian Aboriginal and Torres Strait Islander people. The Institute identifies its collection as a “keeping place for culturally significant objects” that is “a resource for anybody looking to improve their knowledge of Aboriginal and Torres Strait Islander history and culture.” The Institute's holdings represent thousands of years of history and more than 500 Australian Indigenous languages, dialects and groups. This collection supports, and is a result of, research in the fields of Aboriginal and Torres Strait Islander Studies.\n\nAn independent assessment in 2014 confirmed that AIATSIS holds over 6 million feet of film, over 40,000 hours of audio, 12,800 unpublished manuscripts and record series, 653,000 photographs, and 120,000 print and published materials (3,000 of which are rare books) among other miscellanea.\n\nThere are a number of items within the AIATSIS collection that have been both nationally and internationally recognised as significant:\n\nThe Audiovisual Archives also holds copies of the first audio recorded in Australia; a series of ethnographic wax cylinder recordings made in the Torres Strait Islands in 1898. The Cambridge Anthropological Expedition to the Torres Strait, led by Alfred Cort Haddon, recorded songs and speech from Mer/Murray Island, Mabuiag/Jervis Island, Saibai Island, Tudu Island and Iama/Yam Island.\n\nThe AIATSIS collection is housed and managed through the Library and the Audiovisual Archive, and is broadly categorised into the following groups:\n\nArt and artefact: a collection of items including ritual objects, folk art, children’s art and modern or ‘high art’ and span from the late 19th century to the present day. This sub-collection comprises around 600 artworks and 500 artefacts, acquired either as a result of AIATSIS-sponsored field research or through donation or purchase.\n\nBooks and printed material: a collection of books, pamphlets, serials including magazines and government reports, reference publications such as dictionaries and other published material. This sub-collection holds over 175,680 titles, including 16,000 books and 3740 serials consisting of 34,000 individual issues and is used to support research, especially in Native Title cases and Link-Up services for members of the Stolen Generations.\n\nFilm: a collection of historical ethnographic films, documentaries and other published film and video titles, consisting of over 8 million feet of film and 4000 videos. Many of the films in the collection were produced by the AIAS Film Unit, which operated between 1961 and 1991.\n\nManuscripts and rare books: a collection of more than 11,700 manuscripts, 2,600 rare books dating from 1766, 2,200 rare pamphlets and 1,700 rare serial titles consisting of 14,650 issues held in secure, environmentally controlled storage. Items are included in this classification on the basis of their age, rarity, value or sensitivity of the content for Aboriginal and Torres Strait Islander people. Among these items are the Sorry Books and the WEH Stanner papers.\n\nPictorial: this collection contains roughly 650,000 photographs that date from modern day as far back as the late 1800s, and more than 90% of images in the pictorial collection are unique to AIATSIS, making it the most comprehensive record of its kind relating to Australian Aboriginal and Torres Strait Islander people.\n\nSound: a collection of many unique and unpublished sound recordings totalling approximately 40,000 hours of audio. The recordings represent a breadth of cultural and historical information including languages, ceremonies, music, oral histories and interviews with participants in significant events such as the 1965 Freedom Rides and Prime Minister Kevin Rudd’s Apology to the Stolen Generations.\n\nSince the establishment of the Institute in 1964, the AIATSIS collection has been developed through acquisition by donation, gift and purchase or, through materials created and collected during the work of ethnographic field researchers and filmmakers funded by the AIATSIS grants program. The collection has also been built through deposits of materials, an arrangement which permits the original owners to assign access and use conditions appropriate to the cultural information contained in the items.\n\nAIATSIS’ approach to collection building is based on three primary criteria:\n\nOnce material has been acquired by AIATSIS, the Institute faces the challenges of maintaining a cultural resource collection. This is achieved through a collection management plan that involves processes of recording and cataloguing, and appropriate storage and handling to extend the life of physical items and preserving their content through format shifting.\n\nPreservation of physical items in the collection is achieved in two key ways:\n\nThere are a wide variety of analogue photograph, tape and film formats held in the AIATSIS collection, which pose special preservation and future access risks. The age of some of these formats and materials, combined with the varying conditions in which they were stored prior to their acquisition by AIATSIS, heightens the deterioration of the media. Another preservation issue inherent in these analogue materials is the machines that can play back that particular format, as in some cases the material and the playback device are no longer manufactured. To manage these risks and maintain future access to the collection, preservation of the actual content contained in collection items is also achieved through a program of digitisation.Due to the potential issues of long-term archiving and storage of digital items, the opposite process is often employed to ensure access and preservation. In the case of digital publications and manuscripts, the originals will often be printed and incorporated into the print collections as an additional preservation measure.\n\nThe AIATSIS collection holds material that is sensitive and/or secret/sacred to Aboriginal and Torres Strait Islander peoples. In accordance with its founding Act, and as part of their collection management plan, AIATSIS adheres to strict protocols when handling and processing these sensitive items. The Institute also supports and adheres to the protocols developed by the Aboriginal and Torres Strait Islander Library, Information and Resource Network (ATSILIRN). Restricted visual media such as photographs and printed items are stored separately to the rest of the collection and audio and moving image items are not played until any cultural requirements are checked. Restricted material must also be carefully handled during digitisation, which means that the work is carried out in secured conditions such as enclosed booths and by staff that can meet the protocols of the item being digitised.\nAIATSIS launched its Library Digitisation Pilot Program in 2001, before which the Library had no dedicated digitisation equipment or policies for managing digital materials. This two-year program was originally funded by the Aboriginal and Torres Strait Islander Commission (ATSIC), and involved the creation of digital collections across the institution.\n\nSince then AIATSIS has continued to incorporate digitisation of the collection into its management plan, but have publicly stated that an increase in funding is required for the Institute to digitise some of the at risk formats held in the collection before those items are lost.\n\nGiven these limitations, AIATSIS prioritises the selection of materials for digitisation using factors including significance of the item/s, the level of deterioration, cultural protocols, copyright status, and client demand. One of the identified priorities of the program is to digitise and preserve all of the audiovisual collection currently on endangered magnetic tape formats by the 2025 deadline set by UNESCO.\n\nThe collection is housed in the AIATSIS building on Acton Peninsula and is accessible through a number of resources. The AIATSIS Library is open to the public and holds a range of printed materials including manuscripts, journals, readers in different Aboriginal and Torres Strait Islander languages, dictionaries, published books and rare books, maps, and posters.\n\nAccess to AIATSIS' print and manuscript collections can be made through the Library's Stanner Reading Room and the film, sound and pictorial collections by appointment through the Access Unit. These physical access points are open limited hours.\n\nThe AIATSIS Digitisation Program contributes to increased access to the collection; whether access is through on site resources, the provision of copies of materials or the sharing of the collection online. Due to increasing obsolescence of analogue formats, AIATSIS identifies digitisation as the way to preserve those items for future generations to access. This is considered to be particularly important for facilitating “remote access by Aboriginal and Torres Strait Islander communities” as well as for access by researchers and the general public.\n\nThe AIATSIS Access Unit runs a program called Return of Material to Indigenous Communities (ROMTIC), through which Aboriginal and Torres Strait Islander clients are provided with up to twenty copies of collection materials that relate to their language group or family. This service is limited to items that have been preserved, so AIATSIS’ digitisation program has allowed an increasing number of digital items available to ROMTIC clients.\n\nAIATSIS also makes the collection available through a series of online exhibitions and digitised collection material published on their website. These showcase different themes or discrete collections of material, including:\n\n\nAccess to the AIATSIS collection is also dictated by legislation governing the Institute and in some instances by legal agreements outlining the terms under which collection materials can be used.\n\nThe terms for access to the AIATSIS collection are in the first instance set by the AIATSIS Act, Section 41. This section states:\n\nThe conditions referred to in Section 41(1) of the AIATSIS Act are usually covered in the agreement that AIATSIS enters into when material is deposited. These agreements, along with the section 41(2) of the Act, can govern the way that unpublished material can be accessed and used.\n\nAccess to and use of material in the AIATSIS collection is also subject to the terms set out in the Copyright Act (1968).\n\nWhen a donation or deposit is being made, AIATSIS requests to be made aware of any sensitive items included in the material. The secret or sacred nature of information contained in many collection items is an important factor in access to the AIATSIS collection. To protect items of high cultural sensitivity and reflect appropriate cultural values, access to items that contain culturally sensitive information are restricted to groups or individuals who have the permission of the relevant Aboriginal or Torres Strait Islander community and the depositor if restrictions have been applied by them.\n\nAIATSIS also acknowledges the United Nations Declaration on the Rights of Indigenous Peoples and in particular Article 31's recognition of the right of Indigenous people to \"maintain, control, protect and develop their cultural heritage, traditional knowledge and traditional cultural expressions.\"\n\nIn response to these complex issues AIATSIS developed an overarching Access and Use Policy in 2014, to “manage legal and cultural rights over material while maximising accessibility.”\n\nSince its inception, AIATSIS has developed and maintained a range of resources to enhance discoverability of the collection.\n\nOne of the most significant of these resources is the Aboriginal and Torres Strait Islander Biographical Index (ABI). The ABI had its beginnings in 1979 as a non-selective biographical register of names, constructed using information on Aboriginal and Torres Strait Islander people from published material in the collection. In the early years of the biographical register, it was hoped it could “provide an important record of the achievements of Aboriginal people, and be a source of pride for generations to come\".\n\nToday the index continues to be updated, now containing over 70,000 records and searchable online through AIATSIS’ collection catalogue.\n\nOther resources available on site include the Perfect Pictures Database, which contains over 140,000 digitised images from the AIATSIS Photographic Collection. This database is added to as more images are digitised and only includes images that are free of secret/sacred access restrictions.\n\nAIATSIS also hosts or contributes to a number of online resources, aimed at facilitating access to and understanding of the collection. These include:\n\n\nIn keeping with its mandated functions, AIATSIS publishes the results of Aboriginal and Torres Strait Islander Studies through their publishing arm, Aboriginal Studies Press (ASP). The Institute began publishing in 1962 with \"A demographic survey of the Aboriginal population of the Northern Territory, with special reference to Bathurst Island Mission\". This and other early publications were released under the imprint Australian Institute of Aboriginal Studies, the former title of AIATSIS. The ASP publishing imprint was trademarked in 2002, but was operating as the publishing arm of AIATSIS as early as the publication of Helen Ross’ \"Just For Living\" in 1987.\n\nThe AIATSIS Research Publications became an imprint in 2011 and its stated purpose is to publish scholarly research that is derived from the AIATSIS Research Program. Along with the Research program, ASP also publishes the Australian Aboriginal Studies (AAS) journal. All Aboriginal Studies Press-branded titles are peer-reviewed and the majority are published concurrently in print and several ebook formats. The first phone app was published in 2013, and was shortlisted for the 2013 Mobile Awards.\n\nTitles published by ASP have included research reports, monographs, biographies, autobiographies, family and community histories, and children’s books. Since 2005 the list has aligned more closely with the Institute’s research focus. Most publications derive from academic research, some funded by AIATSIS. ASP publishes books by both Aboriginal and Torres Strait Islander and non-Indigenous authors who are writing in the field of Aboriginal and Torres Strait Islander Studies. In some cases Aboriginal authors, like Doreen Kartinyeri and Joan Martin, have chosen to write in collaboration with non-Aboriginal oral historians.\n\n\"Cleared Out\" (2005) won two WA Premier’s Book Awards and inspired the multi-award-winning documentary film, \"Contact\". The creation of both the book and film reflect strong family and community engagement.\n\n\"The Little Red Yellow Black Book\" (updated 2008, 2012) was shortlisted with its companion website in the Australian Publishers Association Educational Awards, and is a widely recognised as an educational and cross-cultural training resource.\n\nAnother widely used resource published by Aboriginal Studies Press is the Aboriginal Australia map. The Aboriginal Australia map represents the general locations of larger groupings of Aboriginal people, using research that was conducted during the development of \"The Encyclopaedia of Aboriginal Australia\", which was another significant ASP publication. Previous milestone publications included the book \"After 200 Years\", a collaboration showcasing photographs and stories of Aboriginal people as selected by members of those communities. Both books are now out of print and only available in libraries.\n\nASP also publishes the Stanner Award winner for a manuscript by an Aboriginal or Torres Strait Islander, which recognises the importance of being published to emerging academics. The prize includes mentoring and editorial support by ASP, as well as publication of the manuscript.\n\nThe Publishing Advisory Committee makes recommendations to the AIATSIS Principal and Aboriginal Studies Press about which manuscripts to publish from those submitted.\n\nAboriginal Studies Press has relationships with distributors and resellers for both national and international print and ebook distribution.\n\n\nAIATSIS hosts a range of special events and research workshops, symposiums and conferences. Yearly and two-early events and conferences include:\n\n\nAIATSIS is located on the Acton Peninsula in a building that was newly built for the Institute and opened in 2001. The building was officially opened by the Honourable W.C. Wentworth and Mr Ken Colbung. As part of the opening the Ngunnawal people, the traditional owners of the land on which the AIATSIS building stands performed a Welcome to Country and smoking ceremony, and the Anbarra people from North Central Arnhem Land performed a friendship ceremony, known as Rom.\n\nThe architect, Howard Ragatt of the firm Ashton Raggatt McDougall designed the building for AIATSIS and for its neighbour on the Acton Peninsula, the National Museum of Australia. The building cost $13.75 million and was funded by the Commonwealth Government’s Centenary of Federation Grants Program.\n\nThe design of the AIATSIS building has been the subject of differing interpretations. The rear of the building has been described as a black copy of pioneer architect Le Corbusier's 1920's Villa Savoye in France. The architect, Howard Raggatt, was quoted as confirming this influence but has also stated that it is designed to be reminiscent of Sidney Nolan's famous paintings of Ned Kelly.\n\nDuring design of the AIATSIS building, it was reoriented from original plans to save two Apple Box trees that were identified as significant to the Peninsula.\n"}
{"id": "33469100", "url": "https://en.wikipedia.org/wiki?curid=33469100", "title": "Ayu language", "text": "Ayu language\n\nAyu is a minor and endangered Plateau language of Nigeria. Its subsequent classification is uncertain, but it may be one of the Ninzic languages (Blench 2008). It is not being passed on to many children.\n"}
{"id": "290257", "url": "https://en.wikipedia.org/wiki?curid=290257", "title": "Baby sign language", "text": "Baby sign language\n\nBaby sign language is the use of manual signing allowing infants and toddlers to communicate emotions, desires, and objects prior to spoken language development. With guidance and encouragement signing develops from a natural stage in infants development known as gesture. These gestures are taught in conjunction with speech to hearing children, and are not the same as a sign language. Some common benefits that have been found through the use of baby sign programs include an increased parent-child bond and communication, decreased frustration, and improved self-esteem for both the parent and child. Furthermore, along with positive results, researchers have found that baby sign neither benefits nor harms the language development of infants. Promotional products and ease of information access have increased the attention that baby sign receives, making it pertinent that caregivers become educated before making the decision to use baby sign.\n\nBaby sign involves enhanced gestures and altered signs that infants are taught in conjunction with spoken words with the intention of creating richer parent-child communication. The main reason that parents use baby sign is with hope that it will reduce the frustration involved in trying to interpret their pre-verbal child's needs. It can be considered a useful method of communication in the early developmental stages since speech production follows children's ability to express themselves through bodily movement.\n\nBaby sign is distinct from sign language. Baby sign is used by hearing parents with hearing children to improve communication. Sign languages, including ASL, BSL, ISL and others, are natural languages, typically used in the Deaf community. Sign languages maintain their own grammar, and sentence structure. Because sign languages are as complex to learn as any spoken language, simplified signs are often used with infants in baby sign. Teaching baby signs allows for greater flexibility in the form of sign and does not require the parent to learn the grammar of a sign language. Baby signs are usually gestures or signs taken from the sign language community and modified to make them easier for an infant to form.\n\nIt is common for the difference between symbolic gestures and baby signs to be mistaken. Symbolic gestures are a form of communication that children adopt before they develop the ability to produce spoken language. This includes pointing to what they want or using a hand motion in conjunction with a word which allows greater communication for infants. Infants from about six months of age can begin to learn the basic signs, which cover such objects and concepts as “thirsty,” “milk,” “water,” “hungry,” “sleepy,” “pacifier,” “more,” “hot,” “cold,” “play,” “bath,” and “teddy bear.” Typically, developing children will produce their first gestures between the ages of 9 and 12 months without any prompting or assistance from a caregiver. Infants learn how to use their body language, eye gaze, and hand gestures as a way to attract attention and communicate. Once children gain some language production, they will couple language with gesture to further communicate. Gesture remains present in all individuals at any age which is a distinguishing factor from baby sign.\n\nBaby sign promotes communication before a child is able to verbally communicate with others. Since gestures are part of normal speech, teaching baby sign allows infants to learn an aspect of communication that is used with language. It is not, however designed to replace language. Prior to any teaching of signs by adults, children will gesture while making babbling sounds or without babbling. They will not however, during infancy, babble without making a gesture. This demonstrates that infants are able to learn gestures before mastering verbal skills. Therefore, those who learn these simplified signs may enhance their cognitive development by gaining language skills through both visual and auditory modes.\n\nIn an article in \"The Psychologist,\" Gwyneth Doherty-Sneddon has considered in detail the theory behind the growth of this phenomenon and some of the claims made by its supporters. Doherty-Sneddon points out that baby sign is not entirely new. Variations have been used by speech and language therapists for decades with children who have impairments to either their speech, cognitive abilities, or both. It is widely recognized that communication is at the heart of cognitive, social, emotional, and behavioral development in children. Baby sign may assist in improving these significant developmental functions.\n\nBaby signs create mutual attention between the parent and child leading to further elaboration of what the infant is communicating. A study collected self reports from mothers, who engaged in a baby sign training workshop, to clarify whether or not signing with their child would create added parental stress and/or enhance parent-child communication. Overall the parents did not express feeling heightened stress or frustration from the baby sign training process but rather they reported a greater ability to understand their child. This richer communication was found to lead to a more positive interaction with their child which overall benefits the establishment of an earlier parent-child bond.\n\nChildren who learned enhanced symbolic gestures performed better on both expressive and receptive verbal language tests compared to those who had not been encouraged to learn such gestures. Receptive language means being able to recognize words and signs, while expressive language involves the process of forming words or signs. Research has shown that enhanced gesture input for hearing children is the first step toward successfully mastering gesture use, and the use of representational form and symbolic communicative function. Improved symbolic gestures may contribute to language development by providing children with increased knowledge of concepts by explaining the functions of the objects that they are exposed to. In support of expressive language development studies have shown that learning symbolic gestures can lead to advanced verbal development and accelerated language acquisition. An effective baby sign workshop also resulted in the improvement of numerous areas of development by comparing the child's results before and after the workshop. Some of these areas included communicative, cognitive, social, adaptive behavior, physical, and fine motor skill development of children. This enhancement however, is short-lived (from between 12 and 15 months of age). Doherty-Sneddon argues, however, that this timescale represents only a general norm. The enhancement and advantage is far more extended in the many toddlers who do not speak until well after their second birthdays.\n\nDoherty-Sneddon also states a key issue is ensuring that sufficient and appropriately designed research is available to back the claims made in relation to baby signing. A literature review concluded that although benefits were reported in 13 of 17 studies, various weaknesses in the methods used for baby sign studies leave the evidence unsupported. Certainly, research into the effects of baby signing needs better control groups, such as children who are involved in equally interesting and fun activities based around adult and child language interaction, but not baby signing. This suggestion for further research implies that it may not be the baby signs themselves that facilitate language development but rather the underlying benefit being active, joint attention that is stimulated by baby sign.\n\nTherefore, the enhanced joint visual attention during parent-child interaction empowers the infant to focus the topic and context of the conversation, clarify concepts, and creates added practice with symbolic interaction. These underlying mechanisms of baby sign are proposed to create benefits for the infant such as; enhancing vocabulary, advancing cognitive development, reducing tantrums and frustration, and improving the parent-child relationship and communication. More specifically language development is improved by advancing comprehension, promoting literacy and successfully allowing the infant to express their needs so the parent becomes more responsive and observant of their baby.\n\nResearchers have suggested the possibility of parents and experimenters being overly liberal in attributing sign or word status to early attempts at communication by children. Puccini and Liszkowski found that when infants associate labels with objects, they use verbal cues more frequently than gestures to make these associations. The process of further facilitating gesturing with baby signs is suggested to possibly cause interference toward children's mapping of these words. This may be a result of infants lacking enough attention to take in these two types of information and process it at the same time. It is suggested that these labels, and further through the facilitation of baby sign, that it is unlikely that baby sign is facilitating speech development in infants.\n\nBaby sign programs encourage parents to improve their communication skills between themselves and their infants before they have developed speech. Kirk and colleagues have found that the results of their study with hearing infants provided no evidence to support that a child’s language development would benefit from learning baby sign. They also found that children who participated in baby sign had similar language development to children who did not learn baby sign. It is suggested that participating in baby sign may be an unnecessary effort with infants when being motivated by the hopes of advanced language learning for the child. However, it was found that mothers who used baby sign with their infants encouraged increased independence with them and supported a higher level of independence for their child. Another conducted research study has shown that there are no significant differences found with language acquisition between infants who are receiving or not receiving exposure to baby sign, including reaching language milestones Although no support for using baby sign was found in this study, there was also no negative effects found to be associated with language development when using baby sign with your child. It is possible that baby sign is working in support of infant's spoken language, but was not found to further their later language development.\n\nThe results of multiple studies regarding baby sign have found that the advantages provided do not go beyond children over the age of two years old. The results of this literature review have not shown support that baby sign increases a child's linguistic development. When teaching a child baby sign, an infant's attention is directed away from what they are interested in and is redirected towards the adult and the desired sign. This interaction has been claimed to increase joint attention between parent and child, but has yet to be studied enough in research literature. It has also been proposed by researchers that baby sign may increase parental stress rather than decrease it because of busy lifestyles that may be disrupting interactions between parents and children. Teaching baby sign outside of research settings does not allow for the parent to raise questions or concerns to trained individuals. Reaching fundamental linguistic milestones and the natural course of children's language development has been suggested to be disrupted because of the unnatural intervention in language development that baby sign provides, supported by the lack of support in prior studies which have been analyzed.\n\nThere are numerous concepts to keep in mind when encouraging baby sign. Caregivers should ensure that they have their infant's attention, maintain consistency with what sign is used and how it is used in relation to an item, repeat signs often, encourage the infant, and be alert to recognize when the infant is signing back.\n\nWhen it comes to infants who have not yet acquired language abilities, signs are an easy and readily accessible form of communication. Prior to infants learning specific signs or developing language skills, they acquire the spontaneous use of gesture. An infant’s first gesture may appear between 9–12 months of age, often classified as pointing. Gesturing gradually increases as infants connect pointing to word meaning, making a gesture-plus-word combination that will evolve into a two word combination. It is thought that gestures may be easier for infants to remember than a name alone since a gesture is representative of what the child can picture happening, when thinking about the item.\n\nTo determine how infant communication is influenced by gesture and speech, Iverson and Goldin-Meadow conducted a study. Infants in the study used eye gaze, body position, and vocalization to attract and direct their target audience's attention, while gesturing to items. Results looked to see if the gestures that children use are related to the word they say while doing the gesture. Iverson and Goldin-Meadow found that infants gesture for items that they did not have the ability to express with words. When words were produced by the child, they typically were ones that the child had already been gesturing for. This shows that gesture is directly linked to the words that children will produce.\n\nSymbolic gesture is the specific term that encompasses baby sign. This form of gesture aids in communication through the use of hand movements that represent an item or feeling. Infants are quick to note if there is a connection between an item and a symbolic gesture. Once they make the connection infants will imitate actions that are produced by the caregiver. Consistency from the caregiver is crucial during the teaching and feedback stage in order for infants to learn from repetition. This repetition applies to how the caregiver uses the sign and in what way the sign is associated with the object or emotion. If the association changes then the child will have a harder time understanding how the symbolic gesture links to the item. One way for caregivers to ensure the infant associates the symbolic gesture with the object or emotion is to gain the infant's attention, and say the name of the object at the same time that the sign is performed.\n\nInfants watch their caregiver during everyday routines and situations. This observation allows infants to learn symbols by borrowing the actions from the observed routine. A natural association occurs between signs and items, allowing infants to explore and express new ideas prior to language development. Infants will learn to associate a word with the general motion that they carry out while using an object, such as throwing a ball. After this association children begin to make connections with the word and motion alone, in this case a throwing gesture. Infants now can make the throwing gesture to alert caregivers that they wish to throw a ball, thus increasing their non-verbal communication. Representative abilities such as these are further used by infants to demonstrate emotional feelings as they associate a motion or sign with a feeling.\n\nFurther studies demonstrate that increasing the use of gesture, not necessarily use of a sign language, can increase the richness of a child's linguistic development. It is suggested that learning signs happens over a period of time, inferring the importance of caregivers being patient with children as it takes more than a brief interaction between parent and child. Parent-child interactions are vital to the learning of baby sign since the infant looks to the caregiver for guidance. By consciously demonstrating the sign to the infant, the caregiver and infant are sustaining joint attention which increases communication. When caregivers aid infants in creating the sign with their hands, they are further increasing encouragement, repetition, and communication. It is the caregiver’s job to not only teach specific hand signals, beyond what infants naturally pick up, but to provide support and feedback to infants when signs are produced correctly. Through making a connection, and parental encouragement of that connection, infants can learn and actively engage in baby sign language.\n\nIn 1998, a program was conducted at A. Sophie Rogers Infant-Toddler Laboratory School in Ohio State University by Kimberlee Whaley. Infants as young as 9 months old and their teachers began to learn to use some signs from American Sign Language to communicate with each other effectively. The program found that children would use the signs they learned in the classroom at home. Based on this study, learning baby sign appears to be a beneficial tool for children if implemented in schools and day cares.\n\nDue to promotional products, easy access to baby sign tutorial videos, and representations in popular culture parental attempts at signing with their baby may be more focused on the social fad instead of an intention to potentially enhance their child's communication skills.\n\nA study examined the degree to which information about baby sign found on the internet was based on research. Results found thirty-three websites that all promoted baby sign and the benefits associated. Over 90% of the information referred to opinion articles or promotional products encouraging parents to sign, with little to no basis in research. Although websites claim that using baby sign will reduce tantrums, increase infant’s self-esteem, satisfaction, feelings of accomplishment, increase parent-child bonding, and decrease frustration, the sites do not provide enough research-based evidence to support these claims.\n\nAnother study examined internet information found using Google Scholar as well as a few academic databases. Researchers examined whether results claimed baby sign encouraged developmental, social, cognitive, and language skills while achieving a greater bond between parent and child. The goal of asking this question was to find information that allows parents, caregivers, childhood educators, and clinicians to make informed decisions about the amount of emphasis to place on baby sign. When all the cited material was gathered there were 1747 articles with only 10 articles providing research regarding infant's developmental outcome in connection to baby sign. Consensus gathered from these 10 articles states that baby sign, as used by the commercially advertised product authored by Acredolo and Goodwyn, does not benefit language production or parent-child relationships. However, there is also no evidence from these articles that baby sign is in any way harmful to infants. Through these two studies it is illustrated that websites may not contain 100% research based information. Individuals looking for information regarding the pros and cons of using baby sign should ensure they are accessing sites backed by research and not opinion.\n\nCommercial products available to parents participating in baby sign workshops or implementing it at home, are found to be comparable to the quality of products used in research studies. It is suggested that parents be cautious of baby sign products as it is difficult to tell the credibility of commercialized products for facilitating baby sign with your child. Drs. Linda Acredolo and Susan Goodwyn produced books, such as \"Baby Signs: How to Talk with Your Baby Before Your Baby Can Talk\" which was published in 2009, that greatly influenced the baby sign movement, by providing guidance, suggestions, and information to caregivers. Acredolo and Goodwyn's book is not the only one dominating the baby sign industry. \"Essential Baby Sign Language\", a relatively short book written by Teresa Simpson, explains why a caregiver may want to sign with their child, how to start signing, and the best strategies to achieve success. Simpson explains 75 common signs in this book but has other books that are for the more advanced signer, and provide numerous different signs.\n\nA preschool teacher named Karyn Warbuton used baby sign with her daughter and incorporated it into her work with infants, children who spoke English as a second language, and special needs children. \"Baby Sign Language for Hearing Babies\", is one book that explains the type of workshops that Warburton runs with her students, and includes a dictionary of baby signs. In a similar style of providing guidance, and structure to caregivers at home signing, Monta Z. Briant has published different baby sign books as well as a website. One of her books, \"Baby Sign Language Basics: Early Communication for Hearing Babies and Toddlers\", explains how to start signing, when is a good time to begin, how to optimize the experience, and what limits should be set. In \"The Complete Guide to Baby Sign Language: 101 Tips and Tricks Every Parent Needs to Know\", a book by Tracy Porpora, some differences between baby sign and sign language are discussed. As in most products aimed at aiding caregivers, there are pictures to illustrate how specific signs look when done according to the guidelines in the book. These are just a few books that are accessible on the specific topic of teaching baby sign to infants and by no means an exhaustive list.\n\n\n\n"}
{"id": "16249324", "url": "https://en.wikipedia.org/wiki?curid=16249324", "title": "Balanced sentence", "text": "Balanced sentence\n\nA balanced sentence is a sentence that employs parallel structures of approximately the same length and importance.\n\n\n"}
{"id": "41805462", "url": "https://en.wikipedia.org/wiki?curid=41805462", "title": "Basis of articulation", "text": "Basis of articulation\n\nIn phonetics, the basis of articulation, also known as articulatory setting, is the default position or standard settings of a speaker's organs of articulation when ready to speak. Different languages each have their own basis of articulation, which means that native speakers will share a certain position of tongue, lips, jaw, possibly even uvula or larynx, when preparing to speak. These standard settings enable them to produce the sounds and prosody of their native language more efficiently. Honikman suggests thinking of it in terms of having a \"gear\" for English, another for French, and so on depending on which language is being learned; in the classroom, when working on pronunciation, the first thing the learner must do is to think themselves into the right gear before starting on pronunciation exercises. Jenner (2001) gives a detailed account of how this idea arose and how Honikman has been credited with its invention despite a considerable history of prior study.\n\nDifferent accents within a given language may have their own characteristic basis of articulation, resulting in one accent being perceived as, e.g., more 'nasal', 'velarized' or 'guttural' than another. According to Cruttenden, \"The articulatory setting of a language or dialect may differ from GB [General British]. So some languages like Spanish may have a tendency to hold the tongue more forward in the mouth, while others like Russian may have a tendency to hold it further back in the mouth. Nasalization may be characteristic of many speakers of American English, while denasal voice ... is frequently said to occur in Liverpool\". A more detailed exposition can be read in Gili Gaya (1956). Non-native speakers typically find the basis of articulation one of the greatest challenges in acquiring a foreign language's pronunciation. Speaking with the basis of articulation of their own native language results in a foreign accent, even if the individual sounds of the target language are produced correctly.\n\nThe term \"Basis of articulation\" is used in a slightly different sense to refer to a hypothesized articulatory \"baseline\" which is neutral in respect of individual vowels and consonants. This is done in the phonetic framework section of Chomsky and Halle (1968) for the purposes of explaining various distinctive features in terms of their deviation from the neutral position. More recently, Odden has written \"...some features are characterized in terms of the 'neutral position' which is a configuration that the vocal tract is assumed to have immediately prior to speaking. The neutral position, approximately that of the vowel [ɛ], defines relative movement of the tongue” It is not clear if this should be taken to refer only to English.\n\n\n"}
{"id": "34776464", "url": "https://en.wikipedia.org/wiki?curid=34776464", "title": "Bilingual memory", "text": "Bilingual memory\n\nBilingualism is the regular use of two fluent languages, and bilinguals are those individuals who need and use two (or more) languages in their everyday lives. A person's bilingual memories are heavily dependent on the person's fluency, the age the second language was acquired, and high language proficiency to both languages. High proficiency provides mental flexibility across all domains of thought and forces them to adopt strategies that accelerate cognitive development. People who are bilingual integrate and organize the information of two languages, which creates advantages in terms of many cognitive abilities, such as intelligence, creativity, analogical reasoning, classification skills, problem solving, learning strategies, and thinking flexibility. \n\nOne of the first researchers on the subject of bilingual memory and representation was linguist Uriel Weinreich. \"Languages in Contact\", an essay published by Weinreich in 1953, proposed a model of bilingual memory organization that made the theoretical distinction between the lexical and conceptual level of representation. Three different types of organizational models were proposed: coordinate, compound, and subordinate, each having a different relationship between the lexical and conceptual levels of representation. In 1954, Ervin and Osgood reformulated Weinreich's compound-coordinate representational model and placed further emphasis on the context of language learning, similar to the encoding specificity principle later proposed by Tulving in the 1970s. In 1984, Potter et al. proposed the hierarchical model of bilingual memory, consisting of two memory structures, the word association model and concept mediation model. The word association model proposes a link between languages at the lexical level while the concept mediation model proposes a direct link between the conceptual representation and the lexical representation in each language. The hierarchical model was later revised by Kroll and Stewart in 1994 to account for linguistic proficiency and direction of translation, since then it has been re-revised.\n\nOne of the processes involved in analyzing which neural regions of the brain are involved in bilingual memory is a subtraction method. Researchers compare what has been impaired with what is functioning regularly. This contrast between the destroyed and intact regions of the brain, aids researchers in discovering the components of language processing. It has been found that under typical circumstances, when multiple languages are lost at the same time, they are usually regained in the same fashion. It is therefore presumed that areas of the brain, which are responsible for processing language, are potentially the same. There have been examples of cases where languages have been restored prior to one another and to a greater degree, but this is fairly uncommon. The techniques allowing researchers to observe brain activity in multilingual patients are conducted whilst the subject is simultaneously performing and processing a language. Research has proposed that the entire production and comprehension of language is most likely regulated and managed by neural pools, whose stations of communication are in the cortical and subcortical regions. It has been shown that there are no grounds on which to assume the existence of distinct cerebral organization of separate languages in the bilingual brain. That is to say, the cerebral regions that are engaged for both languages are the same. Although neurologists have a basic understanding of the underlying neural components and mechanisms of bilingual language, further research is necessary in order to fully understand or conclude any other findings. \nNeuroimaging techniques such as fMRIs have shown that at least four brain areas are involved in bilingual switching: dorsolateral prefrontal cortex, inferior frontal cortex, anterior cingulate, and supramarginal gyrus. It is expected that switching from one language to another should involve different functional processes when compared to the brain of an individual who only speaks one language. However further studies on brain activation during this switching of languages needs to be done.\n\nEpisodic memory is closely related to semantic memory, Tulving created the two categories as a way to distinguish the specific knowledge from the general knowledge. Episodic memory contains the records of unique events which occurred at particular times, particularly Autobiographical memories are stored in episodic memory. It holds the events from personally experienced past, they exist in subjective time and space and using it requires a conscious recollection and a controlled process. Tulving referred to this as \"mental time travel\", and he \"classifies encoding as an event, rather than a process\".\n\nIt is suggested that bilinguals that have better control of their language processing should perform better in episodic than semantic memory tasks. Bilinguals store the input of language exceedingly well, regardless of their intention to learn. Language forms a surface in the progressive retrieval of features of an event (e.g., on College Ave, at Tim Hortons, on Tuesday...), that triggers further forms within the same language serving to guide retrieval. The events, objects, characters, etc. are all cued by linguistic elements that might serve as a series of triggers. This information is highly integrated, the superiority of action memory is due to better episodic integration for action memory (vs verbal); we remember events based on language cues and these cues further solidify the events.\n\nTo test episodic memory researchers usually use items that can be better related to normal everyday life, such as sentences. Language recognition depends somewhat on the retrievability of meaning, but the extent of this dependence is unknown. Retrieval of memories is language-specific, it matches the language spoken at the time. Depending on what language is used what is recalled may be different because a cue can activate many meanings, it is the context that conditions what meaning is considered first, and context can change over language and cultures.\n\nBilinguals also tend to be bicultural, it is known that we filter all of our experiences through culturally shaped scripts. So, those that are bilingual and therefore for the most part bicultural have multiple scripts to draw from, or more than one set of narrative constraints. All experiences imply some sort of narrative structure, and narrative traditions are culturally shaped. They direct our perception of reality and the encoding of memories. Though they may not directly determine their perception of reality, they determine \"how the story is told\" which may be different from \"how it happened\". This shapes memory, as stories that are deemed as worthy to be told are further solidified by the retelling and reliving of the experience.\n\nAutobiographical memory is a type of Episodic memory process which is involved in the recall of one's life experiences and personal events of ones past. Bilinguals have the ability to recall some life experiences in one language, and other events using another. When recalling language information it is important that the language is recalled in the same context as it was encoded. This is referred to as Context-dependent memory Ex. If one who is bilingual were to learn a Spanish song in a Spanish speaking country, and then come back to their native land, they would have difficulty remembering the song. However once they were immersed in a Spanish context again, recall would come with much more ease. Research has shown that autobiographical memories have increased availability in the language they were created in. That is to say, memories are richer and more elaborate when recalled in the language that the event has taken place, rather than the other language available to them. This can also be referred to as the Encoding specificity principle, where memories appear to be encoded in a language-specific manner. Earlier memory events that occur during youth and are encoded in the first and dominant language, are more emotionally charged, have a higher quality of detail and are greater in number than those memories recalled in the second language. It can also be argued that the language that is spoken and recalled more frequently, will have more associations to multiple circumstances and is therefore more likely to be remembered. Problems can arise if a language that comes to mind 'internally' is not the language that is being spoken externally. For example, if someone recalled an event in Spanish, but then reported it in English. This changeover in languages is most likely to do with the content of the memory itself. Evidence has been shown that language-specific recall of information when probed or cued in the matching language, is recalled vividly, and with much more elaboration and detail. It has also been shown that each language that a bilingual possesses, may represent experiences in somewhat different fashions.\n\nWorking memory is an active part of the memory system that temporarily stores and processes information during mental operations. Highly related are the concepts of attention and executive control. A major function of the working memory system is the retention and processing of verbal information. Baddeley's model of working memory suggests the phonological loop, a slave system that is responsible for the rehearsal of verbal information and has been implicated in language acquisition.\n\nMeasures of verbal working memory are predictive of proficiency in a second language and working memory capacity is strongly correlated with first and second language abilities. Despite these correlations, research into the effects of bilingualism on working memory have been largely inconclusive. Bilingual performance on working memory tasks can be affected by language dominance, language proficiency, and the nature of the task, variables which can be difficult to control and assess. However, most recent research suggests that there are no differences between monolingual and bilingual individuals in regards to working memory performance, although more research is still required to make any conclusive claims. The evidence suggests that working memory performance has a stronger relationship with general linguistic proficiency than it does with the acquisition of a second language. It has also been observed that there are no significant cross-language differences within bilinguals, providing further support for the hypothesis that working memory is not language specific. Bilingual speakers are, however, more accurate in assessing their metalinguistic reading and working memory abilities compared to monolingual speakers.\n\nResearch has found that there are cross-linguistic differences on a short-term memory test known as the digit-span task. For example, Chinese speakers as compared to English speakers had a greater digit span. An explanation of this observation is that digits in English take longer to say and subvocally rehearse in the phonological loop, a component of Baddely's model of working memory. It has been suggested that because memory for short words is better than for long words, a phenomenon known as the \"word-length effect\", that there are cross-linguistic differences on the digit span task. This difference has also been observed in Welsh-English bilinguals, who rated themselves as more proficient in Welsh but had a greater digit span in English because of the shorter digit names. However, research has suggested that familiarity and long-term memory may play an important role and that differences are not strictly the result of subvocal rehearsal rates.\n\nOur thoughts often occur as the inner speech of our natural language. Inner speech is used for such things as rehearsing facts, having a mental conversation with oneself, and counting, among many others. Being fluent in more than one language can affect inner speech in multiple ways. Studies have revealed that fluent bilinguals use their natural language to mentally represent exact numbers, however, non-numerical facts are retrieved in either language with equal ease. Bilingual individuals report feeling and acting different when in different linguistic mindsets and are capable of switching between them for the strategic purpose of activating different (context/language-dependent) information. As perceived language proficiency in a second languages increases, the use of that second language for inner speech becomes more habitual. As well, it has been reported that bilinguals who suffer from psychosis experience hallucinations or reduced linguistic competence in only one language.\n\nSemantic memory is a term coined by Tulving and is closely related to episodic memory, it is a kind of mental dictionary containing all the attributes of event-free knowledge. It relates to general facts about the world (e.g., the sky is blue, 2+2=4) and it has no concern with time or space. Semantic memory does not require conscious thought, as it generally is automatic; it is not bound, except as interest links themes. It has been suggested that retrieval cues for semantic data are themselves semantic.\n\nRecent studies have shown that knowing a second language extends semantic memory and other cognitive capabilities as they recruit different cognitive operations. It is shown to increase the normal capacity and expose the person to new situations and different ways of organizing thoughts. They learn to incorporate different concepts, and language specific inputs. The finding of a positive bilinguality effect for semantic memory provides support for the role of organization in bilinguality. Bilingualism and monolingualism semantic memory is often tested using word fluency tests, to gauge whether and how well these individuals organize their thoughts. These tests have indicated that the type of material is not necessarily of importance but rather the mental activity is more important. It is also found that the bilingualism effect can be observed more under automatic processing than under deliberate processing.\n\nThere are two predominant models of bilingual memory, the Hierarchical Model and the Concept features model. The Hierarchical Model assumes three linked components: a first language lexicon, a second language lexicon, and a conceptual store containing semantic referents. Links between words in the first language lexicon and their meanings in the underlying conceptual store would be strong for bilinguals. For newer bilinguals links running from the second language lexicon to the conceptual store would be relatively weak, if present at all, the links from the second language lexicon to the first language lexicon would be the strong ones. So the bilingual would translate the word from the second language into the first language and from there access the conceptual store (Cheval to horse to basic idea of a horse vs. cheval to basic idea of a horse). Fluent bilinguals have stronger and more direct links to the conceptual store form both languages. In the Concept Features Model, when words have highly prototypical, concrete referents (desk, juice) the translations in both languages would activate the same set of underlying semantic nodes. In more conceptual and abstract referents (poverty, intelligence) translation equivalents activate different but overlapping sets of semantic nodes.\n\nIn bilingual memory as Colin M. MacLeod found the two translated words (e.g., Horse and Cheval) are not stored as synonyms, they share the same supralinguistic semantic representation in memory (a supralinguistic concept is an abstraction of meaning more primitive than the word itself, it cannot be defined). It is stored in a kind of tag on a language free semantic representation of the world, where the input language is stored as a semantic trace.\n\nIn general a positive effect of bilingualism in semantic memory is more pronounced for older than for younger children. Since bilingual children engage in extensive practice of two languages at an early age, they become better at paying attention to parts of information and at inhibiting other parts. Overall they have better recall and recognition in letter fluency especially when older and more educated, but the more similarity between their two languages lessens the advantage, as when they are very close there is more overlap of information.\n\nMental lexicon refers to the permanent store of words in an individual's memory, and is thought to be organized in a semantic network. This network is related to the spreading activation model purposed by Collins and Loftus, as one word (node) is activated, words that are semantically and lexically related will also be activated. Evidence has been found to support the view that a bilingual individual has the same conceptual system for both of their languages. Dong, Gui, and Macwhinney have demonstrated the convergence of a new language into a preexisting mental lexicon in their article \"Shared and Separate Meanings in the Bilingual Mental Lexicon\". When a person first learns a second language, the language has its own conceptual system and is heavily reliant on the first language to gain understanding and meaning of the new words. For example, a Spanish learner is learning the word \"gato\", and will refer back to their original language (ex. English) to translate it into \"cat\" to gain meaning, relation, and contextual information surrounding that word. However, the more advanced an individual becomes in acquiring a certain language, the two conceptual systems will eventual converge into one, where one language influences the other and vice versa.\n\nIt has been found that Bilinguals are more susceptible to the tip of the tongue, in cases where the phonology of a word is different in both languages. For example, when recalling a word such as \"hair\" in English, there is more interference from the French word \"cheveux\", because they sound and are spelled differently. However, when a word is phonologically similar in both languages, bilinguals produce less errors than individuals who are monolingual. For example, the word \"chocolate\" is similar to the translated word in French, which is \"chocolat\". Overall, bilinguals experience the tip of the tongue phenomenon more than individuals who are monolingual. This is confirmed by the evidence that bilinguals are less able to recall words, or initiate representations of words that are different in each language.\n\nThe dual-coding theory was first postulated by Paivio and Desrochers in 1980, and indicates that two systems are responsible for the encoding and retrieval of information from memory. The verbal representational system encodes verbal information, such as words. While the imagery system encodes and retrieves non-verbal objects, such as images and scenes. The dual-coding theory enunciates that these two systems can operate independently, as well as interdependently. Therefore, verbal cues can be activated independently of images, and vice versa. However verbal cues can also prime images through associative relationships, while images can prime verbal items through associative connections as well. This is not surprising, as a person can often describe an image using verbal behaviors, indicating the interconnectedness of the two systems. This theme continues into the bilingual adaptation of the dual-coding theory, which indicates that an individual's verbal representational systems for their two languages operate independently of one another, but also have associative connections with each other. For example, thinking of synonyms for \"fierce\" using English words, would only involve the English language system. But if a person is required to translate the word \"fierce\" into the French version, this would entail the two language systems to have associative connections. Indicating that the two language systems can act independently of each other, and that each language system has their own within language connections.\n\nSome flaws with the bilingual dual coding theory have been identified. One of which deals with the constant finding that translated items are better recollected than the words that are directly recalled or require deriving synonyms for. This was originally thought because translated words are better remembered because they engage both memory systems, compared to synonyms which require the use of only one memory system. With this in mind, it was also thought that between language systems have stronger associations, compared to within language systems. This means that there are well developed associations for the translated words because there are stronger associations between two languages, compared to the connections within only one language, as seen with synonyms. Other explanations have also been explored to explain this phenomenon, one is that the translated words are better remembered because they are more deeply processed than words that people are simply asked to recall or create synonyms for. This is in line with the levels of processing effect, where in relation to the bilingual dual coding theory, words that participants are required to think of synonyms for are better recalled than the words they were simply asked to copy. This is because creating synonyms requires deeper processing than just duplicating a word. Similarly, words that participants are required to translate will be better remembered than the words they created synonyms for.\n\nLanguage-dependent recall is a phenomenon that signifies memories are best recalled when the language at encoding matches the language during recall. This is related to the encoding specificity principle purposed by Tulving and Thompson, which states that recall is better when the retrieval context is similar to the context in which the memory was encoded.\n\nLanguage-dependent recall is also significantly related to context-dependent memory. In the perspective of bilingualism, context dependent memory indicates that the language spoken during the encoding of the event acts as the external context. Whereas the language that a person thinks, rehearses and conducts inner speech constitutes the internal environment. Therefore, it is important to reinstate these internal and external contexts in which a person encodes the memory in order to enhance recall.\n\nConsequently, this has major impacts on bilingual individuals, who can interchangeably encode a memory in English, for instance, and encode another memory in French due to their diverse language capabilities. An example of context-dependent memory in the case of bilingualism is seen in an example by Viorica and Kaushanskaya. They asked participants this question: \"name a statue of someone standing with a raised arm while looking into the distance\". This inquiry was asked in two separate languages, English and Mandarin. When asked the question in Mandarin, the individuals were more likely to say the \"Statue of Mao\". However, when asked in English, the participants said the \"Statue of Liberty\". Furthermore, when a person encodes a memory in English, but is asked about the memory in French, their inner verbalization of the memory, matches that during the encoding (i.e. they are remembering the event in the language that it was encoded with). Thus indicating the importance of reinstating the internal and external context during retrieval to match the context during encoding.\n\nAccordingly, autobiographical memories and semantic knowledge can be impaired when the language during the recall (ex. English) of the memory does not match the language during encoding (ex. French). However, there are several benefits when the contexts do match. For example, Viorica and Fausey found that when the linguistics at encoding match the linguistics during retrieval it increases the speed, accuracy, and emotional intensity of the memory. Thus suggesting that language impacts the cues that are involved in the retrieval of bilingual memories.\n\n"}
{"id": "2964506", "url": "https://en.wikipedia.org/wiki?curid=2964506", "title": "Double articulation", "text": "Double articulation\n\nDouble articulation, or duality of patterning is a concept used in linguistics and semiotics. It refers to the two-level structure inherent to a sign system, insofar as it is composed by two kinds of elements: 1) significant or meaningful, and 2) distinctive or meaningless.\n\n\"Double articulation\" refers to the two fold structure of the stream of speech, which can be primarily divided into \"meaningful\" signs (like words or morphemes), and then secondarily into \"distinctive\" elements (like letters or phonemes). For example, the meaningful English word \"cat\" is composed of the sounds [k], [æ], and [t], which are meaningless as separate individual sounds (and which can also be combined to form the separate words \"tack\" and \"act\", with distinct meanings). These sounds, called phonemes, represent the secondary and lowest level of articulation in the hierarchy of the organization of speech. Higher, primary, levels of organization (including morphology, syntax, and semantics) govern the combination of these individually meaningless phonemes into meaningful elements.\n\nThe French concept of \"double articulation\" was first introduced by the André Martinet, in 1949. The English calque \"double articulation\" has been criticised as inaccurate and is often replaced by \"duality of patterning\".\n\nAccording to Charles F. Hockett and other linguists, this duality is an important property of human languages, since it allows for the expression of a potentially infinite number of meaningful language sequences. Strictly speaking, however, such expressiveness follows from generativity or productivity (a finite number of components combining via rules to produce a potentially infinite arrangement of novel utterances), not of duality per se (one could have a system with 2 levels of the kind referred to as duality, and yet have only finite productivity. For further discussion, see figurae, as well as Hockett's_design_features, which treats productivity and duality as distinct essential properties of language.\n\nSign languages may have less double articulation because more gestures are possible than sound and able to convey more meaning without double articulation.\n\n"}
{"id": "3560440", "url": "https://en.wikipedia.org/wiki?curid=3560440", "title": "Ecolinguistics", "text": "Ecolinguistics\n\nEcolinguistics, or ecological linguistics, emerged in the 1990s as a new frame of study of linguistic research, widening sociolinguistics to take into account not only the social context in which language is embedded, but also the ecological context.\n\nMichael Halliday's 1990 paper \"New ways of Meaning: the challenge to applied linguistics\" is often credited as a seminal work which provided the stimulus for linguists to consider the ecological context and consequences of language. Among other things, the challenge that Halliday put forward was to make linguistics relevant to overarching contemporary issues, particularly the widespread destruction of the ecosystems that life depends on. The main example Halliday gave was that of 'economic growth', describing how 'countless texts repeated daily all around the world contain a simple message: growth is good. Many is better than few, more is better than less, big is better than small, grow is better than shrink', which leads to ecologically destructive consequences. \n\nSince Halliday's initial comments, the field of ecolinguistics has developed in several directions, employing a wide range of linguistic frameworks and tools to investigate language in an ecological context. The International Ecolinguistics Association, characterizes ecolinguistics in these terms:\"Ecolinguistics explores the role of language in the life-sustaining interactions of humans, other species and the physical environment. The first aim is to develop linguistic theories which see humans not only as part of society, but also as part of the larger ecosystems that life depends on. The second aim is to show how linguistics can be used to address key ecological issues, from climate change and biodiversity loss to environmental justice.\"In this way, the 'eco' of ecolinguistics corresponds to ecology in its literal sense of the relationship of organisms (including humans) with other organisms and the physical environment. This is a sense shared with other ecological humanities disciplines such as ecocriticism and ecopsychology.\n\nThe term 'ecolinguistics' has also been used with a metaphorical sense of 'ecology', for example in 'Linguistic ecology', 'communication ecology' and 'learning ecology' in ways which do not include consideration of other species or the physical environment. This is becoming less prevalent now as ecolingusitics becomes increasingly understood as a form of ecological humanities/social science.\n\nAnother aspect of ecolinguistics is the influence of the natural world on language. In 1996, David Abram's book, \"The Spell of the Sensuous: Perception and Language in a More-than-Human World,\" described how the wider ecology (or 'the more than human world') shapes language in oral cultures (Abram, 1996), helping people attune to their environment. On the other hand, writing has gradually alienated people in literate cultures from the natural world, to the extent that 'our organic atonement to the local earth is thwarted by our ever-increasing intercourse with our own signs' (1996:267).\n\nOverall there are three main areas of interest for ecolinguistics. The first can be described as 'The Ecological Analysis of Language', the second 'Language Diversity', and the third 'The Influence of Ecology on Language'.\n\nThe ecological analysis of language draws on a wide range of linguistic tools including critical discourse analysis, framing theory, cognitive linguistics, identity theory, rhetoric and systemic functional grammar to reveal underlying worldviews or the 'stories we live by'. The stories we live by are cognitive structures in the minds of individuals or across a society (social cognition) which influence how people treat each other, other animals, plants, forests, rivers and the physical environment. The stories are questioned from an ecological perspective with reference to an ecological framework (or ecosophy), and judged to be beneficial in encouraging people to protect the ecosystems that life depends on, or destructive in encouraging behavior which damages those ecosystems. Ecolinguistics attempts to make a practical difference in the world through resisting destructive stories and contributing to the search for new stories to live by (Stibbe 2015). Stories which have been exposed and resisted by ecolinguistics include consumerist stories, stories of unlimited economic growth, advertising stories, stories of intensive farming, and stories which represent nature as a machine or a resource. Using Positive Discourse Analysis, ecolinguistics has also searched for new stories to live by through exploring nature writing, poetry, environmental writing and traditional and indigenous forms of language around the world.\n\nThis form of analysis started with the application of critical discourse analysis to texts about the environment and environmentalism, in order to reveal hidden assumptions and messages and comment on the effectiveness of these in achieving environmental aims (e.g. Harré et al. 1999). It then developed to include analysis of any discourse which has potential consequences for the future of ecosystems, such as neoliberal economic discourse or discursive constructions of consumerism, gender, politics, agriculture and nature (e.g. Goatly 2000). The cognitive approach and the term 'stories we live by' was introduced in Stibbe (2015), which describes eight kinds of story: ideology, framing, metaphor, evaluation, identity, conviction, salience and erasure. Approaches such as environmental communication and ecocriticism have broadly similar aims and techniques to this form of ecolinguistics.\n\nLanguage diversity is part of ecolinguistics because of the relationship between diversity of local languages and biodiversity. This relationship arises because of the ecological wisdom (or cultural adaptation to the environment) that is encoded in local languages. The forces of globalisation and linguistic imperialism are allowing dominant language to spread, and replace these local languages (Nettle and Romaine 2000). This leads to a loss of both sustainable local cultures and the important ecological knowledge contained within their languages. One of the goals of ecolinguistic research is to protect both cultural diversity and the linguistic diversity that supports it (Terralingua 2016, Nettle and Romaine 2000, Harmond 1996, Mühlhaüsler 1995). This research is in line with the United Nations Environment Program's position that:\n\n\"Biodiversity also incorporates human cultural diversity, which can be affected by the same drivers as biodiversity, and which has impacts on the diversity of genes, other species, and ecosystems. (UNEP 2007)\"\n\nNettle and Romaine (2000:166) write that 'Delicate tropical environments in particular must be managed with care and skill. It is indigenous peoples who have the relevant practical knowledge, since they have been successfully making a living in them for hundreds of generations. Much of this detailed knowledge about local ecosystems is encoded in indigenous language and rapidly being lost'. Mühlhaüsler (2003:60) describes how 'The rapid decline in the world's linguistic diversity thus must be regarded with apprehension by those who perceive the interconnection between linguistic and biological diversity'.\n\nOverall, language diversity is part of ecolinguistics because of the correlation between the diversity of language and biological diversity, with the ecological wisdom embedded in local cultures being the link between the two.\n\nAbram's early chapter on \"The Flesh of Language\" examined the contribution of the sensate body—and of the body's ongoing interaction with the earthly terrain—in the emergence of meaningful speech. A longer chapter on \"Animism and the Alphabet\" contrasted the discourse of indigenous, oral cultures with the discourse of literate cultures. For oral cultures, the coherence of spoken language is inseparable from the coherence of the surrounding ecology, from the expressive vitality of the more-than-human terrain. For these peoples \"it is the animate earth that speaks; human speech is but a part of that vaster discourse.\" (p. 179) A subsequent chapter, entitled \"In the Landscape of Language,\" drew examples from a range of divergent oral cultures to show some of the diverse ways that the local, more-than-human terrain informs and influences the discursive speech of oral cultures. Overall, Abram argues that ecology plays a key role in shaping human language in oral cultures, but with writing this role becomes less and less significant. This results in a situation where ‘our organic atonement to the local earth is thwarted by our ever-increasing intercourse with our own signs’ (1996:267). He therefore argues for using language in ways which bring ecology (or the 'more-than-human-world') back into language:\n\n\"there can be no question of simply abandoning literacy, of turning away from all writing. Our task, rather, is that of taking up the written word, with all of its potency, and patiently, carefully, writing language back into the land. Our craft is that of releasing the budded, earthy intelligence of our words, freeing them to respond to the speech of the things themselves - to the green uttering-forth of leaves from the spring branches.\" (Abram 1996:273)\n\nThe International Ecolinguistics Association is an international network of ecolinguists. The website includes a bibliography, online journal (Language & Ecology) and other resources.\n\nThe Stories We Live By is a free online course in ecolinguistics created by the University of Gloucestershire and the International Ecolinguistics Association.\n\nThe Ecolinguistics Website (http://www-gewi.kfunigraz.ac.at/ed/project/ecoling) is an archive website of early ecolinguistics.\n\n"}
{"id": "303486", "url": "https://en.wikipedia.org/wiki?curid=303486", "title": "Ethnolinguistics", "text": "Ethnolinguistics\n\nEthnolinguistics (sometimes called cultural linguistics) is a field of linguistics that studies the relationship between language and culture and how different ethnic groups perceive the world. It is the combination between ethnology and linguistics. The former refers to the way of life of an entire community: all the characteristics that distinguish one community from the other. Such characteristics make the cultural aspects of a community or a society.\n\nEthnolinguists study the way perception and conceptualization influences language and show how that is linked to different cultures and societies. An example is how spatial orientation is expressed in various cultures. In many societies, words for the cardinal directions \"east\" and \"west\" are derived from terms for sunrise/sunset. The nomenclature for cardinal directions of Inuit speakers of Greenland, however, is based on geographical landmarks such as the river system and one's position on the coast. Similarly, the Yurok lack the idea of cardinal directions; they orient themselves with respect to their principal geographic feature, the Klamath River.\n\nCultural Linguistics is a related branch of linguistics that explores the relationship between language and cultural conceptualisations. Cultural Linguistics draws on and expands the theoretical and analytical advancements in cognitive science (including complexity science and distributed cognition) and anthropology. Cultural linguistics examines how various features of human languages encode cultural conceptualisations, including cultural schemas, cultural categories, and cultural metaphors. In , language is viewed as deeply entrenched in the group-level, cultural cognition of communities of speakers. Thus far, the approach of Cultural Linguistics has been adopted in several areas of applied linguistic research, including intercultural communication, second language learning, Teaching English as an International Language, and World Englishes.\n\n\n"}
{"id": "4829003", "url": "https://en.wikipedia.org/wiki?curid=4829003", "title": "Farfallino alphabet", "text": "Farfallino alphabet\n\nThe farfallino alphabet (in Italian alfabeto farfallino) is a language game used primarily in Italy, which can be regarded as an elementary form of substitution cipher. It is usually used by children for amusement or to converse in (perceived) privacy from adults. The name \"farfallino\" comes from the word \"farfalla\" (butterfly), which is an ordinary Italian word but sounds like the \"codified\" words in farfallino alphabet. The farfallino alphabet is similar to games found in other languages such as jeringonza (Spanish/Portuguese), langue de feu (French), Fay Kee Bolee (Urdu) and pig latin (English).\n\nThe usual rules for farfallino alphabet are based on the substitution of each vowel with a 3 letter sequence where the vowel itself is repeated with an interceding \"f\".\n\nIts translation in Italian is:\nWhich means, in English:\n\nThere are several minor variations to this scheme. One such variation is based on the following substitution rules: \n\nAlthough rules for \"e\" and \"i\" look different, they are not; the additional \"h\" is needed in Italian to enforce a voiced velar plosive sound for letter \"g\", which is implicit in the other combinations. Another more complicated scheme, which is used in some regions of Italy, is as follows:\n\n"}
{"id": "1025265", "url": "https://en.wikipedia.org/wiki?curid=1025265", "title": "Gender of connectors and fasteners", "text": "Gender of connectors and fasteners\n\nIn electrical and mechanical trades and manufacturing, each half of a pair of mating connectors or fasteners is conventionally assigned the designation male or female. The \"female\" connector is generally a receptacle that receives and holds the \"male\" connector. On occasion, the terms \"male\" and \"female\" are respectively referred to as the A and B ends, though the names of some standards conflict with this as they contain the letters A or B within the name; unambiguous, though rare, terms include plug and socket or jack.\n\nThe assignment is a direct analogy with genitalia and heterosexual sex; the part bearing one or more protrusions, or which fits inside the other, being designated male in contrast to the part containing the corresponding indentations, or fitting outside the other, being designated female. Extension of the analogy results in the verb to mate being used to describe the process of connecting two corresponding parts together. \n\nIn some cases (notably electrical power connectors), the gender of connectors is selected according to rigid rules, to enforce a sense of one-way directionality (e.g. a flow of power \"from\" one device \"to\" another). This gender distinction is implemented to enhance safety or ensure proper functionality by preventing unsafe or non-functional configurations from being set up.\n\nIn terms of mathematical graph theory, an electrical power distribution network made up of plugs and sockets is a directed tree, with the directionality arrows corresponding to the female-to-male transfer of electrical power through each mated connection. This is an example where male and female connectors have been deliberately designed and assigned to physically enforce a safe network topology.\n\nIn other contexts, such as plumbing, one-way flow is \"not\" enforced through connector gender assignment. Flows through piping networks can be bidirectional, as in underground water distribution networks which have designed-in redundancy. In plumbing situations where one-way flow \"is\" desired, it is implemented through other means (e.g. gravity flow, one-way check valves), and not through male-female gender schemes.\n\nIn mechanical design, the prototypical \"male\" component is a threaded bolt, but an alignment post, a mounting boss, or a sheet metal tab connector can also be considered as male. Correspondingly, a threaded nut, an alignment hole, a mounting recess, or sheet metal slot connector is considered to be female.\n\nWhile some mechanical designs are \"one-off\" custom setups not intended to be repeated, there is an entire fastener industry devoted to manufacturing mass-produced or semi-custom components. To avoid unnecessary confusion, conventional definitions of fastener gender have been defined and agreed upon.\n\nAlthough this aspect is not highlighted in their promotional literature, several common construction toys embody gendered (and in some cases, genderless) mechanical interconnections. This should not be surprising, since these toys feature the nearly infinite flexibility and versatility of shape that a modular interconnect architecture can enable. Mathematicians have begun to classify well-known construction sets using group theory to study the combinatoric possibilities of structures that can be built.\n\nFor example, the canonical LEGO plastic blocks have \"female\" indentations on the lower surface, and \"male\" bosses or protrusions on the upper surfaces. Meccano and Erector have many gendered connections, starting with the nut-and-bolt fasteners they use frequently.\n\nStickle bricks, using interlocking plastic protrusions, are effectively genderless. Lincoln logs use a very simple form of genderless connections. Kapla or KEVA planks are extremely simple genderless systems interconnected only by gravity.\n\nIn plumbing fittings, the \"M\" or \"F\" usually comes at the beginning rather than the end of the abbreviated designation. For example:\n\nA short length of pipe having an MIP thread at both ends is sometimes called a nipple. A short pipe fitting having an FIP thread at both ends is sometimes called a coupling.\n\nHermaphroditic connections, which include both male and female elements in a single unit, are used for some specialized tubing fittings, such as Storz fire hose connectors. A picture of such fittings appears in the \n\nDownspouts (downpipes, rain conductors or leaders) are used to convey rainwater from roof gutters to the ground through hollow pipes or tubes. These tubes usually come in sections, joined by inserting the male end (often crimped with a special tool to slightly reduce its size) into the female end of the next section. These connections are usually not sealed or caulked, instead relying on gravity to move the rainwater from the male end and into the receiving female connection located directly below.\n\nSheet metal ductwork for conveying air in HVAC systems typically uses gendered connections. Typically, the airflow through a ductwork connection is from male to female. However, since one-way flow is implemented by forced-air fans or blowers, \"backwards\" gendered connections can be seen frequently in some systems, since all connections are typically sealed with duct sealing mastic or tape to prevent leakage anyway. The flow convention is usually loosely adhered to for simplicity of design, and to reduce the number of gender changer fittings required, but exceptions are made whenever expedient.\n\nAlthough the gender of tubing and plumbing fittings is usually obvious, this may not be true of electrical connectors because of their more complex and varying constructions. Instead, connector gender is conventionalized and thus can be somewhat obscure to the uninitiated. For example, the female D-subminiature connector body projects outward from the mounting plane of the chassis, and this protrusion could be erroneously construed as male. Instead, the \"maleness\" of the D-subminiature connectors is defined by specific presence of \"male pins\", rather than by the protrusion of the connector, which is also true for many other pin-based connectors like XLR. The male/female distinction is more obvious with ring crimp lug connectors which are placed around a screw post, but again with spade or split ring crimp lug connectors the end alone is not obviously female.\n\nFurther confusion can be caused by the term \"jack\", which is used for both female and male connectors and typically refers to the fixed (panel) side of a connector pair. IEEE STD 100, IEEE-315-1975 and IEEE 200-1975 (replaced by ASME Y14.44-2008) define \"Plug\" and \"Jack\" by location or mobility, rather than gender.\n\nA connector in a fixed location is a jack and a moveable connector is a plug. The distinction is relative, so a portable radio is considered stationary compared to the cable from the headphones; the radio has a jack, and the headphone cable has a plug. Where the relationship is equal, such as when two flexible cables are connected, each is considered a plug. Jacks use the reference designator prefix of J and plugs use the reference designator prefix of P. It is possible in the case of box mounted connectors for the connector to be a receptacle with male pin contacts. In this case the connector is designated a jack (J ref des) regardless of the contact gender because the housing for the contacts is in fact configured as the receptacle even though its mate (the plug) goes around the receptacle. See MIL-STD-38999 and similar cases.\n\nIt is common practice to use female connectors for jacks, so the informal gender-based usage often happens to agree with the functional description of the technical standards. However, this is \"not\" always the case; often-seen exceptions include a computer's AC Power Inlet and EIA232 DE9 Serial Port, or the male coaxial power jacks for connecting external power adapters to portable equipment.\n\nTo summarize, it is considered best practice to use \"male\" and \"female\" for connector \"gender\", and \"plug\" and \"jack\" for connector \"function\" or \"mobility\".\n\nIn the UK, many Commonwealth countries and some non-English-speaking countries, the word \"jack\" may refer to the \"plug\" on the end of a removable cable. These connectors were originally referred to as \"jack plugs\", or plugs intended to be mated with fixed receptacles, or \"sockets\" (which North Americans would call \"jacks\"), but the second word was dropped. This variant usage is in direct contradiction to common usage and official standards in North America.\n\nIn the United Kingdom, for example, the connector on the end of a headphone lead is known as a \"jack\", that plugs into a \"socket\" on the main unit. The same generally occurs also in Italy, where the English word \"jack\" is commonly used to indicate the connector on the end of a headphone lead.\n\nIn Romania female connectors are known as \"mamă\" (mother) and male connectors are \"tată\" (father).\n\nThe standard letters \"M\" and \"F\" are commonly used in part numbers to designate connector gender. For example, in Switchcraft XLR microphone or hydrophone connectors, the part numbers are denoted as follows:\n\nThe terms plug, pin, and prong are also often used for \"male\" connectors, and receptacle, socket, and slot are used for \"female\" connectors. In many cases these terms are more common than \"male\" and \"female\", especially in documentation intended for the non-specialist. These nearly synonymous terms can cause a fair amount of confusion when the designations are shortened in labels.\n\nFor example, a female high-density D-subminiature connector with a size 1 shell can be named DE15F or DE15S (see accompanying pictures). Both terms mean the same thing but could be construed to be completely different items. Similarly, a male standard-density D-sub with a size 1 shell can be named DE9M or DE9P; a female standard-density D-sub with a size 2 shell can be named DA15F or DA15S; a male high-density D-sub with a size 3 shell can be named DB44M or DB44P; and so forth.\n\nElectronic designers often select female jack connectors for fixed mounting on electronic equipment they design. This is usually done because female connectors are more resistant to damage or contamination, by virtue of their concealed or recessed electrical contacts. A damaged motherboard connector can result in the scrapping of an expensive piece of electronic equipment. The risk of expensive damage is reduced by relegating the more exposed male contacts to connecting cables, which can be repaired or replaced at lower cost.\n\nWith an RS232 serial port, the male connector is more fragile than the female connector.\n\nSome people say the male coaxial connector is more prone to damage.\nOther people say the female coaxial connector is more prone to damage.\n\nSuch cost and reliability considerations probably drove the design decision to use female jack connectors on many computer terminals (and some personal computers) for the serial port, in direct violation of the connector gender convention specified in the RS-232 standard for \"DTE\" computer equipment. This confusing reversal of the RS-232 connector gender convention would cause many hours of frustration for ill-informed end users, as they tried to troubleshoot non-functional serial port equipment connections.\n\nIn the case of electrical power connections, designers do not reverse connector gender in such a casual fashion, because exposing live AC line power on male connectors is unsafe and generally illegal. Devices that need to be robust against mechanical damage use a special male IEC 60320 C14 connector (see Gallery above), which is recessed below the surface of a mounting panel, providing the desired physical protection while conforming to safety regulations.\n\nIn electrical connections where voltage or current is sufficient to cause injury, the part permanently connected to the power \"source\" is invariably female, with concealed contacts, to prevent inadvertent touching of live conductors. A male plug, with fully exposed protruding contacts, is installed on the cord of (or directly onto) the device \"receiving\" the power.\n\nIn the case of consumer-level AC power, connector gender is used to implicitly enforce safe use of power connectors. Because of this consideration, it is illegal under electrical code to make or use any \"gender changers\" to connect AC line power to consumer-level equipment.\n\nIn low-voltage use such as for data communications, electrical shock hazard is not an issue, and male or female connectors are used based on other engineering factors such as convenience of use, cost, or ease of manufacturing. For example, the common \"patch cables\" used for Ethernet (and the similar cords used for telephones) typically have male modular plugs on both ends, to connect to jacks on equipment or mounted in walls.\n\nAs an illustrative example of some design tradeoffs in power connector selection, consider the adjacent picture. A commonly seen coaxial power connector is usually set up so that power is fed \"from\" the female plug on the right \"into\" the male jack on the left (which is typically a part of the electronic device accepting the power). Although the plug is female, with a partially recessed center contact, it is still possible for casual accidental contact with a metallic object to short-circuit the power source. Depending on the design of the power adapter, it may react to a short circuit by shutting down temporarily, or instead by blowing out an internal safety fuse.\n\nIn this example, the marginal reliability of the connector choice was deemed to be acceptable by the equipment designer, since the power adapter supplies low voltage that does not pose an electric shock hazard. The potential fire hazard from accidental short-circuiting is addressed by the internal safety fuse, although this requires that a failed power adapter must be completely replaced. In a different design, if the power adapter were intended to supply a voltage sufficient to cause electrical shock, the semi-exposed center contact of the female plug would be considered unacceptably hazardous, requiring a different choice of power connector.\nSome electrical connectors are hermaphroditic because they include both male and female elements in a single unit intended to interconnect freely, without regard for gender. See the discussion of Genderless connectors elsewhere in this article for more detailed information.\n\nAs an additional complication, certain electronic connector designs may incorporate combinations of male and female pins in a \"single\" connector body, for mating with a complementary connector with opposite gender pins in corresponding positions. In these unusual cases, gender is often defined by the shape of the connector \"body\", rather than the mixed-gender connector \"pins\" and \"sockets\". These types of connectors are not strictly speaking hermaphroditic, since mating connectors are \"not\" freely interchangeable. An informal term that has been used for these connectors is \"bisexual\", in addition to the more official terminology, mixed-gender. Thus, for example, one can have a mixed-gender female plug that connects to a mixed-gender male jack (though a reversed gender assignment of connectors would be a more typical design choice in this example).\n\nMale connector pins are often protected by a shell (also called a shroud, surround, or shield), which may envelop the entire female connector when mated. RF connectors often have multiple layers of interlocking shells to properly connect the shields of coaxial and triaxial cable. In such cases, the gender is assigned based on the \"innermost\" connecting point. With the exception of reverse polarity BNC or TNC, where the outer shell determines the gender and the innermost connecting points are opposite to a standard connector, for example a female RP-TNC connector has a solid innermost pin.\n\nAnother ambiguous situation arises with the connectors used for USB, FireWire (IEEE-1394), HDMI, and Thunderbolt serial data bus connections. Close examination of these connectors reveals that the contact \"pins\" are not actually pins, but instead are conductive surfaces that slide past each other when they mate. Therefore, the traditional pin and socket nomenclature is not applicable. Instead, most computer hardware people fall back to referring to the wrap-around metal shield on the plug connector \"as if\" it were a connector \"pin\". By this convention, the connectors on serial bus cables are \"male plugs\", and the corresponding connectors on equipment are \"female jacks\". A unique connector configuration where the contacts are hermaphroditic is the ELCO Varicon where the contacts are bifurcated and nest with one another axial at a 90 degree rotation in cross-shaped wells. In this case the plugs had the contacts oriented transversely and the sockets longitudinally. \n\nA casual glance at a USB \"Type A\" plug connector may give the false impression that it is hermaphroditic. However, a physical attempt to mate two USB \"Type A\" cables with each other reveals the fact that the connectors will not interconnect. Classifying according to mathematical graph theory, USB buses are directed trees, whereas FireWire buses have a true bus network topology. This difference is reflected in the bus connectors used, in that USB cables are asymmetrical (one end Type A, other end Type B) while FireWire cables may have identical connectors at both ends.\n\nBy definition, a hermaphroditic connector includes mating surfaces having simultaneous male and female aspects, involving complementary paired identical parts each containing both protrusions and indentations. These mating surfaces are mounted into identical fittings which can freely mate with any other, without regard for gender (provided that the size and type are already matched). Alternative names include hermaphrodite, androgynous, genderless, sexless, combination (or combo), two-in-one, two-way, and other descriptive terms. Several of these latter alternate names are ambiguous in meaning, and should not be used unless carefully defined in context. True hermaphroditic connectors should not be confused with \"mixed gender\" connectors, which are described elsewhere in this article.\n\nAnother closely related type is the stackable connector for electronics, which typically has male pins on one surface, and complementary female sockets on the opposite surface, allowing multiple units to be stacked up like plastic milk crates. Examples of this include stackable banana plugs, and interconnect cables specified for the IEEE-488 instrumentation bus. Stackable mezzanine bus connectors are used on some modular microcomputer accessory boards for systems such as the Arduino add-on daughterboards called \"shields\". The older PC/104 embedded PC modules use a similar stackable format for interconnection. Stackable connectors are not classified as hermaphroditic in the strictest sense, but are often described as such in looser usage.\n\nThe hermaphroditic design is useful when multiple complex or lengthy components must be arbitrarily connected in various combinations. For example, if hoses have hermaphroditic fittings, they can be connected without having to pull a lengthy hose and reverse it because it has the wrong gender to connect to another hose. Some military fiber optical cables also have hermaphroditic connectors to prevent \"wrong gender\" connector problems in field deployments. In a similar fashion, railcars are usually equipped with hermaphroditic railway coupling mechanisms that allow either end of the vehicle to be connected to a train consist without having to turn the railcar around first.\nFor the same reason, several spacecraft docking mechanisms are designed to be \"androgynous\",\nincluding the Androgynous Peripheral Attach System, the NASA Docking System, and Chinese Docking Mechanism.\n\nIn the absence of genderless connectors, \"gender changer\" fittings might be used to enable certain connections. The designer of a connection system may use one or both schemes to allow arbitrary connectivity, or even combine both schemes into a single system.\n\nWhen an enforced sense of unidirectionality or \"one-way flow\" is required for safety or other reasons (for example, AC electrical power connections), a strict assignment of connector genders is implemented to prevent undesired configurations, and gender changers are banned.\n\nSome commonly seen examples of hermaphroditic connectors include the SAE connector for 12 V DC power, jackhammer air hose connectors, and the Anderson Powerpole series of modular high-current power connectors. The IBM token ring connector was another widespread example, but it has become obsolete and is being phased out. The General Radio Corporation (GenRad) developed a hermaphroditic coaxial radio frequency connector often called the \"GR connector\".\n\nSome audio multicore cables are fitted with hermaphroditic multipin quick-disconnect connectors for ease of use in the field. One style of this audio signal cable is fitted on both ends with connectors that are each populated half with pins and half with sockets. The advantage to the user is that it does not matter which end connects to the stage and which to the audio mixer, facilitating faster set up. Another style of connector uses hybrid male/female pins with a receiving slot fitted in the center of each two-tine pin, and relies on 90-degree rotation of the pin axes to mate. The connector housings themselves are sexed male and female.\n\nDevices used for mating two connectors of the same gender have a wide variety of terms, including for example: \"gender changer\", \"gender mender\", \"gender bender\", \"gender blender\", \"sex changer\", and \"homosexual adapter\". A specific gender changer can be referred to by either the gender of its connectors, or the gender which it is designed to connect to, resulting in a thoroughly ambiguous terminology. Thus a \"male gender changer\" might have female connectors to mate two male ends, or male connectors to mate two female ends.\n\nAdding to this potential for confusion, some gender changers also combine additional functions such as cross-over pin-outs or even embedding micro-controllers for performance, or for logic level or protocol adaptations, which would properly make them an adapter, but this nomenclature is sometimes neglected in marketing materials or common parlance.\n\n\n"}
{"id": "33526402", "url": "https://en.wikipedia.org/wiki?curid=33526402", "title": "German Orthographic Conference of 1901", "text": "German Orthographic Conference of 1901\n\nThe German Orthographic Conference of 1901 (the Berlin II Orthographic Conference; or \"\") took place in Berlin from 17th till 19 June 1901. The results of the conference became official in the German Empire in 1902. \nThe standardized German spelling that resulted from the conference was largely based on the Prussian school spelling, but also on the Orthographic Conference of 1876.\n\nThe conference results removed numerous existing variant forms.\nSoon after the conference, its results were criticized by people who believed there should be further changes.\n\nThe spelling was used in Germany, Austria and Switzerland, apart from the replacement of \"ß\" with \"ss\" in Switzerland in later years.\nThe \"Erziehungsrat des Kantons Zürich\" stopped the teaching of \"ß\" in schools in 1935 with the Kanton Zürich being the first to do so, and the \"Neue Zürcher Zeitung\" as last Swiss newspaper stopped using \"ß\" in 1974. However, some Swiss book publishers still use \"ß\".\n\nIt was not until 95 years later that the German spelling was changed with a reform in 1996.\n"}
{"id": "1432872", "url": "https://en.wikipedia.org/wiki?curid=1432872", "title": "Hakuchi Adyghe dialect", "text": "Hakuchi Adyghe dialect\n\nHakuchi (Xakuchi; Хьакӏуцубзэ \"Kh′ak′ucubză\" or Къарацхаибзэ \"Qaracxaibză\" in Hakuchi Adyghe) is a variety of the Shapsug sub-dialect of West Adyghe dialect of Adyghe language spoken in Turkey.\n\nThe dialect is phonologically peculiar when compared to the other Adyghe sub-dialects. Its lexicon and consonantal system are substantially affected by the Ubykh language, the first language of many Hakuchi speakers before its death. Hakuchi Adyghe is one of the most divergent dialects from the literary dialect of Adyghe.\n\nThe Hakuchi has an uvular ejective [qʼ] and a labialized uvular ejective [qʷʼ] that correspond to West Adyghe and Kabardian Adyghe glottal stop [ʔ] and labialized glottal stop [ʔʷ].\n\n\n"}
{"id": "52945567", "url": "https://en.wikipedia.org/wiki?curid=52945567", "title": "IHunch", "text": "IHunch\n\niHunch is a term used to describe the common spinal problem of an excessively kyphotic (hunched) thoracic spine driving neck pain and cervicogenic headache. Other terms include iPosture, forward head posture, poking chin posture, computer neck, text neck and dowager’s hump.\n\nIndications are that the prevalence of upper back and neck pain has increased dramatically in the decade leading up to 2016. This increase has been attributed to the corresponding widespread adoption of laptop computers, tablets, smartphones and other small portable digital devices.\n\nBecause their screens do not separate from their keyboards these small devices cannot be set up ergonomically correctly (unless an extra screen or extra keyboard is added). They are unlike personal desk top computers (PCs) in this respect. Most commonly, the user hunches to operate them, often for many hours a day.\n\nHunching increases the effective load on the neck up to several times more than does erect posture, due to increasing moment arm. Local pain, cervicogenic headache and referred pain extending down the arms can arise from the sustained muscle strain, cervical facet joint (or apophyseal, or zygapophyseal joint) compression and diminution of the cervical foraminal nerve exits.\n\nA hunched posture also sends out a body language message of submission and lower self-confidence, with some research indicating it can actually promote these in the person holding it. A comprehensive view of the research and concepts is found in Dr Amy Cuddy’s book ‘Presence’ (2015).\n\nTreatment may include analgesic and/or anti-inflammatory medications, regular breaks while using the small devices, muscle strengthening and stretching, massage, spinal manipulation and mobilsation, posture instruction and spinal fulcrums. Biomechanical analysis suggests a combination of approaches is best and gives more lasting results.\n\nIn a neck with perfect posture (as seen for instance in young children) the head is balanced above the shoulders. In this position the load on each vertebra of the cervical spine is spread evenly between the two facet (apophyseal) joints at the back and the intervertebral disc and vertebral body at the front.\n\nThe iHunch is characterised by a posture with the head sitting somewhat forward of the shoulders (i.e., the ear lobe is anterior to a vertical line through the point of the shoulder (acromion process)). This can be very marked, with the back of the skull positioned anterior to the breastbone (sternum). The chin is poked forward.\n\nWhen the patient is asked to look up at the ceiling, the hunched-forward upper thoracic curve does not change as viewed from the side. Rather, the lower cervical spine ‘hinges’ backward at C5/6/7, a movement pattern known as ‘swan-necking'.\n\nThis indicates that the upper back vertebrae have frozen in their habitual flexed positions, with the surrounding collagen of the ligaments, joint capsules and fascia shortening to reinforce this hypomobility. (This is the dowager’s hump of the elderly of earlier generations, now observable in modern (2016) late teenagers.)\n\nSymptoms include overuse muscle pain and fatigue along the back of the neck and reaching down to the mid-back, often starting with the upper trapezius muscle bellies between the shoulders and neck. Cervicogenic headache from the joints and muscle attachments at the top of the neck is common.\n\nThe compressive load on the cervical facet joints predisposes to acute joint locking episodes, with pain and movement loss. In older patients with already diminished cervical foramina spaces and/or osteophytes, nerve root irritation and impingement can trigger referred pain down the arm(s).\n\nThe human spine is well suited to erect upright posture, with the increased heart rate from movement shunting a good blood supply to the muscles. This is clearly not the\ncase for vast numbers of sedentary humans spending many hours daily bent over laptops, tablets, smartphones and similar. A biomechanical assessment of thoracic hunching shows the abnormal spinal loading and other effects which plausibly account for the recent steep rise in thoracic and cervical pain in step with the ubiquitous adoption of the small IT devices.\n\nHunching has always caused problems, for instance in occupational groups like dentists, surgeons, hairdressers, nurses, chefs, teachers, computer workers and students. Some rheumatoid conditions like ankylosing spondylitis and neurodegenerative conditions like Parkinson's Disease cause characteristic excessive thoracic kyphosis. What has changed is the amount of hunching in society generally, and especially with the technologically adept young.\n\nThe first laptop was produced in 1981 but it took more than a decade of development for the designs to approach current (2016) levels of portability and capacity, and hence uptake. Apple produced the first smartphone (the iPhone) in 2007 and the first tablet (the iPad) in 2010. In 2015 there were 4.43 billion mobile phone (cellphone) users in the world, of which 2.6 billion had smartphones. In the US, 45% owned a tablet computer in 2014 and 92% owned a mobile phone; for younger adults aged 18–29, only 2% didn’t own a mobile phone and 50% had tablets.\n\nA large Finnish cross-sectional study on school-age adolescents published in 2012 concluded that more than two hours a day spent on computers was associated with a moderate/severe increase in musculoskeletal pain. In the following year, the average UK 18-24 year-old spent 8.83 hours a day in front of a PC, laptop or tablet. Neck pain per se has been a large problem for a long time, and surveyed repeatedly. A composite review of studies with good methodology by Fejer et al published in 2006 found that point prevalence (in pain right now) of neck pain in the adult (15–75 years) population ranged from 5.9% to 22.2%, with one study of the elderly (65+ years) finding 38.7% were in pain when surveyed. Generally, more urban populations had more neck pain, e.g. 22.2% of a large 1998 Canadian study had neck pain when surveyed.\n\nBased on these surveys of neck pain prevalence, and adding to them the prevalence of thoracic pain and cervicogenic headache, it is reasonable to estimate that around one adult in six (15%) probably has pain in any, some or all of those areas right now. However the published epidemiological papers draw on raw data from surveys done at least 10 years ago, and there are indications that the numbers have been rising dramatically since then – as rapidly as the adoption of laptops, tablets and smartphones. This is reflected in the recent rise in the number of popular articles, news items and media discussions about the problem.\n\nThe iHunch is a multi-factorial problem.\n\n\nNeck pain generally has been treated with a profusion of approaches and modalities, including nonsteroidal anti-inflammatory drugs (NSAIDs) such as ibuprofen; pain relief medications (analgesics) such as acetaminophen; low dose tricyclic antidepressants such as amytriptyline for chronic problems; Physical therapy (a.k.a. physiotherapy in British-derived cultures) which utilises a wide range of techniques and modalities; spinal manipulation from osteopaths, chiropractors, manipulating physiotherapists and doctors; massage; muscle strengthening programmes including gyms and Pilates; postural approaches such as the Feldenkrais Method and the Alexander Technique; stretching approaches such as yoga; ergonomic approaches including setting up desk top computers correctly and frequent breaks; acupuncture; and surgery for severe structural problems such as osteophytic impingement on the cervical nerve roots and cervical disc herniation.\n\nA biomechanical analysis of the iHunch indicates its standard, logical development from much flexed activity and its multi-factorial character. (See Pathogenesis)\n\nA composite approach which covers each component of the problem is therefore likely to be most successful and lasting. Most of the general treatment approaches to neck pain cover only one aspect. A logical response should include as a minimum:\n\n\n"}
{"id": "59114506", "url": "https://en.wikipedia.org/wiki?curid=59114506", "title": "Influence of French on English", "text": "Influence of French on English\n\nThere has been a long-standing influence of French on English, in terms of syntax, grammar, lexicon, spelling and pronunciation.\n\nMost French vocabulary that entered English occurred after the Norman conquest of England in 1066 and the establishment of a French-speaking administration. French became the language of the court, the administration and the elites for several centuries, until after the Hundred Years War. English has been constantly influenced by French from that time till present day.\nAccording to Laura K. Lawless, more than a third of the current English vocabulary is of French origin. According to linguist Henriette Walter, words of French origin represent more than two thirds of the English vocabulary. It is estimated by linguist Anthony Lacoudre that over 40 000 English words are directly French and may be understood without orthographical change by French speakers.\n\nAt the beginning of XIth century, the English language did not have a well-defined status. Indeed, the inhabitants of what would become Great Britain did not have a language that allowed them to communicate with each other. There were many different dialectal forms. Great Britain, in which various Celtic idioms had coexisted since the IVth century, had experienced partial Roman occupation since the 1st century A.D., and this for four centuries.\n\nFrom 450 onwards, the Saxons, the Angles and the Jutes, who came from the continent, settled in the south and east. Germanic dialects would prevail in these regions, supplanting Celtic dialects, which would remain in the west and north of the island (Wales, Cornwall, Scotland) and Ireland. In the VIIIth century, Vikings from Scandinavia settled on the island. Their languages, also Germanic, in turn influence the languages already present on the island. Thus, at the dawn of XIth century, the country was made up of a series of peoples with significantly different speeches, most of them Germanic, with multiple influences.\n\nIt is therefore a linguistically disunited people that the Normans will get massively in contact with, from 1066. William II of Normandy, supported by his King, Philip I of France, and his blood legitimacy to the throne of England, landed at Hastings, in Sussex, on 29 September 1066. His men are deployed around the city waiting for the king Harold II's troops. On October 14, exhausted by the long journey to Hastings, Harold II's troops lost the battle after a day. Following the defeat of the English, Duke William II of Normandy became King of England on December 25, 1066, crowned under the name of William I of England, also known as William the Conqueror. This date marks the beginning of a long period of ties between the peoples and languages.\n\nIn fact, these links already existed before the Battle of Hastings. Indeed, the geographical location of Normandy, facing the English Channel, favoured commercial contacts with England. These ties will be further strengthened at the beginning of the XIth century when the daughter of the Duke Richard II of Normandy, Emma, marries King Æthelred II of England. But it is really from the 1066 conquest that proto-English becomes massively impregnated with Old French, then modern French. It should be noted, however, that only French will influence English in the centuries following the conquest. The reverse contribution of English to French will only be real from the XVIIIth century.\n\nThe arrival of William the Conqueror and his barons significantly changed the linguistic situation in England. Norman is essentially imposed in the upper layers of society. The Anglo-Saxon dialects were supplanted by Norman in the circles of the court and aristocracy, justice and the Church. The influential circles, who came from Normandy and settled in England, kept their Norman mother tongue, while the more modest rural and urban strata continued to speak English.\n\nNorman is a particular variety of the Gallo-Roman language, spoken in Normandy. It is one of the Oil languages alongside, among others, the Picard and the Walloon. The Norman language is modified in contact with the Anglo-Saxon language. It then integrates words and phrases from English and will give birth to a dialect, Anglo-Norman, still spoken on the Anglo-Norman isles. Anglo-Norman can be described as a vernacular language, on English soil in the XIth century, in the field of literature, culture, court and among the clergy. French was therefore, at first, spoken in England under the form of this Anglo-Norman dialect.\n\nDuring the XIIth century, continental French has a greater influence on Old English. It acquires great prestige in England, especially within the aristocracy and the clergy. It becomes the language of law and justice nationwide. Rich and noble families, most of them of Norman origin, teach their children French or send them to study in France. The expansion of the French language in England was also encouraged by royal marriages. From Henry II Plantagenet and Eleanor of Aquitaine at the beginning of the century, to Henri VI and Marguerite in the XVth century, all kings of England married French princesses. These marriages made French the language of the English court for several centuries and were decisive in strengthening the use of French in England. This period (XIIth-XVth centuries) is characterized by a massive influx of French words into Old English vocabulary.\n\nIn 1204, Philippe Auguste Normandy is officially annexed to the kingdom of France, politically isolating England from the continent. Normans who choose to stay in England move further away from France and, therefore, from the French language. Keeping its status as the language of justice and the language of power, England saw the first teaching manuals for teaching French to the English. These manuals were intended for English nobles who wish to perfect their knowledge of French and teach it to their children. Two types of French spoken in the higher spheres of English society can be distinguished during the XIIIth century : the Anglo-Norman dialect, which was the aristocrats' mother tongue, and a more prestigious type of French as a second language. Knowing \"parisian\" French was a mark of social distinction. As a language of culture, French supplanted Latin from the XIIth century onward as the language of diplomacy and worldly relations throughout Europe. The mass and influence of French literature reinforced its reputation and appeal.\n\nThe XVIth century, that of the Renaissance, is a decisive century for French since king François I of France, through the Ordonnance de Villers-Cotterêts (1539), makes French the official language of administration in the whole kingdom.\nAlthough troubled by the European wars of religion, the Italian Wars, the language is marked by intellectual, technical and scientific effervescence. It ushered in an era of prosperity that would also spread to England through French.\n\nThe XVIIth century announces the apogee of the Kingdom of France. This period was characterized by the political, literary and artistic prestige of France and the French language. Peace restored and unity ensured in the country, economy grew considerably. Personalities such as the King Henri IV, the Cardinal of Richelieu or the Sun King contribute to fixing and enhancing the French language in Europe, the Americas, India and Oceania.\n\nThe creation of the Académie française by Richelieu in 1635, under Louis XIII, was a step that led to the standardization of French in continental Europe and abroad, including England. French is then the second language of all the elites in Europe, from Turkey to Ireland and from Moscow to Lisbon. The greatest scholars and intellectuals, writers and scientists, express themselves and correspond in this new standardised French. French is considered a perfect language, whose beauty and elegance are determined by the development of scientific logic, aided by dictionaries and grammars.\n\nThe geographical use of French has continuously and greatly diversified in the last five hundred years, with countries and states like New-Brunswick, Quebec, Ivory Coast, Benin, Togo, Guinea, Cameroon, Congo, Democratic Republic of the Congo, Madagascar, Mauritius, Tchad, Djibouti, Senegal, Morocco, Algeria, Tunisia, Lebanon, France, Belgium, Switzerland, Luxembourg, Monaco, Aosta Valley, French Polynesia, New Caledonia, and Vanuatu adopting it as their official language. This geographical diversity has led to many different contacts with vernacular dialects, regional and international languages, from which French has often been enriched locally.\nIn a number of countries and regions where French shares co-officiality with English (Cameroon, Canada, Jersey, Mauritius, Rwanda, Vanuatu), particular lexical regionalisms are observed where French and English terms are used interchangeably.\n\nSeveral elements must be observed.\n\n\nThe following French glossary in English is in no way exhaustive. These words come as examples to illustrate the countless French words that are part of the English language.\n\nIn this section, examples of French-to-English lexical contributions are classified by field and in chronological order. The periods during which these words were used in the English language are specified as much as possible. It is not always possible to state with certainty the precise period from which a word was borrowed or integrated.\n\nThe English word is on the left, with its current French equivalent in brackets, then comes its Old French origin in bold and the century of its introduction on the right.\n\n\n\n\n\n\n\n\n\n"}
{"id": "3436875", "url": "https://en.wikipedia.org/wiki?curid=3436875", "title": "Language policies of Francoist Spain", "text": "Language policies of Francoist Spain\n\nLanguage politics in Francoist Spain centered on attempts in Spain under Franco to increase the dominance of the Spanish language (Castilian) over the other languages of Spain.\nThe regime of Francisco Franco had Spanish nationalism as one of its bases.\n\nUnder his dictatorship, the Spanish language (known in some parts of Spain as \"castellano\", i.e., \"Castilian\") was declared Spain's only official language.\nThe public use of other languages was either banned, discouraged or frowned upon depending on the particular circumstances and timing, while the use of non Castilian names for newborns was forbidden in 1938, except for foreigners. \nThe situation evolved from the harshest years of the immediate afterwar (especially the 1940s, also the 1950s) to the relative tolerance of the last years (late 1960s and early 1970s); Franco died in 1975, and his successor Juan Carlos of Spain began the Spanish transition to democracy.\n\nFor the first time in the history of Spain, the Second Republic recognised Galician, Basque, and Catalan as official languages when it granted autonomy for some regions with a regional language.\nAs part of the nationalistic efforts:\n\nIn the first decade of Franco's rule, languages other than Castilian were \"confined to private spaces\".\n\nIn the regime's most radical discourse, languages other than Spanish were often considered \"dialects\" in the sense of speeches that were not developed enough to be \"real languages\". Basque was different enough that it could not be taken as a debased form of Spanish but was despised as a rural language of limited currency, unfit for modern discourse. This never happened at the academic level, though.\n\nAll these policies became less strict and more permissive as time passed.\n\nThe Press Law of Manuel Fraga Iribarne replaced the pre-publication censorship with after-the-fact punishments.\n\nMost notably, several sporting organizations -- including FC Barcelona and Athletic Bilbao, among others -- were forced to change their names from the local language to Spanish. In fact, Atlético Madrid, itself with roots in Athletic Bilbao, received its current name as a result of Franco's language policies, in 1941. \n\n\n\n\n\n\n\n\n\n\nCA Osasuna was allowed to maintain its Basque name, unlike other football teams with non-Spanish names.\n\n\n\n\n\n"}
{"id": "34470329", "url": "https://en.wikipedia.org/wiki?curid=34470329", "title": "Latvian constitutional referendum, 2012", "text": "Latvian constitutional referendum, 2012\n\nA constitutional referendum on the \"Amendments to the Constitution of the Republic of Latvia\" was held on 18 February 2012. Proposed amendments included Articles 4, 18, 21, 101 and 104 of the Constitution of Latvia by adding the condition about Russian as the second official language, as well as prescribing two working languages — Latvian and Russian — for self-government institutions. The referendum's question was \"Do you support the adoption of the Draft Law \"Amendments to the Constitution of the Republic of Latvia\" that provides for the Russian language the status of the second official language?\".\n\nAccording to the 2000 census, Russian was the native language of 37.5% and the second language of 43.7% of the residents. Since 2000, Russian has been regarded as a foreign language according to the Official Language Law.\n\nIn 2010, the National Alliance started to collect signatures to force a referendum on whether all publicly financed schools would have to use Latvian exclusively. By 9 June 2011, they had gathered 120,433 signatures of the minimum 153,232 signatures required, failing to force a referendum.\n\nProtesting against the National Alliance initiative, on 15 February 2011, the youth movement \"United Latvia\" (), led by Eduard Svatkov, announced the idea of making Russian an official language, alongside Latvian. On 4 March 2011, \"United Latvia\", together with the newly created organisation \"Mother Tongue\" (), led by activist Vladimir Linderman (former leader of the Latvian branch of the Russian National Bolshevik Party), Yevgeny Osipov (leader of \"Osipov Party\"), and Aleksandr Gaponenko (director of the Institute of European Studies, economist), started to collect signatures for a referendum petition. They gathered 187,378 signatures, forcing a referendum.\n\nThe referendum initiators mentioned possible assimilation of minority children as the main reason to protest. One of the goals of this protest action was to slow down the ongoing process of National Alliance signature collecting. Those initiating the referendum to make Russian co-official argued: \"In such case there is no other defense method than attack. The initiator of hysteria should be shaken strongly to stop hysteria.\"\n\nThe referendum was held after the Saeima rejected the draft law \"Amendments to the Constitution of the Republic of Latvia\" supported by more than one-tenth of the voters during the Collection of signatures. At least half of the entire electorate has to vote Yes in the referendum in order for it to be valid (771,893).\n\nLegal scholars stated that beside statehood elements, the initiative would have influenced multiple basic human rights and general principles of law protected by the Constitution of Latvia, such as the right to preserve and develop the Latvian language and Latvian ethnic and cultural identity, to participate in the work of the state and of local government, and to hold a position in the civil service; the right to choose one’s employment and workplace freely; the right to education; the rights of a child; and the right to equality and non-discrimination, principles of proportionality, legal certainty, and legitimate expectations.\n\nThe referendum organisers did not deny that the main achievement would be to show a large number of Russian language supporters and the final goal would be to change the status of Russian from foreign to some legal (i.e. regional) in the future. Official status for Russian was requested due to the fact that the Constitution and Official Language Law do not have any other definitions for language status other than making a language official. Amendments for granting any other status for Russian (i.e. regional) would have had a higher risk of rejection by the Constitutional Court, thus cancelling the referendum.\n\nOrganization for Security and Co-operation in Europe High Commissioner on National Minorities Knut Vollebæk planned to visit Latvia after the referendum.\n\nA total of 85 polling stations in 41 countries — the greatest number ever — have been open outside Latvia. Besides the stations in all Embassies and many Consulates General and Honorary Consulates of Latvia, polling stations were operating in the Latvian Houses in Australia, in the Daugavas Vanagi House in London, and in the Latvian Evangelical Lutheran Churches in the United States. New polling stations were operating in Austria, Chile, Ireland, Norway, Switzerland, Venezuela, and in the British cities of Boston and Manchester, as well as the island of Guernsey.\n\nMayor of Riga Nils Ušakovs, an ethnic Russian, initially refrained from supporting the referendum, but later called for a \"yes\" vote. President Andris Bērziņš initially stated he would abstain before calling for a \"no\" vote. Prime Minister Valdis Dombrovskis also called for a \"no\".\n\nAccording to research conducted by the Baltic Institute of Social Sciences in 2004, 51% of respondents supported or rather supported official status for Russian, 44% opposed or rather opposed it. The focus group for this research was all the inhabitants of Latvia, including Latvian non-citizens.\n\nAccording to a poll performed by TNS Latvia in January 2012, 59% of citizens would vote 'no', 25% 'yes', 10% would abstain, and 6% had no opinion on the issue.\nAccording to a poll performed by Latvijas fakti in January 2012, 62.4% of citizens would vote 'no', 28% 'yes', 12.8% would abstain, and 7% had no opinion on the issue.\n\nAround three-quarters of voters voted against Russian as a second national language, with only the eastern region of Latgale seeing a majority of citizens voting for the change. The referendum had considerably higher voter participation than in previous elections and referendums, with more than 71.1% of registered voters casting ballots.\n\nA large part of the Russian speaking community in Latvia (290,660 or 14.1% of Latvia's entire population) could not vote in this referendum because, since 1991, they have held non-citizen status and thus have no right to vote. However, the above numbers also show that non-citizens could not have changed the result of the referendum if they had been allowed to vote. If all 290,660 members of the Russian community had participated and voted in favor of the motion, the proposal would still have been rejected with 59.15% against and 40.60% in favor, with turnout increasing to 75.68% from 71.11%.\n\nAnalysts say the turnout, at nearly 70 percent, indicates the strength of feeling among many ordinary Latvians, who are keen to distance themselves culturally from their former Soviet rulers. The referendum can widen the schism in society and the government will have to undertake serious efforts to consolidate the country's two groups. Though the Russians who spearheaded the referendum admitted they had no chance at winning the plebiscite, they at least hope the approximate 25 percent of support will force Latvia's center-right government to begin a dialogue with national minorities. Many fear the disgruntled minority will keep up the pressure by calling for more referendums to change Latvia's constitution for minorities' benefit.\n\n"}
{"id": "670497", "url": "https://en.wikipedia.org/wiki?curid=670497", "title": "Lecture", "text": "Lecture\n\nA lecture (from the French 'lecture', meaning 'reading' [process]) is an oral presentation intended to present information or teach people about a particular subject, for example by a university or college teacher. Lectures are used to convey critical information, history, background, theories, and equations. A politician's speech, a minister's sermon, or even a businessman's sales presentation may be similar in form to a lecture. Usually the lecturer will stand at the front of the room and recite information relevant to the lecture's content.\n\nThough lectures are much criticised as a teaching method, universities have not yet found practical alternative teaching methods for the large majority of their courses. Critics point out that lecturing is mainly a one-way method of communication that does not involve significant audience participation but relies upon passive learning. Therefore, lecturing is often contrasted to active learning. Lectures delivered by talented speakers can be highly stimulating; at the very least, lectures have survived in academia as a quick, cheap, and efficient way of introducing large numbers of students to a particular field of study.\n\nLectures have a significant role outside the classroom, as well. Academic and scientific awards routinely include a lecture as part of the honor, and academic conferences often center on \"keynote addresses\", i.e., lectures. The public lecture has a long history in the sciences and in social movements. Union halls, for instance, historically have hosted numerous free and public lectures on a wide variety of matters. Similarly, churches, community centers, libraries, museums, and other organizations have hosted lectures in furtherance of their missions or their constituents' interests. Lectures represent a continuation of oral tradition in contrast to textual communication in books and other media. Lectures may be considered a type of grey literature.\n\nThe noun \"lecture\" dates from 14th century, meaning \"action of reading, that which is read,\" from the Latin \"lectus\", pp. of \"legere\" \"to read.\" Its subsequent meaning as \"oral discourse on a given subject before an audience for purposes of instruction\" is from the 16th century. The verb \"to lecture\" is attested from 1590.\nThe noun \"lectern\" refers to the reading desk used by lecturers.\n\nThe practice in the medieval university was for the instructor to read from an original source to a class of students who took notes on the lecture. The reading from original sources evolved into the reading of glosses on an original and then more generally to lecture notes. Throughout much of history, the diffusion of knowledge via handwritten lecture notes was an essential element of academic life.\nEven in the twentieth century, the lecture notes taken by students, or prepared by a scholar for a lecture, have sometimes achieved wide circulation (see, for example, the genesis of Ferdinand de Saussure's \"Cours de linguistique générale\"). Many lecturers were, and still are, accustomed to simply reading their own notes from the lectern for exactly that purpose. Nevertheless, modern lectures generally incorporate additional activities, e.g. writing on a chalk-board, exercises, class questions and discussions, or student presentations.\n\nThe use of multimedia presentation software such as Microsoft PowerPoint has changed the form of lectures, e.g. video, graphics, websites, or prepared exercises may be included. Most commonly, however, only outlines composed of \"bullet points\" are presented. Critics such as Edward Tufte contend that this style of lecture bombards the audience with unnecessary and possibly distracting or confusing graphics.\n\nA modified lecture format, generally presented in 5 to 15 minute short segments, is now commonly presented as video, for example in massive open online courses (MOOCs) or in programs such as the Khan Academy.\n\nBligh, in \"What's the Use of Lectures?\", argues that lectures \"represent a conception of education in which teachers who know give knowledge to students who do not and are therefore supposed to have nothing worth contributing.\" Based on his review of numerous studies, he concludes that lecturing is as effective, but not more effective, as any other teaching method in transmitting information. Nevertheless, lecturing is not the most effective method for promoting student thought, changing attitudes, or teaching behavioral skills.\nBligh summarises research on memory to show the significance of the meaningfulness of material on retention (Marks and Miller 1964) and the importance of immediate rehearsal of information (Bassey 1968). He relates his own research on arousal during lectures to suggest a decrement in attention during the first 25 minutes. Lloyd (1968) and Scerbo et al. (1992) showed that students take less and less notes as lectures proceed. Bligh shows that after a short break filled by buzz group discussion, attention will recover somewhat. \nThe largest section of Bligh's book is devoted to lecturing technique, particularly the organisation of lectures, how to make a point, the effectiveness of taking notes, the use of handouts, and ways of obtaining feedback.\nEarly editions of the book contained a reply paid evaluation card. This research showed that the section on alternative teaching methods within lectures was the most highly praised.\n\nThe conception of the lecture as needing to be a didactic event has been challenged by Meltzer and Manivannan (2002) and Sandry (2005) who maintain that lectures can involve active learning. However, Elliot (2005) sees difficulties in the encouragement of active learning with phenomena such as social loafing and evaluation apprehension causing audience members to be reluctant to participate. A possible solution to the encouragement of audience involvement in lectures is the use of an audience response system which allows audience members to participate anonymously.\n\nThe effectiveness of traditional lecture is and has been debated. Some advantages of lecturing include: quick exposure to new material, greater teacher control in the classroom, an engaging format, which may complement and clarify course material, and facilitating large-class communication. Lecturing also permits the dissemination of unpublished or not readily available material.\n\nThere has been much debate as to whether or not lecturing actually improves student learning in the classroom. Commonly cited disadvantages of lecture include: placing students in a passive (rather than an active) role, encouraging one-way communication, requiring significant out-of-class time for students to engage with the material, and requiring the speaker to possess effective speaking skills.\n\nThe criticisms of lectures are often summarized by a quote generally misattributed to Mark Twain:\n\nWhile lecturing is generally accepted as an effective form of instruction, there have been some prominent educators who have succeeded without the help of lectures.\n\nMany university courses relying on lectures supplement them with smaller discussion sections, tutorials, or laboratory experiment sessions as a means of further actively involving students. Often these supplemental sections are led by graduate students, tutors, teaching assistants, or teaching fellows rather than senior faculty. Those other forms of academic teaching include discussion (recitation if conducted by a teaching assistant), seminars, workshops, observation, practical application, case examples/case study, experiential learning/active learning, computer-based instruction, and tutorials. \nIn schools, the prevalent mode of student-teacher interaction is lessons.\n\nThe term \"parlor lecture\" gained currency throughout the British Commonwealth of Nations and the United States of America during the mid-19th century. It referred to the custom of inviting noted speakers to deliver private lectures, which were typically hosted in the parlors of wealthy and socially influential families.\n\n\n\n"}
{"id": "2576095", "url": "https://en.wikipedia.org/wiki?curid=2576095", "title": "Lingua Ignota", "text": "Lingua Ignota\n\nA Lingua Ignota (Latin for \"unknown language\") was described by the 12th century abbess of Rupertsberg, St. Hildegard of Bingen, OSB, who apparently used it for mystical purposes. To write it, she used an alphabet of 23 letters denominated \"litterae ignotae\".\n\nShe partially described the language in a work titled \"Lingua Ignota per simplicem hominem Hildegardem prolata\", which survived in two manuscripts, both dating to ca. 1200, the Wiesbaden Codex and a Berlin MS (Lat. Quart. 4º 674), previously Codex Cheltenhamensis 9303, collected by Sir Thomas Phillipps. The text is a glossary of 1011 words in Lingua Ignota, with glosses mostly in Latin, sometimes in German; the words appear to be a priori coinages, mostly nouns with a few adjectives. Grammatically it appears to be a partial relexification of Latin, that is, a language formed by substituting new vocabulary into an existing grammar.\n\nThe purpose of Lingua Ignota is unknown, and it is not known who, besides its creator, was familiar with it. In the 19th century some believed that Hildegard intended her language to be an ideal, universal language. However, nowadays it is generally assumed that Lingua Ignota was devised as a secret language; like Hildegard's \"unheard music\", she would have attributed it to divine inspiration. Inasmuch as the language was constructed by Hildegard, it may be considered one of the earliest known constructed languages.\n\nIn a letter to Hildegard, her friend and provost Wolmarus, fearing that Hildegard would soon die, asks \"ubi tunc vox inauditae melodiae? et vox inauditae linguae?\" (Descemet, p. 346; \"where, then, the voice of the unheard melody? And the voice of the unheard language?\"), suggesting that the existence of Hildegard's language was known, but there were no initiates who would have preserved its knowledge after her death.\n\nThe only extant text in the language is the following short passage:\nThese two sentences are written mostly in Latin with five key words in Lingua Ignota; as only one of these is unambiguously found in the glossary (\"loifol\" \"people\"), it is clear that the vocabulary was larger than 1011 words. (Higley 2007 finds probable correspondences for two other words.)\n\n\"loifol\" \"people\" apparently is inflected in Latin, yielding \"loifol-um\".\n\nNewman (1987) conjectures the translation\n\nThe glossary is in a hierarchical order, first giving terms for God and angels, followed by terms for human beings and terms for family relationships, followed by terms for body-parts, illnesses, religious and worldly ranks, craftsmen, days, months, clothing, household implements, plants, and a few birds and insects. Terms for mammals are lacking (except for the bat, Ualueria, listed among birds, and the gryphon, Argumzio, a half-mammal, also listed among the birds).\n\nThe first 30 entries are (after Roth 1880):\n\nNominal composition may be observed in \"peueriz\" \"father\" : \"hilz-peueriz\" \"stepfather\", \"maiz\" \"mother\" : \"hilz-maiz\" \"stepmother\", and \"scirizin\" \"son\" : \"hilz-scifriz\" \"stepson\", as well as \"phazur\" : \"kulz-phazur\". Suffixal derivation in \"peueriz\" \"father\", \"peuearrez\" \"patriarch\".\n\n\n\n\n"}
{"id": "31689940", "url": "https://en.wikipedia.org/wiki?curid=31689940", "title": "Mawa language (Nigeria)", "text": "Mawa language (Nigeria)\n\nMawa is an extinct and unattested language of Nigeria. It was apparently different from a language of Chad also known as Mawa, and so is unclassified.\n"}
{"id": "2530829", "url": "https://en.wikipedia.org/wiki?curid=2530829", "title": "Maxim (philosophy)", "text": "Maxim (philosophy)\n\nA maxim is a concise expression of a fundamental moral rule or principle, whether considered as objective or subjective contingent on one's philosophy. A maxim is often pedagogical and motivates specific actions. The \"Oxford Dictionary of Philosophy\" defines it as:\n\nIn deontological ethics, mainly in Kantian ethics, maxims are understood as subjective principles of action. A maxim is thought to be part of an agent's thought process for every rational action, indicating in its standard form: (1) the action, or type of action; (2) the conditions under which it is to be done; and (3) the end or purpose to be achieved by the action, or the motive. The maxim of an action is often referred to as the agent's intention. In Kantian ethics, the categorical imperative provides a test on maxims for determining whether the actions they refer to are right, wrong, or permissible.\n\nThe categorical imperative is stated canonically as: \"Act only according to that maxim whereby you can, at the same time, will that it should become a universal law.\"\n\nIn his \"Critique of Practical Reason\", Immanuel Kant provided the following example of a maxim and of how to apply the test of the categorical imperative:\nI have, for example, made it my maxim to increase my wealth by any safe means. Now I have a deposit in my hands, the owner of which has died and left no record of it. . . . I therefore apply the maxim to the present case and ask whether it could indeed take the form of a law, and consequently whether I could through my maxim at the same time give such a law as this: that everyone may deny a deposit which no one can prove has been made. I at once become aware that such a principle, as a law, would annihilate itself since it would bring it about that there would be no deposits at all.\n\nAlso, an action is said to have \"moral worth\" if the maxim upon which the agent acts cites the purpose of conforming to a moral requirement. That is, a person's action has moral worth when he does his duty purely for the sake of duty, or does the right thing for the right reason. Kant himself believed that it is impossible to know whether anyone's action has ever had moral worth. It might appear to someone that he has acted entirely \"from duty\", but this could always be an illusion of self-interest: of wanting to see oneself in the best, most noble light. This indicates that agents are not always the best judges of their own maxims or motives.\n\nMichael Polanyi in his account of tacit knowledge stressed the importance of the maxim in focusing both explicit and implicit modes of understanding. “Maxims are rules, the correct application of which is part of the art they govern...Maxims can only function within a framework of personal (i.e., experiential) knowledge”.\n\n\n"}
{"id": "20837956", "url": "https://en.wikipedia.org/wiki?curid=20837956", "title": "Mitigated speech", "text": "Mitigated speech\n\nMitigated speech is a linguistic term describing deferential or indirect speech inherent in communication between individuals of perceived High Power Distance which has been in use for at least two decades with many published references. \n\nThe term was popularized by Malcolm Gladwell in his book, \"Outliers\", where he defines mitigated speech as \"any attempt to downplay or sugarcoat the meaning of what is being said\". He continues with reference to Fischer and Orasanu, to describe 6 degrees of mitigation with which we make suggestions to authority: \n\n\nGladwell brings up the concept in the context of how crews relate to each other in the cockpit of a commercial airliner, graphically illustrating the degree to which mitigated speech can be detrimental in high-risk situations which require clear communication.\n\n\n"}
{"id": "34404303", "url": "https://en.wikipedia.org/wiki?curid=34404303", "title": "Morphome (linguistics)", "text": "Morphome (linguistics)\n\nThe term morphome refers to a function in linguistics which is purely morphological or has an irreducibly morphological component. The term was introduced by Martin Maiden following Mark Aronoff's identification of morphomic functions and the morphomic level—a level of linguistic structure intermediate between and independent of phonology and syntax. In distinguishing this additional level, Aronoff makes the empirical claim that all mappings from the morphosyntactic level to the level of phonological realisation pass through the intermediate morphomic level.\n\nFunctions defined at the morphomic level are of many qualitatively different types.\n\nOne example is the different ways the perfect participle can be realised in English––sometimes, this form is created through suffixation, as in \"bitten\" and \"packed\", sometimes through a process of ablaut, as in \"sung\", and sometimes through a combination of these, such as \"broken\", which uses ablaut as well as the suffix \"-n\". Since these processes, which achieve the same result, are of different categories, it is not possible to call the formation of the perfect participle in English a suffix, so it must be assumed that it exists as an abstract category on the morphomic level.\n\nAnother is the division of lexemes into distinct inflectional classes. Inflectional classes present distinct morphological forms, but these distinctions bear no meaning beyond signalling inflectional patterns; they are internal to morphology, and thus morphomic.\n\nMartin Maiden's theory of morphomes has been mostly developed with regard to the Romance languages, where he identified many examples of morphomic stem distributions.\n\nA different typology of morphomic patterns has been put forth by Erich Round. He distinguishes rhizomorphomes, which are a property of roots (corresponding to the traditional notion of inflectional class), metamorphomes, which are a property of paradigms, a set of cells which behave in a particular way (corresponding to the morphome in Maiden's terms, such as patterns of stem distribution), and meromorphomes, which are a property of exponents, and have only been identified for now in Kayardild and related languages.\n"}
{"id": "1555127", "url": "https://en.wikipedia.org/wiki?curid=1555127", "title": "Official multilingualism", "text": "Official multilingualism\n\nOfficial multilingualism is the policy adopted by some states of recognizing multiple languages as official and producing all official documents, and handling all correspondence and official dealings, including court procedure, in these languages. It is distinct from personal multilingualism, the capacity of a person to speak several languages.\n\nAfghanistan uses Dari (or Afghan Persian) and Pashto as official languages. Many citizens are bilingual. These two languages account for 85% of Afghanis' native tongues.\n\nIn Belarus, Russian is far more common than Belarusian, and Section 17 of the Constitution designates both as official languages.\n\nThe official languages of Burundi are the local Kirundi language as well as the colonial French.\n\nCameroon is extremely diverse linguistically and uses English and French as official languages.\n\nIn Canada English and French have special legal status over other languages in Canada’s courts, parliament and administration. \nAt the provincial level, New Brunswick is the only official bilingual province, while Quebec is the only province where French is the sole official language. The remaining provinces have English as the only official language. In practice, all provinces, including Quebec, offer some bilingual services and some education in both official languages up to the high school level. English and French are official languages in all three territories (because they are federally administered). In addition, Inuktitut is also an official language in Nunavut, and nine aboriginal languages have official status in the Northwest Territories.\n\nOut of 120 languages spoken in the Central African Republic, French and the Ngbandi-based creole Sango are official.\n\nCitizens of Chad speak over 120 languages, and the standardized Chadian Arabic serves as the lingua franca with colonial language French also being official.\n\n\nIsland nation of Cyprus has had Greek and Turkish as its languages since the 1960 Constitution (Article 3, section 1). The usage of either language is complicated by the political dispute that lead to the creation of the Turkish Republic of Northern Cyprus.\n\n\nIn Finland, Finnish and Swedish are both considered \"national languages\". Municipalities of Finland are divided into three categories: unilingual Swedish, unilingual Finnish or bilingual. Finnish is the maternal language of about 90% of the population, and the bilingual or swedophone population is concentrated to the coastal areas of Ostrobothnia and Southwest Finland. The autonomous province of Åland is officially unilingual (Swedish). Both Swedish and Finnish are compulsory school subjects.\n\nHong Kong is officially bilingual. Both English and Cantonese are official languages.\n\nThe Philippine constitution designates Filipino as the national language and – along with English – as official languages. Spanish was the national and official language of the country for more than three centuries under Spanish colonial rule, and became the lingua franca of the Philippines in the 19th and early 20th centuries. It remained, along with English, as a de facto official language until removed in 1973 by a constitutional change. After a few months it was re-designated an official language by presidential decree and remained official until 1987, when the present Constitution removed its official status. Spanish and Arabic are currently designated to be promoted on a voluntary and optional basis.\n\nSome people in native Tagalog areas are bilingual, while in non-Tagalog areas it is common to be multilingual in Filipino, English, and in one or more of the regional languages, or as in other cases in languages such as Spanish, Minnan (Hokkien), and Arabic due to factors such as ancestry and religion. Eleven regional languages are recognised by the government as auxiliary official languages in their respective regions, while 90+ other languages and dialects are spoken by various groups.\n\n\n\n"}
{"id": "53445996", "url": "https://en.wikipedia.org/wiki?curid=53445996", "title": "Optimot", "text": "Optimot\n\nOptimot, linguistic inquiries, is a service provided by the Directorate - General of Linguistic Policy of the Catalan Government in collaboration with the Institute for Catalan Studies and the Terminology Center TERMCAT. It consists of a search engine for linguistic information that helps to clarify doubts about the Catalan language. With Optimot different sources can be checked at the same time in an integrated way. When the search options provided by Optimot do not manage to answer the linguistic question, a personalized inquiry service can be accessed.\n\nUp to 2007, the Consortium for Linguistic Normalization, the TERMCAT Terminology Centre, the Institute of Catalan Studies, and the directorate-general of Linguistics Politics dealt with linguistic inqueries that came from general population, companies, organizations, and language professionals. In order to avoid decentralization of the linguistic enquiries and to offer a unified service, Optimot was implemented. The search engine started working in October 2007 and the personalized service began in February 2008. Mainly, Optimot was to improve quality in linguistic-inquiry service by unifying criteria, and to promote linguistic autonomy.\n\nThe sources used in the searches performed by Optimot are the following:\n\n\n"}
{"id": "10417456", "url": "https://en.wikipedia.org/wiki?curid=10417456", "title": "Orality", "text": "Orality\n\nOrality is thought and verbal expression in societies where the technologies of literacy (especially writing and print) are unfamiliar to most of the population. The study of orality is closely allied to the study of oral tradition. \n\nThe term “orality” has been used in a variety of ways, often to describe, in a generalised fashion, the structures of consciousness found in cultures that do not employ, or employ minimally, the technologies of writing. \n\nWalter J. Ong’s work was foundational for the study of orality, and reminds us that despite the striking success and subsequent power of written language, the vast majority of languages are never written, and the basic orality of language is permanent. \n\nIn his later publications Ong distinguishes between two forms of orality: 'primary orality' and 'secondary orality'. Primary orality is thought and expression un-touched by the culture of writing of print; \"secondary orality\" is explained by Ong as oral culture defined by (implicitly influenced) by the written and printed word, and includes oral culture made possible by technology such as a newscaster reading a news report on television.\n\nIn addition, 'residual orality' is also defined - it is the remnants, legacy, or influence of a predominately oral culture carried over into the written realm - an example might include the use of dialogue as a philosophical or didactic tool in written literature, such as used by the Greek thinker Plato.\n\nBefore writing became a way for many cultures before we had orality. Unfortunately many of the retained orality has been lost or drastically changed. Those that were able to be preserved gives us insight to past cultures and just how much we have evolved since then. In \"Orality and Literacy\" (2nd ed. ), Ong sums up his own work over the previous three decades as well as the work of numerous other scholars. With regard to oral tradition and primary orality he draws on pioneering work by Milman Parry, Albert B. Lord, and Eric A. Havelock. Marshall McLuhan was among the first to fully appreciate the significance of the Ong's earlier work about print culture and the written and printed word as a technology. In his work \"The Gutenberg Galaxy\" McLuhan quotes and discusses works by Ong in the 1950s regarding print culture.; Orality gave us the stepping stones that allowed us to get where we are today, it was a necessity for the growth of civilization. But using his own examples to amplify Ong's thought, McLuhan shows how each stage in the development of this technology throughout the history of communication – from the invention of speech (primary orality), to pictograms, to the phonetic alphabet, to typography, to the electronic communications of today – restructures human consciousness, profoundly changing not only the frontiers of human possibility, but even the frontiers it is possible for humans to imagine.\n\n'Primary orality' refers to thought and its verbal expression within cultures \"totally untouched by any knowledge of writing or print.\"\n\nAll sound is inherently powerful. If a hunter kills a lion he can see it, touch it, feel it and smell it. But if he hears a lion he must act, fast, because the sound of the lion signals its presence and its power. Speech is a form of sound that shares this common power. Like other sounds, it comes from within a living organism. A text can be ignored; it is just writing on paper. But to ignore speech can be unwise; our basic instincts compel us to pay attention.\n\nWriting is powerful in a different way: it permits people to generate ideas, store them, and retrieve them as needed across time in a highly efficient and accurate way. The absence of this technology in oral societies limits the development of complex ideas and the institutions that depend on them. Instead, sustained thought in oral settings depends on interpersonal communication, and storing complex ideas over a long period of time requires packaging them in highly memorable ways, generally by using mnemonic tools.\n\nIn his studies of the Homeric Question, Milman Parry was able to show that the poetic metre found in the \"Iliad\" and the \"Odyssey\" had been 'packaged' by oral Greek society to meet its information management needs. These insights first opened the door to a wider appreciation of the sophistication of oral traditions, and their various methods of managing information. Later, ancient and medieval mnemonic tools were extensively documented by Frances Yates in her book \"The Art of Memory\".\n\n‘Residual orality’ refers to thought and its verbal expression in cultures that have been exposed to writing and print, but have not fully ‘interiorized’ (in McLuhan’s term) the use of these technologies in their daily lives. As a culture interiorizes the technologies of literacy, the ‘oral residue’ diminishes.\n\nBut the availability of a technology of literacy to a society is not enough to ensure its widespread diffusion and use. For example, Eric Havelock observed in \"A Preface to Plato\" that after the ancient Greeks invented writing they adopted a scribal culture that lasted for generations. Few people, other than the scribes, considered it necessary to learn to read or write. In other societies, such as ancient Egypt or medieval Europe, literacy has been a domain confined to political and religious elites.\n\nMany cultures have experienced an equilibrium state in which writing and mass illiteracy have co-existed for hundreds or even thousands of years.\n\nOral residue rarely disappears quickly and never vanishes completely. Speech is inherently an oral event, based on human relationships, unlike texts. Oral societies can mount strong resistance to literate technologies, as vividly shown in the arguments of Socrates against writing in Plato's \"Phaedrus\". Writing, Socrates argues, is inhuman. It attempts to turn living thoughts dwelling in the human mind into mere objects in the physical world. By causing people to rely on what is written rather than what they are able to think, it weakens the powers of the mind and of memory. True knowledge can only emerge from a relationship between active human minds. And unlike a person, a text can’t respond to a question; it will just keep saying the same thing over and over again, no matter how often it is refuted.\n\nThe Canadian communications scholar, Harold Innis argued that a balance between the spoken word and writing contributed to the cultural and intellectual vitality of ancient Greece in Plato's time. Plato conveyed his ideas by writing down the conversations of Socrates thus \"preserving the power of the spoken word on the written page.\" Aristotle, Innis wrote, regarded Plato's style as \"halfway between poetry and prose.\" Plato was able to arrive at new philosophical positions \"through the use of dialogues, allegories and illustrations.\"\n\nFurthermore, as McLuhan emphasizes, modernization attenuates some oral capabilities. For example, in medieval Europe silent reading was largely unknown. This tilted the readers' attention towards the poetic and other auditory aspects of the text. Educated modern adults may also occasionally long for something like \"the capacious medieval memory, which, untrammeled by the associations of print, could learn a strange language with ease and by the methods of a child, and could retain in memory and reproduce lengthy epic and elaborate lyric poems.\"\nMcLuhan and Ong also document the apparent re-emergence, in the electronic age, of a kind of 'secondary orality' that displaces written words with audio/visual technologies like radio, telephones, and television. Unlike primary oral modes of communication, these technologies depend on print for their existence. Mass Internet collaborations, such as Wikipedia, rely primarily on writing, but re-introduce relationships and responsiveness into the text.\n\nIt has been a habit of literate cultures to view oral cultures simply in terms of their lack of the technologies of writing. This habit, argues Ong, is dangerously misled. Oral cultures are living cultures in their own right. A 1971 study found that of 3,000 extant languages, only 78 had a written literature. While literacy extends human possibilities in both thought and action, all literate technologies ultimately depend on the ability of humans to learn oral languages and then translate sound into symbolic imagery.\n\nUnderstanding between nations may depend to some degree on understanding oral culture. Ong argues that \"many of the contrasts often made between 'western' and other views seem reducible to contrasts between deeply interiorized literacy and more or less residually oral states of consciousness.\"\n\nDrawing on hundreds of studies from anthropology, linguistics and the study of oral tradition, Ong summarizes ten key aspects of the 'psychodynamics of orality'. While these are subject to continuing debate, his list remains an important milestone. Ong draws his examples from both primary oral societies, and societies with a very high 'oral residue'.\n\nTo retain complex ideas requires that they be packaged memorably for easy recall.\n\nAnthropologist Marcel Jousse identifies a close linkage between rhythm and breathing patterns, gestures and the bilateral symmetry of the human body in several ancient verse traditions. This synergy between the body and the construction of oral thought further fuels memory.\n\nOral cultures avoid complex 'subordinative' clauses. Ong cites an example from the Douay-Rheims version of Genesis (1609–10), noting that this basic additive pattern (in \"italics\") has been identified in many oral contexts around the world:\n\nDemonstrating how oral modes of communication tend to evolve into literate ones, Ong additionally cites the New American Bible (1970), which offers a translation that is grammatically far more complex:\n\nOral expression brings words together in pithy phrases that are the product of generations of evolution: the 'sturdy oak tree', the 'beautiful princess' or 'clever Odysseus'. This does not apply specifically to poetry or song; rather the words are brought together out of habit during general communication. 'Analyzing' or breaking apart such expressions is risky: they represent the work of generations and \"there is nowhere outside the mind to store them.\"\n\nOng cites an American example, noting that in some parts of the United States with heavy oral residue, until the early twentieth-century it was still considered normal or even obligatory to use the adjective ‘glorious’ when referring to the 'Fourth of July'.\n\nSpeech that repeats earlier thoughts or thought-pictures, or shines a different light on them somehow, helps to keep both the speaker and the listener focused on the topic, and makes it easier for all to recall the key points later. \"Oral cultures encourage fluency, fulsomeness, volubility. Rhetoricians were to call this \"\n\nBecause oral societies have no effective access to writing and print technologies, they must invest considerable energy in basic information management. Storage of information, being primarily dependent on individual or collective recall, must be handled with particular thrift. It is possible to approximately measure oral residue \"from the amount of memorization the culture's educational procedures require.\"\n\nThis creates incentives to avoid exploring new ideas and particularly to avoid the burden of having to store them. It does not prevent oral societies from demonstrating dynamism and change, but there is a premium on ensuring that changes cleave to traditional formulas, and \"are presented as fitting the traditions of the ancestors.\"\n\nOral cultures take a practical approach to information storage. To qualify for storage, information must usually concern matters of immediate practical concern or familiarity to most members of the society.\n\nLong after the invention of writing, and often long after the invention of print, basic information on how to perform a society’s most important trades was left unwritten, passed from one generation to the next as it always had been: through apprenticeship, observation and practice.\n\nBy contrast, only literary cultures have launched phenomenological analyses, abstract classifications, ordered lists and tables, etc. Nothing analogous exists in oral societies.\n\n'Agonistic' means 'combative', but Ong actually advances a deeper thesis with this point. Writing and to an even greater extent print, he argues, disengage humans from direct, interpersonal struggle.\n\nProducts of \"the highly polarized, agonistic, oral world of good and evil, virtue and vice, villains and heroes,\" the great works of oral literature from Homer to Beowulf, from the Mwindo epic to the Old Testament, are extremely violent by modern standards. They are also punctuated by frequent and intense intellectual combat and tongue-lashings on the one hand, and effusive praise (perhaps reaching its height among African praise singers) on the other.\n\nIn an oral culture the most reliable and trusted technique for learning is to share a \"close, empathetic, communal association\" with others who know.\n\nOng cites a study of community decision-making from 12th Century England. Writing already had a long history in England, and it would have been possible to use texts to establish for example, the age of majority of the heir to an estate. But people were skeptical about texts, noting not only the cost of generating and managing them, but the problems involved in preventing tampering or frauds.\n\nAs a result, they retained the traditional solution: gathering together \"mature wise seniors of many years, having good testimony\", and publicly discussing the age of the heir with them, until agreement was reached. This hallmark principle of orality, that truth emerges best from communal process, resonates today in the jury system.\n\nOral societies conserve their limited capacity to store information, and retain the relevance of their information to the interest of their present members, by shedding memories that have lost their past significance.\n\nWhile many examples exist, the classic example was reported by . Written records prepared by the British in Ghana in the early 1900s show that Ndewura Jakpa, the seventeenth century founder of the state of the Gonja people, had seven sons, each of whom ruled a territorial division within the state. Six decades later two of the divisions had disappeared for various reasons. The myths of the Gonja had been revised to recount that Jakpa had five sons, and that five divisions were created. Since they had no practical, present purpose, the other two sons and divisions had evaporated.\n\nIn oral cultures, concepts are used in a way that minimizes abstraction, focusing to the greatest extent possible on objects and situations directly known by the speaker. A study by Alexander Luria, a psychologist who did extensive fieldwork comparing oral and literate subjects in remote areas of Uzbekistan and Kirghizia in 1931–2 documented the highly situational nature of oral thinking.\n\n\n\n"}
{"id": "4574535", "url": "https://en.wikipedia.org/wiki?curid=4574535", "title": "Paremiology", "text": "Paremiology\n\nParemiology () is the collection and study of proverbs.\n\nParemiology can be dated back as far as Aristotle. Paremiography, on the other hand, is the collection of proverbs. The proverb scholar Wolfgang Mieder defines the term \"proverb\" as follows:\n\nAs well as actual proverbs, the following may be considered proverbial phrases:\n\nTypical stylistic features of proverbs (as Shirley Arora points out in her article, \"The Perception of Proverbiality\" (1984)) are:\n\n\nIn some languages, assonance, the repetition of a vowel, is also exploited in forming artistic proverbs, such as the following extreme example from Oromo, of Ethiopia.\nSimilarly, from Tajik:\nNotice that in all of these cases of complete assonance, the vowel is , the most common vowel in human languages.\n\nAlso in Amharic, complete assonance is not infrequent when verbs are in the 3rd person masculine singular, past tense. The vowel <ä> is the most frequent vowel in the language.\n\nInternal features that can be found quite frequently include:\n\nTo make the respective statement more general most proverbs are based on a metaphor. Further typical features of the proverb are its shortness and the fact that its author is generally unknown.\nIn the article \"Tensions in Proverbs: More Light on International Understanding\", Joseph Raymond comments on what common Russian proverbs from the 18th and 19th centuries portray: Potent antiauthoritarian proverbs reflected tensions between the Russian people and the Czar. The rollickingly malicious undertone of these folk verbalizations constitutes what might be labeled a \"paremiological revolt\". To avoid openly criticizing a given authority or cultural pattern, folk take recourse to proverbial expressions which voice personal tensions in a tone of generalized consent. Proverbs that speak to the political disgruntlement include: \"When the Czar spits into the soup dish, it fairly bursts with pride\"; \"If the Czar be a rhymester, woe be to the poets\"; and \"The hen of the Czarina herself does not lay swan's eggs\". While none of these proverbs state directly, \"I hate the Czar and detest my situation\" (which would have been incredibly dangerous), they do get their points across.\n\nProverbs are found in many parts of the world, but some areas seem to have richer stores of proverbs than others (such as West Africa), while others have hardly any (North and South America) (Mieder 2004b:108,109).\n\nProverbs are used by speakers for a variety of purposes. Sometimes they are used as a way of saying something gently, in a veiled way (Obeng 1996). Other times, they are used to carry more weight in a discussion, a weak person is able to enlist the tradition of the ancestors to support his position, or even to argue a legal case. Proverbs can also be used to simply make a conversation/discussion more lively. In many parts of the world, the use of proverbs is a mark of being a good orator.\n\nThe study of proverbs has application in a number of fields. Clearly, those who study folklore and literature are interested in them, but scholars from a variety of fields have found ways to profitably incorporate the study proverbs. For example, they have been used to study abstract reasoning of children, acculturation of immigrants, intelligence, the differing mental processes in mental illness, cultural themes, etc. Proverbs have also been incorporated into the strategies of social workers, teachers, preachers, and even politicians. (For the deliberate use of proverbs as a propaganda tool by Nazis, see Mieder 1982.)\n\nThere are collections of sayings that offer instructions on how to play certain games, such as dominoes (Borajo \"et al.\" 1990) and the Oriental board game go (Mitchell 2001). However, these are not prototypical proverbs in that their application is limited to one domain.\n\nOne of the most important developments in the study of proverbs (as in folklore scholarship more generally) was the shift to more ethnographic approaches in the 1960s. This approach attempted to explain proverb use in relation to the context of a speech event, rather than only in terms of the content and meaning of the proverb.\n\nAnother important development in scholarship on proverbs has been applying methods from cognitive science to understand the uses and effects of proverbs and proverbial metaphors in social relations.\n\n"}
{"id": "41602973", "url": "https://en.wikipedia.org/wiki?curid=41602973", "title": "Parinama-vada (Hindu thought)", "text": "Parinama-vada (Hindu thought)\n\nPariṇāma-vāda (), or theTransformation theory is that which pre-supposes the cause to be continually transforming itself into its effects, and it has three variations – the Satkarya-vada of the Samkhyas, the Prakrti Parinama-vada of the Saiva Siddhanta and the Brahma-Parinama-vada of the Vishishtadvaita Vedanta School of Thought.\n\nIn Indian philosophy, there are basically three major cosmological theories of origination – 1) Arambha-vada (the theory of atomic agglomeration, based on the theory of Asatkarya-vada that the effect, which is something newly produced, does not exist in the cause), 2) Parinama-vada (the theory of real transformation, based on satkarya-vada that the effect, though phenomenally different, is substantially identical with the cause, and pre-exists latently in it), and 3) Vivartavada (the theory of apparent transformation or of false appearance). There is also the fourth, Pratityasamutpada-vada, the theory of dependent origination of Buddhism.\n\nAccording to the Sat-Karya-vada of the Samkhya School of Vedanta, also accepted by the Vishishtadvaitavada Vedanta, causation is the manifestation of what is in the latent condition in the cause. The Prakrti Parnama-vada is based on the premise that the world is a transformation of the primordial Nature or Prakrti. According to the Brahman Parinama-vada, the world is a transformation of Brahman.\nParināma-vāda is the term that refers to the Monotheistic Schools’ theory of ‘actual transformation’ different from Vivartavada, the Monistic Schools’ theory of apparent transformation. It is the theory that the effect is a real transformation of the cause. According to the Brahman-parinama, this universe is a real transformation of Brahman.\n\nThe Arambha-vada theory of causation is advocated by the Nyaya School, which is the creationistic view of causation and implies new creation as the effect that puts an end to its antecedent nonexistence and marks a new beginning. According to this school the effect, being the counter-entity of its prior nonexistence, must be held to be nonexistent before its appearance as an effect although it arose out of a previously existent cause. This theory is the reverse of Parinama-vada.\n\nThe general Vedanta view is that Brahman is both, the Material and the Efficient, cause of the entire universe. There is nothing outside the Omnipresent Brahman. Brahman is the only being which contains the elements of cit and a-cit which are transformed into the forms of individual souls and material objects. There is no external world of souls and matter produced out of external material causes, and the very concept of Pradhana or Primal Matter, outside Brahman, involves contradiction.\n\nAccording to this philosophy, which follows from Sat-Karya-vada, the cause first, potentially contains the effect in it as its Shakti (power), in an un-manifest way; then through the instrumentality of the efficient cause, that potential, latent, un-manifest effect is made actual, patent and manifest. Creation is not a new beginning but the manifestation of the already present un-manifest. The world, as the effect arisen from the pure cause, cannot be impure and imperfect because Brahman, the pure essence, merely transforms itself and does not change, and therefore, remains the same always, whereas the effects are mere names, due to words, for knowing and identifying the effects.\n\nPrakrti is orderly. The Ṛta (order) that makes Prakrti appear to be composed of sub-systems arranged hierarchically with each sub-system being progressively inclusive, co-ordinating and interdependent is traditionally held to be the main basis of the doctrine of pre-existent effect or Sat-Karya-vada or the doctrine of real transformation or Parinama-vada, which R.A.Sinari states is “the earliest and epistemologically the most valuable attempt made in Indian Philosophy to set up a theory of causal order”. All phenomena, belonging to the surface and/or the deeper structure of Prakrti, are parinama i.e. transformation, of one and the same substratum.\n\nThe Svetasvatara Upanishad says: मायां तु प्रकृतिं – “Know Maya to be Prakrti”. But, both the Samkhya School and the Brahma Sutras base their understandings of the process of transformation for origination of things on the will of the creator. Badarayana by stating – नासतोऽदृष्टत्वात् | (Brahma Sutra 2.2.26), declares that Existence does not come out of non-existence. The entire creation is the result of Brahman’s will – अभिध्योपदेशाच्च | (Brahma Sutra 1.4.24), and that all transmigratory existence has no beginning - उपपद्यते चाप्युलभ्यते च | (Brahma Sutra 2.1.36).\n\nTantra has influenced the Hindu, the Buddhist and the Jain traditions. According to the Srividya and the Saivite texts, the thirty-six tattvas covering the entire range of the un-manifest and manifest world, from the gross to the most subtle known as siva, pure illumination. Parinama-vada called Sakti parinama-vada, along with the doctrine of Abhasavada or Pratibimbavada, explains the relationship between samvit or Tripura and the world; Tripura refers to the totality of the three-folds – sthula (gross), suksma (subtle) and para (transcendent), it represents. According to Abhasa-vada, samvit is like a mirror and the universe is a reflection appearing on it. But the universe cannot be outside the mirror i.e. citi or samvit. According to Parinama-vada, citi (consciousness) manifests in the form of the universe without losing its pristine nature.\n\nGaudapada treats creation as an imaginary event even though it seems to follow a sequential order. Badarayana also states that creation for Brahman is a mere pastime out of his spontaneity without any extraneous motive. But, Gaudapada, who was aware of the concepts of the real and apparent transformations, develops the doctrine of creation as an illusory transformation of Brahman without recourse to ‘vivarta’ terminology. The followers of Advaita School promoted by Adi Sankara, to whom owing to Maya the world appears as if it is real i.e. distortion or false apprehension of the all encompassing unity of Brahman, use this term ‘vivarta’ to support the principle of the immutability of reality. Vidyaranya reminds us – एकमेवाद्वितीयं सन्नामरूपविवर्जितम् | - that before the creation there existed the Reality, one only, without a second, and without name and form (Panchadasi 5.5), this after explaining (in verse 2.59) that with Brahman as its basis, Maya creates the various objects of the world, just as a variety of pictures are drawn on a wall by the use of different colours, in other words, “Maya makes it possible for the imagination to attribute different changes to the unchangeable”. it is, therefore, said that “Maya resembles avidya, the source of common illusions, and described as the principle of cosmic illusion, thus differing from Prakrti of the Samkhyas which is real in the full sense of the term”.\n\nBoth, Parnama-vada and Vivartavada, have their own critics. Madhava rejects Bhaskara on the ground that it is not possible for Brahman to transform at the loss of original nature, and there cannot exist unbridgeable gulf between Cit (Spirit) and Jada (Matter).239 A perfect being of pure intelligence and bliss cannot evolve out of itself an effect that is inert and wholly lacking in intelligence. Ramanuja accepts the material causality of Brahman which is absolutely without personal modification and which has the transforming Prakrti as its body. Vivarta concept is rejected because Brahman is not the constituent cause of Maya, therefore Brahman cannot be the constituent cause of the world through Maya.\n"}
{"id": "42649463", "url": "https://en.wikipedia.org/wiki?curid=42649463", "title": "Passive fluency", "text": "Passive fluency\n\nPassive fluency is where a person can fluently read and audibly understand a language whilst not having the ability to fluently speak or write the language. Passive fluency is often brought about by being raised in one language (which becomes the person's passive language) and being schooled in another language (which becomes the person's native language).\n\nPeople who are passively fluent in a language are often latent speakers who were raised in an environment where the language was spoken but did not become native speakers.\n\nA more common term for this phenomenon is 'passive bilingualism'. Grosjean argues that there has been a monolingual bias regarding who is considered a 'bilingual', where people who do not have equal competence in all their languages are judges not speaking properly. 'Balanced bilinguals' are, in fact, very rare, and the fluency of a bilingual in his/ her languages is domain- specific: it depends on what they need the languages for. This means that speakers may not admit to their fluency in their passive language, despite the fact that there are social (extralinguistic) factors underlying their different competencies.\n\nKarlos Cid Abasolo discusses that passive bilingualism would be a minimum requirement for the co- official status of Basque and Spanish to become a working reality. As there are currently many monolingual Spanish speakers, and no monolingual Basque speakers, there is not yet a situation where an individual fluent in Basque could speak in his/ her mother tongue, regardless of the domain, circumstance or interlocutor.\n"}
{"id": "4221065", "url": "https://en.wikipedia.org/wiki?curid=4221065", "title": "Passive speaker (language)", "text": "Passive speaker (language)\n\nA passive speaker (also referred to as a receptive bilingual or passive bilingual) is a category of speaker who has had enough exposure to a language in childhood to have a native-like comprehension of it, but has little or no active command of it. Such passively fluent individuals are often raised in an environment where the language was spoken but did not become native speakers.\n\nSuch speakers are especially common in language shift communities where speakers of a declining language do not acquire active competence. Around 10% of the Ainu people who speak the language are considered passive speakers. Passive speakers are often targeted in language revival efforts to increase the number of speakers of a language quickly, as they are likely to gain active and near-native speaking skills more quickly than those with no knowledge of the language. They are also found in areas where people grow up hearing another language outside their family with no formal education.\n\nA \"passive language\" is a related term used in interpreting or translating. It is the language or languages from which the interpreter works. For example if an interpreter's job is to translate from German, Dutch and Swedish into French, then French is the active language while the others are passive.\n\nA more common term for the phenomenon is 'passive bilingualism'. Grosjean argues that there has been a monolingual bias regarding who is considered a 'bilingual' in which people who do not have equal competence in all their languages are judged as not speaking properly. 'Balanced bilinguals' are, in fact, very rare. One's fluency of a bilingual in a languages is domain-specific: it depends on what each language is used for. That means that speakers may not admit to their fluency in their passive language although there are social (extralinguistic) factors that underlie their different competencies.\n\nKarlos Cid Abasolo discusses that passive bilingualism would be a minimum requirement for the co-official status of Basque and Spanish to become a working reality. As there are now many monolingual Spanish-speakers, and no monolingual Basque-speakers in the Basque Country, there is little reason for those fluent in Basque to speak it, regardless of the domain, circumstance or interlocutor.\n\n\nAAIC Glossary: Passive language\n"}
{"id": "23193", "url": "https://en.wikipedia.org/wiki?curid=23193", "title": "Philology", "text": "Philology\n\nPhilology is the study of language in oral and written historical sources; it is the intersection between textual criticism, literary criticism, history, and linguistics. Philology is more commonly defined as the study of literary texts as well as oral and written records, the establishment of their authenticity and their original form, and the determination of their meaning. A person who pursues this kind of study is known as a philologist.\n\nIn older usage, especially British, philology is more general, covering comparative and historical linguistics.\n\nClassical philology studies classical languages. Classical philology principally originated from the Library of Pergamum and the Library of Alexandria around the fourth century BCE, continued by Greeks and Romans throughout the Roman/Byzantine Empire. It was preserved and promoted during the Islamic Golden Age, and eventually resumed by European scholars of the Renaissance, where it was soon joined by philologies of other non-Asian (European) (Germanic, Celtic), Eurasian (Slavistics, etc.) and Asian (Arabic, Persian, Sanskrit, Chinese, etc.) languages. Indo-European studies involves the comparative philology of all Indo-European languages.\n\nPhilology, with its focus on historical development (diachronic analysis), is contrasted with linguistics due to Ferdinand de Saussure's insistence on the importance of synchronic analysis. The contrast continued with the emergence of structuralism and Chomskyan linguistics alongside its emphasis on syntax.\nThe term \"philology\" is derived from the Greek (\"philología\"), from the terms (\"phílos\") \"love, affection, loved, beloved, dear, friend\" and (\"lógos\") \"word, articulation, reason\", describing a love of learning, of literature, as well as of argument and reasoning, reflecting the range of activities included under the notion of . The term changed little with the Latin \"philologia\", and later entered the English language in the 16th century, from the Middle French \"philologie\", in the sense of \"love of literature\".\n\nThe adjective (\"philólogos\") meant \"fond of discussion or argument, talkative\", in Hellenistic Greek, also implying an excessive (\"sophistic\") preference of argument over the love of true wisdom, (\"philósophos\").\n\nAs an allegory of literary erudition, \"philologia\" appears in fifth-century postclassical literature (Martianus Capella, \"De nuptiis Philologiae et Mercurii\"), an idea revived in Late Medieval literature (Chaucer, Lydgate).\n\nThe meaning of \"love of learning and literature\" was narrowed to \"the study of the historical development of languages\" (historical linguistics) in 19th-century usage of the term. Due to the rapid progress made in understanding sound laws and language change, the \"golden age of philology\" lasted throughout the 19th century, or \"from Giacomo Leopardi and Friedrich Schlegel to Nietzsche\". In the Anglo-Saxon world, the term philology to describe work on languages and literatures, which had become synonymous with the practices of German scholars, was abandoned as a consequence of anti-German feeling following World War I. Most continental European countries still maintain the term to designate departments, colleges, position titles, and journals. J. R. R. Tolkien opposed the nationalist reaction against philological practices, claiming that \"the philological instinct\" was \"universal as is the use of language\". In British English usage, and in British academia, \"philology\" remains largely synonymous with \"historical linguistics\", while in US English, and US academia, the wider meaning of \"study of a language's grammar, history and literary tradition\" remains more widespread. Based on the harsh critique of Friedrich Nietzsche, US scholars since the 1980s have viewed philology as responsible for a narrowly scientistic study of language and literature.\n\nThe comparative linguistics branch of philology studies the relationship between languages. Similarities between Sanskrit and European languages were first noted in the early 16th century and led to speculation of a common ancestor language from which all these descended. It is now named Proto-Indo-European. Philology's interest in ancient languages led to the study of what were, in the 18th century, \"exotic\" languages, for the light they could cast on problems in understanding and deciphering the origins of older texts.\n\nPhilology also includes the study of texts and their history. It includes elements of textual criticism, trying to reconstruct an author's original text based on variant copies of manuscripts. This branch of research arose among Ancient scholars in the 4th century BC Greek-speaking world, who desired to establish a standard text of popular authors for the purposes of both sound interpretation and secure transmission. Since that time, the original principles of textual criticism have been improved and applied to other widely distributed texts such as the Bible. Scholars have tried to reconstruct the original readings of the Bible from the manuscript variants. This method was applied to Classical Studies and to medieval texts as a way to reconstruct the author's original work. The method produced so-called \"critical editions\", which provided a reconstructed text accompanied by a \"critical apparatus\", i.e., footnotes that listed the various manuscript variants available, enabling scholars to gain insight into the entire manuscript tradition and argue about the variants.\n\nA related study method known as higher criticism studies the authorship, date, and provenance of text to place such text in historical context. As these philological issues are often inseparable from issues of interpretation, there is no clear-cut boundary between philology and hermeneutics. When text has a significant political or religious influence (such as the reconstruction of Biblical texts), scholars have difficulty reaching objective conclusions.\n\nSome scholars avoid all critical methods of textual philology, especially in historical linguistics, where it is important to study the actual recorded materials. The movement known as New Philology has rejected textual criticism because it injects editorial interpretations into the text and destroys the integrity of the individual manuscript, hence damaging the reliability of the data. Supporters of New Philology insist on a strict \"diplomatic\" approach: a faithful rendering of the text exactly as found in the manuscript, without emendations.\n\nAnother branch of philology, cognitive philology, studies written and oral texts. Cognitive philology considers these oral texts as the results of human mental processes. This science compares the results of textual science with the results of experimental research of both psychology and artificial intelligence production systems.\n\nIn the case of Bronze Age literature, philology includes the prior decipherment of the language under study. This has notably been the case with the Egyptian, Sumerian, Assyrian, Hittite, Ugaritic and Luwian languages. Beginning with the famous decipherment and translation of the Rosetta Stone by Jean-François Champollion in 1822, a number of individuals attempted to decipher the writing systems of the Ancient Near East and Aegean. In the case of Old Persian and Mycenaean Greek, decipherment yielded older records of languages already known from slightly more recent traditions (Middle Persian and Alphabetic Greek).\n\nWork on the ancient languages of the Near East progressed rapidly. In the mid-19th century, Henry Rawlinson and others deciphered the Behistun Inscription, which records the same text in Old Persian, Elamite, and Akkadian, using a variation of cuneiform for each language. The elucidation of cuneiform led to the decipherment of Sumerian. Hittite was deciphered in 1915 by Bedřich Hrozný.\n\nLinear B, a script used in the ancient Aegean, was deciphered in 1952 by Michael Ventris and John Chadwick, who demonstrated that it recorded an early form of Greek, now known as Mycenaean Greek. Linear A, the writing system that records the still-unknown language of the Minoans, resists deciphering, despite many attempts.\n\nWork continues on scripts such as the Maya, with great progress since the initial breakthroughs of the phonetic approach championed by Yuri Knorozov and others in the 1950s. Since the late 20th century, the Maya code has been almost completely deciphered, and the Mayan languages are among the most documented and studied in Mesoamerica. The code is described as a logosyllabic style of writing, which could be used to fully express any spoken thought.\n\nIn the \"Space Trilogy\" by C.S. Lewis, the main character, Elwin Ransom, is a philologist - as was Lewis' close friend J. R. R. Tolkien.\n\nDr. Edward Morbius, one of the main characters in the science-fiction film \"Forbidden Planet\", is a philologist.\n\nMoritz-Maria von Igelfeld, the main character in Alexander McCall Smith's 1997 comic novel \"Portuguese Irregular Verbs\" is a philologist, educated at Cambridge.\n\nThe main character in the Academy Award Nominee for Best Foreign Language film in 2012, \"Footnote\", is a Hebrew philologist, and a significant part of the film deals with his work.\n\n\n"}
{"id": "1850174", "url": "https://en.wikipedia.org/wiki?curid=1850174", "title": "Philosophical language", "text": "Philosophical language\n\nA philosophical language is any constructed language that is constructed from first principles, like a logical language, but may entail a strong claim of absolute perfection or transcendent or even mystical truth rather than satisfaction of pragmatic goals. Philosophical languages were popular in Early Modern times, partly motivated by the goal of recovering the lost Adamic or Divine language. The term ideal language is sometimes used near-synonymously, though more modern philosophical languages such as Toki Pona are less likely to involve such an exalted claim of perfection. It may be known as a language of pure ideology. The axioms and grammars of the languages together differ from commonly spoken languages today. \n\nIn most older philosophical languages, and some newer ones, words are constructed from a limited set of morphemes that are treated as \"elemental\" or fundamental. \"Philosophical language\" is sometimes used synonymously with \"taxonomic language\", though more recently there have been several conlangs constructed on philosophical principles which are not taxonomic. Vocabularies of oligosynthetic languages are made of compound words, which are coined from a small (theoretically minimal) set of morphemes; oligoisolating languages, such as Toki Pona, similarly use a limited set of root words but produce phrases which remain series of distinct words. \n\nToki Pona is based on minimalistic simplicity, incorporating elements of Taoism. Láadan is designed to lexicalize and grammaticalize the concepts and distinctions important to women, based on muted group theory. \n\nA priori languages are constructed languages where the vocabulary is invented directly, rather than being derived from other existing languages (as with Esperanto or Ido). Philosophical languages are almost all a priori languages, but most \"a priori\" languages are not philosophical languages. For example, Quenya, Sindarin, and Klingon are all \"a priori\" but not philosophical languages: they are meant to seem like natural languages, even though they have no genetic relation to any natural languages.\n\nWork on philosophical languages was pioneered by Francis Lodwick (\"A Common Writing\", 1647; \"The Groundwork or Foundation laid (or So Intended) for the Framing of a New Perfect Language and a Universal Common Writing\", 1652), Sir Thomas Urquhart (\"Logopandecteision\", 1652), George Dalgarno (\"Ars signorum\", 1661), and John Wilkins (\"An Essay towards a Real Character, and a Philosophical Language\", 1668). Those were systems of hierarchical classification that were intended to result in both spoken and written expression. In 1855, English writer George Edmonds modified Wilkins' system, leaving its taxonomy intact, but changing the grammar, orthography and pronunciation of the language in an effort to make it easier to speak and to read.\n\nGottfried Leibniz created \"lingua generalis\" (or \"lingua universalis\") in 1678, aiming to create a lexicon of characters upon which the user might perform calculations that would yield true propositions automatically; as a side effect he developed binary calculus.\n\nThese projects aimed not only to reduce or model grammar, but also to arrange all human knowledge into \"characters\" or hierarchies. This idea ultimately led to the \"Encyclopédie\", in the Age of Enlightenment. Leibniz and the encyclopedists realized that it is impossible to organize human knowledge unequivocally as a tree, and so impossible to construct an \"a priori\" language based on such a classification of concepts. Under the entry \"Charactère\", D'Alembert critically reviewed the projects of philosophical languages of the preceding century. \n\nAfter the \"Encyclopédie\", projects for \"a priori\" languages moved more and more to the fringe. Individual authors, typically unaware of the history of the idea, continued to propose taxonomic philosophical languages until the early 20th century (for example, Ro). More recent philosophical languages have usually moved away from taxonomic schemata, such as 21st century Ithkuil by John Quijada.\n\n\n"}
{"id": "53839997", "url": "https://en.wikipedia.org/wiki?curid=53839997", "title": "Podaná", "text": "Podaná\n\nPodaná () is a Greek argot based on rearranging syllables, similar to Verlan and Vesre. Podaná itself is a reversal of anápoda (ανάποδα), meaning \"upside-down.\"\n\nExamples include: \"tsosbá\" (inverted \"bátsos\", slang for \"cop\"), \"zakipré\" (inverted \"prezáki\", slang for \"junkie\"), \"dafoú\" (inverted \"foúnda\", \"hashish\"), \"fosbá\" (inverted \"báfos\", \"joint\").\n"}
{"id": "9858901", "url": "https://en.wikipedia.org/wiki?curid=9858901", "title": "Prior consistent statements and prior inconsistent statements", "text": "Prior consistent statements and prior inconsistent statements\n\nPrior consistent statements and prior inconsistent statements, in the law of evidence, occur where a witness, testifying at trial, makes a statement that is either consistent or inconsistent, respectively, with a previous statement given at an earlier time such as during a discovery, interview, or interrogation. The examiner can impeach the witness when an inconsistent statement is found, and may conversely bolster the credibility of an impeached witness with a prior consistent statement.\n\nBefore the witness can be impeached the examiner must have extrinsic evidence of the prior statement. The examiner must also provide the witness with the opportunity to adopt or reject the previous statement. \n\nIn the majority of U.S. jurisdictions, prior inconsistent statements may not be introduced to prove the truth of the prior statement itself, as this constitutes hearsay, but only to impeach the credibility of the witness. \n\nHowever, under Federal Rule of Evidence 801 and the minority of U.S. jurisdictions that have adopted this rule, a prior inconsistent statement may be introduced as evidence of the truth of the statement itself if the prior statement was given in live testimony and under oath as part of a formal hearing, proceeding, trial, or deposition.\n\n\nA prior consistent statement is not a hearsay exception, the FRE specifically define it as non hearsay. A prior consistent statement is admissible:\n\nThere is no requirement that the prior consistent statement have been made under oath at a prior trial or hearing.\n\nA form of prior consistent statement excepted from this rule is that of prior identification by the witness of another person in a lineup.\n"}
{"id": "5391832", "url": "https://en.wikipedia.org/wiki?curid=5391832", "title": "Proceedings in Courts of Justice Act 1730", "text": "Proceedings in Courts of Justice Act 1730\n\nThe Proceedings in Courts of Justice Act 1730 (\"4 Geo II. c. 26\") was an Act of the Parliament of Great Britain which made English (instead of Law French and Latin) the obligatory language for use in the courts of England and in the court of exchequer in Scotland. The Act followed a medieval law from 1362 (the Pleading in English Act 1362), which had made it permissible to debate cases in English, but all written records had continued to be in Latin. It was amended shortly later to extend it to the courts in Wales, and to exempt from its provisions the \"court of the receipt of his Majesty's exchequer\" in England. It never applied to cases heard overseas in the court of admiralty.\n\nA similar act was pasted on 22 November 1650 by the Rump Parliament during the Commonwealth of England: Act for turning the Books of the Law and all Process and Proceedings in Courts of Justice into the English Tongue.\n\nThe Act was introduced by the then Lord Chancellor, Lord King, and came into force on 25 March 1733. It was repealed by the Civil Procedure Acts Repeal Act 1879.\n\nA similar Act was passed by the Parliament of Ireland in 1737, the Administration of Justice (Language) Act (Ireland) 1737.\n"}
{"id": "2786731", "url": "https://en.wikipedia.org/wiki?curid=2786731", "title": "Pseudoword", "text": "Pseudoword\n\nA pseudoword or non-word is a unit of speech or text that appears to be an actual word in a certain language, while in fact it has no meaning in the lexicon. It is a kind of non-lexical vocable.\n\nSuch words without a meaning in a certain language or no occurrence in any text corpus or dictionary can be the result of (the interpretation of) a truly random signal, there will usually be an underlying deterministic source as is the case for:\n\n\nWhen nonsensical words are strung together, gibberish may arise. Word salad in contrast may contain legible and intelligible words but without semantic or syntactic correlation or coherence.\n\nWithin linguistics, a pseudoword is defined specifically as respecting the phonotactic restrictions of a language. That is, it does not include sounds or series of sounds that do not exist in that language: it is easily pronounceable for speakers of the language. Also, when written down, a pseudoword does not include strings of characters that are not permissible in the spelling of the target language. \"Vonk\" is a pseudoword in English, while \"dfhnxd\" is not. The latter is an example of a nonword. Nonwords are contrasted with pseudowords in that they are not pronounceable and by that their spelling could not be the spelling of a real word.\n\nPseudowords are also sometimes called wug words in the context of linguistic experiments. This is because \"wug\" [wʌg] was one such pseudoword used by Jean Berko Gleason in her wug test 1958 experiments. Words like \"wug\", which could have been a perfectly acceptable word in English but isn't due to an accidental gap, were presented to children. The experimenter would then prompt the children to create a plural for \"wug\", which was almost invariably \"wugs\" [wʌgz]. The experiments were designed to see if English morphophonemics would be applied by children to novel words. They revealed that even at a very young age, children have already internalized many of the complex features of their language.\n\nA logatome is a short pseudoword or just a syllable which is used in acoustic experiments to examine speech recognition.\n\nA logatome or nonsense syllable is a short pseudoword consisting most of the time of just one syllable which has no meaning of its own. Examples of English logatomes are the nonsense words \"snarp\" or \"bluck\".\n\nLike other pseudowords, logatomes obey all the phonotactic rules of a specific language.\n\nLogatomes are used in particular in acoustic experiments. They are also used in experiments in the psychology of learning as a way to examine speech recognition. and in experimental psychology, especially the psychology of learning and memory.\n\nNonsense syllables were first introduced by Hermann Ebbinghaus in his experiments on the learning of lists. His intention was that they would form a standard stimulus so that experiments would be reproducible. However, with increasing use it became apparent that different nonsense syllables were learned at very different rates, even when they had the same superficial structure. Glaze introduced the concept of association value to describe these differences, which turned out to be reliable between people and situations. Since Glaze's time, experiments using nonsense syllables typically control association value in order to reduce variability in results between stimuli.\n\nNonsense syllables can vary in structure. The most used are the so-called CVC syllables, composed of a consonant, a vowel, and a consonant. These have the advantage that nearly all are pronounceable, that is, they fit the phonotactics of any language that uses closed syllables, such as English and German. They are often described as \"CVC trigrams\", reflecting their three-letter structure. Obviously many other structures are possible, and can be described on the same principles, e.g. VC, VCV, CVCV. But the CVC trigrams have been studied most intensively; for example, Glaze determined association values for 2019 of them.\n\nThe term nonsense syllable is widely used to describe non-lexical vocables used in music, most notably in scat singing but also in many other forms of vocal music. Although such usages do not invoke the technical issues about structure and associability that are of concern in psychology, the essential meaning of the term is the same.\n\n"}
{"id": "10511206", "url": "https://en.wikipedia.org/wiki?curid=10511206", "title": "Register complex", "text": "Register complex\n\nIn linguistics, a register complex is a combination of phonation type, pitch, length, vowel quality and/or other variants that function dependently as distinguishing features within a single phonological system. In languages employing register systems, differences in a distinguishing feature correlate relative to the quality of another distinguishing feature.\n\nFor instance, in a system where pitch, voice quality and stress timing were distinguishing features, the meaning of a vowel-consonant cluster like \"Pai\" (as in the English word \"Pie\") may depend on whether the cluster is voiced in a high, medium or low pitch relative to the clearness, breathiness and glotteral quality of speech, as well as relative to the duration of the cluster relative to other neighboring clusters. Thus, \"Pai\" voiced in a high tone with a breathy quality and unstressed along with other unstressed clusters would connote a different meaning if any of the three features changed relative to other features.\n\nMany register languages are tonal. However, tone is not a universal distinguishing feature among register systems and register complexes are not a component of most tonal languages. In fact, tonal languages can employ either a register tone systems or a contour tone systems. Mandarin has a contour tone system, where the distinguishing feature of the tones are their shifts in pitch (their pitch shapes or contours, such as rising, falling, dipping, or peaking) rather than simply their pitch relative to each other as in a register tone system. Register tone systems are found in Bantu languages and throughout Africa. In some register tone systems, there is a default tone, usually low in a two-tone system or mid in a three-tone system, that is more common and less salient than other tones. There are also languages that combine register and contour tones, such as the Kru languages, though in such cases the register tones may be analysed as being 'level' (unvarying pitch) contour tones. Furthermore, often the term 'register,' when not in the phrase 'register tone,' is used to indicate vowel phonation combined with tone in a single phonological system. Burmese, Khmer and possibly Vietnamese are register languages. Burmese is usually considered a tonal language and Khmer a vowel-phonation language, but in both cases differences in relative pitch or pitch contours are correlated with vowel phonation, so that neither exists independently.\n"}
{"id": "596795", "url": "https://en.wikipedia.org/wiki?curid=596795", "title": "Rigid designator", "text": "Rigid designator\n\nIn modal logic and the philosophy of language, a term is said to be a rigid designator or absolute substantial term when it designates (picks out, denotes, refers to) the same thing in \"all possible worlds\" in which that thing exists and does not designate anything else in those possible worlds in which that thing does \"not\" exist. A designator is \"persistently rigid\" if it designates the same thing in every possible world in which that thing exists and designates nothing in all other possible worlds. A designator is \"obstinately rigid\" if it designates the same thing in every possible world, period, whether or not that thing exists in that world. Rigid designators are contrasted with \"connotative terms\", \"non-rigid\" or \"flaccid designators\", which may designate different things in different possible worlds.\n\nThe Scholastic philosophers in the Middle Ages developed a theory of properties of terms in which different classifications of concepts feature prominently.\n\nConcepts, and the terms that signify them, can be divided into absolute or connotative, according to the mode in which they signify. If they signify something absolutely, that is, after the manner of substance, they are absolute, for example rock, lion, man, whiteness, wisdom, tallness. If they signify something connotatively, that is, with reference to a subject of inherence, i.e., after the manner of accidents, they are connotative, for example, white, wise, tall.\n\nBoth connotative and absolute concepts can be used to signify accidents, but since connotative concepts signify with a reference to a subject of inherence, they can refer to object with different definitions and properties (i.e. with different \"essences\"). For example, large, as a connotative concept, can signify objects with many distinct essences: a man, a lion, a triangle can be large.\n\nOn the other hand, absolute concepts signify objects that have the same definitions and properties. For example, the concept of gold, as an absolute concept, can signify only objects with the same definitions and properties (i.e. with the same \"essence\").\n\nThe notion of absolute concepts was then revived by Saul Kripke, with the name “rigid designation”, in the lectures that became \"Naming and Necessity\", in the course of his argument against descriptivist theories of reference, building on the work of Ruth Barcan Marcus. At the time of Kripke's lectures, the dominant theory of reference in analytic philosophy (associated with the theories of Gottlob Frege and Bertrand Russell) was that the meaning of sentences involving proper names could be given by substituting a contextually appropriate description for the name. Russell, for example, famously held that someone who had never met Otto von Bismarck might know of him as \"the first Chancellor of the German Empire\", and if so, his statement that (say) \"Bismarck was a ruthless politician\" should be understood to mean \"The first Chancellor of the German Empire was a ruthless politician\" (which could in turn be analysed into a series of more basic statements according to the method Russell introduced in his theory of definite descriptions). Kripke argued—against both the Russellian analysis and several attempted refinements of it—that such descriptions could not possibly \"mean the same thing\" as the name \"Bismarck,\" on the grounds that proper names such as \"Bismarck\" always designate \"rigidly\", whereas descriptions such as \"the first Chancellor of the German Empire\" do not. Thus, for example, it \"might have been the case\" that Bismarck died in infancy. If so, he would not have ever satisfied the description \"the first Chancellor of the German Empire,\" and (indeed) someone else probably would have. It does not follow that the first Chancellor of the German Empire may not have been the first Chancellor of the German Empire—that is (at least according to its surface-structure) a contradiction. Kripke argues that the way that proper names \"work\" is that when we make statements about what might or might not have been true of Bismarck, we are talking about what might or might not have been true of \"that particular person\" in various situations, whereas when we make statements about what might or might not have been true of, say, \"the first Chancellor of the German Empire\" we \"could\" be talking about what might or might not have been true of \"whoever\" would have happened to fill that office in those situations.\n\nThe \"could\" here is important to note: rigid designation is a property of the \"way terms are used\", not a property of \"the terms themselves\", and some philosophers, following Keith Donnellan, have argued that a phrase such as \"the first Chancellor of the German Empire\" \"could\" be used rigidly, in sentences such as \"the first Chancellor of the German Empire could have decided never to go into politics.\" Kripke himself doubted that there was any need to recognize rigid uses of definite descriptions, and argued that Russell's notion of scope offered all that was needed to account for such sentences. But in either case, Kripke argued, nothing important in his account depends on the question. Whether definite descriptions can be used rigidly or not, they can at least \"sometimes\" be used non-rigidly, but a proper name \"can only be used rigidly\"; the asymmetry, Kripke argues, demonstrates that no definite description could \"give the meaning\" of a proper name—although it might be used to explain \"who\" a name refers to (that is, to \"fix the referent\" of the name).\n\nIn \"Naming and Necessity\", Kripke argues that proper names and certain natural kind terms—including biological taxa and types of natural substances (most famously, \"water\" and \"HO\") designate rigidly. He argues for a form of scientific essentialism not unlike Aristotelian essentialism. Essential properties are common to an object in all possible worlds, and so they pick out the same objects in all possible worlds - they rigidly designate.\n\nProper names rigidly designate for reasons that differ from natural kinds terms. The reason 'Johnny Depp' refers to one particular person in all possible worlds is because some person initially gave the name to him by saying something like \"Let's call our baby 'Johnny Depp'\". This is called the initial baptism. This usage of 'Johnny Depp' for referring to some particular baby got passed on from person-to-person in a giant causal and historical chain of events. That is why everybody calls Johnny Depp 'Johnny Depp'. Johnny's mother passed it onto her friends who passed it onto their friends who passed it onto their friends, and so on.\n\nOne puzzling consequence of Kripke semantics is that identities involving rigid designators are necessary. If water is HO, then water is \"necessarily\" HO. Since the terms 'water' and 'HO' pick out the same object in every possible world, there is no possible world in which 'water' picks out something different from 'HO'. Therefore, water is necessarily HO. It is possible, of course, that we are mistaken about the chemical composition of water, but that does not affect the necessity of identities. What is not being claimed is that water is necessarily HO, but \"conditionally\", \"if\" water is HO (though we may not know this, it does not change the fact if it is true), then water is necessarily HO.\n\n"}
{"id": "42312430", "url": "https://en.wikipedia.org/wiki?curid=42312430", "title": "Sakshi (Witness)", "text": "Sakshi (Witness)\n\nSakshi or Sākṣī (Sanskrit: साक्षी) means – 'observer', 'eyewitness' or the 'Supreme Being' the one that lends its shine - \" Chitchhaya\"- to the \"ego\" part of the subtle body - which consists of the everchanging Mind, the decision making Intellect, the Memory & the Illusory Ego ! In Hindu philosophy, the word, \"Sākṣī\" or 'witness' refers to the 'Pure Awareness' that witnesses the world but does not get affected or involved. \"Sakshi\" is beyond time, space and the triad of experiencer, experiencing and experienced; \"sakshi\" witnesses all thoughts, words and deeds without interfering with them or being affected by them, other than \"sakshi\" there is nothing else in the entire universe.\n\nWith regard to the word, साक्षी (\"sākṣī\"), used in the following verse from Shvetashvatara Upanishad,\n\nPanini states that the same indicates a direct seer or eyewitness (Panini Sutras V.ii.91), Sakshi means Ishvara, the चेता (cetā), the sole Self-consciousness, who is the witness of all, who gives consciousness to every human being, thereby making each rational and discriminatory.\n\nVedanta speaks of mind (\"chitta\") or \"antahkarana\" ('internal instrument'), and matter as the subtle and gross forms of one and the same reality; being the subtle aspect of matter, mind is not a tangible reality. The field of mind (\"Chittakasha\") involves the duality of the seer and the seen, the observer (\"drg\") and the observed (\"drshya\"), which duality is overcome in the field of pure Consciousness. \"Drg-drshya-Viveka\" tells us:-\n\n\"Sakshi\", the Atman, the unchangeable eternal Reality, is the Pure Consciousness and knowledge, in which regard Sankara explains that knowledge does not destroy or create, it only illumines, that the senses (\"indriyas\") are not the mind, the mind uses them as an implement.\n\nThe Varaha Upanishad (IV) refers to the \"Bhumika\" ('stage of development of wisdom') which is of the form of \"pranava\" (\"Aum\" or \"Om\") as formed of or divided into – \"akāra\", \"ukāra\", \"makāra\" and \"ardhmātra\", which is on account of the difference of \"sthula\" ('gross'), \"sukshama\" ('subtle'), \"bija\" ('seed' or 'causal') and \"sakshi\" ('witness') whose \"avasthas\" ('states') are – 'waking', 'dreaming', 'dream-less sleep' and 'turiya'. \"Sakshi\" which is 'turiya' is the essence.\n\nThe faculty which perceives the individual personality is \"Sakshi\" or 'Witness' or the higher 'Ego'. Mind (\"manas\"), Ego (\"ahankara\") and \"Sakshi\", all perform different functions but that difference of functions does not mean difference in nature or essence. Indian Philosophy discovered the concept of \"Sakshi\", the ultimate Observer, or Witness behind the sense of individuality, or the ego; the \"Sakshi\" is the timeless Being which witnesses all this ceaseless flow and change in the world of thought and things.\n"}
{"id": "10418933", "url": "https://en.wikipedia.org/wiki?curid=10418933", "title": "Secondary reference", "text": "Secondary reference\n\nSecondary reference points to the representation as a necessary part in granting a meaning to a (part of a) sentence. In this approach, words that don’t contribute to the representation are void; they can only provide a figurative expression. Examples of phrases which lack a secondary reference are 'a black Monday' (unless it is used figuratively) and Bernard Bolzano's 'round quadrangle'. Alexius Meinong's Types of objects can be mentioned here, too.\n\nIn the first case, one may have a representation of a Monday (or at least of something one calls a Monday), as well as of something black, but not of a 'black Monday', since these qualities don’t combine ('Monday' being too abstract to be combined with a concrete quality such as a color). In the second case, there is an incongruity: a quadrangle can be represented, but not a round one; conversely, there can be a circle, but it can’t be square. It may, therefore, be debated whether a representation is created here.\n\nAnother example is presented by George Berkeley. He says: \"[...] Does it not require some pains and skill to form the general idea of a triangle (which is yet none of the most abstract, comprehensive and difficult) for it must be neither oblique nor rectangle, neither equilateral, equicrural, nor scalenon, but \"all and none\" of these at once?\" (\"A Treatise Concerning the Principles of Human Knowledge\", Introduction, section 13.) Berkeley is here criticizing John Locke, demonstrating that each representation is particular (i.e., individual).\n\nWhether there is a meaning or not depends on the individual person: it is possible that a sentence has a meaning according to A, whereas B can’t discern any. This may, e.g., result from relevant knowledge which A possesses and B lacks, as in the case where one should decide the answer to the question 'Is 15 a prime number?' and A knows what a prime number is and B doesn’t; the sentence then doesn’t have a meaning for B.\n\n"}
{"id": "2800790", "url": "https://en.wikipedia.org/wiki?curid=2800790", "title": "Shabda", "text": "Shabda\n\nShabda, or , is the Sanskrit word for \"speech sound\". In Sanskrit grammar, the term refers to an utterance in the sense of linguistic performance.\n\nIn classical Indian philosophy of language, the grammarian Katyayana stated that \"shabda\" (\"speech\") is eternal (\"nitya\"), as is \"artha\" \"meaning\", and that they share a mutual co-relation. According to Patanjali, the permanent aspect of \"shabda\" is (\"meaning\"), while \"dhvani\" (\"sound, acoustics\") is ephemeral to \"shabda\".\n\nOm, or Aum, a sacred syllable of Hinduism, Buddhism, and Jainism, is considered to be the first resonating vibrational sound within an individual being. It also denotes the non-dualistic universe as a whole. In Buddhism, Om corresponds to the crown chakra and white light.\n\nBhartrihari, on the other hand, held a \"shabda-advaita\" position, identifying \"shabda\" as indivisible, and unifying the notions of cognition and linguistic performance, which is ultimately identical to Brahman. Bhartrhari recognised two entities, both of which may be referred to as \"shabda\". One entity is the underlying cause of the articulated sounds, while the other entity is the functionality that is used to express meaning. Bhartrhari thus rejected the difference posited between the ontological and the linguistic by logicians. His concept of \"shabda-brahman\" which identified linguistic performance and creation itself ran parallel to the Greek concept of \"logos\".\n\nLanguage philosophy in Medieval India was dominated by the dispute of the \"naturalists\" to the Mimamsa school, notably defended by Kumarila, who held that \"shabda\" designates the actual phonetic utterance, and the Sphota school, defended by Mandana Mishra, which identifies \"sphota\" and \"shabda\" as a mystical \"indivisible word-whole\".\n\n\"Shabda\" is a Sanskrit word that was first used as a religio-philosophic term in the context of Hindu religion. It refers to the verbal testimony (of revealed scriptures: \"shruti\" that is indispensable to gaining knowledge of the ultimate reality, Brahman.\n\nIn Sikhism the term \"Shabad\" has two primary meanings. The first context of the term is to refer to a hymn or paragraph or sections of the Holy Text that appears in Guru Granth Sahib, the main holy scripture of the Sikhs. The Guru Granth Sahib is organised by chapters of \"ragas\", with each chapter containing many \"shabads\" of that \"raga\". The first \"Shabad\" in Guru Granth Sahib is the Mool Mantar. The script used for the \"Shabad\" is Gurmukhi. \"Shabad\" is the term also used to refer to hymns within other Sikh scriptures, like Deh Siva Var Mohe. The second use of the term \"Shabad\" in Sikhism is for the holy name of God, Waheguru.\n\nEsoterically, \"Shabd\" is the “Sound Current vibrating in all creation. It can be heard by the inner ears.” Variously referred to as the \"Audible Life Stream\", \"Inner Sound\", \"Sound Current\" or \"Word\" in English, the \"Shabd\" is the esoteric essence of God which is available to all human beings, according to the Shabd path teachings of Sant Mat, Surat Shabd Yoga, Eckankar, Vardankar (a split-off from Eckankar), and Movement of Spiritual Inner Awareness.\n\nAdherents believe that a \"satguru\", Eck Master, or VARDAN Master, who is a human being, has merged with the \"Shabd\" in such a manner that he or she is a living manifestation of it at its highest level (the “Word made flesh”). However, not only can the \"Satguru\" attain this, but all human beings are inherently privileged in this way. Indeed, in Sant Mat the \"raison d’être\" for the human form is to meditate on the Sound Current, and in so doing merge with it until one’s own divinity is ultimately realized.\n\n\"Naam\" (\"Word\") has been described through the use of several different terms. Sant Baljit Singh, a contemporary Sant Mat Master, uses the term \"Light and Sound Current\". He describes it as the connecting link between human beings and God.\n\n\n"}
{"id": "7032057", "url": "https://en.wikipedia.org/wiki?curid=7032057", "title": "Speech-language pathology", "text": "Speech-language pathology\n\nSpeech-Language Pathology is a field of expertise practiced by a clinician known as a speech-language pathologist (SLP), also sometimes referred to as a speech and language therapist or a speech therapist. SLP is considered a \"related health profession\" along with audiology, optometry, occupational therapy, clinical psychology, physical therapy, and others. The field of SLP is distinguished from other \"related health professions\" SLPs are legally permitted to conclude to certain disorders which fall within their scope of practice. SLPs specialize in the evaluation, diagnosis, and treatment of communication disorders (speech disorders and language disorders), cognitive-communication disorders, voice disorders, and swallowing disorders. SLPs also play an important role in the diagnosis and treatment of autism spectrum disorder (often in a team with pediatricians and psychologists).\n\nA common misconception is that speech-language pathology is restricted to adjusting a speaker's speech sound articulation to meet the expected normal pronunciation, such as helping English speaking individuals enunciate the traditionally difficult \"r\". SLPs can also often help people who stutter to speak more fluently. Articulation and fluency are only two facets of the work of an SLP, however. In fact, speech-language pathology is concerned with a broad scope of speech, language, swallowing, and voice issues involved in communication, some of which include:\n\n\nThe components of speech production include:\nThe components of language include:\n\nPrimary pediatric speech and language disorders include: receptive and expressive language disorders, speech sound disorders, childhood apraxia of speech (CAS), stuttering, and language-based learning disabilities. Speech pathologist not only work with adolescents with speech and language impediments, but also those that are elderly.\n\nSwallowing disorders include difficulties in any system of the swallowing process (\"i.e.\" oral, pharyngeal, esophageal), as well as functional dysphagia and feeding disorders. Swallowing disorders can occur at any age and can stem from multiple causes.\n\nSpeech-language pathologists (SLPs) provide a wide range of services, mainly on an individual basis, but also as support for individuals, families, support groups, and providing information for the general public. SLPs work to prevent, assess, diagnose, and treat speech, language, social communication, cognitive-communication, and swallowing disorders in children and adults. Speech services begin with initial screening for communication and swallowing disorders and continue with assessment and diagnosis, consultation for the provision of advice regarding management, intervention, and treatment, and providing counseling and other follow up services for these disorders. Services are provided in the following areas:\n\nSpeech, language, and swallowing disorders result from a variety of causes, such as a stroke, brain injury, hearing loss, developmental delay, a cleft palate, cerebral palsy, or emotional issues.\n\nSLPs collaborate with other health care professionals, often working as part of a multidisciplinary team. They can provide information and referrals to audiologists, physicians, neonatal specialists , dentists, nurses, nurse practitioners, occupational therapists, dietitians, educators, behavior consultants (applied behavior analysis), hospital chaplains/spiritual carers and parents as dictated by the individual client's needs. For example, the treatment for patients with cleft lip and palate, often requires multidisciplinary collaboration. Speech-language pathologists can be very beneficial to help resolve speech problems associated with cleft lip and palate. Research has indicated that children who receive early language intervention are less likely to develop compensatory error patterns later in life, although speech therapy outcomes are usually better when surgical treatment is performed earlier. Another area of collaboration relates to auditory processing disorders, where SLPs can collaborate in assessments and provide intervention where there is evidence of speech, language, and/or other cognitive-communication disorders. Palliative care is another health care area that often involves multi-disciplinary collaboration involving speech-language pathologists. La Trobe University Palliative Care Unit (PCU) (Melbourne, Australia) has been a strong advocate for speech-language pathologists being included within both paediatric and adult palliative care multidisciplinary teams. Currently the PCU is conducting an international modified delphi study to provide 'Recommendations for Speech-Language Pathologist in Paediatric Palliative Care Teams' (\"abbrev\". RESPCT).\n\nSLPs work in a variety of clinical and educational settings. SLPs work in public and private hospitals, skilled nursing facilities (SNFs), long-term acute care (LTAC) facilities, hospice, and home healthcare. SLPs may also work as part of the support structure in the education system, working in both public and private schools, colleges, and universities. Some SLPs also work in community health, providing services at prisons and young offenders' institutions or providing expert testimony in applicable court cases.\n\nFollowing the American Speech-Language-Hearing Association's (ASHA's) 2005 approval of the delivery of speech/language services via video conference or telepractice, SLPs in the United States have begun to use this service model.\n\nSLPs conduct research related to communication sciences and disorders, swallowing disorders, or other upper aerodigestive functions.\n\nIn the United States, speech-language pathology is a Master's entry-level professional degree field. Clinicians must hold a master's degree in Communicative Disorders/Speech-Language Pathology (\"e.g.\" M.A., M.S., or M.Ed.) that is from a university that holds regional accreditation and from a communication sciences and disorders program that is accredited by the American Speech-Language-Hearing Association (ASHA), the profession's national governing body as well as individual state's governing board. Programs that offer the M.Ed. degree are often housed within a university's College of education, but offer the same education and training as programs with a M.A. or M.S. degree. Beyond the master's degree, some SLPs may choose to earn a clinical doctorate in Speech-Language Pathology (\"e.g.\" CScD or SLPD), or a doctoral degree that has a research and/or professional focus (\"e.g.\", Ph.D., or Ed.D.). All degrees must be from a university that holds regional accreditation, but only the master's degree is accredited by the American Speech-Language-Hearing Association (ASHA).\n\nAll clinicians are required to complete 400 clinical hours (25 observation hours often completed during the undergraduate degree and 375 hours of graduate Clinical Practicum). They must pass multiple comprehensive exams also called Knowledge and Skills Acquisition (KASA) exams.\n\nAfter all the above requirements have been met during the SLP's path to earning the graduate degree, SLPs must state licensure and national certification by:\n\nMaintaining licensure through continuing education:\n\nContinuing education and training obligations:\n\nProfessional suffix:\n\nSalaries of SLPs depend on a variety of factors including educational background, work experience, and location. The ASHA 2016 Schools Survey revealed that SLPs received a median academic year salary of 62,000, which is a 2% increase from the latest Schools Survey done in 2014. Additionally, ASHA released results for the 2015 SLP Health Care Survey which placed the median salary for SLPs working within the health care industry at $75,000. However, salaries can range from $47,000–116,000. In Australia, the basic salary that a Graduate SLP would earn is estimated at $59,500 Australian dollars rising to $120,000 for Private SLP.\n\nFor many parents, the decision of whether or not to enroll students into school-based speech therapy or privately practiced therapy is challenging. Speech Pathologists work as part of a team alongside teachers, counselors, social workers and parents when in a school setting. Because school-based speech therapy is run under state guidelines and funds, the process of assessment and qualification is more strict. To qualify for in-school speech therapy, students must meet the state's criteria on language testing and speech standardization. Due to such requirements, some students may not be assessed in an efficient time frame or their needs may be undermined by criteria. For a private clinic, students are more likely to qualify for therapy because it is a paid service with more availability. \n\nSpeech-language pathologists work with clients and patients who may present with a wide range of issues.\n\n\nIn the US, some children are eligible to receive speech therapy services, including assessment and lessons through the public school system. If not, private therapy is readily available through personal lessons with a qualified Speech-Language Pathologist or the growing field of telepractice. Teleconferencing tools such as Skype are being used more commonly as a means to access remote locations in private therapy practice, such as in the geographically diverse south island of New Zealand. More at-home or combination treatments have become readily available to address specific types of articulation disorders. The use of mobile applications in speech therapy is also growing as an avenue to bring treatment into the home.\n\nIn the UK, children are entitled to an assessment by local NHS Speech and Language Therapy teams, usually after referral by health visitors or education settings, but parents are also entitled to request an assessment directly. If treatment is appropriate, an educational plan will be drawn up. Speech therapists often play a role in multi-disciplinary teams where a child has speech delay or disorder as part of a wider health condition.\n\n\n\n\n\n"}
{"id": "5596760", "url": "https://en.wikipedia.org/wiki?curid=5596760", "title": "The N-Word", "text": "The N-Word\n\nThe N-Word is a 2004 documentary film directed and written by Todd Larkins Williams. The movie looks into the history and usage of the word \"nigger\" and its variations.\n\n"}
{"id": "13137840", "url": "https://en.wikipedia.org/wiki?curid=13137840", "title": "The Story of English", "text": "The Story of English\n\nThe Story of English is the title of an Emmy Award-winning nine-part television series, and a companion book, both produced in 1986, detailing the development of the English language.\n\nThe book and the television series were written by Robert MacNeil, Robert McCrum, and William Cran. The book has been revised twice, once in 1993, and again in 2002.\n\nThe documentary series was directed by William Cran, and originally broadcast on BBC and PBS. It was co-produced by MacNeil-Lehrer Productions and the BBC, and was principally funded through a grant from General Foods. The third episode, \"A Muse of Fire\", won the 1987 Primetime Emmy Award for Outstanding Individual Achievement - Informational Programming - Writing. The series was released as a 5 tape box set in 2001, running 495 minutes.\n\nThe book and series have been used in university courses.\n\n"}
{"id": "27133613", "url": "https://en.wikipedia.org/wiki?curid=27133613", "title": "Transcription (service)", "text": "Transcription (service)\n\nA transcription service is a business service basically based on Speech to Text process which converts speech (either live or recorded) into a written or electronic text document. Transcription services are often provided for business, legal, or medical purposes. The most common type of transcription is from a spoken-language source into text such as a computer file suitable for printing as a document such as a report. Common examples are the proceedings of a court hearing such as a criminal trial (by a court reporter) or a physician's recorded voice notes (medical transcription). Some transcription businesses can send staff to events, speeches, or seminars, who then convert the spoken content into text. Some companies also accept recorded speech, either on cassette, CD, VHS, or as sound files. For a transcription service, various individuals and organisations have different rates and methods of pricing. That can be per line, per word, per minute, or per hour, which differs from individual to individual and industry to industry. Transcription companies primarily serve private law firms, local, state and federal government agencies and courts, trade associations, meeting planners and nonprofits.\n\nBefore 1970, transcription was a difficult job, as secretaries had to write down the speech as they heard it using advanced skills, like shorthand. They also had to be at the location where the service was required. But with the introduction of tape cassettes and portable recorders in the late 1970s, the work became much easier and new possibilities emerged. Cassettes can travel through internal mail or external mail which meant for the first time, the transcribers could have the work brought to them in their own office which could be in a different location or business. For the first time, transcribers could work from home for many different businesses at their own convenience, provided they met the deadlines required by their clients.\n\nWith the birth of modern technology like speech recognition, transcription has become much easier. An MP3-based Dictaphone, for example, can be used to record the sound. Recordings for transcription can be in different media file types. The recording can then be uploaded to a PC, uploaded to a cloud storage, or emailed within minutes to someone who could be anywhere in the world. The transcriptionist can then replay the audio many times. The sound can also be filtered, equalised or have the tempo adjusted when the clarity is poor. The completed document can then be emailed back and printed out or incorporated into other documents – all within just a few hours of the original recording being made.\n\nThe industry standard for transcribing an audio file takes one hour for every 15 minutes of audio. For live usage, real-time text transcription services are available for captioning purposes, including Remote CART, Captioned Telephone, and live closed captioning for live broadcasts. Live transcripts are less accurate than offline transcripts, as there is no time for corrections and refinements. However, in a multistage subtitling process with a broadcast delay and access to a live audio feed it is possible to have several correction stages and for the text to be displayed at the same time as the \"live\" transmission.\n\nInterview transcription is a word-to-word written documentation of a taped or live interview. All types of interviews pertaining to legal cases, businesses, research, celebrity interviews and many more can be transcribed. While tapes need to be played and replayed to get the exact information one is looking for, transcribed copies allow easy lookup for the desired information. A written transcript is also important to identify key topics discussed in an interview. People with hearing imparity or deafness can also have access to the interview proceedings with accurately prepared interview transcripts. When transcribing interviews one needs to be aware and plan around conditions that ensure quality recording and transcribing.\n\nBy the early 1900s, the main responsibility of a doctor lay in treating the patient and other responsibilities such as creating a patient's medical record, keeping the files up to date and any other related paperwork eventually fell into the hands of hired medical stenographers. With the invention of typewriters, maintaining records became easier and with the invention of cassette players, it made way for the development of transcription machines. The initial versions available for purchase, offered the ability to record speech on cassette tapes. In fact, they were very popular for a long time although they did not offer much voice clarity at all. As soon as the usage of computers picked up in organizations and in other sectors, cassette tapes were replaced with better storage devices such as floppy discs and CD's. Today, the availability of highly sophisticated recording equipment ensures that multiple high clarity files can be created, stored and sent for medical transcription purposes.\n\nMedical transcription presents other challenges as a service to the transcriber. For example, working knowledge of medical terminology like ICD codes and an understanding of the rules and regulations regarding HIPPA compliance may be necessary to complete a medical transcription service.\n\nBusiness meetings, and professional recordings can contain sensitive data, so security is an important factor which should not be overlooked by a transcription company when providing services to its clients. Companies should therefore follow the various laws and industry best practice, especially so when serving law firms, government agencies or courts. Medical Transcription specifically is governed by HIPAA, which elaborates data security practices and compliance measures to be strictly followed, failure of which leads to legal action and penalties.\n\nTranscription security includes maintaining confidentiality of the data through information security practices including limiting access with passwords and ensuring a secure environment for data and appropriate methods of disposal of all materials and deletion of files. Personnel may be required to sign non-disclosure agreements on a regular basis as well as take various oaths regarding confidentiality and accuracy.\n"}
{"id": "1313388", "url": "https://en.wikipedia.org/wiki?curid=1313388", "title": "Umbrella term", "text": "Umbrella term\n\nAn umbrella term is a word or phrase that covers a wide range of concepts belonging to a common category. For example, \"cryptology\" is an umbrella term that encompasses cryptography and cryptanalysis, among other fields. Similarly, an umbrella organization is a central and coordinating body representing a number of smaller, separate bodies.\n\nA blanket term is a closely related word or phrase that is used to describe multiple groups of related things. The degree of relation may vary or have a minimal relationship, but blanket terms often trade specificity for ease of use. In other words, a blanket term, by itself, gives little detail about the things that it describes or the relationships between them, but it is easy to say and remember. Blanket terms may originate as slang but eventually become integrated into the general vocabulary.\n\n\n\n\n"}
{"id": "92200", "url": "https://en.wikipedia.org/wiki?curid=92200", "title": "Utterance", "text": "Utterance\n\nIn spoken language analysis, an utterance is the smallest unit of speech. It is a continuous piece of speech beginning and ending with a clear pause. In the case of oral languages, it is generally but not always bounded by silence. Utterances do not exist in written language, only their representations do. They can be represented and delineated in written language in many ways.\n\nIn oral/spoken language utterances have several features including paralinguistic features which are aspects of speech such as facial expression, gesture, and posture. Prosodic features include stress, intonation, and tone of voice, as well as ellipsis, which are words that the listener inserts in spoken language to fill gaps. Moreover, other aspects of utterances found in spoken languages are non-fluency features including: voiced/un-voiced pauses (like \"umm\"), tag questions, and false starts when someone begins their utterances again to correct themselves. Other features include: fillers (\"and stuff\"); accent/dialect; deictic expressions, which are utterances like \"over there!\" which need further explanation to be understood; simple conjunctions (\"and,\" \"but,\" etc.); and colloquial lexis which are everyday informal words.\n\nUtterances that are portrayed in writing are planned, in contrast to utterances in improvised spoken language. In written language there are frameworks that are used to portray this type of language. Discourse structure (which can also be found in spoken language) is how the conversation is organized, in which adjacency pairs - an utterance and the answer to that utterance - are used. Discourse markers are used to organize conversation (\"first,\" \"secondly,\" etc.). Lexis denotes the words being used in a text or spoken; these words can create a semantic field. For example, a semantic field of love can be created with lexical choices such as adore, admire, and care. Grammar/syntax is another feature of language in general but also utterances, and pragmatics means that when utterances are spoken or written the meaning is not literal, as in sarcasm.\n\nAn utterance which is found in spoken and written language as in a script has several characteristics. These include paralinguistic features which is a feature of communication that doesn't involve words but is added around an utterance to give meaning. Examples of paralinguistic features include facial expressions, laughter, eye contact, and gestures. Prosodic features refer to the sound of someone's voice as they speak: pitch, intonation and stress. Ellipsis can be used in either written or spoken language, when an utterance is conveyed and the speaker omits words because they are already understood in the situation. For example: A: Juice? B: Please. A: Room temperature? B: Cold.\n\nNon-fluency features also occur when producing utterances. As people think about what to say to while speaking, there are errors and corrections in speech. For example, voiced/un-voiced pauses which are \"umm,\" \"erm,\" etc. in voiced pauses and in transcripts un-voiced pauses are denoted as (.) or (1) relating to the amount of time of the pause. Tag questions are also a part of non-fluency features; these are used by the speaker to check if the listener understands what the speaker is saying. An example is \"Do you know what I mean?\" False alerts occur when the speaker is voicing an utterance but stops and starts again, usually to correct themselves.\n\nFillers usually give the speaker time to think and gather their thoughts in order to continue their utterance; these include lexis such as, \"like,\" \"and stuff,\" Accent/dialect is also a characteristic included in utterances which is the way the words are voiced, the pronunciation and the different types of lexis used in different parts of the world. Deictic expressions are utterances that need more explanation in order to be understood, like: \"Wow! Look over there!\" Simple conjunctions in speech are words that connect other words like \"and,\" \"but,\" etc. Colloquial lexis is a type of speech that is casual in which the utterance is usually more relaxed.\n\nThe development of utterances in children is facilitated by parents, adults, or any other guardian the child has growing up. Studies have indicated that this development of utterances is affected by the parent, adult, or guardian's socioeconomic status (SES). It has been shown that children have larger vocabularies and learn new words more quickly during early childhood from parents with a high education and higher SES status, while children with less educated parents and lower SES status have a smaller vocabulary and a slower growth in their vocabulary skills (Arriaga, Fenson, Cronan & Pethick, 1998; Hart & Risley, 1995; Hoff, Laursen & Tardif, 2002; Hoff-Ginsberg, 1991; Lawrence & Shipley, 1996; Ninio, 1980). This correlation is due to the fact that more educated parents use more lexis when speaking to their children as opposed to parents that are less educated (Hart & Risley, 1995; Hoff, 2003 a; Huttenlocher, Vasilyeva, Waterfall, Vevea & Hedges, in press). Hoff conducted an analysis that shows support for this correlation in 2003 which shows that the mean length of utterance and vocabulary of mothers who talk to their children is related to their SES status and thus child vocabulary development. High-SES mothers use longer utterances when talking to their children and a wider variety of words. They also spend more time talking to their children. Low-SES mothers use shorter utterances and a smaller vocabulary. As a result, children with more educated parents have larger vocabularies (Hoff, 2003).\n\nIn child-directed speech, utterances have several additional features. For example, the phonology in child-directed speech is different: Utterances are spoken more slowly, with longer pauses in between utterances, higher pitches, etc. The lexis and semantics differ, and a speaker uses words suited for children, \"doggie\" instead of \"dog,\" for example. The grammar is simpler, repetitive, with less use of verbs and adjectives. There is a greater use of one word utterances and the pragmatics uses supportive language like expansions and re-casting.\n\nPaul Grice (1989) came up with four maxims necessary in order to have a collegial conversation in which utterances are understood:\n\n\nAccording to philosopher Mikhail Bakhtin, there are four accepted properties that utterances should have:\n\nBakhtin also emphasizes that an utterance and a sentence are not the same thing. According to Bakhtin, sentences do not indicate a change of speech subject, and thus do not automatically satisfy one of the four properties of utterances. According to him, the sentence as a language unit is grammatical in nature, while an utterance is \"ethical\".\n\n\n"}
{"id": "191445", "url": "https://en.wikipedia.org/wiki?curid=191445", "title": "Vocabulary", "text": "Vocabulary\n\nA vocabulary is a set of familiar words within a person's language. A vocabulary, usually developed with age, serves as a useful and fundamental tool for communication and acquiring knowledge. Acquiring an extensive vocabulary is one of the largest challenges in learning a second language.\n\nVocabulary is commonly defined as \"all the words known and used by a particular person\". \"Knowing\" a word, however, is not as simple as merely being able to recognize or use it. There are several aspects of word knowledge that are used to measure word knowledge.\n\nThe first major distinction that must be made when evaluating word knowledge is whether the knowledge is productive (also called achieve) or receptive (also called receive); even within those opposing categories, there is often no clear distinction. Words that are generally understood when heard or read or seen constitute a person's receptive vocabulary. These words may range from well-known to barely known (see degree of knowledge below). A person's receptive vocabulary is the larger of the two. For example, although a young child may not yet be able to speak, write, or sign, he or she may be able to follow simple commands and appear to understand a good portion of the language to which they are exposed. In this case, the child's receptive vocabulary is likely tens, if not hundreds of words, but his or her active vocabulary is zero. When that child learns to speak or sign, however, the child's active vocabulary begins to increase. It is also possible for the productive vocabulary to be larger than the receptive vocabulary, for example in a second-language learner who has learned words through study rather than exposure, and can produce them, but has difficulty recognizing them in conversation.\n\nProductive vocabulary, therefore, generally refers to words that can be produced within an appropriate context and match the intended meaning of the speaker or signer. As with receptive vocabulary, however, there are many degrees at which a particular word may be considered part of an active vocabulary. Knowing how to pronounce, sign, or write a word does not necessarily mean that the word that has been used correctly or accurately reflects the intended message; but it does reflect a minimal amount of productive knowledge.\n\nWithin the receptive–productive distinction lies a range of abilities that are often referred to as \"degree of knowledge\". This simply indicates that a word gradually enters a person's vocabulary over a period of time as more aspects of word knowledge are learnt. Roughly, these stages could be described as:\n\n\nThe differing degrees of word knowledge imply a greater \"depth of knowledge\", but the process is more complex than that. There are many facets to knowing a word, some of which are not hierarchical so their acquisition does not necessarily follow a linear progression suggested by \"degree of knowledge\". Several frameworks of word knowledge have been proposed to better operationalise this concept. One such framework includes nine facets:\n\n\nWords can be defined in various ways, and estimates of vocabulary size differ depending on the definition used. The most common definition is that of a lemma (the uninflected or dictionary form; this includes \"walk\", but not \"walks, walked or walking\"). Most of the time lemmas do not include proper nouns (names of people, places, companies, etc). Another definition often used in research of vocabulary size is that of word family. These are all the words that can be derived from a ground word (e.g., the words \"effortless, effortlessly, effortful, effortfully\" are all part of the word family \"effort\"). Estimates of vocabulary size range from as high as 200 thousand to as low as 10 thousand, depending on the definition used. \n\n\"Listed in order of most ample to most limited:\"\n\nA literate person's vocabulary is all the words they can recognize when reading. This is generally the largest type of vocabulary simply because a reader tends to be exposed to more words by reading than by listening.\n\nA person's listening vocabulary is all the words they can recognize when listening to speech. People may still understand words they were not exposed to before using cues such as tone, gestures, the topic of discussion and the social context of the conversation.\n\nA person's speaking vocabulary is all the words they use in speech. It is likely to be a subset of the listening vocabulary. Due to the spontaneous nature of speech, words are often misused. This misuse, though slight and unintentional, may be compensated by facial expressions and tone of voice.\n\nWords are used in various forms of writing from formal essays to social media feeds. Many written words do not commonly appear in speech. Writers generally use a limited set of words when communicating. For example, if there are a number of synonyms, a writer may have a preference as to which of them to use, and they are unlikely to use technical vocabulary relating to a subject in which they have no knowledge or interest.\n\nFocal vocabulary is a specialized set of terms and distinctions that is particularly important to a certain group: those with a particular focus of experience or activity. A lexicon, or vocabulary, is a language's dictionary: its set of names for things, events, and ideas. Some linguists believe that lexicon influences people's perception of things, the Sapir–Whorf hypothesis. For example, the Nuer of Sudan have an elaborate vocabulary to describe cattle. The Nuer have dozens of names for cattle because of the cattle's particular histories, economies, and environments. This kind of comparison has elicited some linguistic controversy, as with the number of \"Eskimo words for snow\". English speakers with relevant specialised knowledge can also display elaborate and precise vocabularies for snow and cattle when the need arises.\n\nDuring its infancy, a child instinctively builds a vocabulary. Infants imitate words that they hear and then associate those words with objects and actions. This is the listening vocabulary. The speaking vocabulary follows, as a child's thoughts become more reliant on his/her ability to self-express without relying on gestures or babbling. Once the reading and writing vocabularies start to develop, through questions and education, the child starts to discover the anomalies and irregularities of language.\n\nIn first grade, a child who can read learns about twice as many words as one who cannot. Generally, this gap does not narrow later. This results in a wide range of vocabulary by age five or six, when an English-speaking child will have learned about 1500 words.\n\nVocabulary grows throughout our entire life. Between the ages of 20 and 60, people learn some 6,000 more lemmas, or one every other day. An average 20-year-old knows 42,000 words coming from 11,100 word families; an average 60-year-old knows 48,200 lemmas coming from 13,400 word families. People expand their vocabularies by e.g. reading, playing word games, and participating in vocabulary-related programs. Exposure to traditional print media teaches correct spelling and vocabulary, while exposure to text messaging leads to more relaxed word acceptability constraints.\n\n\nEstimating average vocabulary size poses various difficulties and limitations due to the different definitions and methods employed such as what is the word, what is to know a word, what sample dictionaries were used, how tests were conducted, and so on. Native speakers' vocabularies also vary widely within a language, and are dependent on the level of the speaker's education.\n\nAs a result estimates vary from as little as 10,000 to as many as over 50,000 for young adult native speakers of English.\n\nOne most recent 2016 study shows that 20-year-old English native speakers recognize on average 42,000 lemmas, ranging from 27,100 for the lowest 5% of the population to 51,700 lemmas for the highest 5%. These lemmas come from 6,100 word families in the lowest 5% of the population and 14,900 word families in the highest 5%. 60-year-olds know on average 6,000 lemmas more.\nAccording to another, earlier 1995 study junior-high students would be able to recognize the meanings of about 10,000–12,000 words, whereas for college students this number grows up to about 12,000–17,000 and for elderly adults up to about 17,000 or more.\n\nFor native speakers of German average absolute vocabulary sizes range from 5,900 lemmas in first grade to 73,000 for adults.\n\nThe knowledge of the 3000 most frequent English word families or the 5000 most frequent words provides 95% vocabulary coverage of spoken discourse.\nFor minimal reading comprehension a threshold of 3,000 word families (5,000 lexical items) was suggested and for reading for pleasure 5,000 word families (8,000 lexical items) are required. An \"optimal\" threshold of 8,000 word families yields the coverage of 98% (including proper nouns).\n\nLearning vocabulary is one of the first steps in learning a second language, but a learner never finishes vocabulary acquisition. Whether in one's native language or a second language, the acquisition of new vocabulary is an ongoing process. There are many techniques that help one acquire new vocabulary.\n\nAlthough memorization can be seen as tedious or boring, associating one word in the native language with the corresponding word in the second language until memorized is considered one of the best methods of vocabulary acquisition. By the time students reach adulthood, they generally have gathered a number of personalized memorization methods. Although many argue that memorization does not typically require the complex cognitive processing that increases retention (Sagarra and Alba, 2006), it does typically require a large amount of repetition, and spaced repetition with flashcards is an established method for memorization, particularly used for vocabulary acquisition in computer-assisted language learning. Other methods typically require more time and longer to recall.\n\nSome words cannot be easily linked through association or other methods. When a word in the second language is phonologically or visually similar to a word in the native language, one often assumes they also share similar meanings. Though this is frequently the case, it is not always true. When faced with a false friend, memorization and repetition are the keys to mastery. If a second language learner relies solely on word associations to learn new vocabulary, that person will have a very difficult time mastering false friends. When large amounts of vocabulary must be acquired in a limited amount of time, when the learner needs to recall information quickly, when words represent abstract concepts or are difficult to picture in a mental image, or when discriminating between false friends, rote memorization is the method to use. A neural network model of novel word learning across orthographies, accounting for L1-specific memorization abilities of L2-learners has recently been introduced (Hadzibeganovic and Cannas, 2009).\n\nOne useful method of building vocabulary in a second language is the keyword method. If time is available or one wants to emphasize a few key words, one can create mnemonic devices or word associations. Although these strategies tend to take longer to implement and may take longer in recollection, they create new or unusual connections that can increase retention. The keyword method requires deeper cognitive processing, thus increasing the likelihood of retention (Sagarra and Alba, 2006). This method uses fits within Paivio's (1986) dual coding theory because it uses both verbal and image memory systems. However, this method is best for words that represent concrete and imageable things. Abstract concepts or words that do not bring a distinct image to mind are difficult to associate. In addition, studies have shown that associative vocabulary learning is more successful with younger students (Sagarra and Alba, 2006). Older students tend to rely less on creating word associations to remember vocabulary.\n\nSeveral word lists have been developed to provide people with a limited vocabulary either for the purpose of rapid language proficiency or for effective communication. These include Basic English (850 words), Special English (1,500 words), General Service List (2,000 words), and Academic Word List. Some learner's dictionaries have developed defining vocabularies which contain only most common and basic words. As a result word definitions in such dictionaries can be understood even by learners with a limited vocabulary. Some publishers produce dictionaries based on word frequency or thematic groups.\n\nThe Swadesh list was made for investigation in linguistics.\n\n\n\n"}
{"id": "16908902", "url": "https://en.wikipedia.org/wiki?curid=16908902", "title": "Writing in space", "text": "Writing in space\n\nSeveral instruments have been used to write in outer space, including different types of pencils and pens. Some of them have been unmodified versions of conventional writing instruments; others have been invented specifically to counter the problems with writing in space conditions.\n\nA common urban legend states that, faced with the fact that ball-point pens would not write in zero-gravity, NASA spent a large amount of money to develop a pen that would write in the conditions experienced during spaceflight (the result purportedly being the Fisher Space Pen), while the Soviet Union took the simpler and cheaper route of just using pencils. The Fisher Space Pen was developed independently by a private organization in the 1960s.\n\nSpace versus ground recordkeeping presents several serious issues:\n\nAs with submarines before them, space capsules are closed environments, subject to strict contamination requirements. Incoming material is screened for mission threats. Any shedding, including wood, graphite, and ink vapors and droplets, may become a risk. In the case of a manned capsule, the much smaller recirculating volume, combined with microgravity and an even greater difficulty of resupply, make these requirements even more critical.\n\nRelease of wood shavings, graphite dust, broken graphite tips, and ink compounds are a dangerous flight hazard. Lack of gravity makes objects drift, even with air filtration. Any conductive material is a threat to electronics, including the electromechanical switches in use during early manned space programs. Nonconductive particles may also hamper switch contacts, such as normally-open and rotary mechanisms. Drifting particles are a threat to the eyes (and to a lesser extent an inhalation threat), which may risk execution of a critical procedure. Personnel may don protective gear, but both ground and flight crews are more comfortable and more productive \"in shirtsleeves\". Paul C. Fisher of Fisher Pen Company recounts that pencils were 'too dangerous to use in space'.\n\nEven before the Apollo 1 fire, the CM crew cabin was reviewed for hazardous materials such as paper, velcro, and even low-temperature plastics. A directive was issued but poorly enforced. When combined with high oxygen content, the Apollo 1 cabin burned within seconds, killing all three crew members.\n\nCosmonaut Anatoly Solovyev flew with Space Pens starting in the '80s and states \"pencil lead breaks...and is not good in space capsule; very dangerous to have metal lead particles in zero gravity\".\n\nStrict documentation requirements accompany anything as complex as a large-scale aerospace demonstration, let alone a manned spaceflight. Quality assurance records document individual parts, and instances of procedures, for deviances. Low production and flight rates generally result in high variance; most spacecraft designs (to say nothing of individual spacecraft) fly so infrequently that they are considered experimental aircraft. When combined with the stringent weight drivers of orbital and deep-space flight, the quality-control demands are high. Change control records track the evolution of hardware and procedures from their ground testing, initial flights, through necessary corrections and midlife revision and upgrades, and on to retention of engineering knowledge for later programs, and any incident investigations.\n\nWhen the flight also has scientific or engineering science objectives, low-quality data may affect mission success directly.\n\nFaced with these requirements, pencils or other non-permanent recordkeeping methods are unsatisfactory. The act of taking permanent, high-integrity documentation itself deters kludges, workarounds, and \"go fever\". The Apollo 1 investigation uncovered procedural and workmanship deficiencies in multiple areas, up to procedures on the pad.\n\nAt sea level, temperature is moderated by the thick atmosphere. As air pressure falls, temperatures can swing more dramatically. Many early manned missions operated at below standard pressure, to decrease the stresses (and thus, mass) of their capsules. Many did not have separate airlocks, instead exposing the entire cabin to hard vacuum at times. Low pressures also exacerbate contamination issues, as substances acceptable at standard conditions may begin outgassing at lower pressures or higher temperatures. While the Soyuz spacecraft had a design pressure, and could use its orbital module as an airlock, the orbital module would be deleted for planned lunar missions. In any case, a pen which was insensitive to pressure and temperature would eliminate the issue (including accidental depressurizations), provide a margin, and allow the ability to record during extravehicular activities.\n\nThe wood pencil has been used for writing by NASA and Soviet space programs from the start. It is simple with no moving parts, except for the sharpener. However, wood, graphite, and rubber (in the eraser) are all combustible and create dust. Graphite, in particular, both burns and produces dust that conducts electricity.\n\nThe mechanical pencil has been used by NASA starting in the 1960s Gemini program. It can be made to be as wide as the width of astronauts' gloves, yet maintain its light weight. There are no wooden components which might catch fire and create dust. However, the pencil lead still creates graphite dust that conducts electricity.\n\nGrease pencils on plastic slates were used by the Soviet space program as an early substitute for wood pencils. It is simple with no moving parts. The paper shroud is peeled back when needed. The disadvantage is that the paper wrapper has to be disposed of. Writing done with the grease pencil is also not as durable as ink on paper.\n\nBallpoint pens have been used by Soviet and then Russian space programs as a substitute for grease pencils as well as NASA and ESA. The pens are cheap, use paper (which is easily available), and writing done using pen is more permanent than that done with graphite pencils and grease pencils, which makes the ball point pen more suitable for log books and scientific note books. However, the ink is indelible, and depending on composition is subject to outgassing and temperature variations.\n\nFelt-tip pens were used by NASA astronauts in the Apollo missions. However, wick-based instruments are designed around low viscosity, and thus operating temperature and pressure.\n\nThe Fisher Space Pen is a gas-charged ball point pen that is rugged and works in a wider variety of conditions, such as zero gravity, vacuum and extreme temperatures. Its thixotropic ink and vent-free cartridge release no significant vapor at common temperatures and low pressures. The ink is forced out by compressed nitrogen at a pressure of nearly 35 psi (240 kPa), and it functions at altitudes up to 12,500 feet (3800 m) and at temperatures from −30 to 250 °F (−35 to 120 °C). However, it is more expensive than the aforementioned alternatives. It has been used by both NASA and Soviet/Russian astronauts on Apollo, Shuttle, Mir, and ISS missions.\n\n"}
