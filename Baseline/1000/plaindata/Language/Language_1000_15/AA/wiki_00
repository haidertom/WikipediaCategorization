{"id": "52909153", "url": "https://en.wikipedia.org/wiki?curid=52909153", "title": "Bibliography of code-switching", "text": "Bibliography of code-switching\n\nThe bibliography of code-switching comprises all academic and peer-reviewed works on the topic of code-switching. It is sorted by category, then alphabetically.\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "26756364", "url": "https://en.wikipedia.org/wiki?curid=26756364", "title": "Business writing process prewriting", "text": "Business writing process prewriting\n\nIn terms of the 3 × 3 writing process, prewriting belongs to phase one of the writing process. Prewriting focuses on how to properly convey the information in a message by analyzing its purpose, anticipating the audience's reaction and adapting the content of the message to that audience. Examples of methods that may assist you in your pre-writing phase include: free-writing, planning, research, outlining, storyboarding or clustering. \n\nBusiness writing is different from other types of writing because it needs to be purposeful, economical and reader-oriented. It is important for business writers to focus on expressing their ideas rather than impressing the intended audience. The goal is to get the message across in a clear and simple manner. \n\nThe 3 × 3 writing process is divided into three different phases. This chapter focuses on Phase 1 which involves analyzing, anticipating and adapting. Phase 2 requires research, organization and composition. Finally, Phase 3 includes revising, proofreading and evaluating. In the case of short messages, writing can be done relatively quickly by spending a small amount of time on each phase. However, for longer documents, it is better to spend a good amount of time working through each phase of the writing process. It is also possible to rearrange the steps in the process and even repeat some steps if necessary. The writing process is recursive rather than linear so the writer is free to revise the text at any point. \n\nBusiness writing often involves collaborating with others, such as when working in teams. Generally, team members get together in the beginning, during Phase 1, to exchange ideas. During Phase 2, each member can work separately to do some writing. Once that's done, members can meet again for Phase 3 to revise the document as a team.\n\nAnalyzing, which is the first step of the prewriting process, focuses on both detecting the main goals of the business message and choosing the most effective way to express the information to the audience. Finding out the main goals of business writing requires considering and summarizing the needs of the audience, would all be conveyed by: email, instant message, business letters, memos, reports, etc. Only when the information presented through the writing matches the demands of the audience will it attract the audience's attention. Generally, most business writing can be devoted to informing and persuading the audience. However, it is just as necessary to establish a good relationship with the audience.\nChoosing the most appropriate way of conveying information is fairly significant for improving efficiency of expression. Delivering a message in the proper way depends on a few factors. It is helpful to note the importance of the message, the feedback needed and the cost of the method of delivery.\n\nAnticipating includes profiling the audience and learning to adjust the message according to its recipients. Profiling the audience helps the writer establish the proper tone and language of the message. It also helps with choosing the right method to deliver the message. Another benefit of profiling the audience is identifying the possibility of a secondary audience. More information might be needed if the message is also intended for a secondary audience.\n\nAdapting involves using certain techniques to tailor the message to the intended audience. When writing a message, it is essential to pay attention to the tone because it is a good indicator of how the reader will feel while reading the message. Words that are chosen improperly can contribute to an overall negative tone and can make the message sound unpleasant. Therefore, it is a good idea to choose words that will have a positive impact on the tone of the message. One technique involves putting the focus of the message on the receiver. This can be achieved by using second-person pronouns throughout the text and it shows that the writer has empathy towards the reader. Another technique involves using bias-free language which means the message should be free from gender, race, age and disability bias so as to not offend anyone. It is also recommended to use a professional yet friendly tone to make the writer sound professional and approachable at the same time. It is a good idea to use positive words and avoid words that have negative connotations. Finally, it is in the writer's best interest to be polite, use simple language and words that are precise.\n\nIt is the responsibility of the writer to use language that is ethical for the purpose of avoiding litigation. When writing messages about stocks or financial services, it is important to follow the laws that protect investors. Also, regarding safety information, it is essential to write warnings on dangerous products as clearly and succinctly as possible. Messages that are used in sales and marketing should not have any false or misleading information. The messages should not be written in a way that will deceive customers. The use of proper language is also helpful regarding employee evaluation. In letters of recommendation, it is best to use positive language and stick to information that is related to the job.\n\n"}
{"id": "391475", "url": "https://en.wikipedia.org/wiki?curid=391475", "title": "Category mistake", "text": "Category mistake\n\nA category mistake, or category error, or categorical mistake, or mistake of category, is a semantic or ontological error in which things belonging to a particular category are presented as if they belong to a different category, or, alternatively, a property is ascribed to a thing that could not possibly have that property. An example is the metaphor \"time crawled\", which if taken literally is not just false but a category mistake. To show that a category mistake has been committed one must typically show that once the phenomenon in question is properly understood, it becomes clear that the claim being made about it could not possibly be true.\n\nThe term \"category-mistake\" was introduced by Gilbert Ryle in his book \"The Concept of Mind\" (1949) to remove what he argued to be a confusion over the nature of mind born from Cartesian metaphysics. Ryle alleged that it was a mistake to treat the mind as an object made of an immaterial substance because predications of substance are not meaningful for a collection of dispositions and capacities.\n\nThe phrase is introduced in the first chapter. The first example is of a visitor to Oxford. The visitor, upon viewing the colleges and library, reportedly inquired \"But where is the University?\" The visitor's mistake is presuming that a University is part of the category \"units of physical infrastructure\" rather than that of an \"institution\". Ryle's second example is of a child witnessing the march-past of a division of soldiers. After having had battalions, batteries, squadrons, etc. pointed out, the child asks when is the division going to appear. \"The march-past was not a parade of battalions, batteries, squadrons \"and\" a division; it was a parade of the battalions, batteries and squadrons \"of\" a division.\" (Ryle's italics) His third example is of a foreigner being shown a cricket match. After being pointed out batsmen, bowlers and fielders, the foreigner asks: \"who is left to contribute the famous element of team-spirit?\"\n\nHe goes on to argue that the Cartesian dualism of mind and body rests on a category mistake. In the philosophy of the mind, Ryle's category mistake argument can be used to support eliminative materialism. By using the argument, one can attack the existence of a separate, distinct mind. The argument concludes that minds are not conscious, but a collective predicate for a set of observable behaviour and unobservable dispositions.\n\n"}
{"id": "6867", "url": "https://en.wikipedia.org/wiki?curid=6867", "title": "Context-free language", "text": "Context-free language\n\nIn formal language theory, a context-free language (CFL) is a language generated by a context-free grammar (CFG).\n\nContext-free languages have many applications in programming languages, in particular, most arithmetic expressions are generated by context-free grammars.\n\nDifferent context-free grammars can generate the same context-free language. Intrinsic properties of the language can be distinguished from extrinsic properties of a particular grammar by comparing multiple grammars that describe the language.\n\nThe set of all context-free languages is identical to the set of languages accepted by pushdown automata, which makes these languages amenable to parsing. Further, for a given CFG, there is a direct way to produce a pushdown automaton for the grammar (and thereby the corresponding language), though going the other way (producing a grammar given an automaton) is not as direct.\n\nA model context-free language is formula_1, the language of all non-empty even-length strings, the entire first halves of which are 's, and the entire second halves of which are 's. is generated by the grammar formula_2.\nThis language is not regular.\nIt is accepted by the pushdown automaton formula_3 where formula_4 is defined as follows:\n\nUnambiguous CFLs are a proper subset of all CFLs: there are inherently ambiguous CFLs. An example of an inherently ambiguous CFL is the union of formula_6 with formula_7. This set is context-free, since the union of two context-free languages is always context-free. But there is no way to unambiguously parse strings in the (non-context-free) subset formula_8 which is the intersection of these two languages.\n\nThe language of all properly matched parentheses is generated by the grammar formula_9.\n\nThe context-free nature of the language makes it simple to parse with a pushdown automaton.\n\nDetermining an instance of the membership problem; i.e. given a string formula_10, determine whether formula_11 where formula_12 is the language generated by a given grammar formula_13; is also known as \"recognition\". Context-free recognition for Chomsky normal form grammars was shown by Leslie G. Valiant to be reducible to boolean matrix multiplication, thus inheriting its complexity upper bound of \"O\"(\"n\").\nConversely, Lillian Lee has shown \"O\"(\"n\") boolean matrix multiplication to be reducible to \"O\"(\"n\") CFG parsing, thus establishing some kind of lower bound for the latter.\n\nPractical uses of context-free languages require also to produce a derivation tree that exhibits the structure that the grammar associates with the given string. The process of producing this tree is called \"parsing\". Known parsers have a time complexity that is cubic in the size of the string that is parsed.\n\nFormally, the set of all context-free languages is identical to the set of languages accepted by pushdown automata (PDA). Parser algorithms for context-free languages include the CYK algorithm and Earley's Algorithm.\n\nA special subclass of context-free languages are the deterministic context-free languages which are defined as the set of languages accepted by a deterministic pushdown automaton and can be parsed by a LR(k) parser.\n\nSee also parsing expression grammar as an alternative approach to grammar and parser.\n\nContext-free languages are closed under the following operations. That is, if \"L\" and \"P\" are context-free languages, the following languages are context-free as well:\n\nThe context-free languages are not closed under intersection. This can be seen by taking the languages formula_22 and formula_23, which are both context-free. Their intersection is formula_24, which can be shown to be non-context-free by the pumping lemma for context-free languages. As a consequence, context-free languages cannot be closed under complementation, as for any languages \"A\" and \"B\", their intersection can be expressed by union and complement: formula_25. In particular, context-free language cannot be closed under difference, since complement can be expressed by difference: formula_26. \n\nHowever, if \"L\" is a context-free language and \"D\" is a regular language then both their intersection formula_27 and their difference formula_28 are context-free languages.\n\nIn formal language theory, questions about regular languages are usually decidable, but ones about context-free languages are often not. It is decidable whether such a language is finite, but not whether it contains every possible string, is regular, is unambiguous, or is equivalent to a language with a different grammar.\n\nThe following problems are undecidable for arbitrarily given context-free grammars A and B:\n\nThe following problems are \"decidable\" for arbitrary context-free languages:\n\nAccording to Hopcroft, Motwani, Ullman (2003), \nmany of the fundamental closure and (un)decidability properties of context-free languages were shown in the 1961 paper of Bar-Hillel, Perles, and Shamir\n\nThe set formula_8 is a context-sensitive language, but there does not exist a context-free grammar generating this language. So there exist context-sensitive languages which are not context-free. To prove that a given language is not context-free, one may employ the pumping lemma for context-free languages or a number of other methods, such as Ogden's lemma or Parikh's theorem.\n\n"}
{"id": "13630663", "url": "https://en.wikipedia.org/wiki?curid=13630663", "title": "Contrast set", "text": "Contrast set\n\nA contrast set is a bounded collection of items, each of which could fill the same slot in a given schema, syntactic structure, or other linguistic environment. The seven days of the week, the fifty United States, the eight Hawaiian islands, the letters in the alphabet, the categories \"male\" and \"female,\" the students in a class, or the flavors on offer at an ice cream store are all examples of contrast sets.\n\nContrast sets may be relatively natural in origin (such as the eight Hawaiian islands) or relatively conventional (such as the fifty United States). The mastery of certain conventional contrast sets is essential to basic socialization: for example, calendrical units, musical notes, and elements of writing systems like numerals and the alphabet. These contrast sets frequently become the subject of synesthesias.\n\nLinguistic anthropologists Harold Conklin and Charles Frake were the first to work out the concept of the contrast set in the 1950s, and the concept was described in detail in Frake's article \"The ethnographic study of cognitive systems.\"\n\nThe Google Sets program attempts to generate a list of the members of a contrast set given a few starter members.\n\nIn recent years, the term contrast set has been used extensively in the field of data mining.\n"}
{"id": "613505", "url": "https://en.wikipedia.org/wiki?curid=613505", "title": "Distributive writing", "text": "Distributive writing\n\nDistributive writing is the collective authorship of texts.\n\nThis further requires both a definition of \"collective\" and \"texts\", where collective means a connected group of individuals and texts are inscribed symbols chained together to achieve a larger meaning than isolated symbols. This places emphasis on texts being represented as writings. This could be written words, iconic symbology (e.g., graffiti), computer programming languages (C/C++, Java, Perl, etc.), meta-level mark-up (HTML, XML, SVG, PostScript), and their derivative works. Also, not to be excluded are all the above in various languages. Further, to define texts, we must also have an interpreter for the texts. For computer programming languages, we have a compiler, for writings we have written words interpreted by our mental faculties, and for meta-level mark-up there are web browsers, printers to interpret postscript, and various software applications which turn textual representations into another format. (Patrick Deegan and Jon Phillips, 2004)\n\nSocial Software enables people to connect, communicate, and collaborate. It is explicitly the social which is of importance and is what is operated on. It is the commodity in the system. This is different from Distributive Writing because social software is based upon software, whereas DW is not, and is not just about collaborative writing. It is also about other forms of socializing.\n\nGroupWare is about software and more importantly, in common use to describe combining many pieces of software together into a group for so-called easy access for an individual. The original definition had to do with a group of people operating on something collaboratively through software, but this has changed meaning due to corporate appropriation to describe software suites like Microsoft Office and OpenOffice.org.\n\nDistributive writing is not just bound to computing like CSCT.\n\nSynchronous – System of authorship where both author's make changes in real time (at the same time).\n\nAsynchronous – System of authorship where both author's make changes in non-real time (render time or not at the time).\n\n"}
{"id": "40717444", "url": "https://en.wikipedia.org/wiki?curid=40717444", "title": "Dora Sakayan", "text": "Dora Sakayan\n\nDora Sakayan (classical Armenian orthography: ; reformed: ; born January 24, 1931), Professor of German Studies (retired), McGill University. Specializing initially as a Germanist, today she is known for her work in various areas of Applied Linguistics. Sakayan is also noted for pioneering Armenology in Canada, and introducing the two branches of the Armenian language, Western Armenian and Eastern Armenian, to the English-speaking world.\n\nSakayan was born in 1931 in Salonica, Greece, to Armenian parents who had escaped the Armenian Genocide. She grew up in a multilingual environment, with her first languages being Western Armenian and Modern Greek, and she received early exposure to German, French and Turkish. After immigrating to Soviet Armenia, she received her education in Eastern Armenian and Russian. Later on, she mastered English and learned other languages.\n\nSakayan received her elementary education at the Armenian Gulabi Gulbenkian School in Salonica. She then attended the local German high school Deutsche Schule Saloniki. She was 11 years old when her family moved to Vienna, Austria, where she pursued her high school education at the Gymnasium for girls in the 7th District of Vienna \"Oberschule für Mädchen, Wien VII.\"\n\nIn 1946, Sakayan’s family repatriated to Soviet Armenia where she completed her secondary education. In 1948, she was admitted to the Yerevan State Pedagogical Institute of Foreign Languages (YSPL) where she graduated with a diploma in Germanic linguistics and in Pedagogy in 1952. She was then appointed as an instructor of German at YSPL, where she taught from 1952 to 1956. Subsequently, she was invited to teach in the Department of Romance and Germanic Philology at Yerevan State University (YSU, 1956–1958).\n\nSakayan began her graduate studies in Germanic philology in 1958 at the Lomonosov Moscow State University (LMSU), completing them in 1961. Over the following four years, she shared her time between Moscow and Yerevan to pursue her teaching duties in Germanic Philology at YSU and complete her PhD thesis while raising her two young children. She obtained her PhD in Germanic Philology from Moscow Lomonosov University in 1965.\n\nIn 1965, Sakayan became Head of the Department of Foreign languages of YSU, a position she held for ten years. At the same time, she delivered lectures in the Department of Romance-Germanic Philology of YSU.\n\nSakayan immigrated to Canada in January 1975 and began to teach German at two universities: McGill University, (Department of German Studies) and the Université de Montréal (Department of Études des langues anciennes et modernes). In 1977, she was offered a full-time position at McGill and left Université de Montréal. Due to her high ratings as an instructor of German at McGill, in 1978 she was offered a joint appointment with the Department of Russian and Slavic Studies where she taught for ten years. Over the years, Sakayan rose to the rank of Full Professor at McGill University.\n\nIn 1981, Sakayan began her groundbreaking work in Armenian Studies at McGill. At the Centre of Continuing Education, she founded and supervised a program of credited Armenian courses anchored in the Department of Russian and Slavic Studies. She edited and prepared for publication a number of Armenological manuscripts of linguistic, literary and historic interest, translated several books and articles from Armenian into other languages and vice versa, and made book tours. She became a regular participant at international Armenological conferences and congresses, and she also organized Armenological conferences in Canada and Armenia. Seeing her mission as presenting Armenian language and culture to non-Armenians, she founded the series \"Armenian Studies for the English Speaking World\" and published a number of scholarly books and articles under this heading. To promote the publication of her Armenological books, in 1997 she founded a small press under the name AROD Books in Montreal.\n\nAfter 25 years of service at McGill University, Sakayan retired from the Department of German Studies in 2000 and dedicated herself fully to Armenian Studies. She renewed her ties with Yerevan State University, where she regularly spends a few months every year, participating in scholarly projects, organizing international linguistic conferences, publishing her books with YSU Press and organizing book launches at YSU and elsewhere in Armenia. Among many activities in her homeland, she is the supervisor and participant of an ongoing translation project that she carries out with one of her former students, Evelina Makaryan, a researcher at the Institute for Armenian Studies at YSU.\n\nAt the same time, Sakayan continues the promotion of Armenian Studies in Canada. In 2005, she founded an Armenian language program at the Diocese of the Armenian Apostolic Church in Montreal, carrying on a tradition that she established more than three decades ago (in 1981) at the Centre of Continuing Education at McGill University.\n\nAs a Germanist and educator in the East European tradition, Sakayan has received training in Germanic linguistics and language pedagogy. This background has led her to applied linguistics, and from the great variety of its interdisciplinary branches Sakayan has concentrated on the following areas: a) contrastive linguistics, b) foreign language acquisition, c) translation studies.\n\nSakayan includes into the contrastive discussion, besides German, other Indo-European languages: Russian, English, French, and Modern Greek. As an innovation, she also includes Armenian, a non-European language whose agglutinative properties set it apart from other languages in the Indo-European family. In fact, in Sakayan’s work, contrastive analysis is predominantly based on Armenian, and other languages are viewed through the prism of this language. The objectives of such an endeavor are to establish language typologies and to identify areas of difficulty in foreign language acquisition. Her work also incorporates the findings of Armenian and Russian data — not always accessible to Western linguists.\n\nSakayan introduces to the Western reader the idiosyncrasies of Eastern Armenian morphology and syntax, with a special focus on the verb system and its rich paradigm of non-finite verb forms, called \"derbays\" (դերբայ = participle). Over the years, she has dealt extensively with East Armenian deverbal nominalizations, deriving from certain \"derbays\": the Armenian infinitive and three participles: the present, past and the future participle. Within the framework of \"Nominalizations of various degrees\" Sakayan discusses the regular relative clause (RC), the ‘relative participles’ (RP based on the present, past and the future participle), as well and other phenomena of relativization in Eastern Armenian.\n\nSakayan contrasts Armenian clausal nominalizations with their semantic counterparts in a selective number of European languages. A noteworthy monograph in this respect is \"Formen der Textkohärenz: Nominalisierung als sententiale Anapher im Ostarmenischen\". This book explores East Armenian clausal nominalizations that are based on the Armenian infinitive. Sakayan describes the transformation process of finite clauses into economical nominal phrases, gives the morphosyntactic characteristics of these nominalizations, identifies the functions of the agglutinative segments in a synthetic nominalized infinitive (SNI).\n\nSakayan has also taken a keen interest in contrastive phraseology in the general sense of the term. Recognizing the importance of ready-made expressions in human communication, she has based her research on self-collected linguistic corpora of phraseological units, such as proverbs and sayings, idiomatic expressions, and routine formulae (gambits).\n\nSakayan has explored the reproduction of routine formulae (gambits) and their role for turn-taking in conversation and for organizing discourse She has created thematically and pragmatically grouped bilingual concordances of routine formulae (gambits) for language learning. See the use of such concordances in Sakayan’s textbooks.\n\nSakayan's interest in proverbs resulted in a major paremiological study accompanied by a bilingual (Armenian-English), thematically arranged anthology of 2,500 proverbs. An extensive introduction addresses the language and structure, as well as the origin of Armenian proverbs (international, borrowed and specifically Armenian proverbs).\n\nContrastive paremiology being an ongoing project, Sakayan’s next volume became a language-pair-oriented paremiological study with special focus on German-Armenian connections and discussions on cross-cultural translatability. In 2001, the German counterpart of this paremiological study appeared with a new introduction that provides an in-depth analysis of the structure and language of Armenian proverbs. Along with the extreme conciseness of the Armenian proverbs, Sakayan points to their capacity to function in various sizes and shapes, from extremely short and compact units to more elaborate and wordy structures (e.g. dialogues). Some of them encapsulate people’s everyday talk, citations of reported or direct speech. Since dialogue proverbs or dramatized proverbs are not a universal genre and can be found only in a few languages, Sakayan explores them extensively.\n\nSakayan’s scholarly interest in foreign language acquisition is apparent not only in the titles of her published articles, but also in the list of authored and co-authored textbooks, instructional manuals and methodological guides, for the instruction of both German and Armenian as foreign languages Some of these projects demonstrate the benefits of applying the latest trends in linguistics to instructional development.\nIn the 1960s and 1970s, while chairing the Department of Foreign Languages at Yerevan State University (YSU) in Soviet Armenia, Sakayan authored and co-authored several textbooks, manuals and methodological guides for the instruction of German in Armenian high schools and universities. However, in accordance with Soviet censorship rules that deprived expatriate authors of authorship, the production of all books carrying her name had to be discontinued after Sakayan’s departure to Canada in 1975.\n\nAfter resettling in Canada, Sakayan continued her research in Foreign Language Methodology. In close collaboration with Professor Christine Tessier of Université Laval in Quebec City, Canada, Sakayan conducted the research project dedicated to German Stereotyped Speech Forms in Mini-Dialogues. Sakayan and Tessier laid the groundwork for a new method of communicative exercises that has received widespread recognition in the area of DaF (Deutsch als Fremdsprache, or German as a Foreign Language). The project resulted in a book called Rede und Antwort, widely used as a supplement to other DaF textbooks at universities; in 1991 it was declared in the AOL-Reference Manual as \"a hit textbook for DaF.\"\n\nThe innovative method is based on the introduction of German Stereotyped Speech Forms, or gambits, known for their important role in languages while turn-taking in interaction. Gambits used at the beginning of an utterance are seen as cues that signal not only the illocutionary feature of an utterance, but also its syntactic-semantic unfolding. The method broadly applies speech act theory and text linguistics, as well as some insights of \"grammar of expectancy,\" to the teaching of DaF. The Rede und Antwort exercises have proven to be an effective means for promoting oral skills in the classroom, which are readily applicable in real life-settings.\n\nInspired by the success of the Rede und Antwort, in the 1990s Sakayan launched and carried out a completely new project: an introductory university textbook for Western Armenian (Western Armenian for the English-speaking World: A Contrastive Approach). The textbook, which first appeared in 2000, draws on more recent achievements of linguistics in the instruction of Western Armenian. It demonstrates the great potential that contrastive linguistics has for the advancement of foreign language teaching by outlining Armenian-English contrasts throughout the course. It also applies the insights of text linguistics and grammar of expectancy by enhancing the production of correct grammatical forms anticipated by the reproduction of certain ready-made routine formulae. The textbook is conceptualized pragmatically, enabling students to carry out speech acts fundamental for communication. Although grammar receives proper attention, other linguistic aspects such as word formation, semantic vocabulary groups, pronunciation, orthography, etc. are also treated on a regular basis. The textbook was received positively and was adopted by Armenian Studies Programs at universities and schools worldwide.\n\nIn 2007, Sakayan published a new Armenian textbook, this time on Eastern Armenian, also accompanied by a CD-Rom featuring Eastern Armenian native speakers. To bring the level of the existing Western Armenian textbook to that of its Eastern Armenian counterpart, in 2012 Sakayan published a second and revised edition (with CD-Rom).\n\nBoth titles are now published by YSU Press. They are consistent in methodology and structure, with a vast amount of linguistic material proportionally distributed among 12 Units, which each consist of 12 sections. These twin Armenian textbooks are considered to be the highlight of Sakayan’s career, reflecting a lifetime of pedagogical and scholarly experience in foreign language teaching and research in applied linguistics.\n\nSakayan is also a major contributor to the study of the Armenian Genocide. In 1993, she came across the journal of her maternal grandfather, Dr. Garabed Hatcherian, and has since dedicated herself to its publication and dissemination. The journal is a chronicle of the Smyrna catastrophe of 1922, which describes how the ancient port city in Asia Minor was destroyed by a massive fire, whereby the entire Christian population was either massacred or forced to flee. The journal is also a detailed account of the hardship Dr. Hatcherian and his family of eight endured in September 1922. Dr. Hatcherian’s diary is considered to be the most widely translated book about the Armenian Genocide. So far, the journal has appeared in nine languages, three of which were translated by Sakayan, who is also the general editor of all editions. All volumes include a detailed biography of the author, a literary analysis of the journal in an expanded introduction, 52 annotations of an historical and cultural nature, an afterword, and a bibliography. The meticulous editorial work has made \"An Armenian Doctor in Turkey\" a book that has received a highly favorable international reception Sakayan is also the editor-in-chief of an important book documenting the Armenian Genocide: the newest edition of Theodik’s (Theodoros Lapchindjian) book \"Memorial to April 11\" (Armenian: Յուշարձան ապրիլ 11-ի- Hushartsan Abril 11-i), which was created with the assistance of renowned journalist and human-rights activist and publisher Ragip Zarakolu (Istanbul: Belge Publishers) and appeared in 2010. This book was first compiled and published in Turkish by Theodik in 1919 in Istanbul to pay tribute to the murdered intellectuals and community leaders of 1915—writers, journalists, editors, clergymen, academics, teachers, and jurists.\n\nThis latest edition of Theodik’s Hushartsan, published in commemoration of the 95th Anniversary of the Armenian Genocide, is a bilingual production (Armenian and Turkish) with a trilingual introductory section (Armenian, Turkish, and English) dedicated to the memory of Hrant Dink, the Armenian journalist who was murdered in Istanbul in 2007. Also included in this volume is an Armenian and Turkish index of the names of the 761 Armenian martyrs of April 11 (April 24 according to the Gregorian calendar).\nOver the last decade, Sakayan has been working on a translation project with one of her former students, Evelina Makaryan, a researcher at the Institute for Armenian Studies at YSU. This project has yielded six books that Sakayan and Makaryan translated from German into Armenian and published with YSU Press. The translations are predominantly eyewitness testimonies of the Armenian Genocide that Sakayan has collected from libraries in German-speaking countries.\n\nSakayan's latest (and most important) work is a book entitled «Man treibt sie in die Wüste»; Clara und Fritz Sigrist-Hilty als Augenzeugen des Völkermordes an den Armeniern 1915–1918 [\"They drive them into the desert\": Clara and Fritz Sigrist-Hilty as eyewitnesses of the Armenian Genocide 1915-1918] on the writings of Clara Sigrist-Hilty (1884–1988). One day after their church wedding in April 1915, the civil engineer Fritz Sigrist and the nurse Clara Hilty take the train from Werdenberg (Switzerland) and travel through the war zone to South-Eastern Turkey, where Fritz has been working at the construction of the Baghdad railway since 1910. They settle in Keller (today’s Fevzipaşa), a little town on the flank of the Amanus mountains. Shortly after their arrival, the Armenian deportations start and thousands of Armenians walk past their window. For three years the couple has to witness «the lapsing of human lights down there in the steep gorge» while they live their everyday life in their little house on the remote hillside. A visit to Aleppo makes them realize that what they were seeing in Keller on a daily basis was nothing but premeditated death marches. Things deteriorate when the skilled Armenian workers at the Baghdad railway construction site must also join those death marches. Clara feels obliged to record the atrocities, first in her journal, and later in a special eyewitness account. Fritz in his turn writes some important essays on the subject.\n\nSakayan has deciphered and transcribed the documents written in Gothic handwriting; she has meticulously processed the data and embedded them in the historic events of the time. Moreover, based on a memoir by Haig Aramian, Sakayan recounts the adventurous story of how in June 1916 the couple Sigrist-Hilty helped their Armenian storehouse manager Aramian to escape certain death. The structure of the book presented itself from the available archival materials. The book consists of three parts, each centered around one main character: Clara and Fritz Sigrist-Hilty, and Haig Aramian. Through a thoughtful interplay of primary and secondary texts, Sakayan tells a coherent story of endless human suffering, but also of Christian compassion and selflessness.\n\nAt an early stage of her career, Sakayan’s knowledge of languages directed her towards translation and interpretation, and some of her translations were published early on. Sakayan has translated texts of various length and genres, from books to mini-texts, from poems to novels, and from gambits to proverbs. This furthered her interest in the theoretical aspects of translation. During the Summer semesters between 1981 and 1986, her contact and collaboration with the Translation Department of Saarbrücken University in Germany (Chairman: Dr. Wolfram Wilss) intensified her involvement and productivity in that field and resulted in several articles published in scholarly journals and books, as well as in several papers presented at international conferences.\n\n\n\n\n\n\n\n"}
{"id": "8305", "url": "https://en.wikipedia.org/wiki?curid=8305", "title": "Dyslexia", "text": "Dyslexia\n\nDyslexia, also known as reading disorder, is characterized by trouble with reading despite normal intelligence. Different people are affected to varying degrees. Problems may include difficulties in spelling words, reading quickly, writing words, \"sounding out\" words in the head, pronouncing words when reading aloud and understanding what one reads. Often these difficulties are first noticed at school. When someone who previously could read loses their ability, it is known as alexia. The difficulties are involuntary and people with this disorder have a normal desire to learn.\nDyslexia is believed to be caused by both genetic and environmental factors. Some cases run in families. It often occurs in people with attention deficit hyperactivity disorder (ADHD) and is associated with similar difficulties with numbers. It may begin in adulthood as the result of a traumatic brain injury, stroke, or dementia. The underlying mechanisms of dyslexia are problems within the brain's language processing. Dyslexia is diagnosed through a series of tests of memory, spelling, vision, and reading skills. Dyslexia is separate from reading difficulties caused by hearing or vision problems or by insufficient teaching.\nTreatment involves adjusting teaching methods to meet the person's needs. While not curing the underlying problem, it may decrease the degree of symptoms. Treatments targeting vision are not effective. Dyslexia is the most common learning disability and occurs in all areas of the world. It affects 3–7% of the population, however, up to 20% may have some degree of symptoms. While dyslexia is more often diagnosed in men, it has been suggested that it affects men and women equally. Some believe that dyslexia should be best considered as a different way of learning, with both benefits and downsides.\nDyslexia is thought to have two types of cause, one related to language processing and another to visual processing. It is considered a cognitive disorder, not a problem with intelligence. However, emotional problems often arise because of it. Some published definitions are purely descriptive, whereas others propose causes. The latter usually cover a variety of reading skills and deficits, and difficulties with distinct causes rather than a single condition. The National Institute of Neurological Disorders and Stroke definition describes dyslexia as \"difficulty with phonological processing (the manipulation of sounds), spelling, and/or rapid visual-verbal responding\". The British Dyslexia Association definition describes dyslexia as \"a learning difficulty that primarily affects the skills involved in accurate and fluent word reading and spelling\" and is characterized by \"difficulties in phonological awareness, verbal memory and verbal processing speed\".\n\nAcquired dyslexia or alexia may be caused by brain damage due to stroke or atrophy. Forms of alexia include pure alexia, surface dyslexia, semantic dyslexia, phonological dyslexia, and deep dyslexia.\n\nThere is some variability in the definition of dyslexia. Some sources, such as the U.S. National Institutes of Health, define it specifically as a learning disorder. Other sources, however, define it simply as an inability to read in the context of normal intelligence, and distinguish between \"developmental dyslexia\" (a learning disorder) and \"acquired dyslexia\" (loss of the ability to read caused by brain damage). ICD 10, the manual of medical diagnosis used in much of the world, includes separate diagnoses for \"developmental dyslexia\" (81.0) and for \"dyslexia and alexia\" (48.0). DSM 5, the manual of psychiatric diagnosis used in the United States, does not specifically define dyslexia, justifying this decision by stating that \"the many definitions of dyslexia and dyscalculia meant those terms would not be useful as disorder names or in the diagnostic \ncriteria\". Instead it includes dyslexia in a category called specific learning disorders.\n\nIn early childhood, symptoms that correlate with a later diagnosis of dyslexia include delayed onset of speech and a lack of phonological awareness, as well as being easily distracted by background noise. A common myth closely associates dyslexia with mirror writing and reading letters or words backwards. These behaviors are seen in many children as they learn to read and write, and are not considered to be defining characteristics of dyslexia.\n\nSchool-age children with dyslexia may exhibit signs of difficulty in identifying or generating rhyming words, or counting the number of syllables in words – both of which depend on phonological awareness. They may also show difficulty in segmenting words into individual sounds or may blend sounds when producing words, indicating reduced phonemic awareness. Difficulties with word retrieval or naming things is also associated with dyslexia. People with dyslexia are commonly poor spellers, a feature sometimes called dysorthographia or dysgraphia, which depends on orthographic coding.\n\nProblems persist into adolescence and adulthood and may accompany difficulties with summarizing stories, memorization, reading aloud, or learning foreign languages. Adults with dyslexia can often read with good comprehension, though they tend to read more slowly than others without a learning difficulty and perform worse in spelling tests or when reading nonsense words – a measure of phonological awareness.\n\nThe orthographic complexity of a language directly impacts how difficult learning to read the language is. English and French have comparatively \"deep\" phonemic orthographies within the Latin alphabet writing system, with complex structures employing spelling patterns on several levels: letter-sound correspondence, syllables, and morphemes. Languages such as Spanish, Italian and Finnish have mostly alphabetic orthographies, which primarily employ letter-sound correspondence – so-called shallow orthographies – which for dyslexics makes them easier to learn. Logographic writing systems, such as Chinese characters, have extensive symbol use, and pose problems for dyslexic learners.\n\nDyslexia is often accompanied by several learning disabilities, but it is unclear whether they share underlying neurological causes. These associated disabilities include:\n\nResearchers have been trying to find the neurobiological basis of dyslexia since the condition was first identified in 1881. For example, some have tried to associate the common problem among dyslexics of not being able to see letters clearly to abnormal development of their visual nerve cells.\n\nModern neuroimaging techniques such as functional magnetic resonance imaging (fMRI) and positron emission tomography (PET) have shown a correlation between both functional and structural differences in the brains of children with reading difficulties. Some dyslexics show less electrical activation in parts of the left hemisphere of the brain involved with reading, such as the inferior frontal gyrus, inferior parietal lobule, and the middle and ventral temporal cortex. Over the past decade, brain activation studies using PET to study language have produced a breakthrough in the understanding of the neural basis of language. Neural bases for the visual lexicon and for auditory verbal short-term memory components have been proposed, with some implication that the observed neural manifestation of developmental dyslexia is task-specific (i.e. functional rather than structural). fMRIs in dyslexics have provided important data which point to the interactive role of the cerebellum and cerebral cortex as well as other brain structures.\n\nThe cerebellar theory of dyslexia proposes that impairment of cerebellum-controlled muscle movement affects the formation of words by the tongue and facial muscles, resulting in the fluency problems that are characteristic of some dyslexics. The cerebellum is also involved in the automatization of some tasks, such as reading. The fact that some dyslexic children have motor task and balance impairments has been used as evidence for a cerebellar role in their reading difficulties. However, the cerebellar theory is not supported by controlled research studies.\n\nResearch into potential genetic causes of dyslexia has its roots in post-autopsy examination of the brains of people with dyslexia. Observed anatomical differences in the language centers of such brains include microscopic cortical malformations known as ectopias, more rarely, vascular micro-malformations, and microgyrus. The previously cited studies and others suggest that abnormal cortical development presumed to occur before or during the sixth month of fetal brain development was the cause of the abnormalities. Abnormal cell formations in dyslexics have also been reported in non-language cerebral and subcortical brain structures. Several genes have been associated with dyslexia, including DCDC2 and KIAA0319 on chromosome 6, and DYX1C1 on chromosome 15.\n\nThe contribution of gene–environment interaction to reading disability has been intensely studied using twin studies, which estimate the proportion of variance associated with a person's environment and the proportion associated with their genes. Studies examining the influence of environmental factors such as parental education and teacher quality have determined that genetics have greater influence in supportive, rather than less optimal, environments. However, more optimal conditions may just allow those genetic risk factors to account for more of the variance in outcome because the environmental risk factors have been minimized. As environment plays a large role in learning and memory, it is likely that epigenetic modifications play an important role in reading ability. Animal experiments and measures of gene expression and methylation in the human periphery are used to study epigenetic processes; however, both types of study have many limitations in the extrapolation of results for application to the human brain.\n\nThe dual-route theory of reading aloud was first described in the early 1970s. This theory suggests that two separate mental mechanisms, or cognitive routes, are involved in reading aloud. One mechanism is the lexical route, which is the process whereby skilled readers can recognize known words by sight alone, through a \"dictionary\" lookup procedure. The other mechanism is the nonlexical or sublexical route, which is the process whereby the reader can \"sound out\" a written word. This is done by identifying the word's constituent parts (letters, phonemes, graphemes) and applying knowledge of how these parts are associated with each other, for example, how a string of neighboring letters sound together. The dual-route system could explain the different rates of dyslexia occurrence between different languages (e.g. the Spanish language dependence on phonological rules accounts for the fact that Spanish-speaking children show a higher level of performance in non-word reading, when compared to English-speakers).\n\nDyslexia disorder is not caused by mutation in one gene; in fact, it appears to involve the combined effects of several genes. Studying the cognitive problems associated with other disorders helps to better understand the genotype-phenotype link of dyslexia. Neurophysiological and imaging procedures are being used to ascertain phenotypic characteristics in dyslexics, thus identifying the effects of certain genes.\n\nThere are tests that can indicate with high probability whether a person is a dyslexic. If diagnostic testing indicates that a person may be dyslexic, such tests are often followed up with a full diagnostic assessment to determine the extent and nature of the disorder. Tests can be administered by a teacher or computer. Some test results indicate how to carry out teaching strategies.\n\nCentral dyslexias include surface dyslexia, semantic dyslexia, phonological dyslexia, and deep dyslexia. ICD-10 reclassified the previous distinction between dyslexia (315.02 in ICD-9) and alexia (315.01 in ICD-9) into a single classification as R48.0. The terms are applied to developmental dyslexia and inherited dyslexia along with developmental aphasia and inherited alexia, which are considered synonymous.\n\nIn surface dyslexia, words with regular pronunciations (highly consistent with their spelling, e.g. \"mint\") are read more accurately than words with irregular pronunciation, such as \"colonel\". Difficulty distinguishing homophones is a diagnostic used for some forms of surface dyslexia. This disorder is usually accompanied by surface agraphia and fluent aphasia. Acquired surface dyslexia arises when a previously literate person experiences brain damage, which results in pronunciation errors that indicate impairment of the lexical route.\n\nIn phonological dyslexia, sufferers can read familiar words but have difficulty with unfamiliar words, such as invented pseudo-words. Phonological dyslexia is associated with lesions in the parts of the brain supplied with blood by the middle cerebral artery. The superior temporal lobe is often also involved. Furthermore, dyslexics compensate by overusing a front-brain region called Broca's area, which is associated with aspects of language and speech. The Lindamood Phoneme Sequencing Program (LiPS) is used to treat phonological dyslexia. This system is based on a three-way sensory feedback process, using auditory, visual, and oral skills to learn to recognize words and word patterns. Case studies with a total of three patients found a significant improvement in spelling and reading ability after using LiPS.\n\nIndividuals with deep dyslexia experience both semantic paralexia (para-dyslexia) and phonological dyslexia, causing the person to read a word and then say a related meaning instead of the denoted meaning. Deep dyslexia is associated with clear phonological processing impairments. Deep dyslexia is caused by widespread damage to the brain that often includes the left hemisphere. The \"continuum\" hypothesis claims that deep dyslexia develops from phonological dyslexia.\n\nPeripheral dyslexias have been described as affecting the visual analysis of letters as a result of brain injury. Hemianopsia, a visual field loss on the left/right side of the vertical midline, is associated with this condition.\n\nPure, or phonologically-based, dyslexia, also known as agnosic dyslexia, dyslexia without agraphia, and pure word blindness, is dyslexia due to difficulty in recognizing written sequences of letters (such as words), or sometimes even letters. It is considered '\"pure\" because it is not accompanied by other significant language-related impairments. Pure dyslexia does not affect speech, handwriting style, language or comprehension impairments. Pure dyslexia is caused by lesions on the visual word form area (VWFA). The VWFA is composed of the left lateral occipital sulcus and is activated during reading. A lesion in the VWFA stops transmission between the visual cortex and the left angular gyrus. It can also be caused by a lesion involving the left occipital lobe or the splenium. It is usually accompanied by a homonymous hemianopsia in the right side of the visual field. Multiple oral re-reading (MOR) is a treatment for pure dyslexia. It is considered a top-down processing technique in which affected individuals read and reread texts a predetermined number of times or until reading speed or accuracy improves a predetermined amount.\n\nHemianopic dyslexia is commonly considered to derive from visual field loss due to damage to the primary visual cortex. Sufferers may complain of abnormally slow reading but are able to read individual words normally. This is the most common form of peripheral alexia, and the form with the best evidence of effective treatments.\n\nIn neglect dyslexia, some letters, most commonly those at the beginning or left side of a word, are skipped or misread during reading. This alexia is associated with right parietal lesions. The use of prism glasses has been shown to mitigate this condition substantially.\n\nPeople with attentional dyslexia complain of letter-crowding or migration, sometimes blending elements of two words into one. Sufferers read better when words are presented in isolation rather than flanked by other words and letters. Using a large magnifying glass may help mitigate this condition by reducing the effects of flanking from nearby words; however, no trials of this or indeed any other therapy for left parietal syndromes have been published as of 2014.\n\nThrough the use of compensation strategies, therapy and educational support, dyslexic individuals can learn to read and write. There are techniques and technical aids which help to manage or conceal symptoms of the disorder. Removing stress and anxiety alone can sometimes improve written comprehension. For dyslexia intervention with alphabet-writing systems, the fundamental aim is to increase a child's awareness of correspondences between graphemes (letters) and phonemes (sounds), and to relate these to reading and spelling by teaching how sounds blend into words. It has been found that reinforced collateral training focused on reading and spelling yields longer-lasting gains than oral phonological training alone. Early intervention that is done for children at a young age can be successful in reducing reading failure.\n\nThere is some evidence that the use of specially-tailored fonts may help with dyslexia. These fonts, which include Dyslexie, OpenDyslexic, and Lexie Readable, were created based on the idea that many of the letters of the Latin alphabet are visually similar and may, therefore, confuse people with dyslexia. Dyslexie and OpenDyslexic both put emphasis on making each letter more distinctive in order to be more easily identified. The benefits, however, might simply be due to the added spacing between words.\n\nThere have been many studies conducted regarding intervention in dyslexia. Among these studies one meta-analysis found that there was functional activation as a result.\n\nThere is no evidence demonstrating that the use of music education is effective in improving dyslexic adolescents' reading skills.\n\nDyslexic children require special instruction for word analysis and spelling from an early age. While there are fonts that may help people with dyslexia better understand writing, this might simply be due to the added spacing between words. The prognosis, generally speaking, is positive for individuals who are identified in childhood and receive support from friends and family.\n\nThe percentage of people with dyslexia is unknown, but it has been estimated to be as low as 5% and as high as 17% of the population. While it is diagnosed more often in males, some believe that it affects males and females equally.\n\nThere are different definitions of dyslexia used throughout the world, but despite significant differences in writing systems, dyslexia occurs in different populations. Dyslexia is not limited to difficulty in converting letters to sounds, and Chinese dyslexics may have difficulty converting Chinese characters into their meanings. The Chinese vocabulary uses logographic, monographic, non-alphabet writing where one character can represent an individual phoneme.\n\nThe phonological-processing hypothesis attempts to explain why dyslexia occurs in a wide variety of languages. Furthermore, the relationship between phonological capacity and reading appears to be influenced by orthography.\n\nDyslexia was identified by Oswald Berkhan in 1881, but the term \"dyslexia\" was coined in 1887 by Rudolf Berlin, an ophthalmologist in Stuttgart. He used the term to refer to the case of a young boy who had a severe impairment in learning to read and write, despite showing typical intelligence and physical abilities in all other respects. In 1896, W. Pringle Morgan, a British physician from Seaford, East Sussex, published a description of a reading-specific learning disorder in a report to the \"British Medical Journal\" titled \"Congenital Word Blindness\". The distinction between phonological and surface types of dyslexia is only descriptive, and without any etiological assumption as to the underlying brain mechanisms. However, studies have alluded to potential differences due to variation in performance.\n\nThe majority of currently available dyslexia research relates to alphabetic writing systems, and especially to European languages. However, substantial research is also available regarding dyslexics who speak Arabic, Chinese, Hebrew, or other languages.\n\nAs is the case with any disorder, society often makes an assessment based on incomplete information. Before the 1980s, dyslexia was thought to be a consequence of education, rather than a basic disability. As a result, society often misjudges those with the disorder. There is also sometimes a workplace stigma and negative attitude towards those with dyslexia. If a dyslexic's instructors lack the necessary training to support a child with the condition, there is often a negative effect on the student's learning participation.\n\n\n"}
{"id": "21392353", "url": "https://en.wikipedia.org/wiki?curid=21392353", "title": "EcoMobility", "text": "EcoMobility\n\nEcomobility is travel through integrated, socially inclusive, and environmentally friendly transport options, including and integrating walking, cycling, public transport and other climate and people friendly innovative modes of transport. By enabling citizens and organizations to access goods, services, and information in a sustainable manner, ecomobility supports citizens’ quality of life, increases travel choices, and promotes social cohesion.\n\nIt is neither a new kind of transportation nor is it a collective word to indicate heterogeneous transport. Ecomobility indicates a new approach to mobility that highlights the importance of public and non-motorized transport and promotes an integrated use of all modes in a city. Environmentally sustainable and socially inclusive, ecological mobile transport choices have low to no emission compared to the personal automobiles powered by fossil fuels. It supports the use of light electric vehicles, provided that the source of the electricity is from renewable energy sources. Incorporating Ecomobility into the development of traffic systems and policies will benefit local governments in attaining international recognition for the city and its leadership.\n\nICLEI has a dedicated agenda to promote ecomobility in cities titled the EcoMobile City (sustainable urban transport) Agenda. Under this agenda ICLEI executes the following 3 key projects:\nEcoMobility Alliance was created in October 2011 in Changwon, Korea. It is a transformation of the earlier \"Global Alliance for EcoMobility\",which is a non-governmental organization founded and launched in Bali on 10 December 2007, on the occasion of the 2007 United Nations Climate Change Conference (UNFCCC-COP-13). ICLEI legally represents and hosts the Secretariat of the EcoMobility Alliance. The Secretariat office is located in Bonn, Germany. The EcoMobility Alliance is an international non-profit partnership that works to promote EcoMobility and thus reduce citizens’ dependency on private motorized vehicles worldwide. The EcoMobility Alliance is chaired by a visionary city leader.\n\nEcomobility Alliance Chairs [as of December 2016]:\nEcoMobility World Festival, is a month long experiment taken up by challenging and visionary city leaders to display an automobile free lifestyle in a neighborhood of a city. Citizens in this neighborhood will show the world that a normal life can be lead without depending on personal automobiles. Citizens will embrace the improved walking, cycling and public transport facilities and use light electric vehicles, to replace the otherwise motorized trips in the neighborhood.\n\nEcoMobility World Festivals so far [as of December 2016]:\nEcoMobility World Congress, provides with a fresh, visionary and enriching perspectives on sustainable urban mobility. The congresses aim to provide comprehensive international knowledge in the field of ecomobility. Renowned transportation experts, change makers, decision makers, city leaders and innovators, from around the globe will present some of the world’s best case studies, and participants will learn how to kick start and implement good policies while engaging in fruitful debates about mobility for the future of sustainable cities.\n\nEcoMobility World Congresses so far [as of December 2016]\nIn addition to the projects above, ICLEI's EcoMobile City (Sustainable Urban Transport) Agenda also works on the following areas:\nFor more information on EcoMobility visit: https://www.ecomobility.org\n\n"}
{"id": "1198465", "url": "https://en.wikipedia.org/wiki?curid=1198465", "title": "Ecocomposition", "text": "Ecocomposition\n\nEcocomposition is a way of looking at literacy using concepts from ecology. It is a postprocess theory of writing instruction that tries to account for factors beyond hierarchically defined goals within social settings; however, it doesn't dismiss these goals. Rather, it incorporates them within an ecological view that extends the range of factors affecting the writing process beyond the social to include aspects such as \"place\" and \"nature.\" Its main motto, then, is \"Writing Takes Place\" (also the title of one of Sidney I. Dobrin's articles on ecocomposition).\n\nThe theory for ecocomposition dates back to Marilyn Cooper's 1986 essay \"The Ecology of Writing\" and Richard Coe's \"Eco-Logic for the Composition Classroom\" (1975). More recently, Dobrin and Weisser (2002) have assembled a more detailed theory of ecocomposition, placing it in relation to ecofeminism, ecocriticism , and environmental ethics. Other scholars (e.g., Reynolds, 2004) have shown its close proximity to social geography. According to ecofeminist scholar Greta Gaard (2001), \"at its most inclusive, ecocomposition has the potential to address social issues such as feminism, environmental ethics, multiculturalism, politics, and economics, all by examining matters of form and style, audience and argumentation, and reliable sources and documentation\" (p. 163).\n\nEcocomposition is one area of scholarly study discussed at the Conference on College Composition and Communication (CCCC), a national forum for writing instructors and scholars. As an educational endeavor, it is linked most closely with progressive education (Dewey, 1915), critical education (Giroux, 1987), and place-based education (Sobel, 2004).\n\nEcocomposition asks what effects a place has (or different places have) on the writing process. In what ways is our identity influenced by place, and what bearing does this have on our writing? What sets of relationships help us define our place—including the relationship between writer and reader? How do the sometimes contradictory sets of relationships in which we write allow us to see certain possibilities and foreclose others? How do these relationships define reality for each of us in different ways?\n\n\"Ecology\", in the wide sense in which it was used by Coe and Cooper, includes both natural and social relations. Hence, ecocomposition instructors emphasize not only the writer's relationship to physical place but also the social relations among writers and readers. In the classroom, this translates into pedagogical practices that \"emphasize the value of fostering community and collaboration throughout the writing process\" (Gaard, 2001, p. 166). As a post-process method of writing instruction, ecocomposition attends not only to the process of writing but also what happens to texts after they are written. Thus, ecocomposition instructors focus not only on the process of composition but also on its purpose, encouraging students to write for specific audiences, adapting their style and content to match their purpose and audience.\n\nWhile a primary concern has been the relationship between the writing process and natural places, concepts of spatiality also apply to cyberspace and online writing—in MUDs, MOOs, Internet Relay Chat, Instant Messages, and e-mail (Syverson, 1999; Yagelski, 2002). Ecocomposition instructors may use blogs or other means by which to allow students to interact with one another and/or write for a real audience beyond the classroom (see, e.g., Jones, 2008).\n\nEcocomposition should not be confused or conflated with other systemic approaches to writing such as activity theory, which do not account for the dynamic relationship between writing and place but posit a transcendent \"context\" that affects writing.\n\n\n"}
{"id": "244773", "url": "https://en.wikipedia.org/wiki?curid=244773", "title": "Empty name", "text": "Empty name\n\nIn the philosophy of language, an empty name is a proper name that has no referent.\n\nThe problem of empty names is that empty names have a meaning that it seems they should not have. The name \"Pegasus\" is empty; there is nothing to which it refers. Yet, though there is no Pegasus, we know what the sentence \"Pegasus has two wings\" means. We can even understand the sentence \"There is no such thing as Pegasus.\" But, what can the meaning of a proper name be, except the object to which it refers?\n\nThere are three broad ways which philosophers have tried to approach this problem.\n\nSome philosophers, such as Alexius Meinong have argued that there are two senses of the verb \"exists\", exemplified by the sentence \"there are things that do not exist\". The first, signified by \"there are\", is the so-called \"wide sense\", including Pegasus, the golden mountain, the round square, and so on. The second, signified by \"exist\" is the so-called \"narrow sense\", encompassing only things that are real or existent. The difficulty with this \"two sense\" theory is that there is no strong evidence that there really are two such distinct senses of the verb \"to be\".\n\n"}
{"id": "16767719", "url": "https://en.wikipedia.org/wiki?curid=16767719", "title": "Ethnolinguistic group", "text": "Ethnolinguistic group\n\nAn ethnolinguistic group (or ethno-linguistic group) is a group that is unified by both a common ethnicity and language. Most ethnic groups have their own language. Despite this, the term is often used to emphasise when language is a major basis for the ethnic group, especially with regards to its neighbours.\n\nA central concept in the linguistic study of ethnolinguistic groups is ethnolinguistic vitality, the ability of the group's language and ethnicity to sustain. An ethnolinguistic group that lacks such vitality is unlikely to survive as a distinct entity. Factors that influence the ethnolinguistic vitality are demographics, institutional control and status (including language planning factors).\n\n\n\n"}
{"id": "44476602", "url": "https://en.wikipedia.org/wiki?curid=44476602", "title": "Extensionalism", "text": "Extensionalism\n\nExtensionalism, in the philosophy of language, in logic and semantics, is the view that all languages or at least all scientific languages should be extensional. Rudolf Carnap (in his earlier work) and Willard Van Orman Quine were prominent proponents of this view.\n\n"}
{"id": "17234445", "url": "https://en.wikipedia.org/wiki?curid=17234445", "title": "Feminist theory in composition studies", "text": "Feminist theory in composition studies\n\nIn composition studies, feminism is generally focused on giving feedback while taking into account gender difference. Thus, an instructor with a feminist pedagogy is unlikely to favor an androcentric method of teaching. A feminist approach in composition \"would focus on questions of difference and dominance in written language\".\n\nIn the 1960s, the second wave of feminism began and one major goal was to raise society’s consciousness of the struggles of women. The goals of feminists were largely carried out in university classrooms. Specifically, in the composition classroom, Faye Spencer Moar claimed that the way writing was taught largely favored male writers. Mary P Hiatt claimed that women implicitly write differently than men, and that men tended to write in the dominant, most oft taught style.\n\nHiatt argues that the terms \"masculine\" and \"feminine\" are applied to styles of writing–that of men and women, respectively–but, instead of describing the style, what is actually described is the male views on both men and women. Her examples include \"strong\", \"rational\", and \"logical\" for men, and \"emotional\", \"hysterical\", and \"silly\" for women. Thus, the aim of feminism in composition studies was to create a classroom in which women perceived themselves intellectually and in which their voices were relevant in what some feminists perceive to be an androcentric world.\n\nElizabeth Flynn writes that feminist theory \"emphasize[s] that males and females differ in their developmental processes and in their interactions with others\". Thus, a feminist instructor will take into account the implicit differences between male and female writers and teach appropriately, without favoring or focusing on androcentric or gynocentric studies. Feminist pedagogy involves reading texts written by women, and taking care to understand those texts are not simply appropriations of texts written by men, without any sort of critique of androcentrism.\n\nFocus is also placed upon the reading and reviewing of student-created texts. Feminist instructors try to create a supportive classroom environment and validate student’s experiences. Susan Jarratt mentions a feminist pedagogy that advocates women writing about \"personal experiences after reading women’s autobiography, history, and fiction\".\n\nOne style of feminist theory that is being utilized in the composition classroom is the theory of Invitational Rhetoric. Sonja K. Foss and Cindy L. Griffin, first proposed the idea of Invitational Rhetoric as \"grounded in the feminist principles of equality, imminent value and self-determination\" (5). Originally this was considered a communication theory. More recently, it has grown across curriculums, including the use in English composition classrooms. As a newer philosophy in English composition, the use of invitational rhetoric is used as a way to make students feel comfortable in the classroom setting. By using Foss and Griffin’s Invitational Rhetoric theory as a guide in conducting classes, instructors are able to encourage their students to share their beliefs and learn to respect others opinions, without having to feel like opposite views are being force-fed to them in a way that would cause them to turn away from debate or discussions that could foster critical thinking. According to Foss and Griffin, Invitational Rhetoric works through the use of debate and discussion as a way to learn about various viewpoints, with the freedom to ultimately make up one’s own minds about the topic. Abby Knoblauch describes the use of Invitational Rhetoric as a way to make sure conservative students are not put on the offensive by more liberal teachers and their ideals. By using Invitational Rhetoric as a guide in presenting material, an instructor can in turn foster a student’s creativity and encourage them to write about what is important to them.\n\nFlynn researched the narratives of her first-year composition students for their disparities. She says, \"The narratives of the female students are stories of interaction, of connection, or of frustrated connection. The narratives of the male students are stories of achievement, of separation, or of frustrated achievement\". Feminist research \"tries to arrive at hypotheses that are free of gender loyalties,\" says Patricia A. Sullivan.\n\nSandra Harding lists three characteristics of feminist research in her book \"Feminism and Methodology\" that Sullivan deems appropriate for consideration into feminist studies of composition, not just the social sciences, which is what Harding is concerned with. These characteristics are, first, using women’s experiences as an \"indicator of the realist against which hypotheses are tested.\" Second, the research is \"designed for women\" and provides \"social phenomena that [women] want or need.\" Third, it \"insists that the inquirer her/himself be placed in the same critical plane as the overt subject matter\" .\n\nSullivan believes these three characteristics are relevant to composition studies because of the common practice to conduct research from a standpoint that is gender-neutral (neither men over women, nor vice versa), gender-inclusive (considering both male and female perspectives, processes, and styles, not just those of females), and researcher disinterestedness (the common practice of keeping one’s self out of the research process in order to allow for an unbiased analysis).\n"}
{"id": "11709017", "url": "https://en.wikipedia.org/wiki?curid=11709017", "title": "Global language system", "text": "Global language system\n\nThe global language system is the \"ingenious pattern of connections between language groups\". Dutch sociologist Abram de Swaan developed this theory in 2001 in his book \"Words of the World: The Global Language System\" and according to him, \"the multilingual connections between language groups do not occur haphazardly, but, on the contrary, they constitute a surprisingly strong and efficient network that ties together – directly or indirectly – the six billion inhabitants of the earth.\" The global language system draws upon the world system theory to account for the relationships between the world's languages and divides them into a hierarchy consisting of four levels, namely the peripheral, central, supercentral and hypercentral languages.\n\nAccording to de Swaan, the global language system has been constantly evolving since the time period of the early 'military-agrarian' regimes. Under these regimes, the rulers imposed their own language and so the first 'central' languages emerged, linking the peripheral languages of the agrarian communities via bilingual speakers to the language of the conquerors. Then was the formation of empires, which resulted in the next stage of integration of the world language system.\n\nFirstly, Latin emerged from Rome. Under the rule of the Roman Empire, under which an extensive group of states were ruled by, the usage of Latin stretched along the Mediterranean coast, the southern half of Europe, and more sparsely to the North and then into the Germanic and Celtic lands. Thus, Latin evolved to become a central language in Europe from 27 BC to 476 AD.\n\nSecondly, there was the widespread usage of the pre-classical version of Han Chinese in contemporary China due to the unification of China in 221 BC by Qin Shi Huang.\n\nThirdly, Sanskrit started to become widely spoken in South Asia from the widespread teaching of Hinduism and Buddhism in South Asian countries.\n\nFourthly, the expansion of the Arabic empire also led to the increased usage of Arabic as a language in the Afro-Eurasian land mass.\n\nMilitary conquests of preceding centuries generally determine the distribution of languages today.\nSupercentral languages spread by land and sea. Land-bound languages spread via marching empires: German, Russian, Arabic, Hindi, Chinese and Japanese. However, when the conquerors were defeated and were forced to move out of the territory, the spread of the languages receded. As a result, some of these languages are currently barely supercentral languages and are instead confined to their remaining state territories, as is evident from German, Russian and Japanese.\n\nOn the other hand, sea-bound languages spread by conquests overseas: English, French, Portuguese, Spanish. Consequently, these languages became widespread in areas settled by European colonisers and relegated the indigenous people and their languages to peripheral positions.\n\nBesides, the world-systems theory also allowed the global language system to expand further. It focuses on the existence of the core, semi-peripheral and peripheral nations. The core countries are the most economically powerful and the wealthiest countries. Besides, they also have a strong governmental system in the country, which oversees the bureaucracies in the governmental departments. There is also the prevalent existence of the bourgeois, and core nations have significant influence over the non-core, smaller nations. Historically, the core countries were found in northwestern Europe and include countries such as England, France and the Netherlands. They were the dominant countries that had colonized many other nations from the early 15th century to the early 19th century.\n\nThen is the existence of the periphery countries, the countries with the slowest economic growth. They also have relatively weak governments and a poor social structure and often depend on primary industries as the main source of economic activity for the country.\n\nThe extracting and exporting of raw materials from the peripheral nations to core nations is the activity bringing about the most economic benefits to the country. Much of the population that is poor and uneducated, and the countries are also extensively influenced by core nations and the multinational corporations found there. Historically, peripheral nations were found outside Europe, the continent of colonial masters. Many countries in Latin America were peripheral nations during the period of colonization, and today peripheral countries are in sub-Saharan Africa.\n\nLastly, the presence of the semiperiphery countries, those in between the core and the periphery. They tend to be those which started out as peripheral nations and are currently moving towards industrialization and the development of more diversified labour markets and economies. They can as well come about from declining core countries. They are not dominant players in the international trade market. As compared to the peripheral nations, semi-peripheries are not as susceptible to manipulation by the core countries. However, most of these nations have economic or political relations with the core. Semi-peripheries also tend to exert influence and control over peripheries and can serve to be a buffer between the core and peripheral nations and ease political tensions. Historically, Spain and Portugal were semi-peripheral nations after they fell from their dominant core positions. As they still maintained a certain level of influence and dominance in Latin America over their colonies, they could still maintain their semi-peripheral position.\n\nAccording to Immanuel Wallerstein, one of the most well-known theorists who developed the world-systems approach, a core nation is dominant over the non-core nations from its economic and trade dominance. The abundance of cheap and unskilled labour in the peripheral nations makes many large multinational corporations (MNCs), from core countries, often outsource their production to the peripheral countries to cut costs, by employing cheap labour. Hence, the languages from the core countries could penetrate into the peripheries from the setting up of the foreign MNCs in the peripheries. A significant percentage of the population living in the core countries had also migrated to the core countries in search of jobs with higher wages.\n\nThe gradual expansion of the population of migrants makes the language used in their home countries be brought into the core countries, thus allowing for further integration and expansion of the world language system. The semi-peripheries also maintain economic and financial trade with the peripheries and core countries. That allows for the penetration of languages used in the semi-peripheries into the core and peripheral nations, with the flow of migrants moving out of the semi-peripheral nations to the core and periphery for trade purposes.\n\nThus, the global language system examines rivalries and accommodations using a global perspective and establishes that the linguistic dimension of the world system goes hand in hand with the political, economic, cultural and ecological aspects. Specifically, the present global constellation of languages is the product of prior conquest and domination and of ongoing relations of power and exchange.\n\nformula_1 is the communicative value of a language \"i\", its potential to connect a speaker with other speakers of a constellation or subconstellation, \"S\". It is defined as follows:\n\nformula_2\n\nThe prevalence formula_3 of language \"i\", means the number of competent speakers in \"i\", formula_4, divided by all the speakers, formula_5 of constellation \"S\". Centrality, formula_6 is the number of multilingual speakers formula_7 who speak language \"i\" divided by all the multilingual speakers in constellation \"S\", formula_8.\n\nThus, the Q-value or communication value is the product of the prevalence formula_3 and the centrality formula_6 of language \"i\" in constellation \"S\".\n\nConsequently, a peripheral language has a low Q-value and the Q-values increase along the sociology classification of languages, with the Q-value of the hypercentral language being the highest.\n\nDe Swaan has been calculating the Q-values of the official European Union(EU) languages since 1957 to explain the acquisition of languages by EU citizens in different phases.\n\nIn 1970, when there were only four language constellations, Q-value decreased in the order of French, German, Italian, Dutch. In 1975, the European Commission enlarged to include Britain, Denmark and Ireland. English had the highest Q-value followed by French and German.\nIn the following years, the European Commission grew, with the addition of countries like Austria, Finland and Sweden. Q-value of English still remained the highest, but French and German swapped places.\n\nIn EU23, which refers to the 23 official languages spoken in the European Union, the Q-values for English, German and French were 0.194, 0.045 and 0.036 respectively.\n\nDe Swaan likens the global language system to contemporary political macrosociology and states that language constellations are a social phenomenon, which can be understood by using social science theories. In his theory, de Swaan uses the Political Sociology of Language and Political Economy of Language to explain the rivalry and accommodation between language groups.\n\nThis theoretical perspective centres on the interconnections among the state, nation and citizenship. Accordingly, bilingual elite groups try to take control of the opportunities for mediation between the monolingual group and the state. Subsequently, they use the official language to dominate the sectors of government and administration and the higher levels of employment. It assumes that both the established and outsider groups are able to communicate in a shared vernacular, but the latter groups lack the literacy skills that could allow them to learn the written form of the central or supercentral language, which would, in turn allow, them to move up the social ladder.\n\nThis perspective centres on the inclinations that people have towards learning one language over the other. The presumption is that if given a chance, people will learn the language that gives them more communication advantage. In other words, a higher Q-Value. Certain languages such as English or Chinese have high Q-values since they are spoken in many countries across the globe and would thus be more economically useful than to less spoken languages, such as Romanian or Hungarian.\n\nFrom an economic perspective, languages are ‘hypercollective’ goods since they exhibit properties of collective goods and produce external network effects. Thus, the more speakers a language has, the higher its communication value for each speaker. The hypercollective nature and Q-Value of languages thus help to explain the dilemma that a speaker of a peripheral language faces when deciding whether to learn the central or hypercentral language. The hypercollective nature and Q-value also help to explain the accelerating spread and abandonment of various languages. In that sense, when people feel that a language is gaining new speakers, they would assign a greater Q-value to this language and abandon their own native language in place of a more central language. The hypercollective nature and Q-value also explain, in an economic sense, the ethnic and cultural movements for language conservation.\n\nSpecifically, a minimal Q-value of a language is guaranteed when there is a critical mass of speakers committed to protecting it, thus preventing the language from being forsaken.\n\nThe global language system theorises that language groups are engaged in unequal competition on different levels globally. Using the notions of a periphery, semi-periphery and a core, which are concepts of the world system theory, de Swaan relates them to the four levels present in the hierarchy of the global language system: peripheral, central, supercentral and hypercentral.\n\nDe Swaan also argues that the greater the range of potential uses and users of a language, the higher the tendency of an individual to move up the hierarchy in the global language system and learn a more \"central\" language. Thus, de Swaan views the learning of second languages as proceeding up rather than down the hierarchy, in the sense that they learn a language that is on the next level up. For instance, speakers of Catalan, a peripheral language, have to learn Spanish, a central language to function in their own society, Spain. Meanwhile, speakers of Persian, a central language, have to learn Arabic, a supercentral language, to function in their region. On the other hand, speakers of a supercentral language have to learn the hypercentral language to function globally, as is evident from the huge number of non-native English speakers.\n\nAccording to de Swaan, languages exist in \"constellations\" and the global language system comprises a sociological classification of languages based on their social role for their speakers. The world's languages and multilinguals are connected in a strongly ordered, hierarchical pattern. There are thousands of peripheral or minority languages in the world, each of which are connected to one of a hundred central languages. The connections and patterns between each language is what makes up the global language system. The four levels of language are the peripheral, central, supercentral and hypercentral languages.\n\nAt the lowest level, peripheral languages, or minority languages, form the majority of languages spoken in the world; 98% of the world's languages are peripheral languages and spoken by less than 10% of the world’s population. Unlike central languages, these are \"languages of conversation and narration rather than reading and writing, of memory and remembrance rather than record\". They are used by native speakers within a particular area and are in danger of becoming extinct with increasing globalisation, which sees more and more speakers of peripheral languages acquiring more central languages in order to communicate with others.\n\nThe next level constitutes about 100 central languages, spoken by 95% of the world's population and generally used in education, media and administration. Typically, they are the 'national' and official languages of the ruling state. These are the languages of record, and much of what has been said and written in those languages is saved in newspaper reports, minutes and proceedings, stored in archives, included in history books, collections of the 'classics', of folk talks and folk ways, increasingly recorded on electronic media and thus conserved for posterity.\n\nMany speakers of central languages are multilingual because they are either native speakers of a peripheral language and have acquired the central language, or they are native speakers of the central language and have learned a supercentral language.\n\nAt the second highest level, 13 supercentral languages are very widely spoken languages that serve as connectors between speakers of central languages: Arabic, Chinese, English, French, German, Hindi, Japanese, Malay, Portuguese, Russian, Spanish, Swahili and Turkish.\n\nThese languages often have colonial traces and \"were once imposed by a colonial power and after independence continued to be used in politics, administration, law, big business, technology and higher education\".\n\nAt the highest level is the language that connects speakers of the supercentral languages. Today, English is the only example of a hypercentral language as the standard for science, literature, business, and law, as well as being the most widely spoken second language.\n\nAccording to David Graddol (1997), in his book titled \"The Future of English\", the languages of the world comprise a \"hierarchical pyramid\", as follows:\n\n\nThe global language system is also seen in the international translation process as explained by Johan Heilbron, a historical sociologist: \"translations and the manifold activities these imply are embedded in and dependent on a world system of translation, including both the source and the target cultures\".\n\nThe hierarchical relationship between global languages is reflected in the global system for translations. The more \"central\" a language, the greater is its capability to function as a bridge or vehicular language to facilitate communication between peripheral and semi-central languages.\n\nHeilbron's version of the global system of language in translations has four levels:\n\nLevel 1: Hypercentral position — \nEnglish currently holds the largest market share of the global market for translations; 55–60% of all book translations are from English. It strongly dominates the hierarchical nature of book translation system.\n\nLevel 2: Central position — \nGerman and French each hold 10% of the global translation market.\n\nLevel 3: Semi-central position — \nThere are 7 or 8 languages \"neither very central on a global level nor very peripheral\", making up 1 to 3% of the world market (like Spanish, Italian and Russian).\n\nLevel 4: Peripheral position — \nLanguages from which \"less than 1% of the book translations worldwide are made\", including Chinese, Japanese and Arabic. Despite having large populations of speakers, \"their role in the translation economy is peripheral as compared to more central languages\".\n\nAccording to the Google Scholar website, de Swaan's book, \"Words of the world: The global language system\", has been cited by 546 other papers, as of 16 October 2014.\n\nHowever, there have also been several concerns regarding the global language system:\n\nVan Parijs (2004) claimed that 'frequency' or likelihood of contact is adequate as an indicator of language learning and language spread. However, de Swaan (2007) argued that it alone is not sufficient. Rather, the Q-value, which comprises both frequency (better known as prevalence) and 'centrality', helps to explain the spread of (super)central languages, especially former colonial languages in newly independent countries where in which only the elite minority spoke the language initially. Frequency alone would not be able to explain the spread of such languages, but Q-value, which includes centrality, would be able to.\n\nIn another paper, Cook and Li (2009) examined the ways to categorise language users into various groups. They suggested two theories: one by Siegel (2006) who used 'sociolinguistic settings', which is based on the notion of dominant language, and another one by de Swaan (2001) that used the concept of hierarchy in the global language system. According to them, de Swaan's hierarchy is more appropriate, as it does not imply dominance in power terms. Rather, de Swaan's applies the concepts of geography and function to group languages and hence language users according to the global language system. De Swaan (2001) views the acquisition of second languages (L2) as typically going up the hierarchy.\n\nHowever, Cook and Li argues that this analysis is not adequate in accounting for the many groups of L2 users to whom the two areas of territory and function hardly apply. The two areas of territory and function can be associated respectively with the prevalence and centrality of the Q-value. This group of L2 users typically doez not acquire an L2 going up the hierarchy, such as users in an intercultural marriage or users who come from a particular cultural or ethnic group and wish to learn its language for identity purposes. Thus, Cook and Li argue that de Swaan's theory, though highly relevant, still has its drawbacks in that the concept behind Q-value is insufficient in accounting for some L2 users.\n\nThere is disagreement as to which languages should be considered more central. The theory states that a language is central if it connects speakers of \"a series of central languages\". Robert Phillipson questioned why Japanese is included as one of the supercentral languages but Bengali, which has more speakers, is not on the list.\n\nMichael Morris argued that while it is clear that there is language hierarchy from the \"ongoing interstate competition and power politics\", there is little evidence provided that shows that the \"global language interaction is so intense and systematic that it constitutes a global language system, and that the entire system is held together by one global language, English\". He claimed that de Swaan's case studies demonstrated that hierarchy in different regions of the world but did not show the existence of a system within a region or across regions. The global language system is supposed to be part of the international system but is \"notoriously vague and lacking in operational importance\" and therefore cannot be shown to exist. However, Morris believes that this lack of evidence could be from the lack of global language data and not negligence on de Swaan's part. Morris also believes that any theory on a global system, if later proved, would be much more complex than what is proposed by de Swaan. Questions on how the hypercentral language English holds together the system must also be answered by such a global language system.\n\nRobert Phillipson states that the theory is based on selective theoretical foundations. He claimed that there is a lack of consideration about the effects of globalization, which is especially important when the theory is about a global system: \"De Swaan nods occasionally in the direction of linguistic and cultural capital, but does not link this to class or linguistically defined social stratification (linguicism) or linguistic inequality\" and that \"key concepts in the sociology of language, language maintenance and shift, and language spread are scarcely mentioned\".\n\nOn the other hand, de Swaan's work in the field of sociolinguistics has been noted by other scholars to be focused on \"issues of economic and political sociology\" and \"politic and economic patterns\", which may explain why he makes only 'cautious references to socio-linguistic parameters\".\n\n"}
{"id": "27403833", "url": "https://en.wikipedia.org/wiki?curid=27403833", "title": "Heritage language learning", "text": "Heritage language learning\n\nHeritage language learning or heritage language acquisition is the act of learning a heritage language from an ethnolinguistic group that traditionally speaks the language, or from those whose family historically spoke the language. According to a commonly accepted definition by Valdés, heritage languages are generally minority languages in society and are typically learned at home during childhood. When a heritage language learner grows up in an environment with a dominant language that is different from their heritage language, the learner appears to be more competent in the dominant language and often feels more comfortable speaking in that language. \"Heritage language\" may also be referred to as \"community language,\" \"home language,\" and \"ancestral language\".\n\nThere are different kinds of heritage language learners, such as learners with varying levels of proficiency in the heritage language, and also those who learn a \"foreign\" language in school with which they have some connection. Polinsky & Kagan label heritage language learners on a continuum that ranges from fluent speakers to individuals who speak very little of their heritage language. Valdés points out that a connection with a heritage language does not have to be made only through direct previous exposure to the language or a certain amount of proficiency in the language. In her conception of heritage language learners, monolingual English-speaking students of Armenian ancestry in the United States could consider themselves to have a heritage language of Armenian. A different definition of heritage language learners or speakers limits the term to individuals who were exposed to the language in early childhood, but who later lost proficiency in the language in favor of adopting the majority language of the community.\n\nHeritage language acquisition theories are highly contested. The most common theory is the Incomplete Acquisition Theory, but other scholars have considered delayed acquisition, variations in input, and cross-linguistic influence as factors that contribute to heritage language speakers' competence (see section on Acquisition Theories). For children who may have acquired a different dialect of the heritage language, they would require a unique type of instruction that may differ from styles of instruction that would be most beneficial for students who experience incomplete acquisition at an early age.\n\nHeritage languages can be learned in various contexts, including public school instruction and language courses organized by a community which speaks the particular language during after-school hours or on the weekend. When someone is engaged in informal heritage language learning, they are acquiring a language from a particular ethnolinguistic group that traditionally speaks the language, or from someone whose family historically spoke the language. Formal heritage language instruction occurs inside of a classroom, where learners are taught a language that is being used inside of the home or among members of their own ethnic group. Language programs that include Saturday schools and courses that happen outside of school hours are programs where children are encouraged to further develop and improve their heritage language proficiency.\n\nAccording to Valdés, the term \"heritage language\" can be used very broadly and can refer to minority languages which are spoken by what many know as \"linguistic minorities.\" Typically, these heritage languages are endangered or have a high possibility of disappearing soon without intervention, and because of this, there are several communities in the United States that have chosen to work towards maintaining these languages.\n\nThe difference between native language (or First language) and heritage language is an important distinction to make. The term \"native language\" tends to be associated with acquisition at a very early age and carries with it the notion that a person will achieve a high amount of fluency and proficiency in this language. Typically, the native language is the dominant language for a speaker and this speaker is expected to have natural understanding of not only linguistic knowledge, but also pragmatic and cultural knowledge, as well as skills such as writing creatively, making jokes, and translating. On the other hand, the term \"heritage language\" is more associated with the language in which proficiency was sacrificed in order to gain proficiency in the dominant language in a particular community. This is not always the case, however, as some speakers of heritage languages have just as much proficiency in that language as in their other language(s).\n\nHeritage language learners differ from other types of language learners. Kagan & Dillon provide us with distinctions among speakers of Russian as a native language, and learners of Russian as a heritage language or a foreign language in the table below. The goal of the research was to distinguish between types of language learners of Russian and to use that information to create a new perspective for instruction. The table explains that students whose native language was Russian had acquired it as a child and used it throughout life with exposure to a full language community of speakers. For the students who learned Russian as a foreign language (L2), there was first an L1 or native language before they began learning Russian, the foreign language, which was typically learned solely outside of the community. Lastly, the heritage speakers of Russian had acquired Russian as an L1, but when they immigrated to the United States, English became their primary language. This left most heritage language students with varying levels of proficiency in their heritage language due to the limited community that spoke Russian.\n\nAcquisition theories have been proposed in an attempt to explain why heritage speakers’ competence in the heritage language diverges from that of their monolingual peers. Silvina Montrul’s research has been foundational to this work. Her Incomplete Acquisition Theory states that heritage speakers do not completely acquire the heritage language before switching to the L2. As attrition can also render a grammar “incomplete,” attrition is included in this theory. Multiple researchers have refuted Silvina Montrul's proposal by suggesting that the Incomplete Acquisition Theory does not take into consideration delayed acquisition, input variation, and cross-linguistic influence, all of which factor into language competence.\n\nAs research on heritage language learners' acquisition is relatively recent, dating back to the early 2000s, there remains much to be discovered about the process. It should also be noted that the following acquisition theories pertain to language learners who have learned, at least partially, the heritage language before switching to the dominant language. For more information on heritage language learners who lack personal experience with the heritage language but have ancestry who spoke the language, see language revitalization.\n\nThe Incomplete Acquisition Theory recognizes that complete acquisition of L1 takes place throughout childhood, stretching into the school-age period. Therefore, heritage language learners, who typically switch to the dominant culture’s language when they enter school and, consequently, experience a decline in input in the heritage language, do not completely acquire their first language. As heritage language learners are rarely schooled in their L1, they are often orally proficient but illiterate or have underdeveloped written comprehension and production in the heritage language. In treating heritage language learning as interrupted L1 acquisition, in which the learner has access to Universal Grammar, it is expected that heritage language learners have knowledge of concepts found in early stages of L1 development, such as binding constraints, wh-movement, and aspects of lexical semantics, and struggle with grammatical concepts that require sustained exposure and practice in school-aged children, such as specialized vocabulary and uses of the subjunctive in Spanish.\n\nAn incomplete grammar may be the result of attrition and fossilization of concepts in the L1 due to insufficient input once the child has switched to the dominant language. Attrition is the loss of, or failure to make full use of, “grammatical knowledge previously acquired\". Fossilization occurs when a speaker lets go of non-core grammatical concepts but retains the basic core structure of the language. Attrition and fossilization are considered to be part of the Incomplete Acquisition Theory because they render a language incomplete. However, Pires and Rothman (2009) argue that attrition should be distinguished from the Incomplete Acquisition Theory in future studies because, in instances of attrition, the speakers do, indeed, completely acquire the target grammar as children.\n\nDelayed acquisition may contribute to the difference in language competence between heritage speakers and monolingual speakers of the same language. Late or delayed acquisition of a language can have \"consequences for linguistic, neurological, and cognitive mechanisms\" that work to make language acquisition \"fast, effortless, and... successful\". Flores and Barbosa (2014) studied the clitic placement of heritage speakers of Portuguese living in Germany and concluded that the heritage speakers went through the same stages of acquisition as their monolingual counterparts. However, the process of acquisition was delayed and took longer for the heritage speakers because they had reduced input of the heritage language. Thus, this theory must be considered in conjunction with theories on input variation.\n\nTheories of acquisition involving variations of input postulate that heritage language learners' production of the heritage language diverges from that of their monolingual peers who speak the same language because the two groups are exposed to different dialects and quantities of input.\n\nTheories surrounding dialect variation suggest that errors or deviations from the standard dialect made by a heritage language learner may reflect the acquisition of a non-standard variety or informal register of the heritage language, which include variations on certain properties or the lack of certain properties found in the standard dialect. Heritage language learners are often only exposed to one dialect or colloquial variety of the heritage language, unlike their monolingual peers who interact with a standard monolingual dialect found in formal instruction. Furthermore, certain grammatical properties are only present in the standard dialect or are used infrequently in the colloquial dialect. Pires and Rothaman use the expression, \"missing-input competence divergence,\" to refer to instances when a grammatical property is missing from the colloquial variety.\n\nThe dramatic difference between standard and colloquial dialects is particularly evident in cases of verbal morphology, the clitic system, the subjunctive, and inflected infinitives in Brazilian Portuguese. Pires and Rothman (2009) found that Brazilian Portuguese heritage learners do not acquire inflected infinitives because their input does not \"robustly instantiate these forms\". Similarly, Dominguez (2009) found that deviations in the use and distribution of indicative and subjunctive forms that were in the output of heritage Spanish speakers were also found in the children's input (parental speech).\n\nIn certain cases, heritage language learners receive their input from first-generation migrants who have shown effects of attrition in certain domains. Consequently, the language learner would be missing grammatical properties in their input as a result of the interlocutor's attrition and would replicate these errors in their output.\n\nPires and Rothman (2009) claim that due to their \"inborn faculty of language,\" children automatically acquire the grammar found in their input. Therefore, in conclusion, it is not a deficient ability to acquire the language, but rather, the absence of, or limited access to, certain properties in the child's input that leads to errors in language production. Without access to a standard dialect of the target language often found in formal academic contexts, heritage language learners continue to make these production errors.\n\nHeritage language learners may also have a smaller quantity of input than their monolingual peers because the heritage language is only found in a restricted number of contexts and with fewer interlocutors. Citing statistics found in studies on hearing children with deaf parents, Flores and Barbosa (2014) posit that bilingual heritage language learners need a minimum of 5 to 10 hours of interaction per week with the language to develop native-like proficiency. Hours of input may be particularly restricted once the heritage speaker switches to the dominant language.\n\nCross-linguistic influence may contribute to heritage speakers' competence divergence. Heritage language learners show a tendency to overuse grammatical properties that are found in both the heritage language and the dominant language. Furthermore, heritage language learners may prefer grammatical structures from the dominant language and transfer them into the heritage language. To learn more about language transfer in bilingual individuals, see Crosslinguistic influence.\n\nThere are many theories across disciplines that seek to explain the relationship between language and identity, but the existence of such a relationship is the common thread. For heritage language learners, when their native or heritage language is not treated as valuable in the classroom, this negatively affects their view of themselves and their mental health. Many minority language speakers’ children lose the ability to speak the minority language once they enter the classroom, because of several detrimental factors discussed below. Heritage language learning may help these children regain or avoid losing the ability to communicate with their parents.\n\nWithout the ability to communicate with parents or other family members, it becomes difficult to create an identity intertwined with one's heritage culture. In fact, once the heritage language is lost, children may lose the cognitive ability to understand certain concepts or beliefs in their heritage culture. Those who lose the heritage language and choose not to actively maintain its use often assimilate into the dominant culture rather quickly. When heritage language learning does take place, the “standard” language is instructed, and learners whose heritage language is of a different dialect are judged for their variance from the standard. This results in a loss of self-esteem that makes strong self-identity difficult.\n\nOne group of heritage language learners includes international adoptees. Some parents that adopt internationally see heritage language learning as a necessary part of the adoptees connection with their own cultural identity, and choose to learn the heritage language along with their child. Though the language is not a heritage language for these parents, it is the language their child might have been brought up in and is a necessary part of “culture keeping,” or the act of purposefully ensuring the adopted child holds onto their birth culture.\n\nAnother sub-category of heritage language learners are mixed-heritage learners. Studies show that these individuals may have a confused sense of identity because they do not feel that they are fully accepted by either culture. Heritage language learning can be a way to help mixed-heritage individuals connect to the culture of their minority language parent, but these children face several obstacles in pursuing this language, as described in “Detrimental Factors to Heritage Language Learning.”\n\nFor all heritage language learners, Kondo-Brown suggests that proficiency is positively correlated to both a strong perception of heritage and ethnic identity and a strong community in one's ethnic group. Much research backs this claim. In a study of Japanese heritage language learners, Kondo-Brown found that individuals with one parent speaking the language performed much better in both grammatical knowledge, and various self-assessment tools than those without a parent speaking Japanese. Individuals in this same study with either one Japanese speaking grandparent, or only being of Japanese descent performed on the same level, below those with one Japanese speaking parent. Kondo-Brown attributes this difference to variance in sense of ethnic identity.\n\nHeritage language learning is generally an effort to recover one's cultural identity, and is therefore linked to the language loss experienced by immigrant and indigenous populations. Immigration and colonialism around the world have created communities of people who speak languages other than the dominant language at home. Their minority status means that they must navigate the effects of linguistic difference, and the expression of culture, ethnicity, and values through language. Heritage learners often cite a desire to connect with their cultural heritage as a major motivation for studying their heritage language. They may also be motivated by the global prominence and potential career advantages of some heritage languages. As both major immigrant destinations and exporters of the world's dominant language, the United States, Canada, Western Europe, and Australia are home to large populations of heritage language speakers. Indigenous populations in Australia and the Americas also teach their own languages as heritage languages, attempting to revitalize them after the effects of colonial occupation.\n\nThe distribution of immigrant languages around the world largely reflects immigration patterns; for example, Spanish and Chinese are more likely to be taught as heritage languages abroad. The language profile of a single immigrant community can also vary due to the presence of different dialects. This variation in dialects and even writing systems can be another obstacle in meeting community needs. Ebb and flow in a country's immigrant populations can also lead to significant variation in the abilities of heritage learners in a single classroom. A study conducted by the National Heritage Language Resource Center (UCLA) shows that in the United States, heritage speakers' interest in their home language tends to wane as they enter school, but may rise again in the later teenage years, prompting the decision to study it in college.\n\nThe study and teaching of indigenous heritage languages stands at odds with colonial governments' earlier attempts at forced cultural assimilation. The process of language loss accelerated by colonial policies and practices means that many indigenous languages are faced with the threat of extinction, and the effort to teach them as heritage languages intersects with broader language revitalization projects. While learners of immigrant languages are likely to have at least partial knowledge of their language from an early age, indigenous language learners may never have spoken their languages before they began learning them in a formal setting. Education in these languages is further complicated by social stigma, and the feelings of shame or inadequacy that some indigenous people may associate with their language due to colonial intervention. Adult speakers coming from a legacy such as that of Canada's residential schools (a project for assimilating indigenous peoples), whose negative psychological effects have been reported by Canada's Truth and Reconciliation Commission, may be unable or unwilling to pass their language on to their children.\n\nHeritage language learners have widely varying circumstances and educational needs that set them apart from foreign language learners. They may have little to no understanding of the language, or be able to speak but not read or write it. Formal education in heritage languages has existed since the nineteenth century, in immigrant communities and private and religious schools. Heritage languages did not attract the attention of public education and universities until the concept of heritage language itself began to emerge as a separate field from foreign language learning. Heritage languages are also referred to as community, ethnic, ancestral, minority, or non-official languages, but the term \"heritage language\" appears to have originated with Canadian programs of this type.\n\nWhen designing heritage language curricula and teaching methods, linguists and educators attempt to address the ways in which heritage learners are unique. In contrast to the teaching of foreign languages, heritage language teaching methods place more emphasis on literacy and experiential, content-based approaches. Because cultural identity is a definitive part of heritage language learning, languages are often taught alongside cultural practices. Teaching heritage languages is not limited to the classroom; it may be a part of other local community contexts, such as a volunteer work and internships, field trips, oral history projects, or Scout troops.\n\nOne question facing heritage language programs is the relationship of heritage language learners to foreign language learners of that same language. The two types of students have different educational, cultural, and psychological backgrounds, which can lead to uneven learning outcomes if they are taught together. Heritage language learners can be taught in entirely separate programs from foreign language learners, or in courses where different types of learners are integrated to varying degrees. They may also be taught alongside their foreign language counterparts with no distinction between them, as is usually the case in college language courses.\n\nAmerican immigrants often end their pursuit of heritage language learning after two or three generations in the United States, and it is now becoming more common to shift into English within two generations. The decision to end heritage language learning can stem from a variety of factors, but often includes societal pressure to use the dominant language. Some L2 speakers view the dominant language as superior or associate it with higher class society, and prefer it to their heritage language, or believe it will lead them to greater opportunity than their native tongue. Some parents discourage use of the heritage language in the home because of a fear that their children will have a harder time learning the dominant language if they are also learning another language. This belief is not supported by research. Research by Yan and Elena (as cited in Yilmaz 2016) showed better performance in bilinguals as compared to monolinguals in metalinguistic ability, pragmatics, and attention control. This and other research actually points to Cognitive advantages of bilingualism including greater cognitive ability and mental flexibility.\n\nPractical limitations to heritage language learning are also possible, and can include limited access to resources for heritage language learning, and limited materials in the heritage language. A combination of a social and practical limitation, classrooms may also discourage the use of minority languages by students during instruction.\n\nIn the sub-population of mixed-heritage learners, there may other stigmas that contribute to the loss of heritage language learning. If it is not widely accepted to marry outside of their culture, and individuals decide to do so anyhow, they may lose contact with their ethnic community upon marriage. This leaves them without access to a community of speakers in their heritage language. Their children now have little access to one parent’s native language, and little opportunity to pursue heritage language learning.\n\nAlthough heritage language learning can be important in many cases, the stakes are particularly high when the language is near extinction. In some cases, the active pursuit of heritage language learning is necessary to keep a minority languages alive, yet there may be limited learning materials and resources to do so. The language of the Cherokee people in North Carolina and in the Cherokee Nation in Oklahoma fits into this category. In these situations, it is also likely that there is limited access to social communities of native speakers to communicate with. Without this natural input as well as pedagogical input, speakers may not achieve the fluency needed to keep the language alive, and the minority language may be lost.\n\n"}
{"id": "14863", "url": "https://en.wikipedia.org/wiki?curid=14863", "title": "Incunable", "text": "Incunable\n\nAn incunable, or sometimes incunabulum (plural incunables or incunabula, respectively), is a book, pamphlet, or broadside printed in Europe before the year 1501. (Importantly, incunabula are not manuscripts.) there are about 30,000 distinct known incunable editions extant. The number of surviving copies in Germany alone is estimated at around 125,000.\n\n\"Incunable\" is the anglicised singular form of \"incunabula\", Latin for \"swaddling clothes\" or \"cradle\", which can refer to \"the earliest stages or first traces in the development of anything\". A former term for \"incunable\" is \"fifteener\", referring to the 15th century.\n\nThe term \"incunabula\" as a printing term was first used by the Dutch physician and humanist Hadrianus Iunius (Adriaan de Jonghe, 1511–1575) and appears in a passage from his posthumous work (written in 1569): Hadrianus Iunius, \"Batavia\", [...], [Lugduni Batavorum], ex officina Plantiniana, apud Franciscum Raphelengium, 1588, p. 256 l. 3: «inter prima artis [typographicae] incunabula», a term (\"the first infancy of printing\") to which he arbitrarily set an end of 1500 which still stands as a convention.\n\nOnly by a misunderstanding was Bernhard von Mallinckrodt (1591–1664) considered to be the inventor of this meaning of \"incunabula\"; the identical passage is found in his Latin pamphlet \"De ortu ac progressu artis typographicae\" (\"On the rise and progress of the typographic art\", Cologne, 1640): Bernardus a Mallinkrot, \"De ortu ac progressu artis typographicae dissertatio historica\", [...], Coloniae Agrippinae, apud Ioannem Kinchium, 1640 (in frontispiece: 1639), p. 29 l. 16: «inter prima artis [typographicae] incunabula», within a long passage of several pages, which he (correctly) quotes entirely in italic characters (that is between quotation marks), referring to the name of author and work cited: «Primus istorum [...] Hadrianus Iunius est, cuius integrum locum, ex \"Batavia\" eius, operae pretium est adscribere; [...]. Ita igitur Iunius» (ibid., p. 27 ll. 27-32, followed by the long passage, «Redeo → sordes», ibid., p. 27, l. 32 – p. 33 l. 32 [= \"Batavia\", p. 253 l. 28 – p. 258 l. 21]). So the source is only one, the other is a quotation.\n\nThe term \"incunabula\" came to denote the printed books themselves in the late 17th century. John Evelyn, in moving the Arundel Manuscripts to the Royal Society in August 1678, remarked of the printed books among the manuscripts: \"The printed books, being of the oldest impressions, are not the less valuable; I esteem them almost equal to MSS.\" The convenient but arbitrarily chosen end date for identifying a printed book as an incunable does not reflect any notable developments in the printing process, and many books printed for a number of years after 1500 continued to be visually indistinguishable from incunables. \n\n\"Post-incunable\" typically refers to books printed after 1500 up to another arbitrary end date such as 1520 or 1540. From around this period the dating of any edition becomes easier, as the practice of printers including information such as the place and year of printing became more widespread.\n\nThere are two types of \"incunabula\" in printing: the block book, printed from a single carved or sculpted wooden block for each page, employing the same process as the woodcut in art (these may be called \"xylographic\"); and the \"typographic book\", made with individual pieces of cast-metal movable type on a printing press. Many authors reserve the term \"incunabula\" for the latter kind only.\n\nThe spread of printing to cities both in the north and in Italy ensured that there was great variety in the texts chosen for printing and the styles in which they appeared. Many early typefaces were modelled on local forms of writing or derived from the various European forms of Gothic script, but there were also some derived from documentary scripts (such as most of Caxton's types), and, particularly in Italy, types modelled on handwritten scripts and calligraphy employed by humanists.\n\nPrinters congregated in urban centres where there were scholars, ecclesiastics, lawyers, and nobles and professionals who formed their major customer base. Standard works in Latin inherited from the medieval tradition formed the bulk of the earliest printed works, but as books became cheaper, vernacular works (or translations into vernaculars of standard works) began to appear.\n\nThe most famous \"incunabula\" include two from Mainz, the Gutenberg Bible of 1455 and the \"Peregrinatio in terram sanctam\" of 1486, printed and illustrated by Erhard Reuwich; the \"Nuremberg Chronicle\" written by Hartmann Schedel and printed by Anton Koberger in 1493; and the \"Hypnerotomachia Poliphili\" printed by Aldus Manutius with important illustrations by an unknown artist. \n\nOther printers of incunabula were Günther Zainer of Augsburg, Johannes Mentelin and Heinrich Eggestein of Strasbourg, Heinrich Gran of Haguenau and William Caxton of Bruges and London. The first incunable to have woodcut illustrations was Ulrich Boner's \"Der Edelstein\", printed by Albrecht Pfister in Bamberg in 1461.\n\nMany incunabula are undated, needing complex bibliographical analysis to place them correctly. The post-incunabula period marks a time of development during which the printed book evolved fully as a mature artefact with a standard format. After c. 1540 books tended to conform to a template that included the author, title-page, date, seller, and place of printing. This makes it much easier to identify any particular edition.\n\nAs noted above, the \"end date\" for identifying a printed book as an incunable is convenient but was chosen arbitrarily; it does not reflect any notable developments in the printing process around the year 1500. Books printed for a number of years after 1500 continued to look much like incunables, with the notable exception of the small format books printed in italic type introduced by Aldus Manutius in 1501. The term post-incunable is sometimes used to refer to books printed \"after 1500—how long after, the experts have not yet agreed.\" For books printed in the UK, the term generally covers 1501–1520, and for books printed in mainland Europe, 1501–1540.\n\nThe data in this section were derived from the Incunabula Short-Title Catalogue (ISTC).\n\nThe number of printing towns and cities stands at 282. These are situated in some 18 countries in terms of present-day boundaries. In descending order of the number of editions printed in each, these are: Italy, Germany, France, Netherlands, Switzerland, Spain, Belgium, England, Austria, the Czech Republic, Portugal, Poland, Sweden, Denmark, Turkey, Croatia, Montenegro, and Hungary (see diagram). \n\nThe following table shows the 20 main 15th century printing locations; as with all data in this section, exact figures are given, but should be treated as close estimates (the total editions recorded in ISTC at May 2013 is 28,395):\n\nThe 18 languages that incunabula are printed in, in descending order, are: Latin, German, Italian, French, Spanish, English, Hebrew, Catalan, Czech, Greek, Church Slavonic, Portuguese, Swedish, Breton, Danish, Frisian and Sardinian (see diagram).\n\nOnly about one edition in ten (i.e. just over 3,000) has any illustrations, woodcuts or metalcuts.\n\nThe \"commonest\" incunable is Schedel's \"Nuremberg Chronicle\" (\"Liber Chronicarum\") of 1493, with c 1,250 surviving copies (which is also the most heavily illustrated). Many incunabula are unique, but on average about 18 copies survive of each. This makes the Gutenberg Bible, at 48 or 49 known copies, a relatively common (though extremely valuable) edition. Counting extant incunabula is complicated by the fact that most libraries consider a single volume of a multi-volume work as a separate item, as well as fragments or copies lacking more than half the total leaves. A complete incunable may consist of a slip, or up to ten volumes.\n\nIn terms of format, the 29,000-odd editions comprise: 2,000 broadsides, 9,000 folios, 15,000 quartos, 3,000 octavos, 18 12mos, 230 16mos, 20 32mos, and 3 64mos.\n\nISTC at present cites 528 extant copies of books printed by Caxton, which together with 128 fragments makes 656 in total, though many are broadsides or very imperfect (incomplete).\n\nApart from migration to mainly North American and Japanese universities, there has been little movement of incunabula in the last five centuries. None were printed in the Southern Hemisphere, and the latter appears to possess less than 2,000 copies, about 97.75% remain north of the equator. However many incunabula are sold at auction or through the rare book trade every year.\n\nThe British Library's Incunabula Short Title Catalogue now records over 29,000 titles, of which around 27,400 are incunabula editions (not all unique works). Studies of incunabula began in the 17th century. Michel Maittaire (1667–1747) and Georg Wolfgang Panzer (1729–1805) arranged printed material chronologically in annals format, and in the first half of the 19th century, Ludwig Hain published, \"Repertorium bibliographicum\"— a checklist of incunabula arranged alphabetically by author: \"Hain numbers\" are still a reference point. Hain was expanded in subsequent editions, by Walter A. Copinger and Dietrich Reichling, but it is being superseded by the authoritative modern listing, a German catalogue, the \"Gesamtkatalog der Wiegendrucke\", which has been under way since 1925 and is still being compiled at the Staatsbibliothek zu Berlin. North American holdings were listed by Frederick R. Goff and a worldwide union catalogue is provided by the Incunabula Short Title Catalogue.\n\nNotable collections, with the approximate numbers of incunabula held, include:\n\n\n"}
{"id": "26354249", "url": "https://en.wikipedia.org/wiki?curid=26354249", "title": "Index of philosophy of language articles", "text": "Index of philosophy of language articles\n\nThis is an index of articles in philosophy of language\n"}
{"id": "82145", "url": "https://en.wikipedia.org/wiki?curid=82145", "title": "Jean Berko Gleason", "text": "Jean Berko Gleason\n\nJean Berko Gleason (born 1931) is a professor emerita in the Department of Psychological and Brain Sciences (formerly the Department of Psychology) at Boston University,\na psycholinguist who has made fundamental contributions to the understanding of language acquisition in children, aphasia, gender differences in language development, and parent–child interactions.\n\nOf her Wug Test, by which she demonstrated that even young children possess implicit knowledge of linguistic morphology, it has been said, \"Perhaps no innovation other than the invention of the tape recorder has had such an indelible effect on the field of child language research\", the \"wug\" (one of the imaginary creatures Gleason drew in creating the Wug Test) being \"so basic to what [psycholinguists] know and do that increasingly it appears in the popular literature without attribution to its origins.\"\n\nJean Berko was born to Hungarian immigrant parents in Cleveland, Ohio. After graduating from Cleveland Heights High School in 1949, Gleason earned a B.A. in history and literature from Radcliffe College, then an M.A. in linguistics, and a combined Ph.D. in linguistics and psychology, at Harvard;\nfrom 1958 to 1959 she was a postdoctoral fellow at MIT. In graduate school she was advised by Roger Brown, a founder in the field of child language acquisition. In January 1959 she married Harvard mathematician Andrew Gleason; they had three daughters.\n\nMost of Gleason's professional career has been at Boston University, where she served as Psychology Department chair and director of the Graduate Program in Applied Linguistics; Lise Menn and Harold Goodglass were among her collaborators there.\n\nShe has been a visiting scholar at Harvard University, Stanford University, and at the Linguistics Institute of the Hungarian Academy of Sciences. Although officially retired and no longer teaching, she to be involved in research.\n\nGleason is the author or coauthor of some 125 papers on language development in children, language attrition, aphasia, and gender and cultural aspects of language acquisition and use;\nand is editor/coeditor of two widely used textbooks, \"The Development of Language\" (first edition 1985, eighth edition 2012) and \"Psycholinguistics\" (1993).\nShe is a Fellow of the American Association for the Advancement of Science and of the American Psychological Association, and was president of the International Association for the Study of Child Language from 1990 to 1993, and of the Gypsy Lore Society 1996 to 1999.\nShe has also served on the editorial boards of numerous academic and professional journals, and was associate editor of \"Language\" from 1997 to 1999.\n\nGleason was profiled in \"Beyond the Glass Ceiling: Forty Women Whose Ideas Shape the Modern World\" (1996).\nA festschrift in her honor, \"Methods for Studying Language Production\", was published in 2000.\nIn 2016 she received an honorary Doctor of Science degree from Washington & Jefferson College for her work as \"a pioneer in the field of psycholinguistics\",\nand in 2017 the Roger Brown Award (recognizing \"outstanding contribution to the international child language community\") from the International Association for the Study of Child Language.\n\nSince 2007 she has delivered the \"Welcome, welcome\" and \"Goodbye, goodbye\" speeches at the annual Ig Nobel Awards ceremonies.\n\nGleason devised the Wug Test as part of her earliest research (1958), which used nonsense words to gauge children's acquisition of morphological rulesfor example, the \"default\" rule that most English plurals are formed by adding an , or sounds, e.g., \" \"\nA child is shown simple pictures of an imaginary creature or activity,\nwith a nonsense name, and prompted to complete a statement about it:\nA critical attribute of the test is that the \"target\" word be a made-up (but plausible-sounding) pseudoword, so that the child will never have heard it before.\nA child who knows that the plural of \"witch\" is \"witches\" may have heard and memorized that pair, but a child responding that the plural of \"wug\" (which the child presumably has never heard) is \"wugs\" (/wʌgz/, using the /z/ allomorph since \"wug\" ends in a voiced consonant) has apparently inferred (perhaps unconsciously) the basic rule for forming plurals.\n\nThe Wug Test also includes questions involving verb conjugations, possessives, and other common derivational morphemes such as the agentive \"-er\" (e.g. \"A man who 'zibs' is a ________?\"),\nand requested explanations of common compound words e.g. \"Why is a birthday called a birthday?\"\nOther items included:\n(The expected answers were \"QUIRKY\" and \"SPOWED\".)\n\nGleason's major finding was that even very young children are able to connect suitable endingsto produce plurals, past tenses, possessives, and other formsto nonsense words they have never heard before, implying that they have already internalized systematic aspects of the linguistic system which no one has necessarily tried to teach them.\nHowever, she also identified an earlier stage at which children can produce such forms for real words, but not yet for nonsense wordsimplying that children start by memorizing singularplural pairs they hear spoken by others, then eventually extract rules and patterns from these examples which they apply to novel words.\n\nThe Wug Test was the first experimental proof that young children have extracted generalizable rules from the language around them, rather than simply memorizing words that they have heard, and it was almost immediately adapted for children speaking languages other than English, to bilingual children, and to children (and adults) with various impairments or from a variety of cultural backgrounds. Its conclusions are viewed as essential to the understanding of when and how children reach major language milestones, and its variations and progeny remain in use worldwide for studies on language acquisition. It is \"almost universal\" for textbooks in psycholinguistics and language acquisition to include assignments calling for the student to carry out a practical variation of the Wug Test paradigm.\n\nThe Wug Test's fundamental role in the development of psycholinguistics as a discipline has been mapped by studying references to Gleason's work in \"seminal journals\" in the field, many of which carried articles referencing it in their founding issues:\nAccording to Ratner and Menn, \"As an enduring concept in psycholinguistic research, the wug has become a generic, like [\"kleenex\"] or [\"xerox\"], a concept so basic to what we know and do that increasingly it appears in the popular literature without attribution to its origins... Perhaps no innovation other than the invention of the tape recorder has had such an indelible effect on the field of child language research.\"\n\nIt has been proposed that Wug Testlike instruments be used in diagnosis of learning disabilities, but in practice success in this direction has been limited.\n\nAnother of Gleason's early papers \"Fathers and Other Strangers: Men's Speech to Young Children\" (1975) explored differences between mothers' and fathers' spoken interaction with their children, primarily using data produced by two female and two male daycare teachers at a large university, and by three mothers and three fathers, mostly during family dinners.\nAmong other conclusions, this study found that:\n\nIn contrast, both male and female daycare teachers used language that was similar both quantitatively and qualitatively, with both focusing on dialogue based in the present and on the immediate needs of the children.\nDifferences included that the male teachers tended to address the children by name more often than did the female teachers, and that the male teachers issued more imperatives than did the female teachers.\n\nGleason's research eventually extended into the study of children's acquisition of routinesthat is, standardized chunks of language (or language-plus-gesture) that the culture expects of everyone, such as greetings, farewells, and expressions of thanks. Gleason was one of the first to study the acquisition of politeness, examining English-speaking children's use of routines such as \"thank you\", \"please\", and \"I'm sorry\". Researchers in this area have since studied both verbal and non-verbal routinization, and the development of politeness routines in a variety of cultures and languages.\n\nGleason's 1976 paper with Weintraub, \"The Acquisition of Routines in Child Language\",\nanalyzed performance on the culturally standardized Halloween Trick-or-treat routine in 115 children aged two to sixteen years.\nAlterations in ability and the function of parental contribution were analyzed concerning cognitive and social components.\nThey discovered that in the acquisition of routines\n(in contrast to acquisition of much of the rest of language) parents' major interest is for their children to achieve accurate performance, with little stress on children's understanding of what they are expected to say.\nGleason and Weintraub found that the parents rarely if ever explain to children the meaning of such routines as \"Bye bye\" or \"Trick or treat\"there was no concern with the child's thoughts or intentions as long as the routine was performed as expected at the appropriate times.\nThus, parents' role in the acquisition of routines is very different from their role in most of the rest of language development.\n\nGleason and Greif analyzed children's acquisition of three ubiquitous routines in \"Hi, Thanks, and Goodbye: More Routine Information\" (1980).\nSubjects were eleven boys and eleven girls and their parents.\nAt the conclusion of a parent–child play period, an assistant entered the playroom bearing a present, in order to evoke routines from the children.\nThe study's purpose was to analyze how parents communicate these routines to their children; major questions proposed included whether or not some routines were more obligatory than others, and whether mothers and fathers provide different models of politeness behavior for their children. The results suggest that children's \"spontaneous\" construction of the three routines was low, with \"Thank you\" the rarest.\nHowever, parents strongly encouraged their children to generate routines and, typically, the children complied.\nIn addition, parents were more likely to prompt the \"Thank you\" routine than the \"Hi\" and \"Goodbye\" routines.\nParents practiced the routines themselves, though mothers were more likely than fathers to speak \"Thank you\" and \"Goodbye\" to the assistant.\n\nGleason and Ely made an in-depth study of apologies in children's dialogue in their paper, \"I'm sorry I said that: apologies in young children's discourse\" (2006),\nwhich analyzed apology term usage (in parent–child dialogue) of five boys and four girls, aged one to six years.\nTheir research suggested that apologies appear later in children than do other politeness routines, and that as the children grew older they developed a progressively refined expertise with this routine, gradually requiring fewer direct prompts and producing more elaborate apologies instead of just saying \"I'm sorry\".\nThey also found that parents and other adults play an important role in fostering growth of apologetic abilities through the setting of examples, by encouraging the children to apologize, and by speaking specifically and purposefully to them about apologies.\n\nWith Ely, MacGibbon, and Zaretsky, Gleason also explored the discourse of middle-class parents and their children at the dinner table in, \"Attention to Language: Lessons Learned at the Dinner Table\" (2001),\nfinding that the everyday language of these parents involves a remarkable portion of attention to language.\nThe dinner-table conversation of twentytwo middle-class families, each with a child between two years and five and onehalf years old, were recorded,\nthen analyzed for the existence and activity of languagecentered terms, including words like \"ask\", \"tell\", \"say\", and \"speak\".\nMothers spoke more about language than did fathers, and fathers spoke more about it than did children:\nroughly eleven percent of mothers' sentences contained one or more languagecentered terms, and the corresponding proportions for fathers and children were seven percent and four percent.\nUses that were metalinguistic (for example, accounting for and remarking on speech) exceeded uses that were pragmatic (for example, managing how and when speech appears).\n\nThe more that mothers used language-centered terms, the more the children did as wellbut this was not true for fathers.\nThe results imply that in routine family conversations, parents supply children with considerable information on the way language is used to communicate information.\n\nGleason has carried out significant research involving the learning and maintenance of second languages by sequential bilinguals. She has studied the acquisition of a second language while retaining the first (additive bilingualism),\nexamining discourse behaviors of parents who follow the one person-one language principle by using different languages with their child\nShe has also studied language attrition, the loss of a known language through lack of use,\nand suggests that the order in which a language is learned is less important in predicting its retention than the thoroughness with which it is learned.\n\nAn unusual study carried out with Harris and Aycicegi, \"Taboo words and reprimands elicit greater autonomic reactivity in a first language than in a second language\" (2003), investigated the involuntary psychophysiological reactions of bilingual speakers to taboo words.\nThirtytwo TurkishEnglish bilinguals judged an array of words and phrases for \"pleasantness\" in Turkish (their first language), and in English (their second), while their skin conductance was monitored via fingertip electrodes.\nParticipants manifested greater autonomic arousal in response to taboo words and childhood reprimands in their first language than to those in their second language, confirming the commonplace claim that speakers of two languages are less uncomfortable speaking taboo words and phrases in their second language than in their native language.\n\nIn \"Maintaining Foreign Language Skills\", which discusses \"the personal, cultural, and instructional factors involved with keeping up foreign language skills\" (1988), Gleason and Pan consider both humans' remarkable capacity for language acquisition and their ability to lose it.\nIn addition to brain damage, strokes, trauma and other physical causes of language loss, individuals may lose language skills due to the absence of a linguistically supportive social environment in which to maintain such skills, such as when a speaker of a given language relocates to a place where that language is not spoken. Culture also factors in. More often than not, individuals speaking two or more languages come into contact with one another, for reasons ranging from emigration and interrelationships to alterations in political borders. The result of such contact is typically that the community of speakers undergoes a progressive shift in usage from one language to the other.\n\nGleason has also done significant research on aphasia,\na condition (usually due to brain injury) in which a person's ability to understand and/or to produce language, including their ability to find the words they need and their use of basic morphology and syntax, is impaired in a variety of ways.\n\nIn \"Some Linguistic Structures in the Speech of a Broca's Aphasic\" (1972) Gleason, Goodglass, Bernholtz, and Hyde discuss an experiment carried out with a man who, after a stroke, had been left with Broca's aphasia/agrammatism,\na specific form of aphasia typically impairing the production of morphology and syntax more than it impairs comprehension.\nThis experiment employed the Story Completion Test (often used to probe a subject's capacity for producing various common grammatical forms)\nas well as free conversation and repetition to elicit speech from the subject;\nthis speech was then analyzed to evaluate how well he used inflectional morphology\n(e.g. plural and past tense word endings) and basic syntax (the formation of, for example, simple declarative, imperative, and interrogative sentences).\n\nTo do this the investigator, in a few sentences, began a simple story about a pictured situation, then asked the subject to conclude the narrative.\nThe stories were so designed that a nonlanguageimpaired person's response would typically employ particular structures, for example the plural of a noun, the past tense of a verb, or a simple but complete yesno question (e.g. \"Did you take my shoes?\").\n\nGleason, Goodglass, Bernholtz, and Hyde concluded that the transition from verb to object was easier for this subject than was the transition from subject to verb, and\nthat auxiliary verbs and verb inflections were the parts of speech most likely to be omitted by the subject. There was considerable variation among consecutive repeat trials of the same test item, although responses on successive attempts usually came closer to those a normal speaker would have produced.\nThe study concluded that the subject's speech was not the product of a stable abnormal grammar, and could not be accounted for by assuming that he was simply omitting words to minimize his effort in producing themquestions\nof significant theoretical controversy at the time.\n\n\n\n"}
{"id": "33908690", "url": "https://en.wikipedia.org/wiki?curid=33908690", "title": "LanguageLine Solutions", "text": "LanguageLine Solutions\n\nLanguageLine Solutions, formerly known as Language Line Services, is an American company headquartered in Monterey, California. It provides on-demand and onsite language interpretation and document translation services worldwide for law enforcement, healthcare organizations, legal courts, schools, and businesses in over 240 languages. LanguageLine has more than 28,000 clients, including 13 of North America's top 14 medical facilities, 18 of the top 20 insurance companies, eight of the top 10 commercial banks, and thousands of government agencies. LanguageLine is the largest interpretation services provider in the world.\n\nThe company fields a workforce that includes more than 9,000 professional interpreters who handle more than 36 million calls each year.\n\nIn addition to phone interpreting, the company also offers video remote and onsite interpreting, translation and localization services, and language proficiency testing and training.\n\nIn its earlier years, the company was known as CALL (Communication And Language Line) and was formed by Jeff Munks and Michael McFerrin. Jeff Munks was a San Jose, California, policeman Michael McFerrin mastered the Vietnamese language as a US Marine stationed in Vietnam during the Vietnam War. He returned to Northern California and worked as a refugee advocate. The two men founded Language Line Services in 1982 to help police officers communicate with 65,000 Vietnamese refugees.\n\nAT&T acquired the service on February 14, 1990,as a strategic business unit. AT&T Language Line Services received significant investments in technology and interpreter quality, creating standards for the emerging telephone interpreting industry. For a decade, the company served as a vital resource for business, government and health care clients who faced changing demographics and state and federal laws and regulations in the 1990s.\n\nIn 1999, the company became an independent entity, today known as LanguageLine Solutions. The organization that began as a pioneer of the telephone interpreting business broadened its offerings to serve the increasingly complex market. In addition to phone interpreting, the company also offers video remote and onsite interpreting, translation and localization services, and language proficiency testing and training. \n\nScott W. Klein was named CEO on June 21, 2012.\n\nOn September 16, 2016, LanguageLine Solutions was acquired by Teleperformance, the worldwide leader in outsourced omnichannel customer experience management. Teleperformance has stated that LanguageLine will continue to operate as a stand-alone business, headquartered in Monterey, California.\n\n"}
{"id": "221917", "url": "https://en.wikipedia.org/wiki?curid=221917", "title": "Language code", "text": "Language code\n\nA language code is a code that assigns letters or numbers as identifiers or classifiers for languages. These codes may be used to organize library collections or presentations of data, to choose the correct localizations and translations in computing, and as a shorthand designation for longer forms of language-name.\n\nLanguage code schemes attempt to classify the complex world of human languages, dialects, and variants. Most schemes make some compromises between being general and being complete enough to support specific dialects.\n\nFor example, most people in Central America and South America speak Spanish. Spanish spoken in Mexico will be slightly different from Spanish spoken in Peru. Different regions of Mexico will have slightly different dialects and accents of Spanish. A language code scheme might group these all as \"Spanish\" for choosing a keyboard layout, most as \"Spanish\" for general usage, or separate each dialect to allow region-specific idioms.\n\nSome common language code schemes include:\n\n\n"}
{"id": "15735703", "url": "https://en.wikipedia.org/wiki?curid=15735703", "title": "Languages of Turkmenistan", "text": "Languages of Turkmenistan\n\nTurkmen (Turkic language / Oghuz language ) is the official language of Turkmenistan (per the 1992 Constitution), although Russian still is widely spoken in cities as a \"language of inter-ethnic communication\". \n\nTurkmen is spoken by 72% of the population, Russian 12%, Uzbek 9%, and other languages 7%.\n\n\n"}
{"id": "65373", "url": "https://en.wikipedia.org/wiki?curid=65373", "title": "Lingua franca", "text": "Lingua franca\n\nA lingua franca (; ), also known as a bridge language, common language, trade language, auxiliary language, vehicular language, or link language is a language or dialect systematically used to make communication possible between people who do not share a native language or dialect, particularly when it is a third language that is distinct from both of the speakers' native languages.\n\nLingua francas have developed around the world throughout human history, sometimes for commercial reasons (so-called \"trade languages\" facilitated trade) but also for cultural, religious, diplomatic and administrative convenience, and as a means of exchanging information between scientists and other scholars of different nationalities. The term is taken from the medieval Mediterranean Lingua Franca, a Romance-based pidgin language used by European merchants and sailors during the 2nd millennium. A world language – a language spoken internationally and learned and spoken by a large number of people – is a language that may function as a global lingua franca.\n\nLingua Franca refers to any language used for communication between people who do not share a native language. It can refer to hybrid languages such as pidgins and creoles used for communication between language groups. It can also refer to languages which are native to one nation (often a colonial power) but used as a second language for communication between groups. Finally, lingua franca can refer to a third language which allows inter-comprehension among people speaking different mother tongues as a neutral language or jargon of which nobody can claim ownership. Lingua Franca is a functional term, independent of any linguistic history or language structure. \n\nWhereas a vernacular language is the native language of a specific geographical community, a lingua franca is used beyond the boundaries of its original community, for trade, religious, political or academic reasons. For example, English is a vernacular in the United Kingdom but is used as a lingua franca in the Philippines. Arabic, French, Mandarin Chinese, Spanish, Portuguese, and Russian, serve a similar purpose as industrial/educational lingua francas, across regional and national boundaries.\n\nInternational auxiliary languages such as Esperanto and Lingua Franca Nova have not had a great degree of adoption globally so they cannot be described as global lingua francas.\n\nThe term \"lingua franca\" derives from Mediterranean Lingua Franca, the \"language of the Francs\", \"Francs\" being the term used to refer to all Western Europeans as opposed to the Greeks — is considered to be a translation of the Arab lûghat al-Ifranj, which appears for the first time in an Arabic text from the 9th century. However, Western speakers and their contemporaries only began to use the term \"lingua franca\" to describe this phenomenon at the beginning of the 16th century and the language that people around the Levant and the eastern Mediterranean Sea used as the main language of commerce and diplomacy from late medieval times, especially during the Renaissance era, to the 18th century and allowed communication between the people living, fighting in the area without becoming the vernacular language of any of them. At that time, Italian-speakers dominated seaborne commerce in the port cities of the Ottoman Empire and a simplified version of Italian, including many loan words from Greek, Old French, Portuguese, Occitan, and Spanish as well as Arabic and Turkish came to be widely used as the \"lingua franca\" (in the generic sense used) of the region.\n\nIn Lingua Franca (the specific language), \"lingua\" means a language, as in Portuguese and Italian, and \"franca\" is related to \"phrankoi\" in Greek and \"faranji\" in Arabic as well as the equivalent Italian. In all three cases, the literal sense is \"Frankish\", but the name actually applied to all Western Europeans during the late Byzantine Empire.\n\nThe Douglas Harper Etymology Dictionary states that the term \"Lingua Franca\" (as the name of the particular language) was first recorded in English during the 1670s, although an even earlier example of the use of \"Lingua Franca\" in English is attested from 1632, where it is also referred to as \"Bastard Spanish\".\n\nAs recently as the late 20th century, some restricted the use of the generic term to mean only hybrid languages that are used as vehicular languages, its original meaning, but it now refers to any vehicular language.\n\nThe term is well established in its naturalization to English, which is why major dictionaries do not italicize it as a \"foreign\" term. Its plurals in English are lingua francas and linguae francae, with the first of those being first-listed or only-listed in major dictionaries.\n\nThe use of lingua francas has existed since antiquity. The first example of lingua franca in the ancient world, before Greek and Latin, was Aramaic. Latin and Koine Greek were the lingua francas of the Roman Empire and the Hellenistic culture. Akkadian (died out during Classical antiquity) and then Aramaic remained the common languages of a large part of Western Asia from several earlier empires. \n\nIn certain countries, the lingua franca is also the national language. Indonesian has the same function in Indonesia, although Javanese has more native speakers. Still, Indonesian is the sole official language and is spoken throughout the country. Also Persian is both the lingua franca of Iran and its national language.\n\nThe Hindustani language (Hindi-Urdu) is the lingua franca of Pakistan and Northern India. Many Indian states have adopted the Three-language formula in which students in Hindi speaking states are taught: \"(a) Hindi (with Sanskrit as part of the composite course); (b) Urdu or any other modern Indian language and (c) English or any other modern European language.\" The order in non-Hindi speaking states is: \"(a) the regional language; (b) Hindi; (c) Urdu or any other modern Indian language excluding (a) and (b); and (d) English or any other modern European language.\" Hindi has also emerged as a lingua franca for the locals of Arunachal Pradesh, a linguistically diverse state in Northeast India.It is estimated that 90 percent of the state's population knows Hindi.\n\nThe only documented sign language used as a lingua franca is Plains Indian Sign Language, used across much of North America. It was used as a second language across many indigenous peoples. Alongside or a derivation of Plains Indian Sign Language was Plateau Sign Language, now extinct. Inuit Sign Language could be a similar case in the Arctic among the Inuit for communication across oral language boundaries, but little research exists.\n\nIn the European Union, the use of English as a lingua franca has led to the emergence of a new dialect called Euro English.\n\n\n\n"}
{"id": "608935", "url": "https://en.wikipedia.org/wiki?curid=608935", "title": "Marginalia", "text": "Marginalia\n\nMarginalia (or apostils) are marks made in the margins of a book or other document. They may be scribbles, comments, glosses (annotations), critiques, doodles, or illuminations.\n\nBiblical manuscripts have liturgical notes at the margin, for liturgical use. Numbers of texts' divisions are given at the margin (κεφάλαια, Ammonian Sections, Eusebian Canons). There are some scholia, corrections and other notes usually made later by hand in the margin. Marginalia may also be of relevance because many ancient or medieval writers of these marginalia may have had access to other relevant texts that, although they may have been widely copied at the time, have since then been lost due to wars, prosecution or censorship. As such, they might give clues to an earlier, more widely known context of the extant form of the underlying text than is currently appreciated. For this reason, scholars of ancient texts usually try to find as many still existing manuscripts of the texts they are researching, because the notes scribbled in the margin might contain additional clues to the interpretation of these texts.\n\nThe scholia on classical manuscripts are the earliest known form of marginalia. Fermat's last theorem is the most famous mathematical marginal note. The first recorded use of the word \"marginalia\" is in 1819 in \"Blackwood's Magazine\". From 1845 to 1849 Edgar Allan Poe titled some of his reflections and fragmentary material \"Marginalia.\" Five volumes of Samuel T. Coleridge's marginalia have been published. Some famous marginalia were serious works, or drafts thereof, written in margins due to scarcity of paper. Voltaire composed in book margins while in prison, and Sir Walter Raleigh wrote a personal statement in margins just before his execution. Beginning in the 1990s, attempts have been made to design and market e-book devices permitting a limited form of marginalia.\nMarginalia can add to or detract from the value of an association copy of a book, depending on the author of the marginalia and on the book.\n\nCatherine C. Marshall, doing research on the future of user interface design, has studied the phenomenon of user annotation of texts. She discovered that in several university departments, students would scour the piles of textbooks at used book dealers for consistently annotated copies. The students had a good appreciation for their predecessors' distillation of knowledge. In recent years, the marginalia left behind by university students as they engage with library textbooks has also been a topic of interest to sociologists looking to understand the lived experience of being a university student.\n\nAmerican poet Billy Collins has explored the phenomenon of annotation within his poem titled 'Marginalia'.\n\n\n\n"}
{"id": "4153402", "url": "https://en.wikipedia.org/wiki?curid=4153402", "title": "Meaning (semiotics)", "text": "Meaning (semiotics)\n\nIn semiotics, the meaning of a sign is its place in a sign relation, in other words, the set of roles that it occupies within a given sign relation. \n\nThis statement holds whether \"sign\" is taken to mean a \"sign type\" or a \"sign token\". Defined in these global terms, the meaning of a sign is not in general analyzable with full exactness into completely localized terms, but aspects of its meaning can be given approximate analyses, and special cases of sign relations frequently admit of more local analyses.\n\nTwo aspects of meaning that may be given approximate analyses are the \"connotative relation\" and the \"denotative relation\". The connotative relation is the relation between signs and their interpretant signs. The denotative relation is the relation between signs and objects. An arbitrary association exists between the \"signified\" and the \"signifier.\"\nFor example, a US salesperson doing business in Japan might interpret silence following an offer as rejection, while to Japanese negotiators silence means the offer is being considered. This difference in interpretations represents a difference in: semiotics\n\nThe triadic (three part) model of the sign separates the meaning of a sign into three distinct components:\n\n1.The representamen, which is the medium, or ‘sign vehicle’, through which the sign is represented. For example, this could be written/spoken words, a photograph, or a painting.\n\n2.The interpretant, or what is meant by the sign \n\n3. The object, or that to which the sign refers \n\nTogether, these three components generate semiosis. For example, an exclamation mark can be broken down into these components. The representamen is the exclamation mark itself, the interpretant is the idea of excitement or an elevated volume of speech, and the object is the actual excitement or elevated volume of speech to which it refers.\nWhile it might appear that the latter two are the same, the subtle difference lies in the fact that the interpretant refers to the idea of something, and the object is the thing itself.\n\nThe representamen component of the sign can be further broken down into three categories, which are icon, index, and symbol. These denote the degree of abstraction from the object to which they refer. A symbol, which is the most abstract, does not resemble or bear any physical relation to the thing that it represents in any way. For example, a peace sign has no relation to peace aside from its social construction as a symbol that represents it. An icon is slightly less abstract, and resembles to some degree the thing that it represents, and bears some physical likeness to it. A good example of this would be a painted portrait. An index is the least arbitrary category of representamen, and has a definite physical tie to that which it represents. This could be something like a weather vane blowing in the wind indicating that it is windy out, or smoke, which indicates a fire.\n\nThe triadic model of the sign was proposed by Charles Peirce. In contradistinction to Ferdinand de Saussure's dyadic model, which assumed no material referent, Peirce's model assumes that in order for a sign to be meaningful, it must refer to something external and cannot be self-contained, as it is for Saussure. Thus, Peirce's model includes the addition of an 'object'. The ‘representamen’ and ‘interpretant’ components of the triadic model are comparable to Saussure’s dyadic model of the sign, which breaks down into signifier and signified.\n\n\n"}
{"id": "3289566", "url": "https://en.wikipedia.org/wiki?curid=3289566", "title": "Metalinguistics", "text": "Metalinguistics\n\nMetalinguistics is the branch of linguistics that studies language and its relationship to other cultural behaviors. It is the study of dialogue relationships between units of speech communication as manifestations and enactments of co-existence. Jacob L. Mey in his book, \"Trends in Linguistics\", describes Mikhail Bakhtin's interpretation of metalinguistics as \"encompassing the life history of a speech community, with an orientation toward a study of large events in the speech life of people and embody changes in various cultures and ages.\"\n\nJean-Émile Gombert, teaching genetic psychology at Dijon University, France, states that one thing is to find an adequate way to treat the comprehension and the production of language, and another is to successfully adopt a reflexive attitude regarding the language objects and their manipulation. This is the second time that a psycholinguistic tradition recently developed has been given the name metalinguistics.\n\nThe linguist Noam Chomsky defines the field of metalinguistics as the subject knowledge of the characteristics and the operation of language or, from a more functionalist perspective, of its structure, its operation and its use. The relevant psychological description cannot be based on abstraction, it requires that the researchers and theorists widen their scopes till the point they can embrace the importance of the behavioural actions in the cognitive context of the subjects that realise them. The French linguist Jules Gilliéron wrote that \"All consciousness is necessarily 'meta' from the vantage point of the beholder, as it is not based on the real, but on its intelligibility of the real\".\n\nMetalinguistic skills involve amplified and logical understanding of the rules used to govern language. Scholar Patrick Hartwell points out how substantial it is for students to develop these capabilities, especially heightened phonological awareness, which is a key precursor to literacy. An essential aspect to language development is focused on the student being aware of language and the components of language.\n\nThis idea is also examined in the article, 'Metalinguistic Awareness and Literacy Acquisition in Different Languages', that centers on how the construction of a language and writing strategy shape an individual's ability to read. It also discusses the manner in which bilingualism increases particular elements of metalinguistic awareness.\n\nPublished research studies by Elizabeth McAllister have concluded that metalinguistic abilities are associated to cognitive development and is contingent on metalinguistic awareness which relates to reading skill level, academic success and cultural environment that starts at infancy and continues through preschool.\n\nAccording to \"Text in Education and Society\", some examples of metalinguistic skills include discussing, examining, thinking about language, grammar and reading comprehension. The text also states that a student's recognition or self-correction of language in verbal and written form helps them further advance their skills. The book also illustrates manners in which literature can form connections or create boundaries between educational intelligence and practical knowledge.\n\nGail T. Gillion wrote the book, \"Phonological Awareness\", which illustrates the connection between phonological awareness and metalinguistic awareness's in literacy learning. It essentially states that a student's ability to understand the spoken word and their ability to recognize a word and decode it are dependent on each other. The text also discusses ways in which students struggling with speech impairments and reading difficulties can improve their learning process.\n\nLinguists use this term to designate activities associated with \"metalanguage\", a language composed of the entirety of words forming linguistic terminology (for example, syntax, semantics, phoneme, lexeme... as well as terms in more current usage, such as word, sentence, letter, etc.) Metalinguistics is used to refer to the language, whether natural or formalized (as in logic), which is itself used to speak of language; to a language whose sole function is to describe a language. The language itself must constitute the sole sphere of application for the entire vocabulary.\nExperts are undecided about the value of awareness of metalanguage to language learners, and some \"schools of thought\" in language learning have been heavily against it.\n\nMetalinguistic awareness refers to the understanding that language is a system of communication, bound to rules, and forms the basis for the ability to discuss different ways to use language (Baten, Hofman, & Loeys, 2011). In other words, it is the ability to consciously analyze language and its sub-parts, to know how they operate and how they are incorporated into the wider language system (Beceren, 2010). An individual with such ability is aware that linguistic forms and structure can interact and be manipulated to produce a vast variety of meanings. Words are only arbitrarily and symbolically associated with their referents, and are separable from them. For example, a dog is named \"Cat\", but the word \"Cat\" is only a representation for the animal, dog. It does not make the dog a cat.\n\nThe term was first used by Harvard professor Courtney Cazden in 1974 to demonstrate the shift of linguistic intelligence across languages. Metalinguistic awareness in bilingual learners is the ability to objectively function outside one language system and to objectify languages’ rules, structures and functions. Code-switching and translation are examples of bilinguals’ metalinguistic awareness. Metalinguistics awareness was used as a construct in research extensively in the mid 1980s and early 1990s.\nMetalinguistic awareness is a theme that has frequently appeared in the study of bilingualism. It can be divided into four subcategories, namely phonological, word, syntactic and pragmatic awareness (Tunmer, Herriman, & Nesdale, 1988). Amongst the four, phonological and word awareness are the two aspects of metalinguistic awareness that have garnered the greatest attention in bilingual literacy research. Research has shown metalinguistic awareness in bilinguals to be a crucial component because of its documented relationship and positive effects on language ability, symbolic development and literacy skills. Indeed, many studies investigating the impact of bilingualism on phonological and word awareness have indicated a positive bilingual effect (Baten, et al., 2011; Chen et al., 2004; Goetz, 2003; Kang, 2010; Ransdell, Barbier, & Niit, 2006; Whitehurst & Lonigan, 1998). Bilinguals are simultaneously learning and switching between two languages, which may facilitate the development of stronger phonological awareness. It is postulated that bilinguals’ experiences of acquiring and maintaining two different languages aid them in developing an explicit and articulated understanding of how language works (Adesope, Lavin, Thompson, & Ungerleider, 2010). Hence they are equipped with stronger metalinguistic awareness as compared to their monolingual counterparts.\n\nIn their book \"Literacy and Orality\", scholars David R. Olson and Nancy Torrance explore the relationship between literacy and metalinguistic awareness, citing a link that arises from the fact that, in both reading and writing, language can become the object of thought and discussion. Prose reading and writing can be an instrument of metalinguistic reflection and in those cases one must assess the particular meaning of terms and of grammatical relations between them in order, either to understand such texts or write them.\n\n\n"}
{"id": "20837956", "url": "https://en.wikipedia.org/wiki?curid=20837956", "title": "Mitigated speech", "text": "Mitigated speech\n\nMitigated speech is a linguistic term describing deferential or indirect speech inherent in communication between individuals of perceived High Power Distance which has been in use for at least two decades with many published references. \n\nThe term was popularized by Malcolm Gladwell in his book, \"Outliers\", where he defines mitigated speech as \"any attempt to downplay or sugarcoat the meaning of what is being said\". He continues with reference to Fischer and Orasanu, to describe 6 degrees of mitigation with which we make suggestions to authority: \n\n\nGladwell brings up the concept in the context of how crews relate to each other in the cockpit of a commercial airliner, graphically illustrating the degree to which mitigated speech can be detrimental in high-risk situations which require clear communication.\n\n\n"}
{"id": "21173", "url": "https://en.wikipedia.org/wiki?curid=21173", "title": "Natural language", "text": "Natural language\n\nIn neuropsychology, linguistics, and the philosophy of language, a natural language or ordinary language is any language that has evolved naturally in humans through use and repetition without conscious planning or premeditation. Natural languages can take different forms, such as speech or signing. They are distinguished from constructed and formal languages such as those used to program computers or to study logic.\n\nThough the exact definition varies between scholars, natural language can broadly be defined in contrast to artificial or constructed languages (such as computer programming languages and international auxiliary languages) and to other communication systems in nature. Such examples include bees' waggle dance and whale song, to which researchers have found or applied the linguistic cognates of dialect and even syntax. \n\nAll language varieties of world languages are natural languages, although some varieties are subject to greater degrees of published prescriptivism or language regulation than others. Thus nonstandard dialects can be viewed as a wild type in comparison with standard languages. But even an official language with a regulating academy, such as Standard French with the French Academy, is classified as a natural language (for example, in the field of natural language processing), as its prescriptive points do not make it either constructed enough to be classified as a constructed language or controlled enough to be classified as a controlled natural language.\n\nControlled natural languages are subsets of natural languages whose grammars and dictionaries have been restricted in order to reduce or eliminate both ambiguity and complexity (for instance, by cutting down on rarely used superlative or adverbial forms or irregular verbs). The purpose behind the development and implementation of a controlled natural language typically is to aid non-native speakers of a natural language in understanding it, or to ease computer processing of a natural language. An example of a widely used controlled natural language is Simplified English, which was originally developed for aerospace industry maintenance manuals.\n\nConstructed international auxiliary languages such as Esperanto and Interlingua (even those that have native speakers) are not generally considered natural languages. Natural languages have been used to communicate and have evolved in a natural way, whereas Esperanto was designed by L.L. Zamenhof selecting elements from natural languages, not grown from natural fluctuations in vocabulary and syntax. Some natural languages have become naturally \"standardized\" by children's natural tendency to correct for illogical grammatical structures in their parents' speech, which can be seen in the development of pidgin languages into creole languages (as explained by Steven Pinker in \"The Language Instinct\"), but this is not the case in many languages, including constructed languages such as Esperanto, where strict rules are in place as an attempt to consciously remove such irregularities. The possible exception to this are true native speakers of such languages. More substantive basis for this designation is that the vocabulary, grammar, and orthography of Interlingua are natural; they have been standardized and presented by a linguistic research body, but they predated it and are not themselves considered a product of human invention. Most experts, however, consider Interlingua to be naturalistic rather than natural. Latino Sine Flexione, a second naturalistic auxiliary language, is also naturalistic in content but is no longer widely spoken.\n\n\n"}
{"id": "14885290", "url": "https://en.wikipedia.org/wiki?curid=14885290", "title": "New Philology", "text": "New Philology\n\nNew Philology generally refers to a branch of Mexican ethnohistory and philology that uses colonial-era native language texts written by Indians to construct history from the indigenous point of view. The name New Philology was coined by James Lockhart to describe work that he and his doctoral students and scholarly collaborators in history, anthropology, and linguistics had pursued since the mid-1970s. Lockhart published a great many essays elaborating on the concept and content of the New Philology and Matthew Restall published a description of it in the \"Latin American Research Review.\" The techniques of the New Philology have also been applied in other disciplines such as European medieval studies. \nLockhart's discusses philology and in particular the new philology in an essay for a collection of essays hosted digitally at University of Oregon. For him, the new philology was built upon the foundation of the old, which focuses on close reading of texts and resulted in collections of printed documentation. An important nineteenth-century Mexican philologist was Joaquín García Icazbalceta. In Mexico and Latin America, nineteenth-century scholars mined the Spanish archives for colonial documentation for their national histories. A feature of the New Philology is that the publication of indigenous texts in the original language with translations with introductions was standard. The translated texts often appeared first, followed by a separate scholarly monograph analyzing the texts. The two should be considered two parts of the same scholarly publication. Many of the scholars working in the New Philology did so before it gained that designation. A particularly valuable online publication are essays where individual scholars discuss the process and product of translating and publishing particular native language documentation.\n\nThe New Philology was developed from the 1970s and onwards, building on the work of a previous generation of scholars, most especially historian Charles Gibson, whose \"Aztecs under Spanish Rule\" (1964) and his earlier \"Tlaxcala in the Sixteenth Century\" (1952) were major scholarly achievements, placing colonial-era Aztecs (now more commonly called Nahuas) at the center of historical analysis. The leading figure in the establishment of the New Philological historiographical approach was James Lockhart who, in the early 1970s, began learning Nahuatl and studying local level indigenous sources in the Nahuatl language. His magnum opus was published in 1992, \"The Nahuas After the Conquest.\", which incorporated and extended his own work and that of others.\n\nAn early and important text in this vein was \"Nahuatl in the Middle Years\" (1976), published by Lockhart and University of Texas linguist Frances Karttunen. Also important for the early history of the New Philology was the publication of \"Beyond the Codices\" (1976), alluding to the existence of native language texts other than the formal ones termed codices. Arthur J. O. Anderson, a leading figure in Mesoamerican ethnohistory for his collaboration with Charles Dibble in publishing an English translation of the Florentine Codex by Franciscan Bernardino de Sahagún, participated in this early project of publishing local-level colonial documents.\n\nIn the mid-1970s Lockhart began mentoring history doctoral students at UCLA, who learned Nahuatl and began research on particular region documentation in Nahuatl. Sarah Cline was the first to complete a dissertation in 1981, based on these types of local-level sources, a set of 60 testaments from the central Mexican Indian polity or \"altepetl\" of Culhuacán. In 1993 Cline also published a set of early local-level Nahuatl censuses from the Cuernavaca, as \"The Book of Tributes\", as well as an analysis of all three volumes, adding to the existing published corpus. In this first generation Robert Haskett, who examined Nahuatl texts on colonial Cuernavaca, later also publishing on primordial titles. Susan Schroeder delved into the rich texts produced by seventeenth-century Nahua historian, Chimalpahin, resulting in several publications The largest number of local-level indigenous documents, such as testaments and bills of sale, are in Nahuatl, resulting in Nahuatl having the largest set of published sets of documents and monographic scholarly analyses. Rebecca Horn's dissertation on Coyoacan and later Stanford University Press monograph showed the multiple connections between Nahuas and Spaniards. Horn also served as associate editor of the UCLA Latin American Center's Nahuatl Studies Series.\n\nSome UCLA later doctoral students of Lockhart, particularly Matthew Restall and Kevin Terraciano, first learned Nahuatl and then other Mesoamerican indigenous languages (Mixtec and Yucatec Maya) that had a significant corpus of documents in the language. Restall's UCLA 1995 dissertation \"The World of the Cah: postconquest Yucatec Maya Society\" was followed by his 1995 publication of a collection of eighteenth-century wills. and culminating in his Stanford University Press monograph, \"The Maya World: Yucatec culture and society, 1550-1850.\" Terraciano's 1994 dissertation on the Mixtecs of Oaxaca entitled \"Ñudzahui history: Mixtec writing and culture in colonial Oaxaca\" was followed by his 2001 monograph \"The Mixtecs of Colonial Oaxaca: Ñudzahui History\". Both Terraciano and Restall revised the titles of their dissertations in the published monographs to allow better recognition by readers of the publication's subject; Cline used \"Aztec\" in the title of her monograph on Culhuacan, rather than \"Nahua\", which in the 1980s had little recognition value even among specialists on Latin American cultures.\n\nLauren Lambert Jennings explicitly applied techniques from New Philology to the study of European Song texts quoting their \"central premise [as] the idea that codex is not merely a neutral container for its texts.\" She continued by saying that the New Philologists and scholars of \"textual cultures\" \"posit that a work's meaning (literary and cultural) is determined by the entire manuscript matrix — its physical form, contents, scribe(s), readers, and history.\"\n\n"}
{"id": "32115315", "url": "https://en.wikipedia.org/wiki?curid=32115315", "title": "Pimsleur Language Programs", "text": "Pimsleur Language Programs\n\nPimsleur Language Programs () is an American language learning company that develops and publishes courses based on the Pimsleur method.\n\nDr. Paul Pimsleur, a professor and expert in applied linguistics and a founding member of the American Council on the Teaching of Foreign Languages (ACTFL), wrote the original 5 courses: Speak & Read Essential Greek (1963), Speak & Read Essential French (1964), Speak & Read Essential Spanish (1966), German Compact (1967), and Twi developed for the Peace Corps (1971). The programs were originally called \"A Tapeway Program\".\n\nStarting in 1969-70, having tried unsuccessfully to market the programs, Pimsleur gave them to Charles A.S. and Beverly Heinle at The Center for Curriculum Development in Philadelphia. The courses were repackaged and marketed as \"CCD/Tapeway Programs\". In 1974, Charles Heinle bought the rights to Pimsleur and set up Heinle & Heinle Enterprises. In the 1980s, Heinle opened the Cassette Learning Centers, a stand in the Harvard Coop, in Cambridge, Massachusetts. Prospective users were invited to sit down and experience \"The Pimsleur Tape\". \"The Pimsleur Tapes\" were published by Heinle & Heinle Enterprises based in Concord, MA.\n\nIn 1983 Charles Heinle introduced SyberVision Systems founder Steven DeVore to the Pimsleur Russian program. DeVore, who had used a similar method to learn Finnish, exclusively licensed the Pimsleur programs. DeVore sold the programs in SyberVision's catalogs that were placed in the backseat pockets of major international air carriers and also mailed to 3 million SyberVision customers every month. SyberVision also produced and successfully sold Pimsleur programs via an infomercial that featured Beverly Pimsleur. SyberVision marketed the Pimsleur programs until 1997 before the license was sold to Simon & Schuster.\n\nIn 1995, Simon & Schuster took on distribution to bookstores. Before Heinle & Heinle Enterprises sold Pimsleur to Simon & Schuster in 1997, they added 27 new languages to the Pimsleur catalog. Since the acquisition, Simon & Schuster Audio has added another 27 languages. Pimsleur's catalog currently stands at 59 languages and over 200 courses. The courses are still produced in Concord, MA and are available as digital audio downloads, CDs, and select languages are now available in interactive software format.\n\nIn 2005, digital editions of some languages were made available through various resellers.\n\nIn 2008, Pimsleur's first children's line, Speak Spanish with Dora & Diego, was released in coordination with Nickelodeon's Nick Jr.\n\nIn 2008, Playaway was licensed to distribute the entire Pimsleur line to the military on pre-loaded players.\n\nIn 2010, Pimsleur donated its Haitian Creole course for free to relief and charity workers after the devastating earthquake in Haiti.\n\nIn 2010, Pimsleur partnered with the USO, The Boston Foundation and Playaway to produce Pashto and Dari courses for U.S. troops serving in and being deployed to Afghanistan. This course is available for free to all military personnel. Operation Speak Easy was funded by a Boston-area philanthropist and Pimsleur-enthusiast.\n\nIn 2010, Pimsleur Digital line was relaunched in DRM-free format and at a new low price.\n\nIn 2011, Pimsleur donated 8 hours of its Japanese course to support aid agencies and volunteers in the wake of the tsunami disaster.\n\nIn 2012, Pimsleur released a new interactive software version of their Spanish, German, French, and Italian courses called Pimsleur Unlimited.\n\nIn 2013, Pimsleur celebrated its 50th anniversary with the launch of a new blog Pimsleur Speaks: On Language, Learning, and Culture.\n\nIn 2013, Pimsleur donated 15 lessons of its Tagalog course to support aid agencies and volunteers in the wake of Typhoon Haiyan.\n\nIn 2015, Pimsleur released 3 additional Unlimited languages (Mandarin, Portuguese, and Russian) in its interactive software format.\n\nIn 2016, Pimsleur made its Unlimited product line available as digital downloads worldwide.\n\nPimsleur Language Programs is owned by Simon & Schuster Audio, a division of Simon & Schuster, which is part of CBS Corporation.\n\n\nPimsleur Language Programs' courses are available in the following languages:\n\n\n"}
{"id": "17504079", "url": "https://en.wikipedia.org/wiki?curid=17504079", "title": "Reply", "text": "Reply\n\nA reply is a statement or acknowledgment made in response to an interrogative question, request or comment. Replies are communicated in a variety of ways, the most common being spoken or written, and act as a way of conveying relevant information and continuing a conversational exchange.\n\nA simple reply can take the form of a single word, such as \"yes\" or \"no\", or can be expressed via body language, such as nodding the head, winking, shaking the head, et cetera.\n\n"}
{"id": "54540850", "url": "https://en.wikipedia.org/wiki?curid=54540850", "title": "Ronde script (calligraphy)", "text": "Ronde script (calligraphy)\n\nRonde (\"round\" in French) is a kind of script in which the heavy strokes are nearly upright, giving the characters when taken together a round look.\n\nRonde script appeared in France at the end of the 16th century, and was popularized by writing masters such as Louis Barbedor in the 17th century. In its original form, it borrowed some of its letterforms from the round Gothic style. This style of writing was still in use (with some modifications) until the 20th century because it was used in French school manuals to teach the bases of cursive writing. It was also commonly used by the scribes of the French Ministry of Finance until right after World War II, which gave this style the name of \"écriture ronde finnancière\" (\"round financial writing\", not to be confused with the \"financière\" writing style).\n\nThe classic French rondes where also very present in the work of 18th century type founder and calligrapher Nicholas Gando, which has been revived for the digital medium by way of the French 111 font.\n"}
{"id": "17731828", "url": "https://en.wikipedia.org/wiki?curid=17731828", "title": "Saam kap dai", "text": "Saam kap dai\n\nSaam kap dai （; IPA: ） is a writing style combining Classical Chinese, Cantonese and Standard Chinese. The articles and stories written in saam kap dai first appeared in Canton (Guangzhou) newspapers in the 1940s to 1950s. It became more popular in Hong Kong newspapers from the late 1940s to the 1960s.\n\nThe use of different style of Chinese gives the article varied tones. Sentences in Classical Chinese give the formal tone. Standard Chinese is usually neutral. Cantonese gives an impression of colloquial, local speech and slang.\n"}
{"id": "3911668", "url": "https://en.wikipedia.org/wiki?curid=3911668", "title": "Screaming", "text": "Screaming\n\nA scream, shout, yell, shriek, hoot, holler, vociferation, outcry, bellow, or raising one's voice, is a loud vocalization in which air is passed through the vocal folds with greater force than is used in regular or close-distance vocalisation. This can be performed by any creature possessing lungs, including humans. There are slight differences in meaning among them; for example, \"scream\" and \"shriek\" generally refer to a higher-pitched, sharp sound, used by some birds and other animals, and a \"hoot\", such as emitted by an owl, usually does not involve words.\n\nA scream is often an instinctive or reflex action, with a strong emotional aspect, like fear, pain, surprise, joy, anger, etc.\n\nA large number of words exist to describe the act of making loud vocalizations, whether intentionally or in response to stimuli, and with specific nuances. For example, an early twentieth century synonym guide places variations under the heading of \"call\", and includes as synonyms, bawl, bellow, clamor, cry (out), ejaculate, exclaim, roar, scream, shout, shriek, vociferate, and yell, each with its own implications. This source states:\n\nAnother source proposes different implications for some of these terms, stating that \"the call is normally addressed to a specific person... and the shout projected to a distant but identifiable target, the holler is emitted to whomever may be within earshot\". Whooping is another name given to the same kind of noise making as hollering. This source separately notes that a shout \"may be angry or joyous; it may be directed to one person or many; and, sometimes, its purpose may be merely for the satisfaction of release or of hearing an echo\".\n\nIn psychology the scream is an important theme in the theories of Arthur Janov. In his book \"The Primal Scream\", Janov claims that the cure for neurosis is to confront the patient with his suppressed pain resulting from an experienced trauma. This confrontation gives birth to a scream. Janov believes that it is not necessary that it heals the patient from his trauma. The scream is only a form of expression of primal pain, which comes from one’s childhood, and the reliving of this pain and its expression. This finally appears through the scream and can cure the patient from his neurosis.\n\nJanov describes the primal scream as very distinctive and unmistakable. It is a “strangely low, rattling and involuntary sound. […] Some people are moaning, groaning and are coiling themselves up. […] One screams as result of all the other times when it had to stay still, was making fun of, was humiliated or was beaten up”. Janov also says that the primal scream has series of reactions; “the patients that could not even say “piep” at home, suddenly feels powerful. The scream seems to be a liberating experience”. Janov noticed this with all his patients. Women who seem to have baby-voices during the therapy are developing with their primal scream a very low voice.\n\nGregory Whitehead, founder of the \"Institute for Screamscape Studies\", believes that the voice is used to focus the power: “scream used to be a psychological weapon both for you and against your opponent, it raises confidence to the person using it. Creating power with yell is having to affect someone without touching them”. In this case screaming is a protective weapon, as also often used by animals, who scream as an expression of power or during fights with another animals.\n\nScreaming and yelling are also a means of expressing pleasure. Studies on monkeys have shown that when female monkeys scream during sex, it helps the male ejaculate. An approximation of 86 percent of the times, where female monkeys screamed during sexual encounter, brought a 59 percent of success rate, in comparison to the 2 percent, without the female-scream.\nGayle Brewer of the University of Central Lancashire and Colin Hendrie of the University of Leeds made a similar research with women, that shows that women also do scream often during intercourse as an encouragement for their partner to do \"a better job\".\n\nGregory Whitehead defines the giving birth scream as a \"yes scream\", because it expresses an opening into the world for a new human who begins life by screaming. Women describe this scream as unpremeditated and a reaction to the surprise of the baby’s head coming out. Some actually call this moment \"orgasmic pleasure\".\n\nThis moment is considered by most women to be very euphoric, that apparently some women are screaming of pain, pleasure and enthusiasm at the same time.\n\nIna May Gaskin, one of the biggest promoters of the natural birth, is also encouraging women to make out with their man during birth as this helps their state of mind.\n\nReni Celeste, film philosopher and publisher, notes about Michel Chion, composer, that he “locates the scream in the voice of the female and compares it to the female orgasm. The male, he explains, does not scream, he shouts. The shout marks territory, exercising will and structure. Tarzan shouts. The female scream reaches the infinite, it is a sound or cry at the brink of death. The male shout structures, the female scream opens a black hole to the limitless. The male director seeks to master the scream but he cannot-just as the female cannot herself master the scream. It exceeds control of both genders. In the scream speech reaches utter silence”.\n\nJanov believes that for babies, screaming is the only form of communication he or she can have; it is the only way a baby can express his necessities, that he needs food, he is in pain or he simply needs some love. Janov writes, “screaming is a language – a primitive one, but a human language”.\n\nDiana König, journalist and broadcasting author, writes: “If the scream of babies is their first communication method, then the scream of adults is a recession from communication. By screaming, in the opposite of calling, the voice becomes overloaded and over-amplified, and it loses its control, its fundamental sound”. The scream is there before language and it appears where the language reaches its limits.\n\nElaine Scarry, writer and literature professor, talks about language in connection to pain and she thinks that pain almost destroys the language because it brings people back into a state where sounds and screams are dominating as they were their means of communication before they learned how to speak. Pain cannot actually be communicated, as it is a personal experience and can only be experienced individually. Pain, as any other concept, is actually an individual experience that can only be communicated as an idea and it also is to be interpreted as. Hegel writes: “The biggest relief when having pain is to be able to scream it out […] through this expression, the pain becomes objective and this makes the connection between the subject, who is alone in pain, and the object, that is not in pain.”\n\nArnal and colleague demonstrated that human screams exploit a unique acoustic property, roughness, that selectively activates the auditory brain as well as the amygdala, a deep brain structure involved in danger processing.\n\n\"The Scream\" () is the popular name given to each of four versions of a composition, created as both paintings and pastels, by the Expressionist artist Edvard Munch between 1893 and 1910. \"Der Schrei der Natur\" (\"The Scream of Nature\") is the title Munch gave to these works, all of which show a figure with an agonized expression against a landscape with a tumultuous orange sky. Arthur Lubow has described \"The Scream\" as \"an icon of modern art, a Mona Lisa for our time.\"\n\nIn music there are long traditions of scream in rock, punk rock, heavy metal, rock and roll and emo music. Vocalists are developing various techniques of screaming that results in different ways of screaming. In rock and metal music singers are developing very demanding guttural and growled sounds.\n\nScream is also used predominant as an esthetic element in “cante jondo”, a vocal style in flamenco. The name of this style is translated as “deep sing”. The origins of flamenco and also of its name are still not clear. Flamenco is related to the gypsies’ music and it is said to have appeared in Andalusia in Spain. In cante jondo, that is a subdivision of flamenco, which is considered to be more serious and deep, the singer is reduced to the most rudimentary method of expression, which is the cry and the scream. Ricardo Molima, a Spanish poet, wrote \"flamenco is the primal scream in its primitive form, from a people sunk in poverty and ignorance. Thus, the original flamenco song could be described as a type of self-therapy.” \n\nDavid N. Green, musician, writer and composer, wrote in 1987 an essay about musicians using screams as a singing technique in music. He makes the distinction between harmonic scream that relates to the harmony of the music and has components of tonality, the true scream that is atonal, the lyrical scream that is related with the song’s lyrics and the pure scream that is not. The harmonic scream is the scream that is still very clear and has a defined pitch and that I actually relate to a fake scream, as it has no great disturbance, the lyrical scream that is related to words, most of the time swearing and the pure scream or the true scream, that in this case can also be called as the real scream or the primal scream.\n\nScream in music can also be seen in other ways than just a vocal action. Many musicians use scream as an inspirational source for their playing with instruments. This is usually represented in a loud hit on the instrument’s chords, in the case of the instruments that have chords, or a loud striking note, on the blowing instruments.\n\n\"Pressure of the unspeakable\" is a radio feature work by Gregory Whitehead. Initiated in 1991 the project started with the founding of the \"Institute of the Screamscape studies\" where people were asked through radio and television to call on a hot line and scream. Whitehead notes: “In addition to framing the nervous system, the telephone-microphone-tape-recorder-radio circuitry also provided the key for the acoustic demarcation of pressure in the system: distortion, the disruption of digital codes, pure unmanageable noise. The scream as an eruption in excess of prescribed circuitries, as capable of “ blowing” communications technologies not designed for such extreme and unspeakable meanings”. \nWhitehead gathered slowly an archive of screams that was edited and resulted in a theoretical narrative radio feature. \nAllen S. Weiss notes about his work that “the screamscape lies beyond any possible determination of authenticity”. The people’s vociferations are just manifestations that through their anonymity create a sense of togetherness.\n\nActors are taught from the beginning of their careers how to scream correctly. They learn how to awaken that uncomfortable feeling in the listener without necessarily having to have any psychological attachment.\n\nAntonin Artaud's' last written work \"To have done with the judgment of god\" was Artaud's last written work that was recorded by him for the French radio in 1947. One day before it was scheduled, the director of the radio prohibited it for strong anti-religious and anti-American reasons. The piece consists of intensive texts with interludes of instrumental and vocal improvised sounds and screams.\nAllen S. Weiss writes about Antonin Artaud’s scream: “the scream is the expulsion of an unbearable, impossible internal polarization between life’s forces and death’s negation, simultaneously signifying and simulation creation and destruction […] scream, as a nonmaterial double of excrement, may be both expression and expulsion, a sign of birth creation and frustration […] the scream is the desublimation of speech into the body, in opposition to the sublimation of body into meaningful speech”.\n\nThe extreme character of the scream has a life danger element that stands for denying of death. In Artaud’s case, a person that was always very close to death and has been calling himself so ever since having strong shock therapies, the scream represents exactly this border between life and death, creation and destruction, of art work and of oneself.\n\nArtaud’s screams are mostly related to words. The small interludes that are in between the texts parts sometimes contain screams.\n\nMarina Abramovic used scream as an element in different performances: together with Ulay in \"AAA AAA\", the two are facing each other and are gradually screaming louder and louder while getting closer and closer to each other's face, until they both lose their voice; \"Freeing the voice\", where Abramovic is staying with her head upside down and screaming till she is left with no voice anymore.\n\nSome people, when arguing begin to raise their voices to the point that they are screaming at each other in anger while continuing their debate exchange. Terminology includes \"shouting match\".\n\nDrill instructors frequently shout orders at trainees to train recruits into the military culture whilst fostering obedience and expedience.\n\nThe volume levels of outcries may be very high, and this has become an issue in the sport of tennis, particularly with regards to Maria Sharapova's loud tennis grunts which have been measured as high as 101.2 decibels. The loudest verified scream emitted by a human measured 129 dBA, a record set by teaching assistant Jill Drake in 2000.\n"}
{"id": "58071816", "url": "https://en.wikipedia.org/wiki?curid=58071816", "title": "Skolt of the Year Award", "text": "Skolt of the Year Award\n\nThe Skolt of the Year Award (, ) is an annual award founded in 2007. It is awarded to people, groups, organizations, and institutions individually or collectively in recognition of their outstanding linguistic and cultural contributions for the good of the Skolt community. In spite of its name, it is not a requirement that the recipient be a Skolt. The award is administered and voted on by the Skolt Sámi Language and Culture Association Saaʹmi Nueʹtt and the Skolt community council.\n"}
{"id": "14405771", "url": "https://en.wikipedia.org/wiki?curid=14405771", "title": "Speech science", "text": "Speech science\n\nSpeech science refers to the study of production, transmission and perception of speech. Speech science involves anatomy, in particular the anatomy of the oro-facial region and neuroanatomy, physiology, and acoustics.\n\nThe production of speech is a highly complex motor task that involves approximately 100 orofacial, laryngeal, pharyngeal, and respiratory muscles. Precise and expeditious timing of these muscles is essential for the production of temporally complex speech sounds, which are characterized by transitions as short as 10 ms between frequency bands and an average speaking rate of approximately 15 sounds per second. Speech production requires airflow from the lungs (respiration) to be phonated through the vocal folds of the larynx (phonation) and resonated in the vocal cavities shaped by the jaw, soft palate, lips, tongue and other articulators (articulation).\n\nRespiration is the physical process of gas exchange between an organism and its environment involving four steps (ventilation, distribution, perfusion and diffusion) and two processes (inspiration and expiration). Respiration can be described as the mechanical process of air flowing into and out of the lungs on the principle of Boyle's law, stating that, as the volume of a container increases, the air pressure will decrease. This relatively negative pressure will cause air to enter the container until the pressure is equalized. During inspiration of air, the diaphragm contracts and the lungs expand drawn by pleurae through surface tension and negative pressure. When the lungs expand, air pressure becomes negative compared to atmospheric pressure and air will flow from the area of higher pressure to fill the lungs. Forced inspiration for speech uses accessory muscles to elevate the rib cage and enlarge the thoracic cavity in the vertical and lateral dimensions. During forced expiration for speech, muscles of the trunk and abdomen reduce the size of the thoracic cavity by compressing the abdomen or pulling the rib cage down forcing air out of the lungs.\n\nPhonation is the production of a periodic sound wave by vibration of the vocal folds. Airflow from the lungs, as well as laryngeal muscle contraction, causes movement of the vocal folds. It is the properties of tension and elasticity that allow the vocal folds to be stretched, bunched, brought together and separated. During prephonation, the vocal folds move from the abducted to adducted position. Subglottal pressure builds and air flow forces the folds apart, inferiorly to superiorly. If the volume of airflow is constant, the velocity of the flow will increase at the area of constriction and cause a decrease in pressure below once distributed. This negative pressure will pull the initially blow open folds back together again. The cycle repeats until the vocal folds are abducted to inhibit phonation or to take a breath.\n\nIn a third process of speech production, articulation, mobile and immobile structures of the face (articulators) adjust the shape of the mouth, pharynx and nasal cavities (vocal tract) as the vocal fold vibration sound passes through producing varying resonant frequencies.\n\nThe analysis of brain lesions and the correlation between lesion locations and behavioral deficits were the most important sources of knowledge about the cerebral mechanisms underlying speech production for many years. The seminal lesion studies of Paul Broca indicated that the production of speech relies on the functional integrity of the left inferior frontal gyrus.\n\nMore recently, the results of noninvasive neuroimaging techniques, such as functional magnetic resonance imaging (fMRI), provide growing evidence that complex human skills are not primarily located in highly specialized brain areas (e.g., Broca's area) but are organized in networks connecting several different areas of both hemispheres instead. Functional neuroimaging identified a complex neural network underlying speech production including cortical and subcortical areas, such as the supplementary motor area, cingulate motor areas, primary motor cortex, basal ganglia, and cerebellum.\n\nSpeech perception refers to the understanding of speech. The beginning of the process towards understanding speech is first hearing the message that is spoken. The auditory system receives sound signals starting at the outer ear. They enter the pinna and continue into the external auditory canal (ear canal) and then to the eardrum. Once in the middle ear, which consists of the malleus, the incus, and the stapes; the sounds are changed into mechanical energy. After being converted into mechanical energy, the message reaches the oval window, which is the beginning of the inner ear. Once inside the inner ear, the message is transferred into hydraulic energy by going through the cochlea, which is filled with fluid, and on to the Organ of Corti. This organ again helps the sound to be transferred into a neural impulse that stimulates the auditory pathway and reaches the brain. Sound is then processed in Heschl's gyrus and associated with meaning in Wernicke's area. As for theories of speech perception, there are a motor and an auditory theory. The motor theory is based upon the premise that speech sounds are encoded in the acoustic signal rather than enciphered in it. The auditory theory puts greater emphasis on the sensory and filtering mechanisms of the listener and suggests that speech knowledge is a minor role that’s only used in hard perceptual conditions.\n\nSpeech is transmitted through sound waves, which follow the basic principles of acoustics. The source of all sound is vibration. For sound to exist, a source (something put into vibration) and a medium (something to transmit the vibrations) are necessary.\n\nSince sound waves are produced by a vibrating body, the vibrating object moves in one direction and compresses the air directly in front of it. As the vibrating object moves in the opposite direction, the pressure on the air is lessened so that an expansion, or rarefaction, of air molecules occurs. One compression and one rarefaction make up one longitudinal wave. The vibrating air molecules move back and forth parallel to the direction of motion of the wave, receiving energy from adjacent molecules nearer the source and passing the energy to adjacent molecules farther from the source.\nSound waves have two general characteristics: A disturbance is in some identifiable medium in which energy is transmitted from place to place, but the medium does not travel between two places.\n\nImportant basic characteristics of waves are wavelength, amplitude, period, and frequency. Wavelength is the length of the repeating wave shape. Amplitude is the maximum displacement of the particles of the medium, which is determined by the energy of the wave. A period (measured in seconds) is the time for one wave to pass a given point. Frequency of the wave is the number of waves passing a given point in a unit of time. Frequency is measured in hertz (hz); (Hz cycles per second) and is perceived as pitch. Each complete vibration of a sound wave is called a cycle. Two other physical properties of sound are intensity and duration. Intensity is measured in decibels (dB) and is perceived as loudness.\n\nThere are two types of tones: pure tones and complex tones. The musical note produced by a tuning fork is called a pure tone because it consists of one tone sounding at just one frequency. Instruments get their specific sounds — their timbre — because their sound comes from many different tones all sounding together at different frequencies. A single note played on a piano, for example, actually consists of several tones all sounding together at slightly different frequencies.\n\n\n"}
{"id": "305869", "url": "https://en.wikipedia.org/wiki?curid=305869", "title": "Standard language", "text": "Standard language\n\nA standard language or standard variety is either as a language variety used by a population for public purposes, or a variety that has undergone standardization.\nTypically, varieties that become standardized are the local dialects spoken in the centers of commerce and government, where a need arises for a variety that will serve more than local needs.\nStandardization typically involves a fixed orthography, codification in authoritative grammars and dictionaries and public acceptance of these standards.\nA standard written language is sometimes termed by the German word \"Schriftsprache\".\n\nA pluricentric language has multiple interacting standard varieties.\nExamples include English, French, Portuguese, German, Korean, Serbo-Croatian, Spanish, Swedish, Armenian and Chinese.\nMonocentric languages, such as Russian and Japanese, have only one standardized version.\n\nA standard variety is developed from a group of related varieties.\nThis may be done by elevating a single variety, such as the local variety of a center of government or culture.\nAlternatively, a new variety may be defined as a selection of features from existing varieties.\nA fixed orthography is typically created for writing the variety.\nIt may be codified in normative dictionaries and grammars, or by an agreed collection of exemplary texts.\nWhether these dictionaries and grammars are created by private individuals (like \"Webster's Dictionary\") or by state institutions, they become standard if they are treated as authorities for correcting language.\nA fixed written form and subsequent codification make the standard variety more stable than purely spoken varieties, and provide a base for further development or \"ausbau\".\nThis variety becomes the norm for writing, is used in broadcasting and for official purposes, and is the form taught to non-native learners.\n\nThrough this process, the standard variety acquires prestige and a greater functional importance than local varieties.\nThose varieties are said to be dependent on, or heteronomous with respect to, the standard variety, because speakers read and write the standard, refer to it as an authority is such matters as specialist vocabulary, and any standardizing changes in their speech are towards that standard.\nIn some cases, such as Standard English, this process may take place over an extended period without government intervention.\nIn others it may be deliberately directed by official institutions, such as the Académie française or Real Academia Española, and can proceed much more quickly.\n\nLanguage standardization is often linked to the formation, or attempted formation, of nation states, as language is seen as the vehicle of a shared culture.\nDifferent national standards derived from a dialect continuum may be regarded as different languages, even if they are mutually intelligible.\nThe Scandinavian languages, Danish, Norwegian and Swedish, are often cited as examples.\n\nIn other cases governments or neighbouring populations may seek to deny a standard independent status.\nIn response, developers of a standard may base it on more divergent varieties.\nThus after Norway became independent at the start of the 20th century, the Bokmål standard based on the speech of Oslo was felt to be too similar to Danish by Ivar Aasen, who developed a rival Nynorsk standard based on western varieties.\nSimilarly, when a standard was developed in the Yugoslav republic of Macedonia from local varieties within a continuum with Serbia to the north and Bulgaria to the east, it was deliberately based on varieties from the west of the republic that were most different from standard Bulgarian.\nNow known as Macedonian, it is the national standard of the independent Republic of Macedonia, but viewed by Bulgarians as a dialect of Bulgarian.\n\nChinese consists of hundreds of local varieties, many of which are not mutually intelligible, usually classified into seven to ten major groups, including Mandarin, Wu, Yue, Hakka and Min.\nBefore the 20th century, most Chinese spoke only their local variety.\nFor two millennia, formal writing had been done in Literary Chinese (or Classical Chinese), a style modelled on the classics and far removed from any contemporary speech.\nAs a practical measure, officials of the late imperial dynasties carried out the administration of the empire using a common language based on Mandarin varieties, known as \"Guānhuà\" (literally \"speech of officials\").\n\nIn the early 20th century, many Chinese intellectuals argued that the country needed a standardized language.\nBy the 1920s, Literary Chinese had been replaced as the written standard by written vernacular Chinese, which was based on Mandarin dialects.\nIn the 1930s, Standard Chinese was adopted, with its pronunciation based on the Beijing dialect, but with vocabulary also drawn from other Mandarin varieties and its syntax based on the written vernacular.\nIt is the official spoken language of the People's Republic of China (where it is called \"Pǔtōnghuà\" \"common speech\") and of the Republic of China governing Taiwan (as \"Guóyǔ\" \"national language\"), and one of the official languages of Singapore (as \"Huáyǔ\" \"Chinese language\").\nStandard Chinese now dominates public life, and is much more widely studied than any other variety of Chinese.\n\nDutch is a monocentric language, with all speakers using the same standard form (authorized by the Dutch Language Union) based on a Dutch orthography employing the Latin alphabet when writing. A process of standardisation of Dutch started in the Middle Ages, especially under the influence of the Burgundian Ducal Court in Dijon (Brussels after 1477). Till then every region spoke a different Middle Dutch dialect. The dialects of the County of Flanders and the Duchy of Brabant were the most influential around this time. The process of standardisation became much stronger at the start of the 16th century, mainly based on the urban dialect of Antwerp. In 1585 Antwerp fell to the Spanish army: many from the Southern Netherlands fled to the Northern Netherlands (that declared itself independent from Spain), especially to the province of Holland, where they influenced the urban dialects. In 1637, a further important step was made towards a unified language, when the Statenvertaling, the first major Bible translation into Dutch, was created that people from all over the new republic could understand. It used elements from various dialects but was predominantly based on the urban dialects of Holland of post 16th century.\n\nIn British English the standard, known as Standard English (SE), is historically based on the language of the medieval English court of Chancery. The late seventeenth and eighteenth centuries saw the establishment of this standard as the norm of \"polite\" society, that is to say of the upper classes. The spoken standard has come to be seen as a mark of good education and social prestige. Although often associated with the RP accent, SE can be spoken with any accent, such as General American, General Australian, etc.\n\nThe standard form of Modern Greek is based on the Southern dialects; these dialects are spoken mainly in the Peloponnese, the Ionian Islands, Attica, Crete and the Cyclades.\n\nTwo standardised registers of the Hindustani language have legal status India: Standard Hindi (one of 23 co-official national languages) and Urdu (Pakistan’s official tongue), resultantly, Hindustani often called “Hindi-Urdu\".\n\n\"An Caighdeán Oifigiúil\" (\"The Official Standard\"), often shortened to \"An Caighdeán\", is official standard of the Irish language. It is taught in most schools in Ireland, though with strong influences from local dialects. It was first published by the translators in Dáil Éireann in the 1950s. As of September 2013, the first major revision of the Caighdeán Oifigiúil is available, both online and in print. Among the changes to be found in the revised version are, for example, various attempts to bring the recommendations of the Caighdeán closer to the spoken dialect of Gaeltacht speakers, including allowing further use of the nominative case where the genitive would historically have been found.\n\nStandard Italian is derived from the Tuscan dialect, specifically from its Florentine variety — the Florentine influence upon early Italian literature established that dialect as base for the standard language of Italy. In particular, Italian became the language of culture for all the people of Italy, thanks to the prestige of the masterpieces of Dante Alighieri, Francesco Petrarca, Giovanni Boccaccio, Niccolò Machiavelli, and Francesco Guicciardini. It would later become the official language of all the Italian states, and after the Italian unification it became the national language of the Kingdom of Italy. Modern Standard Italian's lexicon has been deeply influenced by almost all regional languages of Italy while its received pronunciation (known as \"Pronuncia Fiorentina Emendata\", Amended Florentine Pronunciation) is based on the accent of Romanesco (Roman dialect); these are the reasons why Standard Italian differs significantly from the Tuscan dialect.\n\nClassical Latin was the literary standard dialect of Latin spoken by higher socioeconomic classes, as opposed to the Vulgar Latin which is the generic term of the colloquial sociolects of Latin spoken across the Roman Empire by uneducated and less-educated classes. The Latin brought by Roman soldiers to Gaul, Iberia, or Dacia was not identical to the Latin of Cicero, and differed from it in vocabulary, syntax, and grammar.\n\nIn Brazil, actors and journalists usually adopt an unofficial, but de facto, spoken standard Portuguese, originally derived from the middle-class dialect of Rio de Janeiro, but that now encompasses educated urban pronunciations from the different speech communities in the southeast. In that standard, represents the phoneme when it appears at the end of a syllable (whereas in Rio de Janeiro this represents ) the rhotic consonant spelled is pronounced in the same situation (whereas in São Paulo this is usually an alveolar flap or trill). European and African dialects have differing realizations of than Brazilian dialects, with the former using and and the latter using , , or .\n\nFour standard variants of the pluricentric Serbo-Croatian are spoken in Bosnia and Herzegovina, Croatia, Montenegro and Serbia. They all have the same dialect basis (Štokavian). These variants do differ slightly, as is the case with other pluricentric languages, but not to a degree that would justify considering them as different languages. The differences between the variants do not hinder mutual intelligibility and do not undermine the integrity of the system as a whole. Compared to the differences between the variants of English, German, French, Spanish, or Portuguese, the distinctions between the variants of Serbo-Croatian are less significant. Serbia, Croatia, Bosnia and Herzegovina, and Montenegro in their constitution have all named the language differently.\n\nIn Somalia, Northern Somali (or North-Central Somali) forms the basis for Standard Somali, particularly the Mudug dialect of the northern Darod clan. Northern Central Somali has frequently been used by famous Somali poets as well as the political elite, and thus has the most prestige among other Somali dialects.\n\n\n"}
{"id": "623398", "url": "https://en.wikipedia.org/wiki?curid=623398", "title": "Sublanguage", "text": "Sublanguage\n\nA sublanguage is a subset of a language. Sublanguages occur in natural language, computer language, and relational databases.\n\nIn Informatics, natural language processing, and machine translation, a sublanguage is the language of a restricted domain, particularly a technical domain. In mathematical terms, \"a subset of the sentences of a language forms a sublanguage of that language if it is closed under some operations of the language: e.g., if when two members of a subset are operated on, as by \"and\" or \"because\", the resultant is also a member of that subset\" (Z. S. Harris \"Language and Information\", Columbia U. Press, 1988, p. 34).\n\nThe term sublanguage has also sometimes been used to denote a computer language that is a subset of another language. A sublanguage may be restricted syntactically (it accepts a subgrammar of the original language), and/or semantically (the set of possible outcomes for any given program is a subset of the possible outcomes in the original language).\n\nFor instance, ALGOL 68S was a subset of ALGOL 68 designed to make it possible to write a single-pass compiler for this \"sublanguage\".\n\nSQL (Structured Query Language) statements are classified in various ways, which can be grouped into sublanguages, commonly: a data query language (DQL), a data definition language (DDL), a data control language (DCL), and a data manipulation language (DML).\n\nIn relational database theory, the term \"sublanguage\", first used for this purpose by E. F. Codd in 1970, refers to a computer language used to define or manipulate the structure and contents of a relational database management system (RDBMS). Typical sublanguages associated with modern RDBMS's are QBE (Query by Example) and SQL (Structured Query Language). In 1985, Codd encapsulated his thinking in twelve rules which every database must satisfy in order to be truly relational. The fifth rule is known as the \"Comprehensive data sublanguage rule\", and states:\n\n"}
{"id": "26860", "url": "https://en.wikipedia.org/wiki?curid=26860", "title": "Syntax", "text": "Syntax\n\nIn linguistics, syntax () is the set of rules, principles, and processes that govern the structure of sentences in a given language, usually including word order. The term \"syntax\" is also used to refer to the study of such principles and processes. The goal of many syntacticians is to discover the syntactic rules common to all languages.\n\nIn mathematics, \"syntax\" refers to the rules governing the notation of mathematical systems, such as formal languages used in logic. (See logical syntax.)\n\nThe word \"syntax\" comes from Ancient Greek: \"coordination\", which consists of \"syn\", \"together\", and \"táxis\", \"an ordering\".\n\nA basic feature of a language's syntax is the sequence in which the subject (S), verb (V), and object (O) usually appear in sentences. Over 85% of languages usually place the subject first, either in the sequence SVO or the sequence SOV. The other possible sequences are VSO, VOS, OVS, and OSV, the last three of which are rare.\n\nWorks on grammar were written long before modern syntax came about; in Ancient India, the \"Aṣṭādhyāyī\" of Pāṇini (c. 4th century BC) is often cited as an example of a premodern work that approaches the sophistication of a modern syntactic theory. In the West, the school of thought that came to be known as \"traditional grammar\" began with the work of Dionysius Thrax.\n\nFor centuries, work in syntax was dominated by a framework known as , first expounded in 1660 by Antoine Arnauld in a book of the same title. This system took as its basic premise the assumption that language is a direct reflection of thought processes and therefore there is a single, most natural way to express a thought.\n\nHowever, in the 19th century, with the development of historical-comparative linguistics, linguists began to realize the sheer diversity of human language and to question fundamental assumptions about the relationship between language and logic. It became apparent that there was no such thing as the most natural way to express a thought, and therefore logic could no longer be relied upon as a basis for studying the structure of language.\n\nThe Port-Royal grammar modeled the study of syntax upon that of logic. (Indeed, large parts of the Port-Royal Logic were copied or adapted from the \"Grammaire générale\".) Syntactic categories were identified with logical ones, and all sentences were analyzed in terms of \"subject – copula – predicate\". Initially, this view was adopted even by the early comparative linguists such as Franz Bopp.\n\nThe central role of syntax within theoretical linguistics became clear only in the 20th century, which could reasonably be called the \"century of syntactic theory\" as far as linguistics is concerned. (For a detailed and critical survey of the history of syntax in the last two centuries, see the monumental work by Giorgio Graffi (2001).)\n\nThere are a number of theoretical approaches to the discipline of syntax. One school of thought, founded in the works of Derek Bickerton, sees syntax as a branch of biology, since it conceives of syntax as the study of linguistic knowledge as embodied in the human mind. Other linguists (e.g., Gerald Gazdar) take a more Platonistic view, since they regard syntax to be the study of an abstract formal system. Yet others (e.g., Joseph Greenberg) consider syntax a taxonomical device to reach broad generalizations across languages.\n\nThe hypothesis of generative grammar is that language is a structure of the human mind. The goal of generative grammar is to make a complete model of this inner language (known as \"i-language\"). This model could be used to describe all human language and to predict the grammaticality of any given utterance (that is, to predict whether the utterance would sound correct to native speakers of the language). This approach to language was pioneered by Noam Chomsky. Most generative theories (although not all of them) assume that syntax is based upon the constituent structure of sentences. Generative grammars are among the theories that focus primarily on the form of a sentence, rather than its communicative function.\n\nAmong the many generative theories of linguistics, the Chomskyan theories are:\n\nOther theories that find their origin in the generative paradigm are:\n\nDependency grammar is an approach to sentence structure where syntactic units are arranged according to the dependency relation, as opposed to the constituency relation of phrase structure grammars. Dependencies are directed links between words. The (finite) verb is seen as the root of all clause structure and all the other words in the clause are either directly or indirectly dependent on this root. Some prominent dependency-based theories of syntax are:\n\n\nLucien Tesnière (1893–1954) is widely seen as the father of modern dependency-based theories of syntax and grammar. He argued vehemently against the binary division of the clause into subject and predicate that is associated with the grammars of his day (S → NP VP) and which remains at the core of most phrase structure grammars. In the place of this division, he positioned the verb as the root of all clause structure.\n\nCategorial grammar is an approach that attributes the syntactic structure not to rules of grammar, but to the properties of the syntactic categories themselves. For example, rather than asserting that sentences are constructed by a rule that combines a noun phrase (NP) and a verb phrase (VP) (e.g., the phrase structure rule S → NP VP), in categorial grammar, such principles are embedded in the category of the head word itself. So the syntactic category for an intransitive verb is a complex formula representing the fact that the verb acts as a function word requiring an NP as an input and produces a sentence level structure as an output. This complex category is notated as (NP\\S) instead of V. NP\\S is read as \"a category that searches to the left (indicated by \\) for an NP (the element on the left) and outputs a sentence (the element on the right).\" The category of transitive verb is defined as an element that requires two NPs (its subject and its direct object) to form a sentence. This is notated as (NP/(NP\\S)) which means \"a category that searches to the right (indicated by /) for an NP (the object), and generates a function (equivalent to the VP) which is (NP\\S), which in turn represents a function that searches to the left for an NP and produces a sentence.\"\n\nTree-adjoining grammar is a categorial grammar that adds in partial tree structures to the categories.\n\nTheoretical approaches to syntax that are based upon probability theory are known as stochastic grammars. One common implementation of such an approach makes use of a neural network or connectionism.\n\nFunctionalist theories, although focused upon form, are driven by explanation based upon the function of a sentence (i.e., its communicative function). Some typical functionalist theories include:\n\n\n\n"}
{"id": "797617", "url": "https://en.wikipedia.org/wiki?curid=797617", "title": "Universal pragmatics", "text": "Universal pragmatics\n\nUniversal pragmatics (UP), more recently placed under the heading of formal pragmatics, is the philosophical study of the necessary conditions for reaching an understanding through communication. The philosopher Jürgen Habermas coined the term in his essay \"What is Universal Pragmatics?\" where he suggests that human competition, conflict, and strategic action are attempts to achieve understanding that have failed because of modal confusions. The implication is that coming to terms with how people understand or misunderstand one another could lead to a reduction of social conflict.\n\nBy coming to an \"understanding,\" he means at the very least, when two or more social actors share the same meanings about certain words or phrases; and at the very most, when these actors are confident that those meanings fit relevant social expectations (or a \"mutually recognized normative background\").\n\nFor Habermas, the goal of coming to an understanding is \"intersubjective mutuality ... shared knowledge, mutual trust, and accord with one another\". In other words, the underlying goal of coming to an understanding would help to foster the enlightenment, consensus, and good will necessary for establishing socially beneficial norms. Habermas' goal is not primarily for subjective feeling alone, but for development of shared (intersubjective) norms which in turn establish the social coordination needed for practical action in pursuit of shared and individual objectives (a form of action termed \"communicative action\").\n\nAs an interdisciplinary subject, universal pragmatics draws upon material from a large number of fields, from pragmatics, semantics, semiotics, informal logic, and the philosophy of language, through social philosophy, sociology, and symbolic interactionism, to ethics, especially discourse ethics, and on to epistemology and the philosophy of mind.\n\nUniversal pragmatics (UP) seeks to overcome three dichotomies: the dichotomy between \"body and mind\", between \"theory and practice\", and between \"analytic and continental philosophy\". It is part of a larger project to rethink the relationship between philosophy and the individual sciences during a period of social crisis. The project is within the tradition of Critical Theory, a program that traces back to the work of Max Horkheimer.\n\nThe term \"universal pragmatics\" includes two different traditions that Habermas and his collaborator, colleague, and friend Karl-Otto Apel have attempted to reconcile. On the one hand, ideas are drawn from the tradition of Plato, Aristotle, and Kant, wherein words and concepts are regarded as universally valid idealizations of shared meanings. And, on the other hand, inspiration is drawn from the American Pragmatist tradition (feat. Charles Sanders Peirce, George Herbert Mead, Charles W. Morris), for whom words are usually arbitrary signs devoid of intrinsic meaning, and whose function is to denote the things and processes in the objective world that surrounds the speakers. \n\nUP shares with speech act theory, semiotics, and linguistics an interest in the details of language use and communicative action. However, unlike those fields, it insists on a difference between the linguistic data that we \"observe\" in the 'analytic' mode, and the \"rational reconstruction of the rules of symbol systems\" that each reader/listener possesses intuitively when interpreting strings of words. In this sense, it is an examination of the two ways that language usage can be analyzed: as an object of scientific investigation, and as a 'rational reconstruction' of intuitive linguistic 'know-how'.\n\nUniversal pragmatics is associated with the philosophical method of \"rational reconstruction\".\n\nThe basic concern in universal pragmatics is \"utterances\" (or \"speech acts\") in general. This is in contrast to most other fields of linguistics, which tend to be more specialized, focusing exclusively on very specific sorts of utterances such as \"sentences\" (which in turn are made up of \"words\", \"morphemes\", and \"phonemes\").\n\nFor Habermas, the most significant difference between a sentence and an utterance is in that sentences are judged according to how well they make sense \"grammatically\", while utterances are judged according to their \"communicative validity\" (see section 1). (1979:31)\n\nUniversal pragmatics is also distinct from the field of sociolinguistics, because universal pragmatics is only interested in the meanings of utterances \"if they have to do with claims about truth or rightness\", while sociolinguistics is interested in all utterances in their social contexts. (1979:31, 33)\n\nThere are three ways to evaluate an utterance, according to UP. There are \"theories that deal with elementary propositions\", \"theories of first-person sentences\", and \"theories of speech acts\".\n\nA theory of elementary propositions investigates those things in the real world that are being \"referenced\" by an utterance, and the things that are implied by an utterance, or \"predicate\" it. For example, the utterance \"The first Prime Minister of Canada\" refers to a man who went by the name of Sir John A. Macdonald. And when a speaker delivers the utterance, \"My husband is a lawyer\", it implies that the speaker is married to a man.\n\nA theory of first-person sentences examines the expression of the \"intentions\" of the actor(s) through language and in the first-person.\n\nFinally, a theory of speech acts examines the setting of standards for interpersonal relations through language. The basic goal for speech act theory is to explain how and when utterances in general are \"performative\". (1979:34) Central to the notion of speech acts are the ideas of illocutionary force and perlocutionary force, both terms coined by philosopher J.L. Austin. \"Illocutionary force\" describes the intent of the speaker, while \"perlocutionary force\" means \"the effect an utterance has in the world\", or more specifically, the effect on others.\n\nA performative utterance is a sentence where an action being performed is done by the utterance itself. For example: \"I inform you that you have a moustache\", or \"I promise you I will not burn down the house\". In these cases, the words are also taken as significant actions: the act of informing and promising (respectively).\n\nHabermas adds to this the observation that speech acts can either succeed or fail, depending on whether or not they succeed on \"influencing\" another person in the intended way. (1979:35)\n\nThis last method of evaluation—the theory of speech acts—is the domain that Habermas is most interested in developing as a \"theory of communicative action\".\n\nThere are a number of ways to approach Habermas's project of developing a formal pragmatic analysis of communication. Because Habermas developed it in order to have a normative and philosophical foundation for his critical social theory, most of the inroads into formal pragmatics start from sociology, specifically with what is called action theory. Action theory concerns the nature of human action, especially the manner in which collective actions are coordinated in a functioning society.\n\nThe coordination and integration of social action has been explained in many ways by many theories. Rational choice theory and game theory are two examples, which describe the integration of individuals into social groups by detailing the complex manner in which individuals motivated only by self-interest will form mutually beneficial and cooperative social arrangements. In contrast to these, Habermas has formulated a theory of \"communicative action\". (Habermas 1984; 1987) This theory and the project of developing a formal pragmatic analysis of communication are inseparable.\n\nHabermas makes a series of distinctions in the service of explaining social action. The first major differentiation he makes is between two social realms, \"the system\" and \"the lifeworld\". These designate two distinct modes of social integration:\n\nThus, communicative action is an indispensable facet of society. It is at the heart of the lifeworld and is, Habermas claims, responsible for accomplishing several fundamental social functions: reaching understanding, cultural reproduction, coordinating action-plans, and socializing individuals.\n\nHowever, Habermas is quick to note, different modes of interaction can (in some ways) facilitate these social functions and achieve integration within the lifeworld. This points towards the second key distinction Habermas makes, which differentiates \"communicative action\" from \"strategic action\". The coordination of action plans, which constitutes the social integration of the lifeworld, can be accomplished either through consensus or influence.\n\nStrategic action is action oriented towards success, while communicative action is action oriented towards understanding. Both involve the symbolic resources of the lifeworld and occur primarily by way of linguistic interaction. On the one hand, actors employing communicative actions draw on the uniquely impelling force of mutual understanding to align the orientation of their action plans. It is this subtle but insistent binding force of communicative interactions that opens the door to an understanding of their meanings. On the other hand, actors employing strategic actions do not exploit the potential of communication that resides in the mutual recognition of a shared action-oriented understanding. Instead strategic actors relate to others with no intention of reaching consensus or mutual understanding, but only the intention of accomplishing pre-determined ends unrelated to reaching an understanding. Strategic action often involves the use of communicative actions to achieve the isolated intentions of individuals, manipulating shared understanding in the service of private interests. Thus, Habermas claims, strategic action is parasitic on communicative action, which means communicative action is the primary mode of linguistic interaction. Reaching a reciprocally defined understanding is communication's basic function.\n\nKeeping in mind this delineation of the object domain, the formal pragmatics of communication can be more readily laid out. The essential insight has already been mentioned, which is that communication is responsible for irreplaceable modes of social integration, and this is accomplished through the unique binding force of a shared understanding. This is, in a sense, the pragmatic piece of formal pragmatics: communication does something in the world. What needs to be explained are the conditions for the possibility of what communication already does. This is, in a sense, the formal piece of formal pragmatics: a rational reconstruction of the deep generative structures that are the universal conditions for the possibility of a binding and compelling mutual understanding.\n\nFrom here, Habermas heads the analysis in two directions. In one direction is a kind of linguistic analysis (of speech acts), which can be placed under the heading of the validity dimensions of communication. The other direction entails a categorization of the idealized presuppositions of communication.\n\nHabermas argues that when speakers are communicating successfully, they will have to defend their meaning by using these four claims.\n\n\nHabermas is emphatic that these claims are universal—no human communication oriented at achieving mutual understanding could possibly fail to raise all of these validity claims. Additionally, to illustrate that all other forms of communication are derived from that which is oriented toward mutual understanding, he argues that there are no other kinds of validity claims whatsoever. This is important, because it is the basis of Habermas' critique of postmodernism.\n\nThe fundamental orientation toward mutual understanding is at the heart of universal pragmatics, as Habermas explains:\n\"The task of universal pragmatics is to identify and reconstruct universal conditions of possible mutual understanding... other forms of social action—for example, conflict, competition, strategic action in general—are derivatives of action oriented toward reaching understanding. Furthermore, since language is the specific medium of reaching understanding at the sociocultural stage of evolution, I want to go a step further and single out explicit speech actions from other forms of communicative action.\"\n\nAny meaning that meets the above criteria, and is recognized by another as meeting the criteria, is considered \"vindicated\" or \"communicatively competent\".\n\nIn order for anyone to speak validly — and therefore, to have his or her comments vindicated, and therefore reach a genuine consensus and understanding — Habermas notes that a few more fundamental commitments are required. First, he notes, actors \"have to treat this formulation of validity so seriously that it might be a precondition for any communication at all\". Second, he asserts that \"all actors must believe that their claims are able to meet these standards of validity\". And third, he insists that there must be a common conviction among actors that all validity claims \"are either already vindicated or could be vindicated\".\n\nHabermas claims that communication rests upon a non-egoistic understanding of the world, which is an idea he borrowed from thinkers like Jean Piaget. A subject capable of a de-centered understanding can take up three fundamentally different attitudes to the world. Habermas refers to such attitudes as \"dimensions of validity\". Specifically, this means individuals can recognize different standards for validity—i.e., that the validation of an empirical truth claim requires different methods and procedures than the validation of subjective truthfulness, and that both of those require different methods and procedures of validation than claims to normative rightness.\n\nThese dimensions of validity can be summarized as claims to \"truth (IT), truthfulness (I),\" and \"rightness (WE)\". So the ability to differentiate between the attitudes (and their respective \"worlds\") mentioned above should be understood as an ability to distinguish between types of validity claims.\n\nM. Cooke provided the only book length treatment of Habermas's communication theory. Cooke explains:\n\nThis is fundamental to Habermas's analysis of communication. He maintains that the performance of any speech act necessarily makes reference to these dimensions of validity, by raising at least three validity claims.\n\nOne way to grasp this idea is to take an inventory of the ways in which an attempt at communication can misfire, the ways a speech act can fail. A hearer may reject the offering of a speech act on the grounds that it is invalid because it:\n\nOf course, from this it follows that a hearer who accepts the offering of a speech act does so on the grounds that it is valid because it:\n\nThis means that when engaging in communication the speaker and hearer are inescapably oriented to the validity of what is said. A speech act can be understood as an offering, the success or failure of which depends upon the hearer's response of either accepting or rejecting the validity claims it raises. The three dimensions of validity pointed out above are implicated in any attempt at communication.\n\nThus, communication relies on its being embedded within relations to various dimensions of validity. Any and every speech act is infused with inter-subjectively recognized claims to be valid. This implicitly ties communication to argumentation and various discursive procedures for the redemption of validity claims. This is true because to raise a validity claim in communication is to simultaneously imply that one is able to show, if challenged, that one's claim is justified. Communication is possible because speakers are accountable for the validity of what they say. This assumption of responsibility on the part of the speaker is described by Habermas as a \"warranty\", because in most cases the validity claims raised during communication are taken as justified, and communication proceeds on that basis. Similarly, the hearer is accountable for the stance he or she takes up in relation to the validity claims raised by the speaker. Both speaker and hearer are bound to the validity claims raised by the utterances they share during communication. They are bound by the weak obligations inherent in pursuing actions oriented towards reaching an understanding. Habermas would claim that this obligation is a rational one:\n\nThis begins to point towards the idea of communicative rationality, which is the potential for rationality that is implicit in the validity basis of everyday communication, the shape of reason that can be extracted from Habermas's formal-pragmatic analyses.\n\nHowever, before the idea of communicative rationality can be described, the other direction of Habermas's formal pragmatic analyses of communication needs to be explained. This direction looks towards the idealized presuppositions of communication.\n\nWhen individuals pursue actions oriented towards reaching an understanding, the speech acts they exchange take on the weight of a mutually recognized validity. This means each actor involved in communication takes the other as accountable for what they have said, which implies that good reasons could be given by all to justify the validity of the understanding that is being achieved. Again, in most situations the redemption of validity claims is not an explicit undertaking (except in \"discourses\", see below). Instead, each actor issues a \"warranty\" of accountability to the other, which only needs to be redeemed if certain validity claims are thrown into question. This suggests that the validity claims raised in every communicative interaction implicitly tie communication to argumentation.\n\nIt is here that the idealized presuppositions of communication arise. Habermas claims that all forms of argumentation, even implicit and rudimentary ones, rest upon certain \"idealizing suppositions,\" which are rooted in the very structures of action oriented towards understanding. These \"strong idealizations\" are always understood as at least approximately satisfied by participants in situations where argumentation (and communication) is thought to be taking place. Thus, when during communication it is discovered that the belief that these presuppositions are satisfied is not justified it is always taken as problematic. As a result, steps are usually taken to reestablish and maintain the belief that they are approximately satisfied, or communication is simply called off.\n\n\nIn sum, all these presuppositions must be assumed to be approximately satisfied in any situation of communication, despite their being necessarily counterfactual. Habermas refers to the positing of these idealized presuppositions as the \"simultaneously unavoidable and trivial accomplishments that sustain communicative action and argumentation\".\n\nHabermas calls \"discourses\" those forms of communication that come sufficiently close to actually satisfying these presuppositions. Discourses often occur within institutionalized forms of argumentation that self-reflectively refine their procedures of communication, and as a result, have a more rigorous set of presuppositions in addition to the ones listed above.\n\nA striking feature of discourse is that validity claims tend to be explicitly thematized and there is the presupposition that all possible interlocutors would agree to the universal validity of the conclusions reached. Habermas especially highlights this in what he calls \"theoretical discourses\" and \"practical discourses\". These are tied directly to two of the three dimensions of validity discussed above: theoretical discourse being concerned with validity claims thematized regarding objective states of affairs (IT); practical discourse being concerned with validity claims thematized concerning the rightness of norms governing social interactions (WE).\n\nHabermas understands presupposition (5) to be responsible for generating the self-understanding and continuation of theoretical and practical discourses. Presupposition (5) points out that the validity of an understanding reached in theoretical or practical discourse, concerning some factual knowledge or normative principle, is always expanded beyond the immediate context in which it is achieved. The idea is that participants in discourses such as these presuppose that any understanding reached could attain universal agreement concerning its universal validity if these discourses could be relieved of the constraints of time and space. This idealized presupposition directs discourses concerning truth and normative certainty beyond the contingencies of specific communicative situations and towards the idealized achievements of universal consensus and universal validity. It is a rational reconstruction of the conditions for the possibility of earnest discourses concerning facts and norms. Recall that, for Habermas, rational reconstructions aim at offering the most acceptable account of what allows for the competencies already mastered by a wide range of subjects. In order for discourse to proceed, the existence of facts and norms must be presupposed, yet the certainty of an absolute knowledge of them must be, in a sense, postponed.\n\nStriking a Piagetian and Peircean chord, Habermas understands the deep structures of collective inquiry as developmental. Thus, the presupposition shared by individuals involved in discourse is taken to reflect this. The pursuit of truth and normative certainty is taken to be motivated and grounded, not in some objective or social world that is treated as a \"given\", but rather in a learning process. Indeed, Habermas himself is always careful to formulate his work as a research project, open to refinement.\n\nIn any case, reconstructing the presuppositions and validity dimensions inherent to communication is valuable because it brings into relief the inescapable foundations of everyday practices. Communicative action and the rudimentary forms of argumentation that orient the greater part of human interaction cannot be left behind. By reconstructing the deep structures of these Habermas has discovered a seed of rationality planted in the very heart of the lifeworld. Everyday practices, which are common enough to be trivial, such as reaching an understanding with another, or contesting the reasons for pursuing a course of action, contain an implicit and idealized rationality.\n\nIn other words, communication is always somewhat rational. Communication could not occur if the participants thought that the speech acts exchanged did not carry the weight of a validity for which those participating could be held accountable. Nor would anyone feel that a conclusion was justified if it was achieved by any other means than the uncoerced force of the better argument. Nor could the specialized discourses of law, science and morality continue if the progress of knowledge and insight was denied in favor of relativism.\n\nIt is a question how appropriate it is to speak of \"communication\" tenselessly, and of \"everyday practices\" as though they cut across all times and cultures. That they do cannot be assumed, and anthropology provides evidence of significant difference. It is possible to ignore these facts by limiting the scope of universal pragmatics to current forms of discourse, but this runs the risk of contradicting Habermas's own demand for (5). Moreover, the initial unease with the classical and liberal views of rationality had to do precisely with their ahistorical character and refusal, or perhaps inability, to acknowledge their own origins in circumstances of the day. Their veneer of false universality torn off by the likes of Foucault, it remains to be seen whether \"universal\" pragmatics can stand up to the same challenges posed by deconstruction and skepticism.\n\n\n"}
{"id": "34565118", "url": "https://en.wikipedia.org/wiki?curid=34565118", "title": "Usus", "text": "Usus\n\nUsus ( — usage; long-established rule, practice, custom) is a term referring to the common usage of linguistic units (words, idioms, forms) in a particular speech community.\n\nUsus can be contrasted with both occasional usage and prescribed standard usage. The term is used to designate usage that has wide currency and acceptance among speakers of a language, even if it diverges from the \"high\" literary standard. \n\nUsus is one of the crucial terms in the research of Danish linguists Otto Jespersen and Louis Hjelmslev.\n"}
{"id": "92200", "url": "https://en.wikipedia.org/wiki?curid=92200", "title": "Utterance", "text": "Utterance\n\nIn spoken language analysis, an utterance is the smallest unit of speech. It is a continuous piece of speech beginning and ending with a clear pause. In the case of oral languages, it is generally but not always bounded by silence. Utterances do not exist in written language, only their representations do. They can be represented and delineated in written language in many ways.\n\nIn oral/spoken language utterances have several features including paralinguistic features which are aspects of speech such as facial expression, gesture, and posture. Prosodic features include stress, intonation, and tone of voice, as well as ellipsis, which are words that the listener inserts in spoken language to fill gaps. Moreover, other aspects of utterances found in spoken languages are non-fluency features including: voiced/un-voiced pauses (like \"umm\"), tag questions, and false starts when someone begins their utterances again to correct themselves. Other features include: fillers (\"and stuff\"); accent/dialect; deictic expressions, which are utterances like \"over there!\" which need further explanation to be understood; simple conjunctions (\"and,\" \"but,\" etc.); and colloquial lexis which are everyday informal words.\n\nUtterances that are portrayed in writing are planned, in contrast to utterances in improvised spoken language. In written language there are frameworks that are used to portray this type of language. Discourse structure (which can also be found in spoken language) is how the conversation is organized, in which adjacency pairs - an utterance and the answer to that utterance - are used. Discourse markers are used to organize conversation (\"first,\" \"secondly,\" etc.). Lexis denotes the words being used in a text or spoken; these words can create a semantic field. For example, a semantic field of love can be created with lexical choices such as adore, admire, and care. Grammar/syntax is another feature of language in general but also utterances, and pragmatics means that when utterances are spoken or written the meaning is not literal, as in sarcasm.\n\nAn utterance which is found in spoken and written language as in a script has several characteristics. These include paralinguistic features which is a feature of communication that doesn't involve words but is added around an utterance to give meaning. Examples of paralinguistic features include facial expressions, laughter, eye contact, and gestures. Prosodic features refer to the sound of someone's voice as they speak: pitch, intonation and stress. Ellipsis can be used in either written or spoken language, when an utterance is conveyed and the speaker omits words because they are already understood in the situation. For example: A: Juice? B: Please. A: Room temperature? B: Cold.\n\nNon-fluency features also occur when producing utterances. As people think about what to say to while speaking, there are errors and corrections in speech. For example, voiced/un-voiced pauses which are \"umm,\" \"erm,\" etc. in voiced pauses and in transcripts un-voiced pauses are denoted as (.) or (1) relating to the amount of time of the pause. Tag questions are also a part of non-fluency features; these are used by the speaker to check if the listener understands what the speaker is saying. An example is \"Do you know what I mean?\" False alerts occur when the speaker is voicing an utterance but stops and starts again, usually to correct themselves.\n\nFillers usually give the speaker time to think and gather their thoughts in order to continue their utterance; these include lexis such as, \"like,\" \"and stuff,\" Accent/dialect is also a characteristic included in utterances which is the way the words are voiced, the pronunciation and the different types of lexis used in different parts of the world. Deictic expressions are utterances that need more explanation in order to be understood, like: \"Wow! Look over there!\" Simple conjunctions in speech are words that connect other words like \"and,\" \"but,\" etc. Colloquial lexis is a type of speech that is casual in which the utterance is usually more relaxed.\n\nThe development of utterances in children is facilitated by parents, adults, or any other guardian the child has growing up. Studies have indicated that this development of utterances is affected by the parent, adult, or guardian's socioeconomic status (SES). It has been shown that children have larger vocabularies and learn new words more quickly during early childhood from parents with a high education and higher SES status, while children with less educated parents and lower SES status have a smaller vocabulary and a slower growth in their vocabulary skills (Arriaga, Fenson, Cronan & Pethick, 1998; Hart & Risley, 1995; Hoff, Laursen & Tardif, 2002; Hoff-Ginsberg, 1991; Lawrence & Shipley, 1996; Ninio, 1980). This correlation is due to the fact that more educated parents use more lexis when speaking to their children as opposed to parents that are less educated (Hart & Risley, 1995; Hoff, 2003 a; Huttenlocher, Vasilyeva, Waterfall, Vevea & Hedges, in press). Hoff conducted an analysis that shows support for this correlation in 2003 which shows that the mean length of utterance and vocabulary of mothers who talk to their children is related to their SES status and thus child vocabulary development. High-SES mothers use longer utterances when talking to their children and a wider variety of words. They also spend more time talking to their children. Low-SES mothers use shorter utterances and a smaller vocabulary. As a result, children with more educated parents have larger vocabularies (Hoff, 2003).\n\nIn child-directed speech, utterances have several additional features. For example, the phonology in child-directed speech is different: Utterances are spoken more slowly, with longer pauses in between utterances, higher pitches, etc. The lexis and semantics differ, and a speaker uses words suited for children, \"doggie\" instead of \"dog,\" for example. The grammar is simpler, repetitive, with less use of verbs and adjectives. There is a greater use of one word utterances and the pragmatics uses supportive language like expansions and re-casting.\n\nPaul Grice (1989) came up with four maxims necessary in order to have a collegial conversation in which utterances are understood:\n\n\nAccording to philosopher Mikhail Bakhtin, there are four accepted properties that utterances should have:\n\nBakhtin also emphasizes that an utterance and a sentence are not the same thing. According to Bakhtin, sentences do not indicate a change of speech subject, and thus do not automatically satisfy one of the four properties of utterances. According to him, the sentence as a language unit is grammatical in nature, while an utterance is \"ethical\".\n\n\n"}
{"id": "12393342", "url": "https://en.wikipedia.org/wiki?curid=12393342", "title": "Vernacular orientation", "text": "Vernacular orientation\n\nVernacular orientation refers to the status that a language is afforded by one of its mother-tongue speakers (Tiessen, 2003). This status is exhibited through the sociolinguistic behaviours of a mother-tongue speaker. A speaker who exhibits positive vernacular orientation is one who exhibits a preferred status for their mother tongue in such things as patterns of language use, language attitudes, social networks and even levels of language proficiency. Likewise, a speaker who exhibits negative vernacular orientation is one who exhibits a preferred status for a language other than their mother tongue in these areas of sociolinguistic behaviour.\n\nAn example of research into vernacular orientation as expressed in a community can be found at . This is a study on vernacular orientation in the Talysh community of the city of Sumgayit in the Republic of Azerbaijan for the purpose of gaining a greater understanding of its causes. Vernacular orientation is described in three areas of sociolinguistic behaviour: patterns of vernacular language use, vernacular language proficiency and frequency of vernacular-speaking individuals in social networks. Data was collected through personal interviews. The questionnaires for these interviews were developed using a qualitative-relational research approach. The description of vernacular orientation takes the form of a criteria-based typology of which an analysis of influential factors is ultimately made. This analysis of influential factors demonstrates the interaction between vernacular orientation as described in the typology and the contextual elements of the family, socio-economic dynamics and individual attitudes.\n"}
{"id": "1013711", "url": "https://en.wikipedia.org/wiki?curid=1013711", "title": "Vesre", "text": "Vesre\n\nVesre (reversing the order of syllables within a word) is one of the features of Rioplatense Spanish slang. Natives of Argentina and Uruguay use vesre sparingly in colloquial speaking, and never in formal circumstances. Tango lyrics make widespread use of lunfardo and vesre to highlight the intended underworld atmosphere, or for comic relief.\n\nVesre is mostly from Buenos Aires, and other cities in Argentina have their own customs. Rosario has its \"Rosarigasino\" method for obfuscating words, and Córdoba has an entirely different set of colloquial conventions. Yet, most Argentines and Uruguayans have been exposed to vesre through tango lyrics or the media.\n\nEven though vesre has spread to other countries, and can be heard in Peru, Chile and Ecuador, Spanish speakers outside the Río de la Plata area are usually less inclined to use it. Popular speech has created some instances; for example, natives of Barranquilla, Colombia often call their city \"Curramba\", in a stylized form of vesre.\n\nNOTE: When the syllables of the noun are switched, the original gender - masculine or feminine - is kept; e.g., \"un café -> un feca\"\n\nOccasionally, vesre is a stepping-stone towards further obfuscation, achieved by evolving into a longer word. For example:\n\n\nThe original and \"vesre\" versions of a word are not always synonyms; sometimes the reversal adds some extra nuance to the meaning. For instance, the word \"hotel\" bears the same meaning as in English (i.e. a normal tourist hotel), whereas \"telo\" implies that the establishment is actually a love hotel. Listen to examples\n\nThese reversed words are only spoken; rarely found in writing.\n\nIn English - Pig Latin; (Not exactly with the same morphological construction but similar in purpose and tone) \n\nColloquial French has a form of intentional metathesis known as verlan.\n\nGreek has Podaná with the same morphological construction.\n\nTagálog, a language of the Philippines, also has a similar construct known as \"binaliktad\", lit. \"inverted.\"\n\nSerbian has a form of slang called Šatrovački followed in the 1990s with a more ambiguous slang called utrovački.\n"}
{"id": "34608521", "url": "https://en.wikipedia.org/wiki?curid=34608521", "title": "Vivid designator", "text": "Vivid designator\n\nIn modal logic and the philosophy of language, a vivid designator is a term which is \"believed\" to designate the same thing in all possible worlds and nothing else where such an object does not exist in a possible world. It is the analogue, in the sense of believing, of a rigid designator, which \"is\" (refers to) the same in all possible worlds, rather than is just \"believed\" to be so.\n\nWillard Van Orman Quine credits David Kaplan (who in turn Montgomery Furth) for the term \"vivid designator\" in his 1953 paper \"Reference and Modality\". He examines the separation between \"de re\" and \"de dicto\" and does away with \"de re\" statements, because \"de re\" statements can only work for names that are used referentially. In fact, both rigid designators and vivid designators are similarly dependent on context and empty otherwise. The same is true of the whole quantified modal logic of necessity because it collapses if essence is withdrawn.\n\n"}
{"id": "1189233", "url": "https://en.wikipedia.org/wiki?curid=1189233", "title": "Word count", "text": "Word count\n\nThe word count is the number of words in a document or passage of text. Word counting may be needed when a text is required to stay within certain numbers of words. This may particularly be the case in academia, legal proceedings, journalism and advertising. Word count is commonly used by translators to determine the price for the translation job. Word counts may also be used to calculate measures of readability and to measure typing and reading speeds (usually in words per minute). When converting character counts to words, a measure of 5 or 6 characters to a word is generally used for English.\n\nVariations in the operational definitions of how to count the words can occur (namely, what \"counts as\" a word, and which words \"don't count\" toward the total). However, especially since the advent of widespread word processing, there is a broad consensus on these operational definitions (and hence the bottom-line integer result). The consensus is to accept the text segmentation rules generally found in most word processing software (including how word boundaries are determined, which depends on how word dividers are defined). The first trait of that definition is that a space (any of various whitespace characters, such as a \"regular\" word space, an em space, or a tab character) is a word divider. Usually a hyphen or a slash is, too. Different word counting programs may give varying results, depending on the text segmentation rule details, and on whether words outside the main text (such as footnotes, endnotes, or hidden text) are counted. But the behavior of most major word processing applications is broadly similar.\n\nHowever, during the era when school assignments were done in handwriting or with typewriters, the rules for these definitions often differed from today's consensus. Most importantly, many students were drilled on the rule that \"certain words don't count\", usually articles (namely, \"a\", \"an\", \"the\"), but sometimes also others, such as conjunctions (for example, \"and\", \"or\", \"but\") and some prepositions (usually \"to\", \"of\"). Hyphenated permanent compounds such as \"follow-up\" (noun) or \"long-term\" (adjective) were counted as one word. To save the time and effort of counting word-by-word, often a rule of thumb for the average number of words per line was used, such as 10 words per line. These \"rules\" have fallen by the wayside in the word processing era; the \"word count\" feature of such software (which follows the text segmentation rules mentioned earlier) is now the standard arbiter, because it is largely consistent (across documents and applications) and because it is fast, effortless, and costless (already included with the application).\n\nAs for which sections of a document \"count\" toward the total (such as footnotes, endnotes, abstracts, reference lists and bibliographies, tables, figure captions, hidden text), the person in charge (teacher, client) can define their choice, and users (students, workers) can simply select (or exclude) the elements accordingly, and watch the word count automatically update.\n\nModern web browsers support word counting via extensions, via a JavaScript bookmarklet, or a script that is hosted in a website. Most word processors can also count words. Unix-like systems include a program, \"wc\", specifically for word counting. There are a wide variety of word counting tools available online.\n\nAs explained earlier, different word counting programs may give varying results, depending on the text segmentation rule details. The exact number of words often is not a strict requirement, thus the variation is acceptable.\n\nNovelist Jane Smiley suggests that length is an important quality of the novel. However, novels can vary tremendously in length; Smiley lists novels as typically being between 100,000 and 175,000 words, while National Novel Writing Month requires its novels to be at least 50,000 words. There are no firm rules: for example, the boundary between a novella and a novel is arbitrary and a literary work may be difficult to categorise. But while the length of a novel is to a large extent up to its writer, lengths may also vary by subgenre; many chapter books for children start at a length of about 16,000 words, and a typical mystery novel might be in the 60,000 to 80,000 word range while a thriller could be well over 100,000 words.\n\nThe Science Fiction and Fantasy Writers of America specifies word lengths for each category of its Nebula award categories:\n\nThe acceptable length of an academic dissertation varies greatly, dependent predominantly on the subject. Numerous American universities limit Ph.D. dissertations to 100,000 words, barring special permission for exceeding this limit.\n\n\n"}
{"id": "15294269", "url": "https://en.wikipedia.org/wiki?curid=15294269", "title": "World language", "text": "World language\n\nA world language is spoken internationally and is learned and spoken by a large number of people as a second language. A world language is characterized not only by the total number of speakers (native and second language speakers), but also by its geographical distribution, as well as use in international organizations and diplomatic relations.\nOne of the most widely spoken and fastest spreading world languages today is English, which has over 980,000,000 first- and second-language users worldwide.\n\nArabic gained international prominence because of the medieval Islamic conquests and the subsequent Arabization of the Middle East and North Africa, and it is also a liturgical language amongst Muslim communities outside the Arab World.\n\nStandard Chinese is the direct replacement of Classical Chinese, which was a historical lingua franca in Far East Asia until the early 20th century, and today serves as a common language between speakers of other varieties of Chinese not only within China proper (between the Han Chinese and other unrelated ethnic groups), but in overseas Chinese communities. It is also widely taught as a second language internationally.\n\nThe major languages of the Indian subcontinent have numbers of speakers comparable to those of major world languages primarily due to the large population in the region rather than a supra-regional use of these languages, although Hindustani (including all Hindi dialects, and Urdu), Bengali and Tamil may fulfill the criteria in terms of supra-regional usage and international recognition. As an example, the native speaking population of Bengali vastly outnumber those who speak French as a first language, and it is one of the most spoken languages (ranking fifth or sixth) in the world with nearly 230 million total speakers, and is known for its long and rich literary tradition.\n\nIn addition to 370 million native speakers, English is estimated to have over 610 million second-language speakers, including anywhere between 200 and 350 million learners/users in China alone, at varying levels of study and proficiency, though this number is difficult to accurately assess. English is also increasingly becoming the dominant language of scientific research and papers worldwide, having even outpaced national languages in Western European countries, including France, where a recent study showed that English has massively displaced French as the language of scientific research in \"hard\" as well as in applied sciences.\n\nDuring the 19th and early 20th centuries, French was the language of communication and diplomacy, and the favoured second language among the elite and the educated classes in Europe (including Russia, Romania, Bulgaria, Greece, and Ukraine) - as well as in many Middle East and North African countries such as Syria, Egypt, Ottoman Turkey and Iran. In addition, French enjoyed high status in some southeast Asian countries (Vietnam, Laos and Cambodia), and several South American ones like Argentina, Brazil, Chile, and Uruguay. However, French has declined steadily since World War I, being gradually displaced by English - although in Lebanon, Tunisia, Algeria and Morocco, French continues to be the favoured second language. Moreover, French still remains one of the working languages of many international organizations, including the United Nations, European Union and NAFTA. French is also internationally recognized to be of high linguistic prestige, still used in diplomacy and international commerce, as well as having a significant portion of second language speakers throughout the world.\n\nGerman served as a lingua franca in large portions of Europe for centuries, mainly the Holy Roman Empire and later the Austro-Hungarian Empire. It remains an important second language in much of Central and Eastern Europe, and in the international scientific community.\n\nRussian was used in the Russian Empire and the Soviet Union, and its teaching was made compulsory in the Eastern Bloc countries. However, the use and teaching of Russian has declined sharply in both the former Eastern bloc and the near abroad since the break up of the Soviet Union and Russia’s deputy education minister was quoted as saying in December 2013 that the number of Russian speakers had fallen by 100 million since that date. It is still widely spoken throughout the Caucasus, Central Asia, Eastern Europe and the Baltic states.\n\nRussian is the largest native language in Europe, one of the six official languages of the United Nations, one of two official languages aboard the International Space Station and the third most widespread language on the Internet after English and German.\n\nSpanish is the world's second-most spoken native language, after Mandarin Chinese. Spanish was used in the Spanish Empire and today is in use in Spain, in Latin American countries (except Brazil, French Guyana, Suriname, Guiana, Haiti and other Caribbean islands), and is spoken in many parts of the United States, particularly in Florida and the states which border Mexico. Indeed, by 2013 Spanish was the most widely taught non-English language in American secondary schools and schools of higher education. It is also an official language of the United Nations. As of December 2017 Spanish had the third largest number of internet users by language (after English and Chinese).\n\nHistorical languages which had international significance as the \"lingua franca\" of a historical empire include Egyptian in Ancient Egypt; Sumerian, Akkadian and Aramaic in the various Mesopotamian civilizations and empires in the Ancient Near East; Ancient Greek in the Greek colonies in the form of various dialects, evolving to Koine Greek in the Hellenistic world, after the conquests of Alexander the Great and the Macedonian Empire, and subsequently in the eastern part of the Roman Empire and the territories of the Byzantine Empire; Latin in the Roman Empire and presently as the standard liturgical language for the Catholic faithful worldwide; Classical Chinese in East Asia during the Imperial era of Chinese history; Persian during the various succeeding Persian Empires, and once served as the second lingua franca of the Islamic World after Arabic; Sanskrit during the ancient and medieval historical periods of various states in South Asia, Southeast Asia, and Central Asia, and like Latin an important liturgical language of the Vedic religions.\n\nThe Romance languages bear testimony to the role of Latin as the \"lingua franca\" of the Roman Empire; for example, Italian has always been important in the Mediterranean region, and nowadays it is the most-spoken language among members of the Roman catholic hierarchy and it is also used in music (especially Opera) and the fashion industry. Turkish was similarly important as the primary language of the Ottoman Empire. Koine Greek was the \"world language\" of the Hellenistic period, but its distribution is not reflected in the distribution of Modern Greek due to the linguistic impact of the Slavic, Arabic and Turkic expansions. The distribution of the Arabic and Turkic languages, in turn, are a legacy of the Caliphates and the Turkic Khaganate, respectively.\n\nJust as all the living world languages owe their status to linguistic imperialism, the suggestion of a given language as a world language or \"universal language\" has strong political implications. Thus, Russian was declared the \"world language of internationalism\" in Soviet literature, which at the same time denounced French as the \"language of fancy courtiers\" and English as the \"jargon of traders\". A number of international auxiliary languages have been introduced as prospective world languages, the most successful of them being Esperanto, but none were learned by as many people as the world languages were. Many natural languages have been proffered as candidates for a global \"lingua franca\".\n\nSome sources define a living world language as having the following properties:\nCertain languages with greater than 100 million speakers, such as Japanese, are not listed. Japanese, although considered to be one of the most significant languages internationally, along with the listed world languages, it is not considered a world language \"per se\". Japan as a region is nearly homogeneous from ethnic, cultural and linguistic standpoints. Thus Japanese has little history as a \"lingua franca\" amongst communities who do not share a mother tongue or first language; their overseas communities are strongly tied to ethnicity. While international interest since the 1980s has prompted many major universities, secondary schools, and even primary schools worldwide to offer courses in the language, Japanese only exerts a regionally limited sphere of influence.\n\nLanguages which are often considered world languages include:\n\nOther sources denote the following languages as world languages, whilst stricter sources list them as supra-regional languages:\n\nOther languages of supra-regional importance which fail some of the other criteria to be considered \"de facto\" world languages include:\n\n\n\n"}
