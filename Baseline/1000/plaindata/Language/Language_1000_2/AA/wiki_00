{"id": "5259993", "url": "https://en.wikipedia.org/wiki?curid=5259993", "title": "Accent reduction", "text": "Accent reduction\n\nAccent reduction, also known as accent modification or accent neutralization, is a systematic approach for learning or adopting a new speech accent. It is the process of learning the sound system (or phonology) and melodic intonation of a language so the non-native speaker can communicate with clarity to be understood by the general public of this second language.  \n\nAccent reduction training is not the same as ESL (English as a Second Language) classes. Accent reduction classes go beyond learning vocabulary and grammar and focus upon clarity of speech and fine tuning a specific accent or dialect. Foreign accent reduction training is typically appropriate for adult learners who have at least a moderate level of conversational proficiency in the second language. Non-native speakers from any background or profession can benefit from accent reduction training. That is not to say that every non-native speaker needs to modify their accent, however. The goal of accent reduction training is to improve speaking clarity so the non-native speaker is understood in the workplace as well as within their community; not necessarily to totally eliminate the accent. Business professionals, physicians, professors, researchers, telemarketers, etc. oftentimes request accent reduction training be provided by their employers so they can communicate more effectively with their colleagues, clients, and customers. \n\nForeign born students and professionals can benefit from accent modification training to improve their English intelligibility to be more competitive when interviewing for jobs.  Under U.S. labor law, employers can make job decisions based on accent if it interferes with work. The federal Equal Employment Opportunity Commission does receive a small number of complaints every year from individuals who believe they are victims of accent-related job discrimination.\n\nTwo distinct types of accent reduction training are available: self-study and instructor-led.  There are many types of self-study books, apps, cds, and software systems on the market.  Some of these products offer materials that are unique to individuals from specific language backgrounds.  The self-study learning methods can be helpful especially if audios are included so the user can hear the correct pronunciations.  Instructor-led training, although significantly more expensive than the self-study option, allows students to receive personalized instruction, obtain immediate feedback from the trainer, and typically make more timely progress.  Instructor-led training is available in a variety of ways:  1:1 with an instructor, small group training, seminars, or workshops.  Delivery can occur in person, web-based using webcams, or via telephone.\n\nAccent modification is offered by various certified speech-language trainers, linguists, and specialists in ESL. In the United States, they are promoted by various organizations including the Accent Freedom, the American Speech–Language–Hearing Association (ASHA), the Accent Reduction Training Association (ARTA), Corporate Speech Pathology Network (CORSPAN),  Voice, Speech Trainers Association (VASTA).\n\nInstructor-led courses typically start with a speech assessment to determine a student’s unique needs.  Speech production is a very complicated process involving coordinating movements of the lips, tongue, jaw, vocal cords, and respiratory system.  Speakers from different language backgrounds have different speech patterns when speaking English as they are attempting to implement their own language’s pronunciation rules while speaking English.  Even people from the same language background can have differing speech patterns based upon the age at which they learned English, the characteristics of their teacher’s speech, and influences of other languages they may speak.\n\nAreas of focus may include teaching students clear articulation of vowels and consonants as well as the intonation patterns that are unique to each language.  The learning sequence is typically broken down into progressive learning segments until they cumulate into using the newly learned skills in conversation. Additional areas might include linking, rate, or voice projection.  Instructor-led accent training will also frequently include conversational practice to help the student transfer these newly learned skills into everyday conversations.  \n\nTraining timelines can vary from a few days to several months depending upon the chosen model of instruction.  Outside practice time is essential for the participant to see significant changes in their speech.\n\n Although accents can be minimized through training, actually eliminating an accent is extremely difficult to master and could take years to accomplish.  It is unrealistic to expect total accent elimination in a short period of time.  \n\nAccent improvement focuses on teaching students how to pronounce difficult sounds such as , , , , and ; intonation, stress, and rhythm. Spanish and Portuguese speakers might add an before the vowel , as in \"his\" for \"is\". Therefore, vowel sounds are also covered in accent reduction training. Practicing of the vowel most commonly spelled \"i\" is done by reciting a few of the following differences: his versus is, hit versus it, hill versus ill. By not letting the back of their tongue touch the palate, native speakers of Asian languages (Chinese, etc.) can avoid adding a before the for example in speaking \"yin\" instead of \"in\".\nSpecialists also use activities, games, and printable workbooks to help students practice what they learn.\nAlthough the accents can be reduced through training, some linguists warn against giving students a false hope that they will lose their accents. According to Dennis Baron, a linguistics professor at the University of Illinois at Urbana-Champaign, eliminating an accent is difficult. Calming an accent, he said, takes years of interaction with native English speakers. Even so, under U.S. labor law, employers can make job decisions based on accent if it interferes with work. The federal Equal Employment Opportunity Commission does receive a small number of complaints every year from individuals who believe they are victims of accent-related job discrimination.\n\nThe actors Portia de Rossi, Tom Holland, Anthony La Paglia, Katherine Langford, and Charlize Theron are examples of notable people who received such training to lose their native accents and develop American accents, even in everyday speech.\n\nWith regard to English accent training, the two most distinct choices of accent reduction are the British or American pathways. However the Australian method of received pronunciation is increasingly preferred by Asian nations, given the two regions' geographic proximity; this is an important consideration given the rise of Asia's economic strength and choice in education.\n\n\n"}
{"id": "928216", "url": "https://en.wikipedia.org/wiki?curid=928216", "title": "Autological word", "text": "Autological word\n\nAn autological word (also called homological word or autonym) is a word that expresses a property that it also possesses (e.g. the word \"short\" is short, \"noun\" is a noun, \"English\" is English, \"pentasyllabic\" has five syllables, \"word\" is a word). The opposite is a heterological word, one that does not apply to itself (e.g. \"long\" is not long, \"monosyllabic\" has five syllables).\n\nUnlike more general concepts of autology and self-reference, this particular distinction and opposition of \"autological\" and \"heterological words\" is uncommon in linguistics for describing linguistic phenomena or classes of words, but is current in logic and philosophy where it was introduced by Kurt Grelling and Leonard Nelson for describing a semantic paradox, later known as Grelling's paradox or the Grelling–Nelson paradox. \n\nOne source of autological words is ostensive definition: the reference to a class of words by an example of the member of the class, as it were by synecdoche: such as mondegreen, oxymoron, eggcorn, bahuvrihi, etc.\nA word's status as autological may change over time. For example, \"neologism\" was once an autological word but no longer is; similarly, \"protologism\" (a word invented recently by literary theorist Mikhail Epstein) may or may not lose its autological status depending on whether or not it gains wider usage.\n\n\n\n"}
{"id": "33469100", "url": "https://en.wikipedia.org/wiki?curid=33469100", "title": "Ayu language", "text": "Ayu language\n\nAyu is a minor and endangered Plateau language of Nigeria. Its subsequent classification is uncertain, but it may be one of the Ninzic languages (Blench 2008). It is not being passed on to many children.\n"}
{"id": "20695536", "url": "https://en.wikipedia.org/wiki?curid=20695536", "title": "Bai (suffix)", "text": "Bai (suffix)\n\nBai or baisaheb is a suffix added to the name of female members of the Maratha and Rajput dynasties.e.g. Shantabai It is also used as an honorific for the elder sister amongst the Marathi-speaking people. This type of suffix is also used in several kshatriya castes and in some of the tribal castes, for example the Lambadi.\n"}
{"id": "31641080", "url": "https://en.wikipedia.org/wiki?curid=31641080", "title": "Book hand", "text": "Book hand\n\nA book hand was any of several stylized handwriting scripts used during ancient and medieval times. It was intended for legibility and often used in transcribing official documents (prior to the development of printing and similar technologies).\n\nIn palaeography and calligraphy the term \"hand\" is still used to refer to a named style of writing, such as the \"chancery hand\".\n\n"}
{"id": "27481187", "url": "https://en.wikipedia.org/wiki?curid=27481187", "title": "Born Talking: A Personal Inquiry into Language", "text": "Born Talking: A Personal Inquiry into Language\n\nBorn Talking: A Personal Inquiry into Language is a 1990 BBC television documentary series written and presented by Jonathan Miller that attempts to shed light on the complexities of language.\n\nThe series consists of four episodes 47 minutes each:\n\n"}
{"id": "54071539", "url": "https://en.wikipedia.org/wiki?curid=54071539", "title": "Carrier tilt", "text": "Carrier tilt\n\nCarrier tilt is a wear issue that can arise in some gas piston-based firearm operating systems. High pressure gas pushes the gas piston back hitting the bolt carrier. This force pushes the bolt carrier down into the buffer tube wall. This can lead to increased wear, shaved and/or chipped metal. This in turn can lead to a loss of accuracy. \n\nColt says that by allowing the operating rod to wiggle the downward force is alleviated and shifted rearward instead. Conversely, Adams Arms cites loose or sloppy tolerances inside the receiver as root source of the problem and thus utilizes a single-piece carrier to solve the problem. Other companies solve this issue modifying the carrier length. Black Rifle Arms utilizing a shorted carrier to accommodate a polymer based buffer and Patriot Ordnance Factory using a lengthened carrier, sporting an extended lower lip.\n"}
{"id": "17220101", "url": "https://en.wikipedia.org/wiki?curid=17220101", "title": "Cognitive and linguistic theories of composition", "text": "Cognitive and linguistic theories of composition\n\nCognitive science and linguistic theory have played an important role in providing empirical research into the writing process and serving the teaching of composition. As composition theories, there is some dispute concerning the appropriateness of tying these two schools of thought together into one theory of composition. However, their empirical basis for research and ties to the process theory of composition and cognitive science can be thought to warrant some connection.\n\nThe cognitive theory of composition (hereafter referred to as “cognitive theory”) can trace its roots to psychology and cognitive science. Lev Vygotsky's and Jean Piaget's contributions to the theories of cognitive development and developmental psychology could be found in early work linking these sciences with composition theory (see Ann E. Berthoff). Linda Flower and John Hayes published “A Cognitive Process Theory of Writing” in 1981, providing the groundwork for further research into how thought processes influence the writing process.\n\nLinguistic theories of composition found their roots in the debate surrounding grammar's importance in composition pedagogy. Scholars, such as Janet Emig, Patrick Hartwell, Martha J. Kolln, Robert Funk, Stephen Witte, and Lester Faigley continued this line of thought around the same time that a cognitive theory of composition was being developed by Flower and Hayes. These scholars, like scholars researching cognitive-oriented composition theory, focused on research providing insight into the writing process, but were also committed to providing pedagogical advancements addressing deficiencies, trends, and insights gained from their linguistic research.\n\nA cognitive theory is focused on gaining insight into the writing process through the writer’s thought processes. Composition theorists have attacked the problem of accessing writers’ thoughts in various ways. Flower and Hayes’ essay, “A Cognitive Process Theory of Writing” sought to outline the writer’s choice-making throughout the writing process, and how those choices constrained or influenced other choices down the line. Other research has focused on capturing the cognitive processes of writers during the writing process through note-taking or speaking aloud, while some early research by Birdwell, Nancrow, and Ross was done with computers to record writers’ keystrokes during the writing process.\n\nLinguistic composition theory has traditionally focused on sentence and paragraph-level composition, with the goal of providing instructors insights into the way students write at various proficiency levels. Stephen Witte and Lester Faigley utilized detailed syntactic analysis to redefine the importance of cohesion and coherence in judging writing quality. Paul Rodgers and Richard Braddock focused on paragraph structure, in separate studies, in order to dispel common misjudgments about the importance of traditional paragraph structure.\n\nApplied linguistics, specifically EFL/ESL studies, has played a large role in development linguistic theories of composition. Liz Hamp-Lyons’ research in ESL/EFL writing assessment is valuable in informing ESL composition pedagogy. Paul Kei Matsuda, has illustrated the deficiency in ESL composition research, and recent compilations by Matsuda and others have attempted to bridge the gap between ESL instruction and composition theory by presenting pedagogical, theoretical, and assessment frameworks in the ESL composition classroom.\n\nCognitive and linguistic theories of composition are heavily tied to process theory. Cognitive and linguistic theories have been instrumental in providing respected empirical research to the field of composition theory, but tend to stay away from making pedagogical suggestions. Instead, research in these fields is typically intended to inform process theory by providing data analysis regarding the writing process, and by bringing scientific research to the field.\n"}
{"id": "29819979", "url": "https://en.wikipedia.org/wiki?curid=29819979", "title": "Cognitive hearing science", "text": "Cognitive hearing science\n\nCognitive hearing science is an interdisciplinary science field concerned with the physiological and cognitive basis of hearing and its interplay with signal processing in hearing aids. The field includes genetics, physiology, medical and technical audiology, cognitive neuroscience, cognitive psychology, linguistics and social psychology.\n\nTheoretically the research in cognitive hearing science combines a physiological model for the information transfer from the outer auditory organ to the auditory cerebral cortex, and a cognitive model for how language comprehension is influenced by the interplay between the incoming language signal and the individual's cognitive skills, especially the long-term memory and the working memory.\n\nResearchers examine the interplay between type of hearing impairment or deafness, type of signal processing in different hearing aids, type of listening environment and the individual's cognitive skills.\n\nResearch in cognitive hearing science has importance for the knowledge about different types of hearing impairment and its effects, as for the possibilities to determine which individuals can make use of certain type of signal processing in hearing aid or cochlear implant and thereby adapt hearing aid to the individual.\n\nCognitive hearing science has been introduced by researchers at the Linköping University research centre Linnaeus Centre HEAD (HEaring And Deafness) in Sweden, created in 2008 with a major 10-year grant from the Swedish Research Council.\n\n"}
{"id": "6138", "url": "https://en.wikipedia.org/wiki?curid=6138", "title": "Conjecture", "text": "Conjecture\n\nIn mathematics, a conjecture is a conclusion or proposition based on incomplete information, for which no proof has been found. Conjectures such as the Riemann hypothesis (still a conjecture) or Fermat's Last Theorem (which was a conjecture until proven in 1995 by Andrew Wiles) have shaped much of mathematical history as new areas of mathematics are developed in order to prove them.\n\nIn number theory, Fermat's Last Theorem (sometimes called Fermat's conjecture, especially in older texts) states that no three positive integers \"a\", \"b\", and \"c\" can satisfy the equation \"a\" + \"b\" = \"c\" for any integer value of \"n\" greater than two.\n\nThis theorem was first conjectured by Pierre de Fermat in 1637 in the margin of a copy of \"Arithmetica\" where he claimed he had a proof that was too large to fit in the margin. The first successful proof was released in 1994 by Andrew Wiles, and formally published in 1995, after 358 years of effort by mathematicians. The unsolved problem stimulated the development of algebraic number theory in the 19th century and the proof of the modularity theorem in the 20th century. It is among the most notable theorems in the history of mathematics and prior to its proof it was in the \"Guinness Book of World Records\" for \"most difficult mathematical problems\".\n\nIn mathematics, the four color theorem, or the four color map theorem, states that, given any separation of a plane into contiguous regions, producing a figure called a \"map\", no more than four colors are required to color the regions of the map so that no two adjacent regions have the same color. Two regions are called \"adjacent\" if they share a common boundary that is not a corner, where corners are the points shared by three or more regions. For example, in the map of the United States of America, Utah and Arizona are adjacent, but Utah and New Mexico, which only share a point that also belongs to Arizona and Colorado, are not.\n\nMöbius mentioned the problem in his lectures as early as 1840. The conjecture was first proposed on October 23, 1852 when Francis Guthrie, while trying to color the map of counties of England, noticed that only four different colors were needed. The five color theorem, which has a short elementary proof, states that five colors suffice to color a map and was proven in the late 19th century ; however, proving that four colors suffice turned out to be significantly harder. A number of false proofs and false counterexamples have appeared since the first statement of the four color theorem in 1852.\n\nThe four color theorem was proven in 1976 by Kenneth Appel and Wolfgang Haken. It was the first major theorem to be proved using a computer. Appel and Haken's approach started by showing that there is a particular set of 1,936 maps, each of which cannot be part of a smallest-sized counterexample to the four color theorem. (If they did appear, you could make a smaller counter-example.) Appel and Haken used a special-purpose computer program to confirm that each of these maps had this property. Additionally, any map that could potentially be a counterexample must have a portion that looks like one of these 1,936 maps. Showing this required hundreds of pages of hand analysis, Appel and Haken concluded that no smallest counterexamples exists because any must contain, yet do not contain, one of these 1,936 maps. This contradiction means there are no counterexamples at all and that the theorem is therefore true. Initially, their proof was not accepted by all mathematicians because the computer-assisted proof was infeasible for a human to check by hand . Since then the proof has gained wider acceptance, although doubts remain .\n\nThe Hauptvermutung (German for main conjecture) of geometric topology is the conjecture that any two triangulations of a triangulable space have a common refinement, a single triangulation that is a subdivision of both of them. It was originally formulated in 1908, by Steinitz and Tietze.\n\nThis conjecture is now known to be false. The non-manifold version was disproved by John Milnor in 1961 using Reidemeister torsion.\n\nThe manifold version is true in dimensions . The cases were proved by Tibor Radó and Edwin E. Moise in the 1920s and 1950s, respectively.\n\nIn mathematics, the Weil conjectures were some highly influential proposals by on the generating functions (known as local zeta-functions) derived from counting the number of points on algebraic varieties over finite fields.\n\nA variety \"V\" over a finite field with \"q\" elements has a finite number of rational points, as well as points over every finite field with \"q\" elements containing that field. The generating function has coefficients derived from the numbers \"N\" of points over the (essentially unique) field with \"q\" elements.\n\nWeil conjectured that such \"zeta-functions\" should be rational functions, should satisfy a form of functional equation, and should have their zeroes in restricted places. The last two parts were quite consciously modeled on the Riemann zeta function and Riemann hypothesis. The rationality was proved by , the functional equation by , and the analogue of the Riemann hypothesis was proved by \n\nIn mathematics, the Poincaré conjecture is a theorem about the characterization of the 3-sphere, which is the hypersphere that bounds the unit ball in four-dimensional space. The conjecture states: An equivalent form of the conjecture involves a coarser form of equivalence than homeomorphism called homotopy equivalence: if a 3-manifold is \"homotopy equivalent\" to the 3-sphere, then it is necessarily \"homeomorphic\" to it.\n\nOriginally conjectured by Henri Poincaré, the theorem concerns a space that locally looks like ordinary three-dimensional space but is connected, finite in size, and lacks any boundary (a closed 3-manifold). The Poincaré conjecture claims that if such a space has the additional property that each loop in the space can be continuously tightened to a point, then it is necessarily a three-dimensional sphere. An analogous result has been known in higher dimensions for some time.\n\nAfter nearly a century of effort by mathematicians, Grigori Perelman presented a proof of the conjecture in three papers made available in 2002 and 2003 on arXiv. The proof followed on from the program of Richard S. Hamilton to use the Ricci flow to attempt to solve the problem. Hamilton later introduced a modification of the standard Ricci flow, called \"Ricci flow with surgery\" to systematically excise singular regions as they develop, in a controlled way, but was unable to prove this method \"converged\" in three dimensions. Perelman completed this portion of the proof. Several teams of mathematicians have verified that Perelman's proof is correct.\n\nThe Poincaré conjecture, before being proven, was one of the most important open questions in topology.\n\nIn mathematics, the Riemann hypothesis, proposed by , is a conjecture that the non-trivial zeros of the Riemann zeta function all have real part 1/2. The name is also used for some closely related analogues, such as the Riemann hypothesis for curves over finite fields.\n\nThe Riemann hypothesis implies results about the distribution of prime numbers. Along with suitable generalizations, some mathematicians consider it the most important unresolved problem in pure mathematics . The Riemann hypothesis, along with the Goldbach conjecture, is part of Hilbert's eighth problem in David Hilbert's list of 23 unsolved problems; it is also one of the Clay Mathematics Institute Millennium Prize Problems.\n\nThe P versus NP problem is a major unsolved problem in computer science. Informally, it asks whether every problem whose solution can be quickly verified by a computer can also be quickly solved by a computer; it is widely conjectured that the answer is no. It was essentially first mentioned in a 1956 letter written by Kurt Gödel to John von Neumann. Gödel asked whether a certain NP complete problem could be solved in quadratic or linear time. The precise statement of the P=NP problem was introduced in 1971 by Stephen Cook in his seminal paper \"The complexity of theorem proving procedures\" and is considered by many to be the most important open problem in the field. It is one of the seven Millennium Prize Problems selected by the Clay Mathematics Institute to carry a US$1,000,000 prize for the first correct solution.\n\n\nFormal mathematics is based on \"provable\" truth. In mathematics, any number of cases supporting a conjecture, no matter how large, is insufficient for establishing the conjecture's veracity, since a single counterexample would immediately bring down the conjecture. Mathematical journals sometimes publish the minor results of research teams having extended the search for a counterexample farther than previously done. For instance, the Collatz conjecture, which concerns whether or not certain sequences of integers terminate, has been tested for all integers up to 1.2 × 10 (over a trillion). However, the failure to find a counterexample after extensive search does not constitute a proof that no counterexample exists nor that the conjecture is true, because the conjecture might be false but with a very large minimal counterexample.\n\nInstead, a conjecture is considered proven only when it has been shown that it is logically impossible for it to be false. There are various methods of doing so; see Mathematical proof#Methods for details.\n\nOne method of proof, usable when there are only a finite number of cases that could lead to counterexamples, is known as \"brute force\": in this approach, all possible cases are considered and shown not to give counterexamples. Sometimes the number of cases is quite large, in which situation a brute-force proof may require as a practical matter the use of a computer algorithm to check all the cases: the validity of the 1976 and 1997 brute-force proofs of the four color theorem by computer was initially doubted, but was eventually confirmed in 2005 by theorem-proving software.\n\nWhen a conjecture has been proven, it is no longer a conjecture but a theorem. Many important theorems were once conjectures, such as the Geometrization theorem (which resolved the Poincaré conjecture), Fermat's Last Theorem, and others.\n\nConjectures disproven through counterexample are sometimes referred to as \"false conjectures\" (cf. the Pólya conjecture and Euler's sum of powers conjecture). In the case of the latter, the first counterexample found for the n=4 case involved numbers in the millions, although subsequently it has been found that the minimal counterexample is smaller than that.\n\nNot every conjecture ends up being proven true or false. The continuum hypothesis, which tries to ascertain the relative cardinality of certain infinite sets, was eventually shown to be undecidable (or independent) from the generally accepted set of axioms of set theory. It is therefore possible to adopt this statement, or its negation, as a new axiom in a consistent manner (much as we can take Euclid's parallel postulate as either true or false).\n\nIn this case, if a proof uses this statement, researchers will often look for a new proof that \"doesn't\" require the hypothesis (in the same way that it is desirable that statements in Euclidean geometry be proved using only the axioms of neutral geometry, i.e. no parallel postulate.) The one major exception to this in practice is the axiom of choice—unless studying this axiom in particular, the majority of researchers do not usually worry whether a result requires the axiom of choice.\n\nSometimes a conjecture is called a \"hypothesis\" when it is used frequently and repeatedly as an assumption in proofs of other results. For example, the Riemann hypothesis is a conjecture from number theory that (amongst other things) makes predictions about the distribution of prime numbers. Few number theorists doubt that the Riemann hypothesis is true. In anticipation of its eventual proof, some have proceeded to develop further proofs which are contingent on the truth of this conjecture. These are called \"conditional proofs\": the conjectures assumed appear in the hypotheses of the theorem, for the time being.\n\nThese \"proofs\", however, would fall apart if it turned out that the hypothesis was false, so there is considerable interest in verifying the truth or falsity of conjectures of this type.\n\nKarl Popper pioneered the use of the term \"conjecture\" in scientific philosophy. Conjecture is related to hypothesis, which in science refers to a testable conjecture.\n\n\n"}
{"id": "6867", "url": "https://en.wikipedia.org/wiki?curid=6867", "title": "Context-free language", "text": "Context-free language\n\nIn formal language theory, a context-free language (CFL) is a language generated by a context-free grammar (CFG).\n\nContext-free languages have many applications in programming languages, in particular, most arithmetic expressions are generated by context-free grammars.\n\nDifferent context-free grammars can generate the same context-free language. Intrinsic properties of the language can be distinguished from extrinsic properties of a particular grammar by comparing multiple grammars that describe the language.\n\nThe set of all context-free languages is identical to the set of languages accepted by pushdown automata, which makes these languages amenable to parsing. Further, for a given CFG, there is a direct way to produce a pushdown automaton for the grammar (and thereby the corresponding language), though going the other way (producing a grammar given an automaton) is not as direct.\n\nA model context-free language is formula_1, the language of all non-empty even-length strings, the entire first halves of which are 's, and the entire second halves of which are 's. is generated by the grammar formula_2.\nThis language is not regular.\nIt is accepted by the pushdown automaton formula_3 where formula_4 is defined as follows:\n\nUnambiguous CFLs are a proper subset of all CFLs: there are inherently ambiguous CFLs. An example of an inherently ambiguous CFL is the union of formula_6 with formula_7. This set is context-free, since the union of two context-free languages is always context-free. But there is no way to unambiguously parse strings in the (non-context-free) subset formula_8 which is the intersection of these two languages.\n\nThe language of all properly matched parentheses is generated by the grammar formula_9.\n\nThe context-free nature of the language makes it simple to parse with a pushdown automaton.\n\nDetermining an instance of the membership problem; i.e. given a string formula_10, determine whether formula_11 where formula_12 is the language generated by a given grammar formula_13; is also known as \"recognition\". Context-free recognition for Chomsky normal form grammars was shown by Leslie G. Valiant to be reducible to boolean matrix multiplication, thus inheriting its complexity upper bound of \"O\"(\"n\").\nConversely, Lillian Lee has shown \"O\"(\"n\") boolean matrix multiplication to be reducible to \"O\"(\"n\") CFG parsing, thus establishing some kind of lower bound for the latter.\n\nPractical uses of context-free languages require also to produce a derivation tree that exhibits the structure that the grammar associates with the given string. The process of producing this tree is called \"parsing\". Known parsers have a time complexity that is cubic in the size of the string that is parsed.\n\nFormally, the set of all context-free languages is identical to the set of languages accepted by pushdown automata (PDA). Parser algorithms for context-free languages include the CYK algorithm and Earley's Algorithm.\n\nA special subclass of context-free languages are the deterministic context-free languages which are defined as the set of languages accepted by a deterministic pushdown automaton and can be parsed by a LR(k) parser.\n\nSee also parsing expression grammar as an alternative approach to grammar and parser.\n\nContext-free languages are closed under the following operations. That is, if \"L\" and \"P\" are context-free languages, the following languages are context-free as well:\n\nThe context-free languages are not closed under intersection. This can be seen by taking the languages formula_22 and formula_23, which are both context-free. Their intersection is formula_24, which can be shown to be non-context-free by the pumping lemma for context-free languages. As a consequence, context-free languages cannot be closed under complementation, as for any languages \"A\" and \"B\", their intersection can be expressed by union and complement: formula_25. In particular, context-free language cannot be closed under difference, since complement can be expressed by difference: formula_26. \n\nHowever, if \"L\" is a context-free language and \"D\" is a regular language then both their intersection formula_27 and their difference formula_28 are context-free languages.\n\nIn formal language theory, questions about regular languages are usually decidable, but ones about context-free languages are often not. It is decidable whether such a language is finite, but not whether it contains every possible string, is regular, is unambiguous, or is equivalent to a language with a different grammar.\n\nThe following problems are undecidable for arbitrarily given context-free grammars A and B:\n\nThe following problems are \"decidable\" for arbitrary context-free languages:\n\nAccording to Hopcroft, Motwani, Ullman (2003), \nmany of the fundamental closure and (un)decidability properties of context-free languages were shown in the 1961 paper of Bar-Hillel, Perles, and Shamir\n\nThe set formula_8 is a context-sensitive language, but there does not exist a context-free grammar generating this language. So there exist context-sensitive languages which are not context-free. To prove that a given language is not context-free, one may employ the pumping lemma for context-free languages or a number of other methods, such as Ogden's lemma or Parikh's theorem.\n\n"}
{"id": "36339441", "url": "https://en.wikipedia.org/wiki?curid=36339441", "title": "Cross-border language", "text": "Cross-border language\n\nA cross-border language or trans-border language is a language spoken by a population (ethnic group or nation) that lives in a geographical area in two or several internationally recognized countries that have common land or maritime borders. Cross-border languages are particularly common in Africa but are found on all other continents as well.\n\nExamples include German (spoken in Germany, Austria, Switzerland and other neighbouring countries), Catalan (spoken in Spain, Andorra and elsewhere), Hungarian (spoken in most countries bordering Hungary) and Gaelic (spoken in Ireland, Scotland and the Isle of Man).\n"}
{"id": "41591480", "url": "https://en.wikipedia.org/wiki?curid=41591480", "title": "Dhi (Hindu thought)", "text": "Dhi (Hindu thought)\n\nDhi (Sanskrit: धी), this Sanskrit word means 'understanding', 'reflection', 'religious thought', 'mind', 'design', 'intelligence', 'opinion', 'meditation', 'imagination', 'notion', 'intellect', This word is directly connected with the word, Vāc (Sanskrit: वाच) meaning Speech, derived from Vac (Sanskrit: वच) meaning, 'to speak'. \"Dhi\" is the voiced \"Vāc\" or 'Speech', it is the thought-mind or intellect. \"Dhi\" also means 'to hold' or 'to place', and indicates the activity of the intellect.\n\nThe natural meaning of \"Dhi\" is 'Thought' which corresponds to the Sanskrit word \"Buddhi\" which means 'the activity of mind', 'thought', 'understanding' and 'intelligence'. Vedic Sanskrit employs two words \"Dhi\" and Brahman for prayerful or meditative contemplation in which context \"Dhi\" means 'visionary insight', 'intense thought and reflection', and the word Brahman is derived from the root \"brh\", meaning 'to grow', 'to expand'.\nManu Smriti describes ten essential rules for observance of Dharma (the path of righteousness or the 'Law of Being', which binds the people of this world and the whole creation) – \"Dhriti\" ('patience'), \"Kshama\" ('forgiveness'), \"Dama\" ('self-control'), \"Asteya\" ('honesty'), \"Shauch\" ('purity'), \"Indriya-nigrah\" ('control of senses'), \"Dhi\" ('reasoning'), \"Vidya\" ('knowledge and learning'), \"Satya\" ('truthfulness') and \"Akrodha\" ('control of anger').\n\nDhi, the prefix of \"Dhimahi\" and \"Dhiyo\" occurring in the Gayatri Mantra (Rig VedaIII.62.10) refers to 'understanding', and its cognate word \"Buddhi\" means 'reasoning faculty of the mind', which understanding must be transcended to experience the Ultimate Reality. The word, \"Dhira\", meaning 'calm', denotes the seeker whose intellect is saturated in knowledge which word is the combination of \"Dhi\" meaning 'intellect' and \"ra\" meaning 'fire' or 'wisdom'.\nThe Non-Atman i.e. the Anatman, which is by its nature disagreeable, is the object of the function of \"Dhi\" (=\"buddhi\") which reveals the joy (\"ananda\"), the nature of the individual consciousness.\nPatanjali defines Yoga as neutralization of the alternating waves in consciousness; in the phrase \"citta vritti nirodha\" (Yoga Sutra I.2), \"Citta\" refers to the 'thinking principle' and includes 'pranic life forces', to \"Manas\" ('mind' or 'sense consciousness'), \"Ahamkara\" ('egoity') and \"Buddhi\" ('intuitive intelligence'), and \"Vritti\" refers to the waves of thought and emotion that ceaselessly arise and Nirodha refers to 'neutralization', 'cessation' or 'control'. The root \"budh\" and its derivatives appear in the Vedas in the sense of 'kindling' or 'awakening', the word \"buddhi\" appears for the first time in \"Samkhyayana Brahmana Upanishad\". \"Dhi\" is derived from \"dhriti\" and its cognate \"didhiti\", it also refers to flash of intuition which is beyond all purely sensuous perception. The mental organs are \"manas\" ('mind') and \"hrd\" ('heart'), and the mental faculties are \"citta\" ('thought'), \"dhi\" ('mental vision') and \"kratu\" ('mental power'). \"Manas\" is said to perform the processes indicated by the verbal roots \"'cit-\", \"dhi-\" and \"man-\"; \"dhi\" requires \"kratu\" in actualizing visions.\n\nDhi refers to 'vision' or 'inspiration which is the exceptional faculty of acquiring a sudden knowledge of transcendent truth or reality', 'the inner light of visionary insight'. Soma is the Lord of Vision who dispenses inspiration and Speech (Vāc) is inspired thought (\"manisa\") or wisdom guarded by the seers on the seat of \"Rta\". The Rig Veda links language not only to thought (\"manas\") but also to vision (\"dhi\"), a word from which comes \"Dhyana\" meaning 'meditation'.\nIn the Yajurveda (29.8), Sarasvati, the Goddess of Speech, is invoked to grant the gift of \"Dhi\", inspired thought, and thought is linked with \"Vāc\"; Sarasvati is also known as the river of inspired thought,\n\nThe Vedas are the sacred texts of the Hindus. They are the repository of what is the known or required to be known, in other words, the true knowledge or the transcendent eternal wisdom articulated in Sound ('sabda') or Speech ('vāc'). The Vedic seers have associated the power of speech or the spoken word with ultimacy and transcendence – \"ekam sat\" (Rig Veda I.164.46). They also know Vishwakarma, the creator, as Vācaspati, the Lord of Speech (Rig Veda X.81.7) (who is also called Brihaspati and Brahmanaspati), and that Vāc or speech or utterance as Brahman is the creative principle and the absolute force in the universe; the person who has gained its knowledge is said to have attained the highest knowledge (Rig Veda X.125.5). As far as Brahman extends so far does \"Vāc\" (Rig Veda X.114.8).\n\nThe Inspired thought (\"dhi\") that precedes utterance though connected with speech undergoes some modifications while being transformed into speech; the Vedic Rishis tell us that the thoughtful one's produce speech with their mind (Rig Veda X.71.2), the different stages in transformation from \"dhi\" to \"vāc\" are described in the Atharvaveda (VII.1.1). \"Dhi\" is the voiced speech. Goddess Saraswati presides over speech but \"vāc\" extends far above and beyond Saraswati (Rig Veda X.125) beyond all known spheres (Rig Veda X.114.8). Vāc is dependent on breath or air; and the Aitareya Brahmana (IV.42.1) states \"Brahman vai vāk\", Vāc is the mother of the Vedas and the Vedas themselves (Shatapatha Brahmana (6.5.3.4).\nThe Vedas are a form of the ritual and cosmological \"Vāc\" (speech). Vāc is presented as consort of Prajapati (Kathaka Samhita 12.5.27.1) whom the Brahmanas express as 'the expressed' (\"nirukta\") and as the 'unexpressed' (\"anirukta\"), the limited and the unlimited. Taittiriya Aranyaka tells us that Vāc is the imperishable one, the (\"Aksara\"), the first-born of the cosmic order (\"Rta\"), the mother of the Vedas (\"vedanam mata\"), the navel of immortality (\"Amrita\") and therefore Vedas themselves are infinite (\"Ananta\"), immortal (\"amrta\") and imperishable (\"akshita\"). The \"Jaiminiya Upanishad\" tells us that Aum or Om, the essence of all essences, is Vāc. On the human plane the mind precedes speech, and on the cosmic plane Prajapati precedes \"vāc\" as the Lord of Thought and Speech, who brings forth \"vāc\" to unite with \"vāc\" to manifest creation.\n\"Vāc\" was probably the language commonly spoken by the Vedic people as the language of men. \"Vāc\" is another name for Aditi or Viraj.\n\nFor the purpose of invoking Agni and other \"devatas\", the mantras of the Rig Veda have a very essential role to play because the \"Upasaka\" when meditating is required to think of the Rcs as Vāc i.e. speech; it is for this reason that the mantras are chanted and there is a prescribed way to do that chanting. Rishi Medhatithi Kanva (Rig Veda I.12.11) prays:\n\n\"May Agni accept the words of praise (adoration) set in newer hymns composed in Gayatri metre and devoutly sung (chanted), (May Agni) accept the oblations made in it (in the prescribed manner) of the offerings rightly earned and belonging to the performers of rites.\" And, Rishi Ayasya (Rig Veda IX.46.2) praying thus-\n\ninforms us that having acquired the knowledge of the highest the learned people (easily) unravel the deeply hidden meaning of the most subtle kind. This means, that each experience of ours is a re-discovery of ourselves, and that in order to really re-discover ourselves so as to understand our true nature we have to firstly awaken our mind, then make the mind speak loudly enough to be heard because Prana, which is the body of the mind, is that very silence waiting to be heard. A sage of the Rig Veda (Rig Veda X.20.9) states that the creator vested \"Agni\" with three coloured flames and made it brilliant, eminent, swift-acting and hot. The sage of the Chandogya Upanishad tells us that behind all things are these three colours, the rest constituted out of them are a modification and a name. Speech is Rk or \"Brhati\" identified with \"Prana\" whose lord is Brihaspati, the same lord is Brahmanaspati when speech is \"Yajus\" associated with Brahman. Speech is \"Sama\"; it cannot reveal itself for it is as formless as the air on which it rides; it rides upon the streams of air constituting the wind, and words once uttered do not return to the speaker.\n\nYajnavalkya tells King Janaka that the light that comes nearest to the supreme light of the Atman is the light of Vāc i.e. speech, since it is the supreme faculty of reason that finally lifts the consciousness towards the pure self-shining awareness of the Atman, and which after serving as a pointer vanishes or goes to rest. The Vedic sages have all along advocated 'Truth', 'Penance' and 'Study' as special virtues. Amongst these three special virtues Truth is held out to be the supreme virtue to be practised by all aspirants. All primary virtues are firstly imbibed from the parents; Satyakama Jabala acquired the spirit of truthfulness from his mother, and Sanat Kumara taught Narada that Truth has to be sought for realization – \"when one indeed understands Truth in its reality one speaks the truth\".\n\nWhile describing the rituals associated with the Ashvamedha yajna, in the Brihadaranyaka Upanishad we are told that the neighing of the horse, representing the cosmos, is Vāc.\n\nA sage of the Chandogya Upanishad after declaring that the syllable \"Aum\", having the individual and also the cosmic efficacy, not only serves to help the meditation of the individual person but even the Sun travels the universe singing \"Aum\" as does \"Prana\" moving in the body (Ch.Up.I.5.1,3) explains that that \"Aum\" is the essence of all beings on this earth, the essence of a person is speech and the essence of speech is the Rig Veda (Ch.Up.I.1.2) but the essence of Samaveda, which is the essence of the Rig Veda, is \"Udgitha\" which is \"Aum\". He declares that all speech is interwoven on the symbol \"Aum\", in the same manner as the leaves of a tree are woven together on a stalk (Ch.Up.II.23.3). Speech is the fuel of fire which is man (Ch.Up.V.7.1). Mind consists of 'food', the Prana consists of 'water' and speech consists of 'fire' (Ch.Up.VI.6.5). Narada is told by Sanat Kumara that all this is but a name by which one knows, even then speech is greater than name because if there is no speech neither righteousness nor unrighteousness would be known, but surely the mind is greater than speech for mind is the entire world (Ch.Up.VII.2 & 3) establishing the claim of the mind (\"dhi\") for primacy over speech (\"vāc\").\n"}
{"id": "639170", "url": "https://en.wikipedia.org/wiki?curid=639170", "title": "Diplomatics", "text": "Diplomatics\n\nDiplomatics (in American English, and in most anglophone countries), or diplomatic (in British English), is a scholarly discipline centred on the critical analysis of documents: especially, historical documents. It focuses on the conventions, protocols and formulae that have been used by document creators, and uses these to increase understanding of the processes of document creation, of information transmission, and of the relationships between the facts which the documents purport to record and reality.\n\nThe discipline originally evolved as a tool for studying and determining the authenticity of the official charters and diplomas issued by royal and papal chanceries. It was subsequently appreciated that many of the same underlying principles could be applied to other types of official document and legal instrument, to non-official documents such as private letters, and, most recently, to the metadata of electronic records.\n\nDiplomatics is one of the auxiliary sciences of history. It should not be confused with its sister-discipline of palaeography. In fact, its techniques have more in common with those of the literary disciplines of textual criticism and historical criticism.\n\nDespite the verbal similarity, the discipline has nothing to do with diplomacy. Both terms are derived, by separate linguistic development, from the word \"diploma\", which originally referred to a folded piece of writing material—and thus both to the materials which are the focus of study in diplomatics, and to accreditation papers carried by diplomats.\n\nThe word \"diplomatics\" was effectively coined by the Benedictine monk Jean Mabillon, who in 1681 published his treatise, \"De re diplomatica\" (Latin: roughly, \"The Study of Documents\"). From there, the word entered the French language as \"diplomatique\", and then English as \"diplomatic\" or \"diplomatics\".\n\n\"Webster's Dictionary\" (1828) defines diplomatics as the \"science of diplomas, or of ancient writings, literary and public documents, letters, decrees, charters, codicils, etc., which has for its object to decipher old writings, to ascertain their authenticity, their date, signatures, etc.\"\n\nGiorgio Cencetti (1908–1970) defined the discipline as \"the study of the \"Wesen\" [being] and \"Werden\" [becoming] of documentation, the analysis of genesis, inner constitution and transmission of documents, and of their relationship with the facts represented in them and with their creators\".\n\nThe Commission International de Diplomatique has defined diplomatics as \"the science which studies the tradition, the form and the issuing of written documents\".\n\nMore pragmatically, Peter Beal defines diplomatics as \"the science or study of documents and records, including their forms, language, script and meaning. It involves knowledge of such matters as the established wording and procedures of particular kinds of document, the deciphering of writing, and document analysis and authentication\".\n\nTheo Kölzer defines diplomatics as \"the teaching and the study of charters\". He treats the terms \"charter\", \"diploma\", and \"document\" as broadly synonymous, and refers to the German scholar Harry Bresslau's definition of \"documents\" as \"written declarations recorded in compliance with certain forms alternating according to the difference in person, place, time, and matter, which are meant to serve as a testimony of proceedings of a legal nature\".\n\nProperly speaking, and as usually understood by present-day scholars, diplomatics is concerned essentially with the analysis and interpretation of the linguistic and textual elements of a document. It is, however, closely associated with several parallel disciplines, including palaeography, sigillography, codicology, and provenance studies, all of which are concerned with a document's physical characteristics and history, and which will often be carried out in conjunction with a diplomatic analysis. The term diplomatics is therefore sometimes used in a slightly wider sense, to encompass some of these other areas (as it was in Mabillon's original work, and as is implied in the definitions of both Webster and Beal quoted above). The recent development of the science in non-English Europe is expanding its scope to a cultural history of documentation including aspects of pragmatic literacy or symbolic communication.\n\nChristopher Brooke, a distinguished teacher of diplomatics, referred to the discipline's reputation in 1970 as that of \"a formidable and dismal science ... a kind of game played by a few scholars, most of them medievalists, harmless so long as it does not dominate or obscure historical enquiry; or, perhaps, most commonly of all, an aid to understanding of considerable use to scholars and research students if only they had time to spare from more serious pursuits\".\n\nIn the ancient and medieval periods, the authenticity of a document was considered to derive from the document's place of preservation and storage, in, for example, temples, public offices, and archives. As a result, those with nefarious motives were able to give forged documents a spurious authenticity by depositing them in places of authority. Diplomatics grew from a need to establish new standards of authenticity through the critical analysis of the textual and physical forms of documents.\n\nThe first notable application of diplomatics was by Nicolas of Cusa, in 1433, and Lorenzo Valla, in 1440, who determined, independently, that the Donation of Constantine, which had been used for centuries to legitimize papal temporal authority, was a forgery. Diplomatics became important during the Reformation and Counter-Reformation. Its emergence as a recognisably distinct sub-discipline, however, is generally dated to the publication of Mabillon's \"De re diplomatica\" in 1681. Mabillon had begun studying old documents with a view towards establishing their authenticity as a result of the doubts raised by the Jesuit Daniel van Papenbroek over supposed Merovingian documents from the Abbey of Saint-Denis. During the Middle Ages, the production of spurious charters and other documents had been common, either to provide written documentation of existing rights or to bolster the plausibility of claimed rights. Mabillon's work engendered a far livelier awareness of the potential presence of forged or spurious documents, in the fields of both history and law.\n\nAlthough Mabillon is still widely seen as the \"father\" of diplomatics, a more important milestone in the formation of the battery of practical techniques which make up the modern discipline was the publication of René-Prosper Tassin and Charles-François Toustain's \"Nouveau traité de diplomatique\", which appeared in six volumes in 1750–65.\n\nThe most significant work in English was Thomas Madox's \"Formulare Anglicanum\", published in 1702. In general, however, the discipline was always studied more intensively by continental scholars than by those in Britain.\n\nDiplomatics is often associated with the study of documents of the medieval period. However, scholars such as Luciana Duranti have argued that many of its theories and principles can be adapted and applied to contemporary archival science.\n\nThe study of diplomatics is a valuable tool for historians, enabling them to determine whether alleged historical documents and archives are in fact genuine or forgeries. Its techniques may also be used to help date undated documents.\n\nDiplomatics has many similar applications in the field of law.\n\nSome famous cases in which the principles of diplomatics have been employed have included:\n\nA diplomatic edition is an edition (in print or online) of an historic manuscript text that seeks to reproduce as accurately as possible in typography all significant features of the manuscript original, including spelling and punctuation, abbreviations, deletions, insertions, and other alterations. Similarly, diplomatic transcription attempts to represent by means of a system of editorial signs all features of a manuscript original. The term \"semi-diplomatic\" is used for an edition or transcription that seeks to reproduce only some of these features of the original. A diplomatic edition is thus distinguished from a \"normalized edition\", in which the editor, while not altering the original wording of the text, renders it using normal (modern) orthography.\n\nA diplomatic edition is also to be distinguished both from a \"facsimile edition\", which, in the modern era, normally employs photographic or digital images; and from a \"type facsimile\" (such as Abraham Farley's edition of \"Domesday Book\"), which seeks to reproduce the appearance of the original through the use of a special typeface or digital font.\n\n\n"}
{"id": "2545484", "url": "https://en.wikipedia.org/wiki?curid=2545484", "title": "English in computing", "text": "English in computing\n\nThe English language is sometimes described as the \"lingua franca\" of computing. In comparison to other sciences, where Latin and Greek are the principal sources of vocabulary, computer science borrows more extensively from English. Due to the technical limitations of early computers, and the lack of international standards on the Internet, computer users were limited to using English and the Latin alphabet. However, this historical limitation is less present today. Most software products are localized in numerous languages and the use of the Unicode character encoding has resolved problems with non-Latin alphabets. Some limitations have only been changed recently, such as with domain names, which previously allowed only ASCII characters.\n\nThe computing terminology of many languages borrows from English. Some language communities resist actively to that trend, and in other cases English is used extensively and more directly. This section gives some examples for the use of English terminology in other languages, and also mentions any notable differences.\n\nBoth English and Russian have influence over Bulgarian computing vocabulary. However, in many cases the borrowed terminology is translated, and not transcribed phonetically. Combined with the use of Cyrillic this can make it difficult to recognize loanwords. For example, the Bulgarian term for motherboard is 'дънна платка' (IPA /danna platka/ or literally \"bottom board\").\n\n\nThe Faroese language has a sparse scientific vocabulary \"based on the language itself\". Many Faroese scientific words are borrowed and/or modified versions of especially Nordic and English equivalents. The vocabulary is constantly evolving and thus new words often die out, and only a few survive and become widely used. Examples of successful words include e.g. \"telda\" (computer), \"kurla\" (at sign) and \"ambætari\" (server).\n\nIn French, there are some generally accepted English loan-words, but there is also a distinct effort to avoid them. In France, the Académie française is responsible for the standardisation of the language and often coins new technological terms. Some of them are accepted in practice, in other cases the English loanwords remain predominant. In Quebec, the Office québécois de la langue française has a similar function.\n\n\nIn German, English words are very often used as well:\n\nThe Icelandic language has its own vocabulary of scientific terms, still English borrowings exist. English or Icelandicised words are mostly used in casual conversations, whereas the Icelandic words might be longer or not widespread.\n\nIt's quite common to use English words in regards to computing in all Scandinavian languages.\n\nnouns: keyboard, webside, mail, software, blogg, spam\n\nverbs: å boote, å spamme, å blogge\n\nPolish language words derived from English:\n\n\nThe English influence on the software industry and the internet in Latin America has borrowed significantly from the Castilian lexicon.\n\n\n\nMany computing terms in Spanish share a common root with their English counterpart. In these cases, both terms are understood, but the Spanish is preferred for formal use:\n\nThe early computer software and hardware had very little support for alphabets other than the Latin. As a result of this it was difficult or impossible to represent languages based on other scripts. The ASCII character encoding, created in the 1960s, only supported 128 different characters. With the use of additional software it was possible to provide support for some languages, for instance those based on the Cyrillic alphabet. However, complex-script languages like Chinese or Japanese need more characters than the 256 limit imposed by 8-bit character encodings. Some computers created in the former USSR had native support for the Cyrillic alphabet.\n\nThe wide adoption of Unicode, and UTF-8 on the web, resolved most of these historical limitations. ASCII remains the de facto standard for command interpreters, programming languages and text-based communication protocols.\n\n\nThe syntax of most programming languages uses English keywords, and therefore it could be argued some knowledge of English is required in order to use them. However, it is important to recognize all programming languages are in the class of formal languages. They are very different from any natural language, including English.\n\nSome examples of non-English programming languages:\n\n\nMany application protocols use text strings for requests and parameters, rather than the binary values commonly used in lower layer protocols. The request strings are generally based on English words, although in some cases the strings are contractions or acronyms of English expressions, which renders them somewhat cryptic to anyone not familiar with the protocol, whatever their proficiency in English. Nevertheless, the use of word-like strings is a convenient mnemonic device that allows a person skilled in the art (and with sufficient knowledge of English) to execute the protocol manually from a keyboard, usually for the purpose of finding a problem with the service.\n\nExamples:\n\nIt is notable that response codes, that is, the strings sent back by the recipient of a request, are typically numeric: for instance, in HTTP (and some borrowed by other protocols)\n\nThis is because response codes also need to convey unambiguous information, but can have various nuances that the requester may optionally use to vary its subsequent actions. To convey all such \"sub-codes\" with alphabetic words would be unwieldy, and negate the advantage of using pseudo-English words. Since responses are usually generated by software they do not need to be mnemonic. Numeric codes are also more easily analysed and categorised when they are processed by software, instead of a human testing the protocol by manual input.\n\nMany personal computers have a BIOS chip, displaying text in English during boot time.\n\nKeyboard shortcuts are usually defined in terms of English keywords such as CTRL+F for find.\n\nEnglish is the largest language on the World Wide Web, with 27% of internet users.\n\nWeb user percentages usually focus on raw comparisons of the first language of those who access the web. Just as important is a consideration of second- and foreign-language users; i.e., the first language of a user does not necessarily reflect which language he or she regularly employs when using the web.\n\nEnglish-language users appear to be a plurality of web users, consistently cited as around one-third of the overall (near one billion). This reflects the relative affluence of English-speaking countries and high Internet penetration rates in them. This lead may be eroding due mainly to a rapid increase of Chinese users.\n\nFirst-language users among other relatively affluent countries appear generally stable, the two largest being German and Japanese, which each have between 5% and 10% of the overall share.\n\nOne widely quoted figure for the amount of web content in English is 80%. Other sources show figures five to fifteen points lower, though still well over 50%. There are two notable facts about these percentages:\n\nThe English web content is greater than the number of first-language English users by as much as 2 to 1.\n\nGiven the enormous lead it already enjoys and its increasing use as a \"lingua franca\" in other spheres, English web content may continue to dominate even as English first-language Internet users decline. This is a classic positive feedback loop: new Internet users find it helpful to learn English and employ it online, thus reinforcing the language's prestige and forcing subsequent new users to learn English as well.\n\nCertain other factors (some predating the medium's appearance) have propelled English into a majority web-content position. Most notable in this regard is the tendency for researchers and professionals to publish in English to ensure maximum exposure. The largest database of medical bibliographical information, for example, shows English was the majority language choice for the past forty years and its share has continually increased over the same period.\n\nThe fact that non-Anglophones regularly publish in English only reinforces the language's dominance. English has a rich technical vocabulary (largely because native and non-native speakers alike use it to communicate technical ideas) and many IT and technical professionals use English regardless of country of origin (Linus Torvalds, for instance, comments his code in English, despite being from Finland and having Swedish as his first language).\n"}
{"id": "43251161", "url": "https://en.wikipedia.org/wiki?curid=43251161", "title": "Episodic storytelling", "text": "Episodic storytelling\n\nEpisodic storytelling is when a story is narrated through episodes, as opposed to chapters, which are typically seen in novels. The term used in literature to refer to a body of work composed of episodes or similar installments is serial. Serials are also known as episodic fiction. \n\nMultiple episodes are usually grouped together into a series through a unifying story arc. Episodes may not always contain the same characters, but each episode draws from a broader group of characters, or cast, all of whom exist in the same story world.\n\n"}
{"id": "4829003", "url": "https://en.wikipedia.org/wiki?curid=4829003", "title": "Farfallino alphabet", "text": "Farfallino alphabet\n\nThe farfallino alphabet (in Italian alfabeto farfallino) is a language game used primarily in Italy, which can be regarded as an elementary form of substitution cipher. It is usually used by children for amusement or to converse in (perceived) privacy from adults. The name \"farfallino\" comes from the word \"farfalla\" (butterfly), which is an ordinary Italian word but sounds like the \"codified\" words in farfallino alphabet. The farfallino alphabet is similar to games found in other languages such as jeringonza (Spanish/Portuguese), langue de feu (French), Fay Kee Bolee (Urdu) and pig latin (English).\n\nThe usual rules for farfallino alphabet are based on the substitution of each vowel with a 3 letter sequence where the vowel itself is repeated with an interceding \"f\".\n\nIts translation in Italian is:\nWhich means, in English:\n\nThere are several minor variations to this scheme. One such variation is based on the following substitution rules: \n\nAlthough rules for \"e\" and \"i\" look different, they are not; the additional \"h\" is needed in Italian to enforce a voiced velar plosive sound for letter \"g\", which is implicit in the other combinations. Another more complicated scheme, which is used in some regions of Italy, is as follows:\n\n"}
{"id": "33526402", "url": "https://en.wikipedia.org/wiki?curid=33526402", "title": "German Orthographic Conference of 1901", "text": "German Orthographic Conference of 1901\n\nThe German Orthographic Conference of 1901 (the Berlin II Orthographic Conference; or \"\") took place in Berlin from 17th till 19 June 1901. The results of the conference became official in the German Empire in 1902. \nThe standardized German spelling that resulted from the conference was largely based on the Prussian school spelling, but also on the Orthographic Conference of 1876.\n\nThe conference results removed numerous existing variant forms.\nSoon after the conference, its results were criticized by people who believed there should be further changes.\n\nThe spelling was used in Germany, Austria and Switzerland, apart from the replacement of \"ß\" with \"ss\" in Switzerland in later years.\nThe \"Erziehungsrat des Kantons Zürich\" stopped the teaching of \"ß\" in schools in 1935 with the Kanton Zürich being the first to do so, and the \"Neue Zürcher Zeitung\" as last Swiss newspaper stopped using \"ß\" in 1974. However, some Swiss book publishers still use \"ß\".\n\nIt was not until 95 years later that the German spelling was changed with a reform in 1996.\n"}
{"id": "11709017", "url": "https://en.wikipedia.org/wiki?curid=11709017", "title": "Global language system", "text": "Global language system\n\nThe global language system is the \"ingenious pattern of connections between language groups\". Dutch sociologist Abram de Swaan developed this theory in 2001 in his book \"Words of the World: The Global Language System\" and according to him, \"the multilingual connections between language groups do not occur haphazardly, but, on the contrary, they constitute a surprisingly strong and efficient network that ties together – directly or indirectly – the six billion inhabitants of the earth.\" The global language system draws upon the world system theory to account for the relationships between the world's languages and divides them into a hierarchy consisting of four levels, namely the peripheral, central, supercentral and hypercentral languages.\n\nAccording to de Swaan, the global language system has been constantly evolving since the time period of the early 'military-agrarian' regimes. Under these regimes, the rulers imposed their own language and so the first 'central' languages emerged, linking the peripheral languages of the agrarian communities via bilingual speakers to the language of the conquerors. Then was the formation of empires, which resulted in the next stage of integration of the world language system.\n\nFirstly, Latin emerged from Rome. Under the rule of the Roman Empire, under which an extensive group of states were ruled by, the usage of Latin stretched along the Mediterranean coast, the southern half of Europe, and more sparsely to the North and then into the Germanic and Celtic lands. Thus, Latin evolved to become a central language in Europe from 27 BC to 476 AD.\n\nSecondly, there was the widespread usage of the pre-classical version of Han Chinese in contemporary China due to the unification of China in 221 BC by Qin Shi Huang.\n\nThirdly, Sanskrit started to become widely spoken in South Asia from the widespread teaching of Hinduism and Buddhism in South Asian countries.\n\nFourthly, the expansion of the Arabic empire also led to the increased usage of Arabic as a language in the Afro-Eurasian land mass.\n\nMilitary conquests of preceding centuries generally determine the distribution of languages today.\nSupercentral languages spread by land and sea. Land-bound languages spread via marching empires: German, Russian, Arabic, Hindi, Chinese and Japanese. However, when the conquerors were defeated and were forced to move out of the territory, the spread of the languages receded. As a result, some of these languages are currently barely supercentral languages and are instead confined to their remaining state territories, as is evident from German, Russian and Japanese.\n\nOn the other hand, sea-bound languages spread by conquests overseas: English, French, Portuguese, Spanish. Consequently, these languages became widespread in areas settled by European colonisers and relegated the indigenous people and their languages to peripheral positions.\n\nBesides, the world-systems theory also allowed the global language system to expand further. It focuses on the existence of the core, semi-peripheral and peripheral nations. The core countries are the most economically powerful and the wealthiest countries. Besides, they also have a strong governmental system in the country, which oversees the bureaucracies in the governmental departments. There is also the prevalent existence of the bourgeois, and core nations have significant influence over the non-core, smaller nations. Historically, the core countries were found in northwestern Europe and include countries such as England, France and the Netherlands. They were the dominant countries that had colonized many other nations from the early 15th century to the early 19th century.\n\nThen is the existence of the periphery countries, the countries with the slowest economic growth. They also have relatively weak governments and a poor social structure and often depend on primary industries as the main source of economic activity for the country.\n\nThe extracting and exporting of raw materials from the peripheral nations to core nations is the activity bringing about the most economic benefits to the country. Much of the population that is poor and uneducated, and the countries are also extensively influenced by core nations and the multinational corporations found there. Historically, peripheral nations were found outside Europe, the continent of colonial masters. Many countries in Latin America were peripheral nations during the period of colonization, and today peripheral countries are in sub-Saharan Africa.\n\nLastly, the presence of the semiperiphery countries, those in between the core and the periphery. They tend to be those which started out as peripheral nations and are currently moving towards industrialization and the development of more diversified labour markets and economies. They can as well come about from declining core countries. They are not dominant players in the international trade market. As compared to the peripheral nations, semi-peripheries are not as susceptible to manipulation by the core countries. However, most of these nations have economic or political relations with the core. Semi-peripheries also tend to exert influence and control over peripheries and can serve to be a buffer between the core and peripheral nations and ease political tensions. Historically, Spain and Portugal were semi-peripheral nations after they fell from their dominant core positions. As they still maintained a certain level of influence and dominance in Latin America over their colonies, they could still maintain their semi-peripheral position.\n\nAccording to Immanuel Wallerstein, one of the most well-known theorists who developed the world-systems approach, a core nation is dominant over the non-core nations from its economic and trade dominance. The abundance of cheap and unskilled labour in the peripheral nations makes many large multinational corporations (MNCs), from core countries, often outsource their production to the peripheral countries to cut costs, by employing cheap labour. Hence, the languages from the core countries could penetrate into the peripheries from the setting up of the foreign MNCs in the peripheries. A significant percentage of the population living in the core countries had also migrated to the core countries in search of jobs with higher wages.\n\nThe gradual expansion of the population of migrants makes the language used in their home countries be brought into the core countries, thus allowing for further integration and expansion of the world language system. The semi-peripheries also maintain economic and financial trade with the peripheries and core countries. That allows for the penetration of languages used in the semi-peripheries into the core and peripheral nations, with the flow of migrants moving out of the semi-peripheral nations to the core and periphery for trade purposes.\n\nThus, the global language system examines rivalries and accommodations using a global perspective and establishes that the linguistic dimension of the world system goes hand in hand with the political, economic, cultural and ecological aspects. Specifically, the present global constellation of languages is the product of prior conquest and domination and of ongoing relations of power and exchange.\n\nformula_1 is the communicative value of a language \"i\", its potential to connect a speaker with other speakers of a constellation or subconstellation, \"S\". It is defined as follows:\n\nformula_2\n\nThe prevalence formula_3 of language \"i\", means the number of competent speakers in \"i\", formula_4, divided by all the speakers, formula_5 of constellation \"S\". Centrality, formula_6 is the number of multilingual speakers formula_7 who speak language \"i\" divided by all the multilingual speakers in constellation \"S\", formula_8.\n\nThus, the Q-value or communication value is the product of the prevalence formula_3 and the centrality formula_6 of language \"i\" in constellation \"S\".\n\nConsequently, a peripheral language has a low Q-value and the Q-values increase along the sociology classification of languages, with the Q-value of the hypercentral language being the highest.\n\nDe Swaan has been calculating the Q-values of the official European Union(EU) languages since 1957 to explain the acquisition of languages by EU citizens in different phases.\n\nIn 1970, when there were only four language constellations, Q-value decreased in the order of French, German, Italian, Dutch. In 1975, the European Commission enlarged to include Britain, Denmark and Ireland. English had the highest Q-value followed by French and German.\nIn the following years, the European Commission grew, with the addition of countries like Austria, Finland and Sweden. Q-value of English still remained the highest, but French and German swapped places.\n\nIn EU23, which refers to the 23 official languages spoken in the European Union, the Q-values for English, German and French were 0.194, 0.045 and 0.036 respectively.\n\nDe Swaan likens the global language system to contemporary political macrosociology and states that language constellations are a social phenomenon, which can be understood by using social science theories. In his theory, de Swaan uses the Political Sociology of Language and Political Economy of Language to explain the rivalry and accommodation between language groups.\n\nThis theoretical perspective centres on the interconnections among the state, nation and citizenship. Accordingly, bilingual elite groups try to take control of the opportunities for mediation between the monolingual group and the state. Subsequently, they use the official language to dominate the sectors of government and administration and the higher levels of employment. It assumes that both the established and outsider groups are able to communicate in a shared vernacular, but the latter groups lack the literacy skills that could allow them to learn the written form of the central or supercentral language, which would, in turn allow, them to move up the social ladder.\n\nThis perspective centres on the inclinations that people have towards learning one language over the other. The presumption is that if given a chance, people will learn the language that gives them more communication advantage. In other words, a higher Q-Value. Certain languages such as English or Chinese have high Q-values since they are spoken in many countries across the globe and would thus be more economically useful than to less spoken languages, such as Romanian or Hungarian.\n\nFrom an economic perspective, languages are ‘hypercollective’ goods since they exhibit properties of collective goods and produce external network effects. Thus, the more speakers a language has, the higher its communication value for each speaker. The hypercollective nature and Q-Value of languages thus help to explain the dilemma that a speaker of a peripheral language faces when deciding whether to learn the central or hypercentral language. The hypercollective nature and Q-value also help to explain the accelerating spread and abandonment of various languages. In that sense, when people feel that a language is gaining new speakers, they would assign a greater Q-value to this language and abandon their own native language in place of a more central language. The hypercollective nature and Q-value also explain, in an economic sense, the ethnic and cultural movements for language conservation.\n\nSpecifically, a minimal Q-value of a language is guaranteed when there is a critical mass of speakers committed to protecting it, thus preventing the language from being forsaken.\n\nThe global language system theorises that language groups are engaged in unequal competition on different levels globally. Using the notions of a periphery, semi-periphery and a core, which are concepts of the world system theory, de Swaan relates them to the four levels present in the hierarchy of the global language system: peripheral, central, supercentral and hypercentral.\n\nDe Swaan also argues that the greater the range of potential uses and users of a language, the higher the tendency of an individual to move up the hierarchy in the global language system and learn a more \"central\" language. Thus, de Swaan views the learning of second languages as proceeding up rather than down the hierarchy, in the sense that they learn a language that is on the next level up. For instance, speakers of Catalan, a peripheral language, have to learn Spanish, a central language to function in their own society, Spain. Meanwhile, speakers of Persian, a central language, have to learn Arabic, a supercentral language, to function in their region. On the other hand, speakers of a supercentral language have to learn the hypercentral language to function globally, as is evident from the huge number of non-native English speakers.\n\nAccording to de Swaan, languages exist in \"constellations\" and the global language system comprises a sociological classification of languages based on their social role for their speakers. The world's languages and multilinguals are connected in a strongly ordered, hierarchical pattern. There are thousands of peripheral or minority languages in the world, each of which are connected to one of a hundred central languages. The connections and patterns between each language is what makes up the global language system. The four levels of language are the peripheral, central, supercentral and hypercentral languages.\n\nAt the lowest level, peripheral languages, or minority languages, form the majority of languages spoken in the world; 98% of the world's languages are peripheral languages and spoken by less than 10% of the world’s population. Unlike central languages, these are \"languages of conversation and narration rather than reading and writing, of memory and remembrance rather than record\". They are used by native speakers within a particular area and are in danger of becoming extinct with increasing globalisation, which sees more and more speakers of peripheral languages acquiring more central languages in order to communicate with others.\n\nThe next level constitutes about 100 central languages, spoken by 95% of the world's population and generally used in education, media and administration. Typically, they are the 'national' and official languages of the ruling state. These are the languages of record, and much of what has been said and written in those languages is saved in newspaper reports, minutes and proceedings, stored in archives, included in history books, collections of the 'classics', of folk talks and folk ways, increasingly recorded on electronic media and thus conserved for posterity.\n\nMany speakers of central languages are multilingual because they are either native speakers of a peripheral language and have acquired the central language, or they are native speakers of the central language and have learned a supercentral language.\n\nAt the second highest level, 13 supercentral languages are very widely spoken languages that serve as connectors between speakers of central languages: Arabic, Chinese, English, French, German, Hindi, Japanese, Malay, Portuguese, Russian, Spanish, Swahili and Turkish.\n\nThese languages often have colonial traces and \"were once imposed by a colonial power and after independence continued to be used in politics, administration, law, big business, technology and higher education\".\n\nAt the highest level is the language that connects speakers of the supercentral languages. Today, English is the only example of a hypercentral language as the standard for science, literature, business, and law, as well as being the most widely spoken second language.\n\nAccording to David Graddol (1997), in his book titled \"The Future of English\", the languages of the world comprise a \"hierarchical pyramid\", as follows:\n\n\nThe global language system is also seen in the international translation process as explained by Johan Heilbron, a historical sociologist: \"translations and the manifold activities these imply are embedded in and dependent on a world system of translation, including both the source and the target cultures\".\n\nThe hierarchical relationship between global languages is reflected in the global system for translations. The more \"central\" a language, the greater is its capability to function as a bridge or vehicular language to facilitate communication between peripheral and semi-central languages.\n\nHeilbron's version of the global system of language in translations has four levels:\n\nLevel 1: Hypercentral position — \nEnglish currently holds the largest market share of the global market for translations; 55–60% of all book translations are from English. It strongly dominates the hierarchical nature of book translation system.\n\nLevel 2: Central position — \nGerman and French each hold 10% of the global translation market.\n\nLevel 3: Semi-central position — \nThere are 7 or 8 languages \"neither very central on a global level nor very peripheral\", making up 1 to 3% of the world market (like Spanish, Italian and Russian).\n\nLevel 4: Peripheral position — \nLanguages from which \"less than 1% of the book translations worldwide are made\", including Chinese, Japanese and Arabic. Despite having large populations of speakers, \"their role in the translation economy is peripheral as compared to more central languages\".\n\nAccording to the Google Scholar website, de Swaan's book, \"Words of the world: The global language system\", has been cited by 546 other papers, as of 16 October 2014.\n\nHowever, there have also been several concerns regarding the global language system:\n\nVan Parijs (2004) claimed that 'frequency' or likelihood of contact is adequate as an indicator of language learning and language spread. However, de Swaan (2007) argued that it alone is not sufficient. Rather, the Q-value, which comprises both frequency (better known as prevalence) and 'centrality', helps to explain the spread of (super)central languages, especially former colonial languages in newly independent countries where in which only the elite minority spoke the language initially. Frequency alone would not be able to explain the spread of such languages, but Q-value, which includes centrality, would be able to.\n\nIn another paper, Cook and Li (2009) examined the ways to categorise language users into various groups. They suggested two theories: one by Siegel (2006) who used 'sociolinguistic settings', which is based on the notion of dominant language, and another one by de Swaan (2001) that used the concept of hierarchy in the global language system. According to them, de Swaan's hierarchy is more appropriate, as it does not imply dominance in power terms. Rather, de Swaan's applies the concepts of geography and function to group languages and hence language users according to the global language system. De Swaan (2001) views the acquisition of second languages (L2) as typically going up the hierarchy.\n\nHowever, Cook and Li argues that this analysis is not adequate in accounting for the many groups of L2 users to whom the two areas of territory and function hardly apply. The two areas of territory and function can be associated respectively with the prevalence and centrality of the Q-value. This group of L2 users typically doez not acquire an L2 going up the hierarchy, such as users in an intercultural marriage or users who come from a particular cultural or ethnic group and wish to learn its language for identity purposes. Thus, Cook and Li argue that de Swaan's theory, though highly relevant, still has its drawbacks in that the concept behind Q-value is insufficient in accounting for some L2 users.\n\nThere is disagreement as to which languages should be considered more central. The theory states that a language is central if it connects speakers of \"a series of central languages\". Robert Phillipson questioned why Japanese is included as one of the supercentral languages but Bengali, which has more speakers, is not on the list.\n\nMichael Morris argued that while it is clear that there is language hierarchy from the \"ongoing interstate competition and power politics\", there is little evidence provided that shows that the \"global language interaction is so intense and systematic that it constitutes a global language system, and that the entire system is held together by one global language, English\". He claimed that de Swaan's case studies demonstrated that hierarchy in different regions of the world but did not show the existence of a system within a region or across regions. The global language system is supposed to be part of the international system but is \"notoriously vague and lacking in operational importance\" and therefore cannot be shown to exist. However, Morris believes that this lack of evidence could be from the lack of global language data and not negligence on de Swaan's part. Morris also believes that any theory on a global system, if later proved, would be much more complex than what is proposed by de Swaan. Questions on how the hypercentral language English holds together the system must also be answered by such a global language system.\n\nRobert Phillipson states that the theory is based on selective theoretical foundations. He claimed that there is a lack of consideration about the effects of globalization, which is especially important when the theory is about a global system: \"De Swaan nods occasionally in the direction of linguistic and cultural capital, but does not link this to class or linguistically defined social stratification (linguicism) or linguistic inequality\" and that \"key concepts in the sociology of language, language maintenance and shift, and language spread are scarcely mentioned\".\n\nOn the other hand, de Swaan's work in the field of sociolinguistics has been noted by other scholars to be focused on \"issues of economic and political sociology\" and \"politic and economic patterns\", which may explain why he makes only 'cautious references to socio-linguistic parameters\".\n\n"}
{"id": "37125418", "url": "https://en.wikipedia.org/wiki?curid=37125418", "title": "Hopi time controversy", "text": "Hopi time controversy\n\nThe Hopi time controversy is the academic debate about how the Hopi language grammaticalizes the concept of time, and about whether the differences between the ways the English and Hopi languages describe time are an example of linguistic relativity or not. In popular discourse the debate is often framed as a question about whether the Hopi \"had a concept of time\", despite it now being well established that they do.\n\nThe debate originated in the 1940s when American linguist Benjamin Lee Whorf argued that the Hopi conceptualized time differently from the Standard Average European speaker, and that this difference correlated with grammatical differences between the languages. Whorf argued that Hopi has \"no words, grammatical forms, construction or expressions that refer directly to what we call 'time'\", and concluded that the Hopi had \"no general notion or intuition of time as a smooth flowing continuum in which everything in the universe proceeds at equal rate, out of a future, through the present, into a past\". Whorf used the Hopi concept of time as a primary example of his concept of linguistic relativity, which posits that the way in which individual languages encode information about the world, influences and correlates with the cultural world view of the speakers. Whorf's relativist views fell out of favor in linguistics and anthropology in the 1960s, but Whorf's statement lived on in the popular literature often in the form of an urban myth that \"the Hopi have no concept of time\". In 1983 linguist Ekkehart Malotki published a 600-page study of the grammar of time in the Hopi language, concluding that he had finally refuted Whorf's claims about the language. Malotki's treatise gave hundreds of examples of Hopi words and grammatical forms referring to temporal relations. Malotki's central claim was that the Hopi do indeed conceptualize time as structured in terms of an ego-centered spatial progression from past, through present into the future. He also demonstrated that the Hopi language grammaticalizes tense using a distinction between future and non-future tenses, as opposed to the English tense system, which is usually analyzed as being based on a past/non-past distinction. Many took Malotki's work as a definitive refutation of the linguistic relativity hypothesis. Linguist and specialist in the linguistic typology of tense Bernard Comrie concluded that \"Malotki's presentation and argumentation are devastating\". Psychologist Steven Pinker, a well-known critic of Whorf and the concept of linguistic relativity, accepted Malotki's claims as having demonstrated Whorf's complete ineptitude as a linguist.\n\nSubsequently the study of linguistic relativity was revived using new approaches in the 1990s, and Malotki's study came under criticism from relativist linguists and anthropologists, who did not consider that the study invalidated Whorf's claims. The main issue of contention is the interpretation of Whorf's original claims about Hopi, and what exactly it was that he was claiming made Hopi different from what Whorf called \"Standard Average European\" languages. Some consider that the Hopi language may be best described as a tenseless language, and that the distinction between non-future and future posited by Malotki may be better understood as a distinction between \"realis\" and \"irrealis\" moods. Regardless of exactly how the Hopi concept of time is best analyzed, most specialists agree with Malotki that all humans conceptualize time by an analogy with space, although some recent studies have also questioned this.\n\nThe Hopi language is a Native American language of the Uto-Aztecan language family, which is spoken by some 5,000 Hopi people in the Hopi Reservation in Northeastern Arizona, US.\n\nIn the large \"\" there is no word exactly corresponding to the English noun \"time\". Hopi employs different words to refer to \"a duration of time\" (\"pàasa\"' \"for that long\"), to a point in time (\"pàasat\" \"at that time\"), and time as measured by a clock (\"pahàntawa\"), as an occasion to do something (\"hisat\" or \"qeni\"), a turn or the appropriate time for doing something (\"qeniptsi\" (noun)), and to have time for something (\"aw nánaptsiwta\" (verb)).\n\nTime reference can be marked on verbs using the suffix \"-ni\"\n\nThe -ni suffix is also used in the word \"naatoniqa\" which means \"that which will happen yet\" in reference to the future. This word is formed from the adverb \"naato\" \"yet\", the \"-ni\" suffix and the clitic -qa that forms a relative clause with the meaning \"that which...\".\n\nThe -\"ni\" suffix is also obligatory on the main verb in conditional clauses:\n\nThe suffix is also used in conditional clauses referring to a past context then often combined with the particle \"as\" that carries past tense or counterfactual meaning, or describes unachieved intent:\n\nThe suffix \"-ngwu\" describes actions taking place habitually or as a general rule.\n\nBenjamin Lee Whorf (1897–1941), a fire prevention engineer by profession, studied Native American linguistics from an early age. He corresponded with many of the greatest scholars of his time, such as Alfred Tozzer at Harvard and Herbert Spinden of the American Museum of Natural History. They were impressed with his work on the linguistics of the Nahuatl language and encouraged him to participate professionally and to undertake field research in Mexico. In 1931 Edward Sapir, the foremost expert on Native American languages, started teaching at Yale, close to where Whorf lived, and Whorf signed up for graduate-level classes with Sapir, becoming one of his most respected students. Whorf took a special interest in the Hopi language and started working with Ernest Naquayouma, a speaker of Hopi from Toreva village on the Second Mesa of the Hopi Reservation in Arizona, who was living in the Manhattan borough of New York City. At this time it was common for linguists to base their descriptions of a language on data from a single speaker. Whorf credited Naquayouma as the source of most of his information on the Hopi language, although in 1938 he took a short field trip to the village of Mishongnovi on the Second Mesa, collecting some additional data.\n\nWhorf published several articles on Hopi grammar, focusing particularly on the ways in which the grammatical categories of Hopi encoded information about events and processes, and how this correlated with aspects of Hopi culture and behavior. After his death his full sketch of Hopi grammar was published by his friend the linguist Harry Hoijer, and some essays on Native American linguistics, many of which had been previously published in academic journals, were published in 1956 in the anthology \"Language, Thought, and Reality\" by his friend psychologist John Bissell Carroll.\n\nWhorf's most frequently cited statement regarding Hopi time is the strongly worded introduction of his 1936 paper \"An American Indian model of the Universe\", which was first published posthumously in Carroll's edited volume. Here he writes that\n\nWhorf argues that in Hopi units of time are not represented by nouns, but by adverbs or verbs. Whorf argues that all Hopi nouns include the notion of a boundary or outline, and that consequently the Hopi language does not refer to abstract concepts with nouns. This, Whorf argues, is encoded in Hopi grammar, which does not allow durations of time to be counted in the same way objects are. So instead of saying, for example, \"three days\", Hopi would say the equivalent of \"on the third day\", using ordinal numbers. Whorf argues that the Hopi do not consider the process of time passing to produce another new day, but merely as bringing back the daylight aspect of the world.\n\nWhorf gives slightly different analyses of the grammatical encoding of time in Hopi in his different writings. His first published writing on Hopi grammar was the paper \"The punctual and segmentative aspects of verbs in Hopi\", published in 1936 in \"Language\", the journal of the Linguistic Society of America. Here Whorf analyzed Hopi as having a tense system with a distinction between three tenses: one used for past or present events (which Whorf calls the \"Factual\" tense or \"present-past\"); one for future events; and one for events that are generally or universally true (here called \"usitative\"). This analysis was repeated in a 1937 letter to J. B. Carroll, who later published it as part of his selected writings under the title \"Discussion of Hopi Linguistics\".\n\nIn the 1938 paper \"Some verbal categories of Hopi\", also published in \"Language\", Whorf abandoned the word \"tense\" in the description of Hopi and described the distinction previously called \"tense\" with the label \"assertions\". Whorf described assertions as a system of categories that describe the speaker's claim of epistemic validity of his own statement. The three \"assertions\" of Hopi described by Whorf are the \"Reportive\", \"Expective\" and \"Nomic\" forms of the Hopi verb. Whorf acknowledges that these \"translate more or less [as] the English tenses\", but maintains that these forms do not refer to time or duration, but rather to the speaker's claim of the validity of the statement. The reportive form is unmarked, whereas the expective form is marked with the verbal suffix \"-ni\", and the nomic form with the suffix \"-ŋʷi\". In Whorf's analysis, by using the reportive form the speaker claims that the event has in fact occurred or is still occurring, whereas by using the expective form the speaker describes an expectation of a future event. Whorf says that the expective can be used to describe events in the past, giving the meaning of \"was going to\" or \"would\".\n\nIn the 1940 article \"Science and Linguistics\", Whorf gave the same three-way classification based on the speaker's assertion of the validity of his statement: \"The timeless Hopi verb does not distinguish between the present, past and future of the event itself but must always indicate what type of validity the intends the statement to have: a. report of an event .. b. expectation of an event ..; generalization or law about events.\"\n\nIn his full sketch of Hopi grammar published posthumously in 1946, Whorf also described how adverbial particles contributed to the linguistic description of time in Hopi. He posited two subclasses of adverbs called \"temporals\" and \"tensors\", which were used in sentences to locate events in time. A central claim in Whorf's work on linguistic relativity was that for the Hopi units of time were not considered objects that can be counted like most of the comparable English words that are described by nouns (\"a day\", \"an hour\" etc.). He argued that only the Hopi word for \"year\" was a noun, the words for days and nights were ambivalent between noun and verbs, but that all other cyclic events and periods were described by adverbial particles used as modifiers for the sentence \nIn his interpretation of Hopi time Whorf was influenced by Einstein's theory of relativity, which was developed in the first decades of the century and impacted the general Zeitgeist. Whorf, an engineer by profession, in fact made occasional reference to physical relativity, and he adopted the term \"linguistic relativity,\" reflecting the general concept of the different but equally valid interpretations of some aspects of physical reality by different observers due to differences in their (for Einstein) physical circumstances or (for Whorf) their psychological-linguistic circumstances.\n\nThe most salient points involve the concepts of \"simultaneity\" and \"spacetime\". In his 1905 Special Relativity paper, Einstein maintained that two given events can legitimately be called simultaneous if and only if they take place at the same point in time and in the same point in space. No two events which take place at a spatial distance from one another can legitimately be declared to be simultaneous in any absolute sense, for the judgement of simultaneity or non-simultaneity will depend on the physical circumstances (to be exact: the relative motion) of the observers. This difference is no artifact; each of the observers is correct (and is wrong only to the extent he or she insists that another observer is incorrect).\n\nHermann Minkowski, in his seminal 1908 address to the Congress of German Physicists, translated Einstein's 1905 mathematical equations into geometric terms. Minkowski famously declared:\n\n\"Henceforth space by itself, and time by itself, are doomed to fade away into mere shadows, and only a kind of union of the two will preserve an independent reality.\"\n\nSpatial distance and temporal distance between any two events was now replaced by a single absolute distance in spacetime.\n\nHeynick points to several passages in Whorf's writings on the Hopis which parallel Einsteinian concepts such as:\n\n\"time varies with each observer and does not permit of simultaneity\" (1940)\n\n\"The Hopi metaphysics does not raise the question whether the things at a distant village exist at the same moment as those in one's own village, for it ... says that any 'events' in the distant village can be compared to any events in one's own village only by an interval of magnitude that has both time and space forms in it.\" (c.1936) \n\nThe concept of a \"simultaneous now\" throughout the cosmos was formulated by Aristotle, Newton, and most succinctly in John Locke's \"Essay Concerning Human Understanding\" (1690):\n\n\"For this moment is common to all things that are now in being ... they all exist in the same moment of time.\"\n\nWhorf saw this notion as derived from the Standard Average European languages in which these thinkers thought: \"Newtonian space, time, and matter are no intuitions. They are recepts from culture and language. That is where Newton got them.\"\n\nHeynick, who claimed no personal knowledge of the Hopi language, posits alternative weaker and stronger interpretations of the influence of Einsteinian relativity on Whorf's analysis of the Hopi language and the Hopi concept of time. In the weaker version, the (then) new questioning of the nature of time and space brought about by the Einsteinian revolution in physics enabled Whorf to approach the Hopis and their language unburdened by traditional Western concepts and presumptions. The stronger version is that Whorf under the influence of Einstein tended inadvertently to \"read into\" his linguistic and cultural data relativistic concepts where they perhaps were not.\n\nWhorf died in 1941, but his ideas took on their own life in academia and in the popular discourse on Native Americans. In 1958 Stuart Chase—an economist and engineer at MIT who had followed Whorf's ideas with great interest, but whom Whorf himself considered utterly incompetent and incapable of understanding the nuances of his ideas—published \"Some things worth knowing: a generalist's guide to useful knowledge\". Here he repeated Whorf's claim about Hopi time, but arguing that because of the Hopi view of time as a process, they were better able to understand the concept of time as a fourth dimension. Similarly, even scientists were intrigued by the thought that the idea of spatio-temporal unity that had taken Albert Einstein seven years to ponder, was readily available to the Hopi, simply because of the grammar of their language.\n\nIn 1964 John Greenway published a humorous portrait of American culture, \"The Inevitable Americans\", in which he wrote: \"You have a watch, because Americans are obsessed with time. If you were a Hopi Indian, you would have none, the Hopi have no concept of time\". And even the 1971 ethnography of the Hopi by Euler and Dobyns claimed that \"The English concept of time is nearly incomprehensible to the Hopi\". The myth quickly became a staple element of New Age conceptualizations of the Hopi.\n\nIn 1959 philosopher Max Black published a critique of Whorf's arguments in which he argued that the principle of linguistic relativity was obviously wrong because translation between languages is always possible, even when there are no exact correspondences between the single words or concepts in the two languages.\n\nGerman linguist and philosopher Helmut Gipper had studied with the neo-Humboldtian linguist Leo Weisgerber and had a basically Kantian understanding of the relation between language and thought. Immanuel Kant considered the categories of time and space to be universals underlying all human thinking. Whorf's argument that the Hopi do not conceive of time and space as speakers of Indo-European languages do clashed with this basic understanding of cognition. Gipper went to the Hopi reservation to collect data for a general critique of Whorf's principle of linguistic relativity published in 1972. His critique included a refutation of Whorf's Hopi arguments. Gipper showed that the Hopi could refer to time, by juxtaposing Hopi phrases with their German equivalents that used words referring to units of time and to distinctions between past and present. Gipper also argued that several time intervals were described by nouns, and that these nouns could take the role of syntactic subject or object, in contradiction of Whorf's explicit statement. He argues that Whorf's assertion that intervals of time are not counted in the same way as objects is \"questionable\".\n\nEkkehart Malotki studied with Gipper at the Westfälische Wilhelms-Universität at Münster and his work was a continuation of his mentor's, spurred on by the frequent claims in the popular literature that \"the Hopi have no concept of time\". Malotki conducted four years of research on the Third Mesa, studying Hopi spatial and temporal reference. He published two large volumes, one in German, \"Hopi-Raum\" [Hopi space] and one in English, \"Hopi Time\". For Malotki it was imperative to demonstrate two facts in contradiction of Whorf's claims: 1. that the Hopi language has an abundance of terms, words and constructions that refer to time. 2. that the Hopi do cognitively conceptualize time in analogy with physical space, using spatial metaphors to describe durations and units of time. He also wanted to demonstrate that Whorf misanalyzed several particularities regarding specific Hopi words and expressions. Malotki states that a main goal is to present \"actual Hopi language data\", since when he was writing very little textual data in Hopi had been published, and Whorf's publications were largely without text examples.\n\nMost of \"Hopi Time\" is dedicated to the detailed description of the Hopi usage of words and constructions related to time. Malotki describes in detail the usage of a large amount of linguistic material: temporal adverbs, time units, time counting practices such as the Hopi calendar, the way that days are counted and time is measured.\n\nThe first part of the book describes \"spatio-temporal metaphors\"; in it he shows several deictic adverbs that are used both to reference distance in space and in time, such as the word \"ep\" that means both \"there\" and \"then\". In the second chapter he describes the way in which the Hopi talk about units of time. He argues that in some contexts, specifically those of the ceremonial cycle, the Hopi do count days, using compound words such as \"payistala\" \"the third day (of a ceremony)\" composed of the morphemes \"paayo\" \"three\", \"s\" \"times\" and \"taala\"' \"day/light\", meaning literally \"three-times-day\". He also shows that the Hopi reckon time through the movement of the sun, having distinct words for the different degrees of light during the dawn and dusk periods. He also notes that the feeling of time passing can be described by saying \"the sun moves slowly/quickly\". Parts 3, 4, 5, and 6 describe Hopi time-keeping practices using the sun relative to the horizon, using the stars, the ceremonial calendar and the use of time-keeping devices such as knotted strings or notched sticks with a mark or knot for every day, sun-hole alignment and shadow observation. The eighth chapter describes the temporal particles that Whorf defined as temporals and tensors. He argues that Whorf's descriptions are vague and alienating.\n\nThe concept of Hopi tense is covered in the last part of chapter 9, titled \"miscellaneous\", and in the conclusion. Malotki follows Gipper in arguing that time is a natural category and that it is naturally experienced in terms of past, present and future, even though many languages do not necessarily grammaticalize all of these distinctions. He analyzes the Hopi \"-ni\" suffix as marking the future tense. He argues that since there is no grammatical distinction between past and present, Hopi has a future-nonfuture tense system. Malotki distinguishes between primary and secondary functions of the -ni suffix, arguing that its primary function is temporal reference and that its many modal functions such as imperative, hortative and desiderative are of secondary importance. Malotki does admit that the English and Hopi systems of tense are different since the English system distinguishes past from non-past, whereas Hopi distinguishes future from non-future.\n\nSubsequent descriptions of Hopi grammar have maintained Malotki's distinction between an unmarked non-future tense and a future tense marked with the -\"ni\" suffix, and a habitual aspect marked by the suffix -\"ngwu\". The review by Bernard Comrie, a well-known authority on the linguistic typology of tense and aspect, accepts that Malotki's work demonstrates that the Hopi do have a concept of time and that it is devastating for Whorf's strong claims. But Comrie also notes that Malotki's \"Claim that Hopi has a tense system based on the opposition of future and non-future ... strikes me as questionable: given the wide range of modal uses of the so-called future, it is at least plausible that this is a modal rather than temporal distinction, with the result that Hopi would have no tense distinction.\"\n\nLinguists and psychologists who work in the universalist tradition such as Steven Pinker and John McWhorter, have seen Malotki's study as being the final proof that Whorf was an inept linguist and had no significant knowledge or understanding of the Hopi language. This interpretation has been criticized by relativist scholars as unfounded and based on a lack of knowledge of Whorf's work.\n\nIn spite of Malotki's refutation, the myth that \"the Hopi have no concept of time\" lived on in the popular literature. For example, in her 1989 novel \"Sexing the Cherry\", Jeanette Winterson wrote of the Hopi: \"...their language has no grammar in the way we recognize it. And most bizarre of all, they have no tenses for past, present and future. They do not sense time in that way. For them time is one.\" And the myth continues to be an integral part of New Age thinking that draws on stereotypical depictions of \"timeless Hopi culture\".\n\nSome linguists working on Universals of semantics, such as Anna Wierzbicka and Cliff Goddard, argue that there is a Natural Semantic Metalanguage that has a basic vocabulary of semantic \"primes\" including concepts such as . They have argued that Malotki's data show that the Hopi share these primes with English and all other languages, even though it is also clear that the precise way in which these concepts fit into the larger pattern of culture and language practices is different in each language, as illustrated by the differences between Hopi and English.\n\nMalotki's work has been criticized by relativist scholars for failing to engage with Whorf's actual argument. John A. Lucy argues that Malotki's critique misses the fact that Whorf's point was exactly that the way in which the Hopi language grammatically structurates the representation of time leads to a different conception of time than the English one, not that they do not have one. Lucy notes that when Whorf makes his strong claim about what it is that Hopi lacks, he consistently puts the word \"time\" in scare quotes, and uses the qualifier \"what we call\". Lucy and others take this as evidence that Whorf was implying specifically that what the Hopi lacked was a concept that corresponds entirely to that denoted by the English word, i.e. he was making a point of showing that the concepts of time were different. Malotki himself acknowledges that the conceptualizations are different, but because he ignores Whorf's use of scare quotes, takes Whorf to be arguing that the Hopi have no concept of time at all.\n\nIn 1991 Penny Lee published a comparison of Malotki and Whorf's analyses of the adverbial word class that Whorf had called \"tensors\". She argues that Whorf's analysis captured aspects of Hopi grammar that were not captured by simply describing tensors as falling within the class of temporal adverbs.\n\nIn 2006 anthropologist David Dinwoodie published a severe critique of Malotki's work, questioning his methods and his presentation of data as well as his analysis. Dinwoodie argues that Malotki fails to adequately support his claim of having demonstrated that the Hopi have a concept of time \"as we know it\". He provides ethnographic examples of how some Hopi speakers explain the way they experience the difference between a traditional Hopi way of experiencing time as tied closely to cycles of ritual and natural events, and the Anglo-American concept of clock-time or school-time.\n\nSparked by the Hopi debate about time a number of studies about how different languages grammaticalize tense and conceptualize time have been carried out. Some of these studies in psycholinguistics and cognitive linguistics have found some evidence that there may be significant differences in how speakers of different languages conceptualize time, although not necessarily in the way Whorf claimed for the Hopi. Specifically, it has been shown that some cultural groups conceptualize the flow of time in a direction opposite to what is usual for speakers of English and other Indo-European languages, i.e. that the future is in front of the speaker and the past behind. It has also been found that not all languages have a grammatical category of tense: some instead use combinations of adverbs and grammatical aspect to locate events in time.\n"}
{"id": "1518227", "url": "https://en.wikipedia.org/wiki?curid=1518227", "title": "Horizontal progression", "text": "Horizontal progression\n\nIn Western handwriting, horizontal progression is the gradual movement from left to right during writing a line of text. In Hebrew and Arabic writing systems, the movement is from right to left.\n\n"}
{"id": "52945567", "url": "https://en.wikipedia.org/wiki?curid=52945567", "title": "IHunch", "text": "IHunch\n\niHunch is a term used to describe the common spinal problem of an excessively kyphotic (hunched) thoracic spine driving neck pain and cervicogenic headache. Other terms include iPosture, forward head posture, poking chin posture, computer neck, text neck and dowager’s hump.\n\nIndications are that the prevalence of upper back and neck pain has increased dramatically in the decade leading up to 2016. This increase has been attributed to the corresponding widespread adoption of laptop computers, tablets, smartphones and other small portable digital devices.\n\nBecause their screens do not separate from their keyboards these small devices cannot be set up ergonomically correctly (unless an extra screen or extra keyboard is added). They are unlike personal desk top computers (PCs) in this respect. Most commonly, the user hunches to operate them, often for many hours a day.\n\nHunching increases the effective load on the neck up to several times more than does erect posture, due to increasing moment arm. Local pain, cervicogenic headache and referred pain extending down the arms can arise from the sustained muscle strain, cervical facet joint (or apophyseal, or zygapophyseal joint) compression and diminution of the cervical foraminal nerve exits.\n\nA hunched posture also sends out a body language message of submission and lower self-confidence, with some research indicating it can actually promote these in the person holding it. A comprehensive view of the research and concepts is found in Dr Amy Cuddy’s book ‘Presence’ (2015).\n\nTreatment may include analgesic and/or anti-inflammatory medications, regular breaks while using the small devices, muscle strengthening and stretching, massage, spinal manipulation and mobilsation, posture instruction and spinal fulcrums. Biomechanical analysis suggests a combination of approaches is best and gives more lasting results.\n\nIn a neck with perfect posture (as seen for instance in young children) the head is balanced above the shoulders. In this position the load on each vertebra of the cervical spine is spread evenly between the two facet (apophyseal) joints at the back and the intervertebral disc and vertebral body at the front.\n\nThe iHunch is characterised by a posture with the head sitting somewhat forward of the shoulders (i.e., the ear lobe is anterior to a vertical line through the point of the shoulder (acromion process)). This can be very marked, with the back of the skull positioned anterior to the breastbone (sternum). The chin is poked forward.\n\nWhen the patient is asked to look up at the ceiling, the hunched-forward upper thoracic curve does not change as viewed from the side. Rather, the lower cervical spine ‘hinges’ backward at C5/6/7, a movement pattern known as ‘swan-necking'.\n\nThis indicates that the upper back vertebrae have frozen in their habitual flexed positions, with the surrounding collagen of the ligaments, joint capsules and fascia shortening to reinforce this hypomobility. (This is the dowager’s hump of the elderly of earlier generations, now observable in modern (2016) late teenagers.)\n\nSymptoms include overuse muscle pain and fatigue along the back of the neck and reaching down to the mid-back, often starting with the upper trapezius muscle bellies between the shoulders and neck. Cervicogenic headache from the joints and muscle attachments at the top of the neck is common.\n\nThe compressive load on the cervical facet joints predisposes to acute joint locking episodes, with pain and movement loss. In older patients with already diminished cervical foramina spaces and/or osteophytes, nerve root irritation and impingement can trigger referred pain down the arm(s).\n\nThe human spine is well suited to erect upright posture, with the increased heart rate from movement shunting a good blood supply to the muscles. This is clearly not the\ncase for vast numbers of sedentary humans spending many hours daily bent over laptops, tablets, smartphones and similar. A biomechanical assessment of thoracic hunching shows the abnormal spinal loading and other effects which plausibly account for the recent steep rise in thoracic and cervical pain in step with the ubiquitous adoption of the small IT devices.\n\nHunching has always caused problems, for instance in occupational groups like dentists, surgeons, hairdressers, nurses, chefs, teachers, computer workers and students. Some rheumatoid conditions like ankylosing spondylitis and neurodegenerative conditions like Parkinson's Disease cause characteristic excessive thoracic kyphosis. What has changed is the amount of hunching in society generally, and especially with the technologically adept young.\n\nThe first laptop was produced in 1981 but it took more than a decade of development for the designs to approach current (2016) levels of portability and capacity, and hence uptake. Apple produced the first smartphone (the iPhone) in 2007 and the first tablet (the iPad) in 2010. In 2015 there were 4.43 billion mobile phone (cellphone) users in the world, of which 2.6 billion had smartphones. In the US, 45% owned a tablet computer in 2014 and 92% owned a mobile phone; for younger adults aged 18–29, only 2% didn’t own a mobile phone and 50% had tablets.\n\nA large Finnish cross-sectional study on school-age adolescents published in 2012 concluded that more than two hours a day spent on computers was associated with a moderate/severe increase in musculoskeletal pain. In the following year, the average UK 18-24 year-old spent 8.83 hours a day in front of a PC, laptop or tablet. Neck pain per se has been a large problem for a long time, and surveyed repeatedly. A composite review of studies with good methodology by Fejer et al published in 2006 found that point prevalence (in pain right now) of neck pain in the adult (15–75 years) population ranged from 5.9% to 22.2%, with one study of the elderly (65+ years) finding 38.7% were in pain when surveyed. Generally, more urban populations had more neck pain, e.g. 22.2% of a large 1998 Canadian study had neck pain when surveyed.\n\nBased on these surveys of neck pain prevalence, and adding to them the prevalence of thoracic pain and cervicogenic headache, it is reasonable to estimate that around one adult in six (15%) probably has pain in any, some or all of those areas right now. However the published epidemiological papers draw on raw data from surveys done at least 10 years ago, and there are indications that the numbers have been rising dramatically since then – as rapidly as the adoption of laptops, tablets and smartphones. This is reflected in the recent rise in the number of popular articles, news items and media discussions about the problem.\n\nThe iHunch is a multi-factorial problem.\n\n\nNeck pain generally has been treated with a profusion of approaches and modalities, including nonsteroidal anti-inflammatory drugs (NSAIDs) such as ibuprofen; pain relief medications (analgesics) such as acetaminophen; low dose tricyclic antidepressants such as amytriptyline for chronic problems; Physical therapy (a.k.a. physiotherapy in British-derived cultures) which utilises a wide range of techniques and modalities; spinal manipulation from osteopaths, chiropractors, manipulating physiotherapists and doctors; massage; muscle strengthening programmes including gyms and Pilates; postural approaches such as the Feldenkrais Method and the Alexander Technique; stretching approaches such as yoga; ergonomic approaches including setting up desk top computers correctly and frequent breaks; acupuncture; and surgery for severe structural problems such as osteophytic impingement on the cervical nerve roots and cervical disc herniation.\n\nA biomechanical analysis of the iHunch indicates its standard, logical development from much flexed activity and its multi-factorial character. (See Pathogenesis)\n\nA composite approach which covers each component of the problem is therefore likely to be most successful and lasting. Most of the general treatment approaches to neck pain cover only one aspect. A logical response should include as a minimum:\n\n\n"}
{"id": "43293772", "url": "https://en.wikipedia.org/wiki?curid=43293772", "title": "Idiom (language structure)", "text": "Idiom (language structure)\n\nIdiom is the syntactical, grammatical, or structural form peculiar to a language. Idiom is the realized structure of a language, as opposed to possible but unrealized structures that could have developed to serve the same semantic functions but did not.\n\nLanguage grammar and syntax is often inherently arbitrary and peculiar to a particular language or a group of related languages. For example, although in English it is \"idiomatic\" (accepted as structurally correct) to say \"cats are associated with agility\", other forms could have developed, such as \"cats associate toward agility\" or \"cats are associated of agility\". Unidiomatic constructions sound wrong to fluent speakers, although they are often entirely comprehensible. For example, the title of the classic book \"English As She Is Spoke\" is easy to understand (its idiomatic counterpart is \"English As It Is Spoken\"), but it deviates from English idiom in the gender of the pronoun and the inflection of the verb. Lexical gaps are another key example of idiom.\n\nMonolingual native speakers in an insulated monolingual-native environment are mostly not conscious of \"idiomaticness\" (the quality or state of a construction matching the idiom of the given language), because in general their minds never reach for, or hear, other possible structures. The main exception is when they hear the natural experimentation of children acquiring the language, when they may encounter, for example, overregularization (for example, \"I seed two deers\" for \"I saw two deer\"). By this correlation, solecism to native-speaking monolingual minds often sounds childish. However, when adults study a foreign language, they become consciously aware of idiomaticness and the lack of it. For example, in English it is idiomatic to use an indefinite article when describing a person's occupation (\"I am a plumber\"; \"she is an engineer\"), but in Spanish and many other languages it is not (\"soy plomero\"; \"ella es ingeniera\"), and a native speaker of English learning Spanish must encounter and accept that fact to become fluent.\n\nThe count sense of the word \"idiom\", referring to a saying with a figurative meaning, is related to the present sense of the word by the arbitrariness and peculiarity aspects; the idiom \"she is pulling my leg\" (meaning \"she is humorously misleading me\") is idiomatic because it belongs, by convention, to the language, whether or not anyone can identify the original logic by which it was coined (arbitrariness), and regardless of whether it translates literally to any other language (peculiarity).\n\n"}
{"id": "43772546", "url": "https://en.wikipedia.org/wiki?curid=43772546", "title": "Interface hypothesis", "text": "Interface hypothesis\n\nThe interface hypothesis in adult second language acquisition is an attempt to explain non-target-like linguistic behavior that persists even among highly advanced speakers. The hypothesis was first put forward by Antonella Sorace.\n\nThe hypothesis posits that for adult second language learners, acquiring grammatical properties within a given linguistic area, such as phonology, syntax, or semantics, should not be problematic. Interfacing between those modules, such as communicating between the syntax and semantic systems, should likewise be feasible. However, grammatical operations where the speaker is required to interface between an internal component of the grammar, and an external component, such as pragmatics or discourse information, will prove to be very difficult, and will not be acquired completely by the second language learner, even at very advanced levels.\n\nExamples of phenomena argued to be influenced by the interface hypothesis include use of overt vs. null subjects, as well as use of subject placement before or after the verb to mark focus vs. using prosody, in languages like Italian by native English speakers.\n\n"}
{"id": "51704277", "url": "https://en.wikipedia.org/wiki?curid=51704277", "title": "Juggling terminology", "text": "Juggling terminology\n\nJuggling terminology, juggling (especially toss juggling) terms:\n\n"}
{"id": "4655864", "url": "https://en.wikipedia.org/wiki?curid=4655864", "title": "Language Proficiency Index", "text": "Language Proficiency Index\n\nThe Language Proficiency Index or LPI is a Canadian standardized test for English proficiency and is administered by Paragon Testing Enterprises, a subsidiary of the University of British Columbia. The results of this test are used mostly by post secondary institutions and professional organizations within the Province of British Columbia, Alberta and in the territory of Yukon.\n\nThe test is 2.5 hours long and consists of five components, Parts I and II are multiple choice and deal with catching various grammar-related mistakes. Part III is a reading-comprehension section, also in multiple choice. Part IV deals with writing brief summaries of a short piece of writing and Part V is a 300-400 word argumentative essay.\n\n"}
{"id": "10261226", "url": "https://en.wikipedia.org/wiki?curid=10261226", "title": "Language bioprogram theory", "text": "Language bioprogram theory\n\nThe language bioprogram theory or language bioprogram hypothesis (LBH) is a theory arguing that the structural similarities between different creole languages cannot be solely attributed to their superstrate and substrate languages. As articulated mostly by Derek Bickerton, creolization occurs when the linguistic exposure of children in a community consists solely of a highly unstructured pidgin; these children use their innate language capacity to transform the pidgin, which characteristically has high syntactic variability, into a language with a highly structured grammar. As this capacity is universal, the grammars of these new languages have many similarities.\n\nBy comparing Hawaiian Creole, Haitian Creole and Sranan, Bickerton identified twelve features which he believed to be integral to any creole: \n\nHaving analyzed these features, he believed that he was able to characterize, at least partly, the properties of innate grammar. Bickerton in his LBH, defined very precisely what he considers to be a creole: a language that has arisen out of a prior pidgin that had not existed for more than a generation and among a population where, at most, 20% were speakers of the dominant language and where the remaining 80% were linguistically diverse. Such a definition excludes many languages that might be called creoles. Moreover, lack of historical data makes it often impossible to evaluate such claims. In addition, many of the creole languages that fit this definition do not display all the twelve features, while, according to , the left-out creoles often display more of them. Another problem, raised by , is that if the same bioprogram was the starting point of all creoles, one must explain the differences between them, and language diversity in general, as the bioprogram is universal.\n\nOn the other hand, Bickerton, puts emphasis on children's contribution to the development of a creole and the abrupt character of this process. For example, in , he exhibits ungrammatical utterances made by English-speaking children between the ages of two and four, and argues that they are very similar to perfectly grammatical sentences of English-based creole languages:\n\nNormally, the grammar behind such utterances made by children is eventually altered as parents continue to model a grammar different from this innate one. Presumably, if such children were removed from exposure to English parents, their grammars would continue to be that of creole languages.\n\nHowever, according to , the differences between the speech of children and adults in Tok Pisin are so big that communication is drastically hindered.\n\nThe verb conjugation is typically close to an ideal tense–modality–aspect pattern. In this system, the absence or presence of auxiliary verbs indicate tense (concurrent or anterior), modality (realis or irrealis) and aspect (punctual or progressive), and when present these auxiliaries occur in that order, and typically are based on similar meaning words in the pidgin or superstrate language. Thus anterior tense may be marked by words such as \"bin\" in English-based creoles (from \"been\"), or \"té\" in French-based creoles (from \"été\"), a future or subjunctive tense may be marked by \"go\" (from English \"go\") or \"al\" (from French \"aller\"), and a non-punctual (non-stative) aspect by a word such as \"stei\" (from English \"stay\").\n\nThe above table demonstrates syntactic similarities of creole languages. Stative verbs are those that cannot form the nonpunctual aspect. According to Bickerton, all observed creole languages strictly follow a structure that has the anterior particle precede the irreal particle, and the irreal particle precede the nonpunctual particle, although in certain languages some compounded forms may be replaced by other constructions.\n\nMcWhorter contributed to the LBH with his Creole Prototype Theory, which argues that creoles exhibit some features that may be used to distinguish them from other languages without referring to the socio-historical dimension. According to , creoles are much less likely than other languages:\n\nThese features do not appear in creoles because creoles are relatively young languages, but they may appear later on in their grammars as the languages change. He does not claim that all creoles are ideal examples of the prototype, rather they exhibit varying degrees of conformity with the prototype.\n\nBickerton proposed in 1976 an empirical test of his theory, which involved putting families speaking mutually unintelligible languages on a previously uninhabited island for three years. Federal funding for the test was obtained, but the experiment was cancelled over concerns that informed consent could not be obtained, given the breadth of unknown possible hazards of participation.\n\n\n"}
{"id": "5512322", "url": "https://en.wikipedia.org/wiki?curid=5512322", "title": "Language proficiency", "text": "Language proficiency\n\nLanguage proficiency or linguistic proficiency is the ability of an individual to speak or perform in a language. As theories among pedagogues as to what constitutes proficiency go, there is little consistency as to how different organizations classify it. Additionally, fluency and language competence are generally recognized as being related, but separate controversial subjects. In predominant frameworks in the United States, proficient speakers demonstrate both accuracy and fluency, and use a variety of discourse strategies. Thus, native speakers of a language can be fluent without being considered proficient. Native-level fluency is estimated to be between 20,000 and 40,000 words, but basic conversational fluency might require only as little as 3,000 words.\n\nThe American Council on the Teaching of Foreign Languages (ACTFL) distinguishes between proficiency and performance. In part, ACTFL's definition of proficiency is derived from mandates issued by the U.S. government, declaring that a limited English proficient student is one who comes from a non-English background and \"who has sufficient difficulty speaking, reading, writing, or understanding the English language and whose difficulties may deny such an individual the opportunity to learn successfully in classrooms where the language of instruction is English or to participate fully in our society\".\n\nACTFL views \"performance\" as being the combined effect of all three modes of communication: interpretive, interpersonal, and presentational.\n\nNote that test scores may not correlate reliably, as different understandings of proficiency lead to different types of assessment:\n\nSee also: \n\n\n"}
{"id": "39206051", "url": "https://en.wikipedia.org/wiki?curid=39206051", "title": "Learning Resource Metadata Initiative", "text": "Learning Resource Metadata Initiative\n\nThe Learning Resource Metadata Initiative (LRMI) is a project led by Creative Commons (CC) and the Association of Educational Publishers (AEP) to establish a common vocabulary for describing learning resources.\n\n"}
{"id": "37506954", "url": "https://en.wikipedia.org/wiki?curid=37506954", "title": "Linguistic boundary of Moselle", "text": "Linguistic boundary of Moselle\n\nThe linguistic boundary in the French department of Moselle (Lorraine region) is a subset of the wider Romance-Germanic language border that stretches through Belgium, France, Switzerland and Italy.\n\nAt the end of the nineteenth century:\n\n"}
{"id": "1723892", "url": "https://en.wikipedia.org/wiki?curid=1723892", "title": "Linguistic philosophy", "text": "Linguistic philosophy\n\nLinguistic philosophy is the view that philosophical problems are problems which may be solved (or dissolved) either by reforming language, or by understanding more about the language we presently use. The former position is that of ideal language philosophy, the latter the position of ordinary language philosophy.\n\n\n"}
{"id": "35138246", "url": "https://en.wikipedia.org/wiki?curid=35138246", "title": "List of language interpreters in fiction", "text": "List of language interpreters in fiction\n\nThis is a list of language interpreters in fiction. Conference interpretation is often depicted in works of fiction, be it in films or in novels. Sydney Pollack’s \"The Interpreter\" and Javier Marias’ \"A Heart So White\" are amongst the most well known examples. Several books, symposia or websites tackle the issue at hand. Below is a list of works of fiction in which interpreters appear.\n\n\n\n\n\n\n\n\n\nSee also:\n\nThis article incorporates information from the \n"}
{"id": "24651272", "url": "https://en.wikipedia.org/wiki?curid=24651272", "title": "MOGUL framework", "text": "MOGUL framework\n\nThe MOGUL framework is a research framework aiming to provide a theoretical perspective on the nature of language. MOGUL (Modular On-line Growth and Use of Language) draws on the common ground underlying various related areas of cognitive science including psycholinguistics, theoretical linguistics, first- and second-language acquisition, neurolinguistics and cognitive psychology; it is designed to be applicable to all these fields of research.\n\nThe MOGUL framework's background assumption is that the mind is composed of expert systems which have evolved over time, one of which is responsible for human linguistic ability. Historically, scientific studies of language have been divided between many sub-disciplines; theoretical linguists focus on the abstract properties of language and researchers in other fields investigate how language is used and processed in real time: either in psychological terms or (in the case of neurolinguistics) through a study of the physical systems of neurons in the brain. Each field of study has developed its own research traditions and technical vocabulary, making it difficult to integrate insights across disciplines. The MOGUL Framework represents an attempt to identify common themes and compatible approaches in different (but related fields), and hence to facilitate integration.\n\nMOGUL is designed as a platform for the generation of new hypotheses, with a terminology and a set of interrelated concepts that can be used across more than one discipline. Although not a full-fledged theory in its own right, it sets out various theoretical claims based on the current literature in a range of research domains. As suggested below it is not connectionist in the most widely used sense of that term, although it employs terms and concepts familiar to connectionists such as competition, activation, activation levels and so forth. The same processing perspective also requires the long-established Chomskyan distinction between competence and performance to be viewed in a somewhat different way. Linguistic competence (knowledge) is not compartmentalised and placed in a separate box in the model, which then forms the object for a processor (or processors) to act on. Rather, it is instantiated and implicit within the processing system. The distinction between mental representation and processing is still valid, but is expressed in a way that ought to allow the abstract properties of linguistic systems in the mind to be more easily investigated in conjunction with real-time linguistic phenomena. The inspiration for this approach is the work of Ray Jackendoff. Here the architecture of the language faculty is formulated in such a way as to facilitate statements about competence-related, representational issues and their relationship to real-time language processing within the same model.\n\nEmpirical evidence for the claims and assumptions set out in MOGUL rests essentially on the experimental findings of the various fields of research on which it is based. The MOGUL framework queries current solutions and raises new questions based upon this body of evidence, in the hope that answers to such questions will be sought in the related areas by appropriate researchers.\n\nMore specifically, MOGUL represents an attempt to provide ways of investigating how first- or second-language processing relates to linguistic development and how language in the monolingual and multilingual language user is situated within human cognitive architecture in general. What exactly happens, even in milliseconds, when someone is exposed to the sights and sounds of a new language? How do we explain what gets noticed and what gets regularly ignored? What about the fixed stages that people seem to pass though? How is it that we have so little conscious control over what we are attempting to acquire? Why do children appear to be worse language learners in the short run and much better in the long run? How can two or more language systems cohabit in one mind? Answers to these questions require an interdisciplinary approach. Two major sources for inspiration for the approach described here are the ideas of generative linguist Ray Jackendoff on language faculty and modularity and Global Workspace Theory, as advanced by Bernard Baars. The first MOGUL publication was released in 2004 and was a keynote article in \"Bilingualism: Language and Cognition\" (Truscott and Sharwood Smith 2004).\n\nIn order to situate languages within a wider cognitive context, the MOGUL framework is designed to provide a basic architecture that purports to explain how (in general terms) the mind functions. This means that it is not an account of brain function, although it is set out in such a way that might facilitate such accounts.\n\nBriefly, MOGUL architecture follows Jackendoff in positing a generic cognitive module (or, in MOGUL, a processing unit) which consists of an integrative processor operating on structural elements (structures) in a memory store. Specifically, it works with activated elements that are raised into working memory from that memory store.\n\nModules are only somewhat generic in structure; the rest is very specific to each module, since each module operates with its own code. Visual memory contains elements that only the visual processor can access; syntactic memory contains elements that only the syntactic processor can deal with, and so on. While Jackendoff prefers to think of working memory as a separate blackboard onto which elements of long-term memory are written, in MOGUL the alternative view of the working-memory blackboard is adopted: it is part of the unified memory system, and elements are raised to the working memory \"surface\" within the same store. In both versions, elements must cross an activation threshold to be visible to the integrative processor.) Note that memory is modularised, so visual memory (including visual working memory) is separate from – and independent of – for example, phonological memory. Modules, useless if entirely autonomous and cut off from other parts of the system as a whole, require some way whereby they can link up and cooperate. This is done by means of interface processors matching structural elements in the memory stores of adjacent modules. The cognitive system as a whole copes with a multitude of different tasks like tying a knot, listening to a speech, driving through a busy city and salsa-dancing by forming appropriate coalitions of processors producing assemblies of structures (linked together via appropriate interfaces) from different modules. The generic structure of a MOGUL module (based on Jackendoff's model) is portrayed in the figure on the right, and also reflected in various places in the third figure in this article (see \"MOGUL architecture in a nutshell\" below).\n\nThis functional architecture may be neurally and anatomically instantiated in different ways: the design of systems such as that proposed by Jackendoff and others (including MOGUL) involves no specific claims about the precise nature and location of the neural system. These are two different levels of description. The auditory module (translated into cortical terms) involves several brain regions distributed across the supratemporal plane; activation in MOGUL terms (when translated into neurological terms) may involve both excitatory and inhibitory neurotransmitters. By the same token, functional auditory structure (as described within the MOGUL framework) must be distinguished from anatomical and physiological auditory structure.\n\nAn important portion of the MOGUL account is devoted to the claim that the acquired (and atrophied, or lost) linguistic structures are natural byproducts of online processing. This means that acquisitional mechanisms do not exist as such, but are embodied in the operations of the parser. This claim is made explicit in Acquisition by Processing Theory (APT). Processing concepts (activation levels, competition and so on), as exploited by other non-modular, domain-specific approaches, are realigned in MOGUL to explain how new cognitive systems emerge. APT is a hypothesis put forward by Sharwood Smith and Truscott as an integral part of MOGUL and is applicable to all kinds of cognitive development, not only language acquisition and language attrition (for a similar approach acquisition which is framed within an emergentist perspective, see O'Grady 2005).\n\nEssentially, the claim is that all development is the lingering effect of processing. As the mind attempts to build mental representations online, various structures at its disposal are activated. Structures compete with one another to be selected for the current representation. As a simple example, on hearing the word \"ship\" an English speaker's processing system will activate various candidate structures so (for instance) the phonological structures underlying \"sheep\" and \"shape\" will compete for selection (and other candidates as well, including phonological structures belonging to other languages known to the listener). The \"ship\" structure is normally selected as the best fit, and thereby its likelihood of being selected in the future is correspondingly strengthened by a small amount. In this way, a basic \"use it or lose it\" principle is invoked; this development principle works throughout the cognitive system as a whole.\n\nAs we match various types of cognitive structure available to us in order to find the best fit for unfamiliar input from the environment new connections are developed, initially with the relevant structures possessing a low resting level of activation. This means they will have a relatively poor chance of selection for future instances of the same input. However, the more they are selected the more they will show up in the observable behaviour of the individual concerned.\n\nAlthough the frequency in which we experience given phenomena influences our development, cognitive growth is not an automatic consequence of experience; our mind is modular, and each module is controlled by its own unique processing principles. This limits, for instance, what we can learn to see or hear or say; seeing, hearing and speaking each involve dedicated processing units, which control their own internal operations. In this way, high-frequency events in the environment may still not impact development because the relevant parts of our mind are incapable of processing them. This may be because a) the relevant modules (processing units) are simply not designed to do so, or b) they are not yet ready to process them, because their internal principles require some prerequisite state of affairs before the potential new input can be integrated. By the same token, an internal operation may be halted because although one processing unit has processed input, an adjacent processing unit (module) with which it is connected is not in a ready state to cooperate (find matching structures within its own memory store). Hence frequent events in the external environment may indeed get processed by some part(s) of the cognitive system but still not by every relevant part. MOGUL espouses both modularity of mind and a constrained form of connectionism with a complex web of expert systems, each with its own particular organising principles. In this way, MOGUL makes claims not only about language abilities but about the mind in general.\n\nThe core modules involved in language comprehension work in two directions. Phonological, syntactic and conceptual processing work in one direction in response to visual and auditory events in the environment (typically in listening to speech or reading a text), but they also work in the other direction to produce speech or writing (or messages in sign language). Production involves a physical response to internal events, the creation of a message to be conveyed. This requires articulation of different parts of the body, following the commands of motor structures. Meanings in the conceptual processor are matched with syntactic structures which in turn are matched with phonological structures; this structural chain continues to be built following different routes according to the selected mode of articulation. The required motor structures that drive the articulation of speech will be different from those involved in writing or signing.\n\nWhen the basic direction of processing is, say, from conceptual structure to speech, the assembling of an appropriate structural chain is not carried out in a rigid unidirectional sequence; at different levels, different options will be available and compete for selection. In production, some options may be partially formed and then be dropped in favour of a better-fitting rival structure. In this way the ultimate structural chain is built up incrementally, out of the more accessible candidate structures that happen to provide the best overall fit at the time. Comprehension works according to the same principles, with parallel processing and split-second editing and revising until a best-fit interpretation is arrived at. It may be the wrong interpretation but it will be the best fit, given the person's current processing resources at that particular moment in time.\n\nAs an example of what processing online means, let us examine speech production in a fluent speaker. The construction of a message will be initiated in the conceptual processor. Conceptual structures will be chosen, which then activate the interface between the conceptual and syntactic system. The conceptual structures are matched up with particular syntactic structures forming the first stage – in other words, a CS+SS (conceptual structure plus syntactic structure) chain. A semantic argument structure in CS code which specifies an action with an agent (the doer) and a patient (what is acted upon), as in \"a boy hit the ball\", is matched up with a syntactic argument structure with the requisite verb and noun phrases (determiner phrases), each in the appropriate case: one in nominative case and the other in objective case. The interface between SS and PS kicks in, causing various appropriate phonological structures to be activated; an SS/PS match is made, the outcome now being a CS+SS+PS chain. As is generally the case, more than one option may be selected in parallel before one particular option is settled on. Structural chains are formed incrementally; as more CS is built so more SS and PS are constructed with more context, earlier options that were provisionally selected are dropped as the representation develops and becomes more complex. The PS is matched up with motor structures responsible for the articulation of speech, and the utterance is produced. Each type of structure (AS, PS, SS, CS and so on) is constructed in its own particular module and by its own unique integrative processor, following its own particular set of principles. Comprehension is a similar process, with the general direction going in reverse; auditory structures are formed in response to acoustic stimuli in the environment. These auditory structures match PS and SS, finally culminating in the interpretation of the message (its conceptual structure).\n\nOne feature of the MOGUL approach is an attempt to spell out in coherent terms the role of perception and affect in issues of language development in the individual. In the earlier example of \"a boy hit the ball\" (where a simple example of a how a CS+SS+PS chain was built up), we assume that the conceptual structures evoked also have interfaces with various perceptual and affective structures to account for the associations individuals have with, for example, the concept \"boy\". In other words, the activation of a chain effectively becomes the activation of a whole network of associations contributed by different modular systems in the mind. The co-activation of structural networks of various kinds is important in explaining facts about attention and noticing. MOGUL follows the view that high levels of activation are strongly implicated in the phenomenon of conscious awareness. This is made explicit in the role of \"perceptual output structures\" (POpS).\n\nPOpS is a generic term covering the output of various perceptual systems corresponding to the five senses – or, more properly, the sensory systems currently believed to exist (which number more than the traditional five). Of greatest interest in MOGUL are \"visual structures\" (VS) and \"auditory structures\" (AS), given the fact that language is usually perceived in visual and auditory terms. Structures reside in the memory stores of the appropriate processing system (processing unit, or module). Exposed to the sound of the word \"dog\" or the sound of a creaking door, the auditory system activates a particular auditory structure (or set of auditory structures) in response to this sensory input. In this way, a given structure can be thought of as an auditory memory that may be re-activated even when there is no external sensory input (in hallucinations and dreams, for example) and grow stronger or weaker (less accessible) depending on the frequency with which it is activated successfully.\n\nPerceptual output structures are strongly interconnected. This enables a coordinated responses to events in the environment and assists the organism's chances of survival. This coordinating function of the POpS system may be related to the role of the global workspace in Baars' theory. At the same time, since POpS mediate between the external environment and the internal operations of the mind that are inaccessible to awareness, POpS conform closely with Jackendoff's Intermediate Theory of Consciousness. The rich interconnections between POpS permit very high levels of activation to be achieved, a hypothetical prerequisite for awareness to occur. It is also reflected in the condition known as synaesthesia: here the connection between two POpS reaches levels that result in an awareness whereby the two senses appear to merge; for example, a particular sound takes on the quality of a particular taste. Another example of connection is provided by the experimentally-induced McGurk effect. Here, two sensory signals are generated to produce a conflict; the subject's awareness is the result of an attempt to resolve the conflict, so that hearing one sound and simultaneously seeing the speaker pronounce a different sound will create the illusion of hearing a sound halfway between the actual sound and the sound suggested by the speaker's facial gestures (especially the movement of the lips).\n\nThe main point is that awareness (whether it can be classified as an illusion or not) is generated indirectly via POpS; we do not have direct access to the contents of any module or processing unit. While we can never become aware of the fine phonological and syntactic properties of the word \"dog\" - or its semantic and pragmatic properties, its \"conceptual structure\"(CS) - we can certainly become aware of its sound. In the same way, we can become aware of the sound of the creaking door. In both cases, it is auditory structure (one of the POpS) that gives rise to the conscious experience. As implied above, it is in the nature of linguistic structures (PS and SS) and its conceptual structures (CS) that they do \"not\" have the rich interconnectivity described above, and consequently do not (and \"cannot\") achieve the appropriate levels of activation for consciousness to occur. What we become conscious of arises directly from POpS activity. In other words, consciousness is always perceptual in nature.\n\nThe affective system works with \"affective structures\" (AfS) that are constructed using primitives such as \"fear\" and \"disgust\", which are discussed in affective neuroscience in the work of António Damásio. AfS are connected to POpS and contribute directly to appropriate responses of the organism to events in the immediate environment, to its chances of survival and to the experience of conscious awareness. Making these aspects of mental life more explicit helps researchers to understand and devise hypotheses about how consciousness and emotion affect online language performance and language acquisition. By the same token, it should help to show how certain aspects of language behaviour are (or might be) immune to such influence.\n\nLanguage is a vague term and is its widest sense involves a host of different processing units, only some of which are what makes human language unique to this species, that is, the phonological and syntactic expert systems that make up what, in generative linguistics, is called the language module and whose special properties are often subsumed under the name Universal Grammar. Closely associated with this core system, but not part of the language module per se, are a rich set of conceptual structures developed over the lifespan, as also b) auditory structures that have been matched up with phonological structures and c) visual structures created for interpreting writing and sign language. In addition, there are the various motor structures involved in the production of language in its different modes. One might lump all of this together and call it \"knowledge of language\". None of it, however, constitutes 'knowledge of language' if, by this term, we rather mean language that we can think and talk about and analyse, in other words \"metalinguistic knowledge\", which, as with all forms of metacognition, is constructed out of conceptual structure and various perceptual output structures. To take a simple example, the word \"horse\" can be discussed or pondered; all that is needed for this is an auditory structure (the sound of the word) and its visual structure (representing its orthographic, written form), both of which are matched up with its meaning as illustrated in the figure on the right. Not represented in the figure is the additional conceptual structure (over above the meaning of horse itself), consisting of metalinguistic concepts such as \"word, syllable, noun, definition\" and the like. These concepts are required for any analytic thinking about language and may vary widely in degree and complexity, depending on an individual's metalinguistic sophistication. In any case, the language module is not directly implicated in any explicit discussion (or explicit thinking) about what is actually a linguistic form. In the MOGUL version of metalinguistic processing, the essential chain of connections that are assembled completely bypasses the PS and SS systems. Processing within the language module will always kick in automatically on exposure of language stimuli, but metalinguistic (explicit) activity is processed elsewhere. Following the standard arguments from learnability theory as applied in generative linguistics, the language module is nevertheless crucial for all other types of linguistic activity and is vital for explaining the acquisition of language. No amount of activation of auditory and conceptual structure alone can explain the growth of language in the mind following repeated exposure to speech, most obviously in the case of little children and (arguably) adults as well.\n\nBecause of these two modes of knowing, we can appear to be very knowledgeable about the grammar of a particular language or grammar in general and yet be very poor users of that language. Or, like many native speakers, we can make metalinguistic assertions about the rules of our language which are not at all borne out by the way we actually speak and comprehend our mother tongue. Knowledge of a language, in this metalinguistic sense of the word, can also be \"right\" or \"wrong\". We can have misconceptions about language, or we can have a view of grammar that accords with the facts. By way of contrast, the system operated subconsciously within our language module can never be right or wrong: it is just the way it is, the way it as has developed in us over time. Metalinguistic knowledge is not useless, however. An essential part of education in many cultures is acquiring such consciously-accessible knowledge about language, and especially about the mother tongue. In MOGUL, however, this should not be confused with the implicit knowledge of language that drives language performance.\n\nIn this figure, the MOGUL version of the cognitive system is sketched in simplified form. The circles or ovals represent specialised processors, and the rectangular boxes each represent the particular memory store of structures which they are designed to handle. Affective structures (AfS) are not differentiated in this figure. Also, for simplicity's sake, only five \"senses\" are portrayed in the POpS system. All languages are handled by the same syntactic and phonological processors, but different languages will involve both shared and unique \"syntactic structures\" (SS) and \"phonological structures\" (PS) residing in (respectively) their syntactic and phonological memory stores. Mental activity is characterised by the formation of chains or networks of structures across different modules. This is achieved by means of interface processors (the dotted arrows) following Jackendoff (1987). These are bimodular, in that they match elements in two adjacent modules; they can only access and link certain structural elements in one or the other module. Moreover, the matching is not a \"translation\" of one element into terms (the code) of another system; there is no exchange of information, merely a chaining of elements that can otherwise only be processed within its own particular processing unit or module.\n\n\n\n"}
{"id": "1436370", "url": "https://en.wikipedia.org/wiki?curid=1436370", "title": "Macrofamily", "text": "Macrofamily\n\nIn historical linguistics, a macrofamily, also called a superfamily or phylum, is a proposed genetic relationship grouping together language families (also isolates) in a larger scale classification. However, Campbell regards this term as superfluous, preferring \"language family\" for those classifications for which there is consensus and \"distant genetic relationship\" for those for which there is no, or not yet, consensus, whether due to lack of documentation or scholarship of the constituent languages, or to an estimated time depth thought by many linguists to be too great for reconstruction.\n\nMore rarely, the term has also been applied to an exceptionally large language family, such as Afro-Asiatic.\n\nExamples of proposed macro-families range from relatively recent such as Macro-Jê, Macro-Waikurúan, Macro-Mayan, Macro-Siouan, Penutian, Na-Dene or Congo-Saharan (Niger-Saharan) to older ones such as Austric, Dené–Caucasian, Eurasiatic, Nostratic or Ural-Altaic.\n\n"}
{"id": "38563793", "url": "https://en.wikipedia.org/wiki?curid=38563793", "title": "Media stylistics", "text": "Media stylistics\n\nMedia stylistics or mediated stylistics is a branch of functional stylistics that studies human communication in mass media. It can be considered a branch of media linguistics; that is, how media speech depends on the content, aims of communicators and the medium.\n\nMedia stylistics as a research approach is widely known in Eastern Europe and especially in Russia, through the work of A. Vasileva, M. Kozhina, V. Kostomarov, L. Maydanova, I. Lysakova, K. Rogova, G. Solganik and others.\n\nModern media stylistics in Russia develops mainly as stylistics of media text. The main particular problems of media stylistics are:\n\nAlong with stylistics of socio-political texts (V. Konkov, V. Salimovsky, G. Solganik, N. Klushina), the stylistics of journalistic leisure-texts develops (L. Duskaeva, N. Klushina, V. Konkov, E. Kara-Murza, T. Redkina, N. Tsvetova). The intentional-stylistic approach to the study of these texts develops extensively (V. Barbashov, L. Duskaeva, N. Kornilova, K.Prokhorova, N. Tsvetova) as well as stylistic approach to lingvo-etic problems (N. Bessarabova, T. Surikova, V. Suzdaltseva). As separate lines of media stylistics can be considered semiotic lingvostylistics of advertising texts (E. Kara-Murza), expert media stylistics (A. Baranov, E. Kara-Murza, M. Gorbanevsky, T. Chernyshova), stylistics of online media texts (E. Kakorina, T. Karpova).\n\n"}
{"id": "5650454", "url": "https://en.wikipedia.org/wiki?curid=5650454", "title": "Montevideo Resolution", "text": "Montevideo Resolution\n\nResolution IV.4.422-4224, commonly referred to as the Montevideo Resolution, is a resolution passed in Montevideo, Uruguay on December 10, 1954 by the General Conference of UNESCO. The resolution officially supports the constructed language Esperanto as an international auxiliary language and recommends that the Director-General of UNESCO follow current developments in the use of the language. The Montevideo Resolution was the result of a long campaign by Ivo Lapenna.\n\nIn 1977, the Director-General visited the World Esperanto Congress in Reykjavík, Iceland, and in 1985, UNESCO passed a further resolution recommending that member countries encourage the teaching of Esperanto.\n\n\"General Conference of Unesco. Eight session. Montevideo (Uruguay), 1954.\nResolution adopted on December 10, 1954, in the 18th plenary meeting.\"\n\n\n\n"}
{"id": "21173", "url": "https://en.wikipedia.org/wiki?curid=21173", "title": "Natural language", "text": "Natural language\n\nIn neuropsychology, linguistics, and the philosophy of language, a natural language or ordinary language is any language that has evolved naturally in humans through use and repetition without conscious planning or premeditation. Natural languages can take different forms, such as speech or signing. They are distinguished from constructed and formal languages such as those used to program computers or to study logic.\n\nThough the exact definition varies between scholars, natural language can broadly be defined in contrast to artificial or constructed languages (such as computer programming languages and international auxiliary languages) and to other communication systems in nature. Such examples include bees' waggle dance and whale song, to which researchers have found or applied the linguistic cognates of dialect and even syntax. \n\nAll language varieties of world languages are natural languages, although some varieties are subject to greater degrees of published prescriptivism or language regulation than others. Thus nonstandard dialects can be viewed as a wild type in comparison with standard languages. But even an official language with a regulating academy, such as Standard French with the French Academy, is classified as a natural language (for example, in the field of natural language processing), as its prescriptive points do not make it either constructed enough to be classified as a constructed language or controlled enough to be classified as a controlled natural language.\n\nControlled natural languages are subsets of natural languages whose grammars and dictionaries have been restricted in order to reduce or eliminate both ambiguity and complexity (for instance, by cutting down on rarely used superlative or adverbial forms or irregular verbs). The purpose behind the development and implementation of a controlled natural language typically is to aid non-native speakers of a natural language in understanding it, or to ease computer processing of a natural language. An example of a widely used controlled natural language is Simplified English, which was originally developed for aerospace industry maintenance manuals.\n\nConstructed international auxiliary languages such as Esperanto and Interlingua (even those that have native speakers) are not generally considered natural languages. Natural languages have been used to communicate and have evolved in a natural way, whereas Esperanto was designed by L.L. Zamenhof selecting elements from natural languages, not grown from natural fluctuations in vocabulary and syntax. Some natural languages have become naturally \"standardized\" by children's natural tendency to correct for illogical grammatical structures in their parents' speech, which can be seen in the development of pidgin languages into creole languages (as explained by Steven Pinker in \"The Language Instinct\"), but this is not the case in many languages, including constructed languages such as Esperanto, where strict rules are in place as an attempt to consciously remove such irregularities. The possible exception to this are true native speakers of such languages. More substantive basis for this designation is that the vocabulary, grammar, and orthography of Interlingua are natural; they have been standardized and presented by a linguistic research body, but they predated it and are not themselves considered a product of human invention. Most experts, however, consider Interlingua to be naturalistic rather than natural. Latino Sine Flexione, a second naturalistic auxiliary language, is also naturalistic in content but is no longer widely spoken.\n\n\n"}
{"id": "53494291", "url": "https://en.wikipedia.org/wiki?curid=53494291", "title": "Near-native speaker", "text": "Near-native speaker\n\nIn linguistics, the term near-native speakers is used for people who are \"highly proficient speakers who are distinguishable from native speakers, but only in small ways.\" Analysis of native and near-native speakers indicates that they differ in their underlying grammar and intuition, meaning that they do not interpret grammatical contrasts the same way. However, this divergence typically does not impact a near-native speaker's regular usage of the language.\n\n\n"}
{"id": "22951462", "url": "https://en.wikipedia.org/wiki?curid=22951462", "title": "Oroch language", "text": "Oroch language\n\nThe Oroch language is spoken by the Oroch people in Siberia. It is a member of the southern group of the Tungusic languages and is closely related to the Nanai language and Udege language. It is spoken in the Khabarovsk Krai (Komsomolsky, Sovetskaya Gavan, and Ulchsky districts). The language is split into three dialects: Tumninsky, Khadinsky, and Hungarisky. At the beginning of the 21st century, a written form of the language was created.\n\n\n"}
{"id": "48878990", "url": "https://en.wikipedia.org/wiki?curid=48878990", "title": "SkELL", "text": "SkELL\n\nSkELL is an abbreviation of Sketch Engine for Language Learning. It is a web interface for language learning. The main purpose is to help students and teachers of languages. SkELL has its own corpus that was gathered so that contained texts covering everyday, standard, formal, and professional language. In the corpus, there are a total of more than 60 million sentences and more than one billion words.\n\nThe SkELL interface provides features such as simple search showing words in context, but the maximum of displayed lines (concordances, in fact) is 40. However, the frequency of searched query is located below the search box and expressed with the number \"hits per million\". The second function is word sketch which enables showing collocates for a given word or words. The last one is named as similar words. It visualises similar words to searched word in a word cloud.\n\nThe tool has been available also for the Russian language (since 2015) and the Czech language (since 2017). \n\nSkELL offers three types of searches.\n\n\nThe corpus for English SkELL consists of English Wikipedia (special sorted out 130,000 articles), English collection of Project Gutenberg, a subset from the web corpus enTenTen14, the whole British National Corpus, and free new sources.\n\nAfter gathering and pre-cleaning (all structures have removed except sentences) data has run through processing pipe: normalization, tokenization, TreeTagger for English, and deduplication. The further process was a compilation of the corpus using manatee indexing library. In the end, all sentences were scored with the GDEX tool.\n\n"}
{"id": "226988", "url": "https://en.wikipedia.org/wiki?curid=226988", "title": "Spoken language", "text": "Spoken language\n\nA spoken language is a language produced by articulate sounds, as opposed to a written language. Many languages have no written form and so are only spoken. An oral language or vocal language is a language produced with the vocal tract, as opposed to a sign language, which is produced with the hands and face. The term \"spoken language\" is sometimes used to mean only vocal languages, especially by linguists, making all three terms synonyms by excluding sign languages. Others refer to sign language as \"spoken\", especially in contrast to written transcriptions of signs.\n\nIn spoken language, much of the meaning is determined by the context. That contrasts with written language in which more of the meaning is provided directly by the text. In spoken language, the truth of a proposition is determined by common-sense reference to experience, but in written language, a greater emphasis is placed on logical and coherent argument. Similarly, spoken language tends to convey subjective information, including the relationship between the speaker and the audience, whereas written language tends to convey objective information.\n\nThe relationship between spoken language and written language is complex. Within the field of linguistics the current consensus is that speech is an innate human capability, and written language is a cultural invention. However some linguists, such as those of the Prague school, argue that written and spoken language possess distinct qualities which would argue against written language being dependent on spoken language for its existence.\n\nBoth vocal and sign languages are composed of words. In vocal languages, words are made up from a limited set of vowels and consonants, and often tone. In sign languages, words are made up from a limited set of shapes, orientations, locations movements of the hands, and often facial expressions; in both cases, the building blocks are called phonemes. In both vocal and sign languages, words are grammatically and prosodically linked into phrases, clauses, and larger units of discourse.\n\nHearing children acquire as their first language the language that is used around them, whether vocal, cued (if they are sighted) signed. Deaf children can do the same with Cued Speech or sign language if either visual communication system is used around them. Vocal language are traditionally taught to them in the same way that written language must be taught to hearing children. (See oralism.)\n\n"}
{"id": "27083405", "url": "https://en.wikipedia.org/wiki?curid=27083405", "title": "Stomagram", "text": "Stomagram\n\nA stomagram (Greek: stoma \"mouth,\" -gram \"drawing\"), is a (typically side-view) pictogram representation of a human mouth, for the sake of diagramming its state during speech as particular sounds are made. Stomagrams may be cut-away images or simple written character forms, representing the degree the mouth is opened, the position of the lips, and the placement or movement of the tongue.\n"}
{"id": "35740951", "url": "https://en.wikipedia.org/wiki?curid=35740951", "title": "Syntactic bootstrapping", "text": "Syntactic bootstrapping\n\nSyntactic bootstrapping is a theory in developmental psycholinguistics and language acquistion which proposes that children learn word meanings by recognizing syntactic categories (such as nouns, adjectives, etc.) and the structure of their language. It is proposed that children have innate knowledge of the links between syntactic and semantic categories and can use these observations to make inferences about word meaning. Learning words in one's native language can be challenging because the extralinguistic context of use does not give specific enough information about word meanings. Therefore, in addition to extralinguistic cues, conclusions about syntactic categories are made which then lead to inferences about a word's meaning. This theory aims to explain the acquisition of lexical categories such as verbs, nouns, etc. and functional categories such as case markers, determiners, etc.\n\nOne of the earliest demonstrations of the existence of syntactic bootstrapping is an experiment done by Roger Brown at Harvard University in 1957. In his research, Brown demonstrated that preschool-aged children could use their knowledge of different parts of speech to distinguish the meaning of nonsense words in English. The results of Brown’s experiment provided the first evidence showing that children could use syntax to infer meaning for newly encountered words and that they acquired grammar and semantics simultaneously. Brown's experiment was the beginning of the framework needed in order for the theory to thrive.\n\nThis led developmental psycholinguists like Lila Gleitman, who coined the term syntactic bootstrapping in 1990, to argue that syntax was pivotal for language learning, as it also gives a learner clues about semantics. According to Gleitman's hypothesis, verbs are learned with a delay compared to other parts of speech because the linguistic information that supports their acquisition is not available during the early stages of language acquisition. The acquisition of verb meaning in children is pivotal to their language development. Syntactic bootstrapping seeks to explain how children acquire these words.\n\nThe syntactic bootstrapping hypothesis is based on the idea that there are universal/innate links between syntactic categories and semantic categories. Learners can therefore use their observations about the syntactic categories of novel words to make inferences about their meanings. This hypothesis is intended to solve the problem that the extralinguistic context is uninformative by itself to make conclusions about a novel word's meaning.\n\nFor example, a child hears the sentence, “The cat meeped the bird.” If the child is familiar with the way arguments of verbs interact with the verb, he will infer that \"the cat\" is the agent and that \"the bird\" is the patient. Then, he can use these syntactic observations to infer that \"meep\" is a behaviour that the cat is doing to the bird.\n\nChildren's ability to identify syntactic categories may be supported by Prosodic bootstrapping. Prosodic bootstrapping is the hypothesis that children use prosodic cues, such as intonation and stress, to identify word boundaries.\n\nLandau and Gleitman (1985) found when studying the acquisition of the verbs \"look\" and \"see\" by blind children that contextual clues appeared to be insufficient to explain their ability to differentiate these verbs \".\" They considered the possibility that perceptual verbs might be used more by the blind child's mother when talking about nearby objects, since the child had to touch objects to perceive them. An analysis of the mother's utterances however, found this not to be the case.\n\nThe solution investigated by Gleitman et al. was that syntactic categories (referred to as 'Sentence Frames' by Gleitman), narrow down the contexts in which verbs are present, allowing children to learn their specific meanings in isolation. This narrowing provided evidence for their original hypothesis. When utterances that selected for \"perception verbs only\" were analyzed, the mother's use of the verbs \"look\" and \"see\" for nearby objects increased significantly. Gleitman concluded that a narrowing of contexts, \"then\" contextual support were required for the blind children to learn verbs (in which they had no direct experience). By proxy, since there are many verbs that sighted children do not have direct experience with, they must use the same mechanism as well.\n\nWaxman and Booth (2001) found that children who heard nouns focused on the object categories and children who focused on adjectives focused on an object's properties and categories. This shows that children are sensitive to different syntactic categories and can use their observations of syntax to infer word meaning.\n\nIn Roger Brown’s 1957 experiment, children between the ages of three and five were shown various pictures depicting nonsense words that represented either singular nouns, mass nouns, count nouns or verbs. When the novel words were positioned in a question format, the children were able to use the placement of the novel word in the sentence to draw conclusions focus on different aspects of the image shown and adjusted their answer. For example, when Brown wanted the child to identify a mass noun, he would ask the children \"do you see any sib\", and the child would point at the pictured mass noun or noun indicating quantity. \n\nWhen children made guesses, they were correct more than half of the time. This shows that children are sensitive to the syntactic position of words, and can correctly associate a novel word with its syntactic category.\n\nHarrigan, Hacquard, and Lidz (2016) —Found that children's interpretation of a new attitude verb depended on the syntactic frame in which it was introduced. In the experiment, children who heard the word 'hope' presented in the same syntactic frame as 'want' (i.e. followed by an infinitival verb) connected the new verb 'hope' with a meaning of desire. On the other hand, those that heard 'hope' presented in the same frame as 'think' (i.e. followed by a finite verb) made no such association between desire and the new verb, instead of associating the novel verb with belief. This provides evidence that children use syntax to some extent in learning the meaning behind these sorts of abstract verbs.\nPapafragou, Cassidy, Gleitman (2007) —Participants were asked to identify verbs within the context of a video. Papafragou et al. had children watch 12 videotaped stories. 4 stories about the subject's desires and 8 stories that varied in the subject's beliefs and the framing of a novel verb. At the end of the tape, they would hear a sentence describing the scene but the sentence's verb was replaced with a novel word. Children were asked to respond with what they thought the word meant. Their responses were categorized 4 ways: Action, Belief, Desire, and Other. They found that action words were easily interpreted by children. However, false belief scenes with the complementizer phrase caused for children to respond with belief words more often. Results showed that participants in the experiment identified the verb most accurately when they could use both the video and sentence contexts. When it comes to attitude verbs, children are sensitive to the syntactic framing of the verb in question.\nWellwood, Gagliardi, and Lidz (2016) — showed that four-year-olds can understand the difference between a quantitative or qualitative word, based on its syntactic position within a sentence. In “Gleebest of the cows are by the barn,” the novel word “gleebest” is in a determiner position, and is inferred to mean “most” or “many.” In “the gleebest cows are by the barn,” “gleebest” is in an adjective position, and children infer it to mean “spotty” or another quality. These results are significant because they show children using syntax to understand word meanings.\n\nIn the Gillette et al. (1999) study—, the researchers tested adults to see what difficulties they would face when asked to identify a word from a muted, videotaped scene. They found that adults had trouble identifying the word, especially verbs, when they could only refer to the scene. Their performance increased once they were given the syntactic context for the mystery word. These results indicate that word learning is aided by the presence of syntactic context.\n\nGillette et al. (1999) performed experiments which found that participants who were provided both environmental and syntactic contexts were better able to infer what muted word was uttered at a particular point in a video than when only the environmental context was provided. In the experiment, participants were shown muted videos of a mother and infant playing. At a particular point in the video, a beep would sound and participants had to guess what word the beep stood for. It was always a verb or noun. Experimental results showed that participants were correct on identifying nouns more often than verbs. This shows that certain contexts are conducive to learning certain categories of words, like nouns, while the same context is not conducive to learning other categories, like verbs. However, when the scene was paired with a sentence containing all novel words, but the same syntactic structure as the original sentence, adults were better able to guess the verb. This shows that syntactic context is useful in the acquisition of verbs.\n\nAn early demonstration by Naigles (1990) of syntactic bootstrapping involved showing 2-year-olds a video of a duck using its left hand to push a rabbit down into a squatting position while both the animals wave their right arms in circles.\n\nDuring the video, children are presented with one of the following two descriptions:\n\nChildren were then presented two distinct follow-up videos.\n\nWhen instructed to \"find kradding\", children looked to the video that illustrated the utterance they heard during the initial video. Children who heard utterance A interpreted \"kradding\" to mean the act of the duck pushing on the rabbit, while children who heard utterance B assumed \"kradding\" was the action of arm waving. This indicates that children arrive at interpretations of a novel verb based on the utterance context and the syntactic structure in which it was embedded.\n\nIn 1990, Lila Gleitman took this idea further by examining the acquisition of verbs in more detail. In her study, she found that children could differentiate between verbs that take one or more arguments and that this knowledge was used to help them narrow down the potential meanings for the verb in question. This discovery explains how children can learn the meaning of verbs that cannot be observed, like ‘think’.\n\nIn later studies, this was exemplified by Fisher as she proposed that children can use the number of noun phrases in a sentence as evidence about a verb's meaning. She argues that children expect the noun phrases in a sentence to map one-to-one with participant roles in the event described by that sentence. For example, if a toddler hears a sentence that contains two noun phrases, she can infer that that sentence describes an event with two participants. This constrains the meaning that the verb in that sentence can have. Fisher presented 3 and 5 year old children a video in which one participant caused a second participant to move. Children who heard that scene described by a transitive clause containing a novel verb, associated the subject of the verb with the agent. Children who heard the scene described by an intransitive clause associated the subject with either the agent or the patient. This shows that children make different inferences about meaning depending on the transitivity of the sentence.\n\nAcquiring the meaning of attitude verbs, which refer to an individual’s mental state, provides a challenge for word learners since these verbs do not correlate with any physical aspects of the environment. Words such as 'think' and 'want' do not have physically observable qualities. Thus, there must be something deeper going on that enables children to learn these verbs referring to abstract mental concepts, such as syntactic frames as described in a study above by Harrigan, Hacquard, and Lidz. Because children have no initial idea about the meaning or usage of the words, syntactic bootstrapping aids them in figuring out when verbs refer to mental concepts. If a child hears the statement, \"Matt thinks his grandmother is under the covers,\" three- to four-year-old children will understand that the sentence is about Matt's belief. Children will understand from the syntactic frame in which it was uttered that the verb for mental state, \"thinks\", refers to Matt's beliefs and not to his grandmother's. In addition, Gillette et al. (1999) show that mental state verbs cannot easily be identified when only visual context is available and that these verbs showed the greatest improvement when syntactic context was provided.\n\nThe acquisition of nouns is related to the acquisition of the mass/count contrast. In 1969, Willard Van Orman Quine claimed that children cannot learn new nouns unless they have already acquired this semantic distinction. Otherwise, the word “apples” might refer to the individual objects in a pile or the pile itself, and the child would have no way to know without already understanding the difference between a mass and a count noun. Nancy N. Soja argues that Quine is mistaken, and that children can learn new nouns without fully understanding the mass/count distinction. She found in her study that 2-year old children were able to learn new nouns (some mass, some count nouns) from inferring meaning from the syntactic structure of the sentence the words were introduced in.\n\nIn a 2010 study, Syrett and Lidz show that children learn the meaning of novel gradable adjectives on the basis of the adverbs that modify them. Gradable adjectives have a scale associated with them: for example, the adjective “large” places the noun that it modifies on a size scale, while the adjective “expensive” places the noun that is modifiers on a price scale. In addition, gradable adjectives (GA's) subdivide into two classes: relative and maximal GA’s.\n\nRelative GA’s are words like “big” in (5), and require a reference point: a big mouse is not the same size as a big elephant. As shown in (6) and (7), while relative GAs can be modified by the adverb \"very\" they cannot be modified by the adverb \"completely\".\n\nMaximal GA’s are words like, “full” in (8); they operate on a close-ended scale. As shown in (9) and (10), while relative GAs cannot be modified by the adverb \"very\" they can be modified by the adverb \"completely\".\n\nIn the 2010 study, Syrett and Lidz showed children pictures of objects that could be described in terms of both relative and maximal GA’s. For example, a picture of a container that could be described as both \"tall\" (a relative GA) and \"clear\" (a maximal GA).\n\nWhen showing these objects to the children, the novel adjective used to describe them was prefaced with either adverb \"very\" (which usually modifies relative GA’s) or the adverb \"completely\" (which modifies maximal GA’s). As a control, in some contexts, no adverb was present. When the novel adjective was presented with the adverb \"very\", the children assigned a relative GA meaning to it, and when it was presented with adverb \"completely\", a maximal GA. When no adverb was present, the children were unable to assign a meaning to the adjective. This shows that, in order for children to learn the meaning of a new adjective, they depend on grammatical information provide by adverbs about the semantic class of the novel adjective.\n\nAn experiment by Wellwood, Gagliardi, and Lidz (2016) showed that four-year-olds associate unknown words with a quality meaning when they are presented with adjective syntax, and with a quantitative meaning when they are presented with determiner syntax. For example, in \"Gleebest of the cows are by the barn,\" \"gleebest\" would be interpreted as \"many\" or \"four,\" a quantity. Yet children associate the same unknown word with a quality interpretation when the word is presented in an adjective position. In the sentence \"The gleebest cows are by the barn,\" \"gleebest\" would be interpreted as \"striped\" or \"purple,\" a quality. This shows that children use syntax to identify whether a word is an adjective or a determiner, and use that category information to infer aspects of the word's meaning.\n\nThere is a basic contrast between lexical categories (which include open-class items such as verbs, nouns, and adjectives), and functional categories (which include closed-class items such auxiliary verbs, case markers, complementizers, conjunctions and determiners. The acquisition functional categories has been studied significantly less than the lexical class, so much remains unknown. A 1998 study led by Rushen Shi shows that, at a very young age, Mandarin and Turkish learners use phonological, acoustic and distributional cues to distinguish between words that are lexical categories from words that are functional categories. 11 to 20-month old children were observed speaking with their mothers to evaluate whether speech directed at the children contained clues that they could then use to categorize words as \"lexical\" or \"function\". Compared to as lexical category words, functional category words were found to have the following properties:\n\n\nSteven Pinker presents his theory of semantic bootstrapping, which hypothesizes that children use the meaning of words to start to learn the syntax of their language. Gleitman (1990) counters Pinker’s ideas by asserting that context is insufficient to supply word meaning, as a single context can allow for multiple interpretations of an uttered sentence. She explains that simply observing objects and events in the world does not provide sufficient information to infer the meanings of words and sentences. Pinker, however, argues that semantic bootstrapping and syntactic bootstrapping aren't conflicting ideas, and that semantic bootstrapping makes no claims about learning word meanings. He argues that since semantic bootstrapping is a hypothesis about how children acquire syntax, while syntactic bootstrapping is a hypothesis about how children acquire word meanings, the opposition between the two theories does not necessarily exist.\n\nPinker agrees that syntactic categories are in fact used by children to learn semantics and accepts syntactic bootstrapping, but argues that Gleitman applies the hypothesis too broadly, and that is insufficient evidence to account for all of Gleitman's claims. Pinker argues that while children can use syntax to learn certain semantic properties within a single frame, like the number of arguments a verb takes or the types of arguments such as agent and patient, there are serious problems with the argument that children pick up on these semantic properties from the syntax when a verb is found in a wide range of syntactic frames. Pinker uses the verb \"sew\" as an example:\n\nPinker argues that the syntax provides information about possible verb frames, but does not help a learner \"zoom in\" on a verb's meaning after hearing it in multiple frames. According to Pinker, the frames presented above for \"sew\" can do nothing for learners other than clue them into the fact that \"sewing\" is some sort of activity. Furthermore, Pinker disagrees with Gleitman's claim that the ambiguities in the situations where a word is used could only be solved by using information about how the word behaves syntactically.\n\nWith all of the studies above supporting or challenging syntactic bootstrapping, how does the theory hold up cross linguistically?\n\nTwo studies focusing on French and German were determining the use of syntactic contexts to classify novel words as nouns or verbs. The German study found that children between 14 and 16 months could use determiners to classify a novel word as a noun, however, they could not show the same ability mapping pronoun environments to verbs. Overall, this exemplifies their ability to determine the categories of function words and shows a sensitivity to syntactic framing. Following this conclusion, Christophe et al. found that children can use this ability along with Prosodic bootstrapping to infer the syntactic category of the neighboring content words; as at 23 months they can classify novel nouns as well as verbs based on their surrounding syntactic envionrment. These studies follow the Syntactic Bootstrapping model of language acquisition, however, the determiner/noun and pronoun/verb environments are also found in English, som, how well does this theory apply to a Language structurally different from English?\n\nLee and Naigles (2005) looked into how Mandarin children use the transitive versus intransitive environments to infer meaning in a language that allows the noun phrase (subject or object) argument to go unpronounced. Following Fisher’s studies where children use the number of NP’s to make conclusions about the causation in the sentence; 1 NP is an intransitive sentence and involves only the agent while 2 NP’s is a transitive environment and involves an action being taken upon something or someone. \n\nThe environment above was presented in the study and then altered to test the change of interpretation the Mandarin children might have. Due to the pervasive ellipsis in Mandarin, the number of NP’s in a phrase is a weaker clue in mapping causation or non-causation of a verb. Presented with an elided transitive environment \"The dog brings,\" the children determined the sentence to be intransitive, meaning they changed their interpretation of the verb based on the number of noun phrases presented. This was shown as the children used toys to act out the scenario they heard; if their interpretation were to be independent of the number of NP's they would have shown the dog bringing the lion, however, they showed the dog going on its own, showing their interpretation of the verb to be non-causative. This follows the syntactic bootstrapping theory as their mapping of verb meaning relied on the syntactic frame and content in the sentence. However, it poses another question about how Mandarin children can go on to map transitive or intransitive environments properly during their development.\n\nA few studies have begun to look at how children learning languages with different word orders represent syntactic structures which are required for children to map word meanings or categories using syntactic bootstrapping. For example, the research on the acquisition of verbs presents English children as using information about the subject and objects to determine if the verb is causative or non-causative, however, will this ability change in a language which has the object occurring before the verb. One could assume this to be a difficult task if both an English child and child leaning an SOV language have the same mental representation of syntactic structure. To address this, a Gervain, et al., looked at an infant’s mental representation of Japanese, which is a complement – head language with an object-verb (OV) word order, and Italian, which like English, is head-complement and therefore has a verb-object (VO) word order. They found that 8-month-olds have a general knowledge of word order specific to their language preceding their acquisition of lexical items or syntactic categories. Their attuning of structural relations of syntactic categories (verbs, nouns, etc.) within their language allows them to then apply this knowledge later in their development, possibly allowing for language-specific syntactic bootstrapping.\n\n"}
{"id": "26009616", "url": "https://en.wikipedia.org/wiki?curid=26009616", "title": "Teaching writing in the United States", "text": "Teaching writing in the United States\n\nTeaching writing in the United States has progressed through several approaches during the history of education in the United States.\n\nAt its most basic level, writing is how people keep track of the thoughts that are important to them. From the ancient Egyptians, to the monks of the Middle Ages, to Thomas Jefferson's Declaration of Independence, writing has been used to capture thought, from the mundane to the profound. In schools, writing serves not only to record and convey thoughts, but to refine and synthesize thinking. As school effectiveness researcher Doug Reeves discovered, \"The association between writing and performance in other academic disciplines [is] striking, and gets to the heart of the curriculum choices teachers must make.\"\n\nEarly academic instruction in writing centered almost exclusively on mechanics, commonly referred to today as conventions. Emphasis was placed on handwriting, grammar, punctuation and spelling. Papers were more likely to be graded on conformity to these conventions and accuracy of content than on style or creative expression of ideas. Historically, instruction in writing has focused on a narrow pool of concrete, easily definable skills.\n\nResearch conducted in the late 1970s by Donald Graves, Janet Emig and others led to a focus on the process, rather than solely the product, of writing. The writing process approach rests on the premise that writing is a complex and individualized task which can be described through a series of recursive stages. These stages, commonly including pre-writing, writing, editing and revision, and the concepts of craft within them, can be modeled and taught to students. This allows the teacher to identify the difficulties students are having with writing and to provide appropriate instruction and support. The writing process approach helps students to understand what writers actually do when they write, providing multiple models and individual feedback on writing pieces in progress. Students are encouraged to choose their own topics and purposes for writing, and to write to real audiences. This approach has been widely adopted in schools throughout the United States.\n\nA new way to have students write is to work together – known as collaborative writing. There are many criticisms against collaborative writing and many people are uncomfortable with it. Darolyn Jones, author of \"Collaborative Writing: Priority, Practice and Process\", says that many people work alone for several reasons. The first one is that many people cannot find time to meet with the rest of the group. Another reason is that each writer has their organization and own process of writing. When students are forced to work with others, they must adjust to the style of the group and get rid of their own. Many times there is a misunderstanding of what is expected of the students. The last reason, and the biggest one, is the fear of being criticized. Many writers do not feel comfortable sharing their work because they are afraid it will be torn down and disliked by readers and their audience.\n\nDespite these issues, there are several benefits to collaborative writing. Collaboration results in a stronger finished product. Each member can contribute their own strengths for the assignment. Working together allows students to mentor each other and practice working with one another, which will help them in the real world when they go out for their job. While the project may seem daunting, working together allows the burden to be shared and there are more eyes for editing the final project.\n\nDuring the 1980s and 1990s, new approaches to teaching writing emerged, as teachers realized that in order to be effective, a piece of writing should be tailored to a specific purpose and audience. Prominent among these was the British-based movement which came to be known as Writing Across the Curriculum. This approach rests on the premise that all teachers, not just language arts teachers, must be teachers of writing. Designed to ease the separation between literacy and content knowledge, this approach emphasizes the connection between writing and cognitive development, teaching students to write in a variety of genres, specific to purpose and discipline. Writing Across the Curriculum teachers often emphasize two basic pedagogical strands: Writing to Learn, informal writing done to prompt students to more deeply understand concepts; and Writing in the Disciplines, in which students are taught writing skills and conventions necessary to participate in specific academic discourse.\n\n\"Writing for understanding\", a 21st-century approach, adapts the principles of backward design to teach students to write effectively. Writing for Understanding grew out of a recognition that most students require explicit instruction in both the knowledge and the structures that they need to construct meaning in writing. Oral processing and the extensive use of models and modeling are core teaching methodologies in this approach. The Writing for Understanding Approach rests on three pillars: Backward Design, Understanding and Direct Instruction. Students are given focused, intentional instruction and practice in:\n\n\nWriting for understanding teachers intentionally design instruction to enable students to appropriately generalize and transfer their skills to multiple contexts. The Vermont Writing Collaborative serves as a clearinghouse for information about Writing for Understanding and provides professional development, instructional materials and support for educators.\n\nAccording to some writing theorists, reading for pleasure provides a more effective way of mastering the art of writing than does a formal study of writing, language, grammar, and vocabulary.\"Studies that sought to improve writing by providing reading experiences in place of grammar study or additional writing practice found that these experiences were as beneficial as, or more beneficial than, grammar study or extra writing practice.\"The apprenticeship approach provides one variant of the reading connection, arguing that the composition classroom should resemble pottery or piano workshops—minimizing dependence on excessive self-reflection, preoccupation with audience, and explicit rules. By watching the master, according to Michael Polanyi, an “apprentice unconsciously picks up the rules of the art, including those which are not explicitly known to the master himself.” Writing instructors, according to this approach, serve as models and coaches, providing explicit feedback in response to the learner's compositions. Students focus their attention on the task at hand, and not on \"an inaccessible and confusing multitude of explicit rules and strategies.\" \n\nIn 2009, the National Governors Association Center for Best Practices (NGA Center) and the Council of Chief State School Officers (CCSSO) assumed the coordination of a state led effort called The Common Core State Standards Initiative. In this initiative, \"Governors and state commissioners of education from 48 states, 2 territories and the District of Columbia committed to developing a common core of state standards in English-language arts.\" The Common Core State Standards Initiative's focus, with regard to writing, is to prepare America's students for college and career writing. These standards indicate key points in English Language Arts Writing through outlining the following main categories: Text Types and Purposes; Production and Distribution of Writing; Research to Build and Present Knowledge; and Range of Writing. These main categories are divided into 10 concepts and skills which are introduced to students in Kindergarten and then built upon in every subsequent grade level. Complexity and rigor increase each year so students develop and master each concept and skill. This effort is ongoing and is certain to have a profound effect nationwide on writing curriculum and pedagogical practice over the next decade. The National Commission on Writing has challenged American public educators \"to teach all students to write effectively, clearly and thoughtfully.\"\n\n\n"}
{"id": "11224670", "url": "https://en.wikipedia.org/wiki?curid=11224670", "title": "Terminology planning policy", "text": "Terminology planning policy\n\nTerminology planning is a planning activity for developing domain communication largely according to the needs and requirements of knowledge representation. Domain-specific conventions of knowledge representation — depending on the domain as such or text within a domain, may comprise not only linguistic representation of concepts (i.e.terms), but also all kinds of non-linguistic representations (e.g. graphs, formulae, numbers, signs, depictions). Therefore, to different degrees depending on the particular domain, terminology planning may have to take into account these non-linguistic representations as well.\n\nWhile the focus of language planning is the deliberate manipulation and development of a linguistic entity to improve communication in society or a language community at large, terminology planning may be language independent or in its objective across languages, aiming at the improvement of communication in a specific domain or application thereof. \n\nWhile terminology planning is an important part of language planning it may be useful for language communities to separate the two activities for simplification of its complexity in order to better focus programmes and resources, and thus receive better results.\n\nBecause language planning also concerns the development of the lexicon of a language, and because domain communication consists to a great extent of linguistic representations of concepts there exists a large area of overlapping between the two concepts. The biggest difference lies in the different point of view and scope (and goal).\n\nPublic strategy formulated at the level of political decision-making in a more or less autonomous language community with the aim of developing or regulating emerging or existing terminologies for an array of purposes. Examples of such regulated terminologies are the hundreds of standards that the International Organization for Standardization (ISO) publishes on an ongoing basis.\n\n\nStrategic planning of terminology work and terminology resources is not only a matter of concern for governments and other public administration. Furthermore, due to the crucial role of terminology for scientific-technical planning, industry, risk communication and business communication processes, as well as basically any other event of domain communication, terminology planning policies play an increasing role for corporate communication of all types (commercial, non-commercial). Especially enterprises increasingly feel the need for a systematic terminology planning in connection with corporate language or language localization and translation questions.\n\nHowever, despite the need for strategic terminology planning the term \"Terminology Planning/Policies\" has not caught on in these communities and may be referred to in a variety of other terms. A meta-language is required.\n\n"}
{"id": "28058043", "url": "https://en.wikipedia.org/wiki?curid=28058043", "title": "Terminology science", "text": "Terminology science\n\nTerminology science is a branch of linguistics studying special vocabulary.\n\nThe main objects of terminological studies are special lexical units (or special lexemes), first of all terms. They are analysed from the point of view of their origin, formal structure, their meanings and also functional features. Terms are used to denote concepts, therefore terminology science also concerns itself with the formation and development of concepts, as well as with the principles of exposing the existing relations between concepts and classifying concepts; also, with the principles of defining concepts and appraising the existing definitions. Considering the fact that characteristics and functioning of term depend heavily on its lexical surrounding nowadays it is common to view as the main object of terminology science not separate terms, but rather the whole terminology used in some particular field of knowledge (also called subject field).\n\nTerminological research started seventy years ago and was especially fruitful at the last forty years. At that time the main types of special lexical units, such as terms proper, nomens, terminoids, prototerms, preterms and quasiterms were singled out and studied.\n\nA nomen, or a nomenclature unit, is a name of a single notion or a certain unit of mass production, e.g. prefix dis-; Canon 550D; UA-24; etc.\n\nTerminoids, or jargon terms, are special lexical units which are used to name the phenomena that are absolutely new and whose concepts are not interpreted in a monosemantic way. E.g., Salmon Day, mouse potato, etc.\n\nPrototerms are special lexemes that appeared and were used in prescientific times.\n\nPreterms are a special group of lexemes which is represented by special lexical units used as terms to name new scientific notions. They are represented by a vast descriptive pattern, e.g. business process re-engineering, management by walking about, etc.\n\nThe main principles of terminological work were elaborated, terminologies of the leading European languages belonging to many subject fields were described and analysed. It should be mentioned that at the former USSR terminological studies were conducted on an especially large scale: while in the 1940s only four terminological dissertations were successfully defended, in the 1950s there were 50 such dissertations, in the 1960s their number reached 231, in the 1970s – 463 and in the 1980s – 1110.\n\nAs the result of development and specialising of terminological studies, some of the branches of terminology science – such as typological terminology science, semasiological terminology science, terminological derivatology, comparative terminology science, terminography, functional terminology science, cognitive terminology science, historical terminology science and some branch terminology sciences – have gained the status of independent scientific disciplines.\n"}
{"id": "43935001", "url": "https://en.wikipedia.org/wiki?curid=43935001", "title": "The Analytical Language of John Wilkins", "text": "The Analytical Language of John Wilkins\n\n\"The Analytical Language of John Wilkins\" (Spanish: \"El idioma analítico de John Wilkins\") is a short essay by Argentine writer Jorge Luis Borges originally published in \"Otras Inquisiciones (1937–1952)\". It is a critique of the English natural philosopher and writer John Wilkins's proposal for a universal language and of the representational capacity of language generally. In it, Borges imagines a bizarre and whimsical (and fictional) Chinese taxonomy later quoted by Michel Foucault, David Byrne, and others.\n\nBorges begins by noting John Wilkins's absence from the 14th edition of the \"Encyclopædia Britannica\" and makes the case for Wilkins's significance, highlighting in particular the universal language scheme detailed in his \"An Essay towards a Real Character and a Philosophical Language\" (1668). Wilkins's system decomposes the entire universe of \"things and notions\" into successively smaller divisions and subdivisions, assigning at each step of this decomposition a syllable, consonant, or vowel. Wilkins intended for these conceptual building blocks to be recombined to represent anything on earth or in heaven. The basic example Borges gives is \"\"de\", which means an element; \"deb\", the first of the elements, fire; \"deba\", a part of the element of fire, a flame.\"\nExamining this and other second-hand examples from Wilkins's schemehe did not have access to Wilkins's actual work, but based his comments on \"others\"' comments on itBorges believes he finds \"ambiguities, redundancies and deficiencies\", concluding \"it is clear that there is no classification of the Universe not being arbitrary and full of conjectures.\" He fancifully likens Wilkins's classification scheme to a \"certain Chinese encyclopedia,\" likely fictitious, but attributed to Franz Kuhn, called the \"Celestial Emporium of Benevolent Knowledge\", said to divide animals into \"(a)those that belong to the Emperor, (b)embalmed ones, (c)those that are trained, (d)suckling pigs, (e)mermaids, (f)fabulous ones, (g)stray dogs, (h)those that are included in the present classification, (i)those that tremble as if they are mad, (j)innumerable ones, (k)those drawn with a very fine camelhair brush, (l)others, (m)those that have just broken a flower vase, (n)those that look like flies from a long way off.\" Borges's point is the arbitrary nature of such taxonomies, regardless of whether they form a language or just a way of understanding and ordering the world. He challenges the idea of the universe as something we can understand at all\"we do not know what thing the universe is\"much less describe using language.\n\nWhile considering Wilkins's effort naïve, Borges ultimately praises the ambition of a universal language and admits that Wilkins's word for salmon, \"zana\", could (for someone well-versed in Wilkins's language) hold more meaning than the corresponding words in conventional languages, which are arbitrary and carry no intrinsic meaning. He says that, \"Theoretically, it is not impossible to think of a language where the name of each thing says all the details of its destiny, past and future.\"\n\nMichel Foucault attributes the inspiration for his \"The Order of Things\" to Borges' \"Celestial Emporium\" passage and \"the laughter that shattered, as I read the passage, all the familiar landmarks of my thought ... breaking up all the ordered surfaces and all the planes with which we are accustomed to tame the wild profusion of existing things...\" Foucault is disturbed less by the \"Emporium's\" arbitrariness than by the idea that such a classification might be intelligible to someone or some culture, then discusses the ways cultures make sense of the world by drawing relationships between things, expressed through language. What Borges did, according to Foucault, was to highlight the importance of the \"site\" of order by taking it away, asking in what context the \"Celestial Emporium\" might make sense.\n\nThe \"Emporium\" has often been used as a shorthand for the subversion of traditional, rational notions of order. The artist and musician David Byrne has created an art work, \"The Evolution of Category\", that shows a hierarchical tree based on this mythical taxonomy.\n\n\n"}
{"id": "1617429", "url": "https://en.wikipedia.org/wiki?curid=1617429", "title": "Tutnese", "text": "Tutnese\n\nTutnese or Double Dutch is a language game primarily used in English, although the rules can be easily modified to apply to almost any language. Tutnese is usually used by children, who use it to converse in privacy from adults; by members of historically marginalized minority groups for the same reason when in the presence of authority figures such as police (\"pupolulisus\" or \"pizolizice\"); or simply for amusement and humor.\n\nIn Tutnese, vowels are pronounced normally, but each consonant is replaced with a syllable from the following table:\n\nDouble letters in a word, rather than being repeated, are preceded by the syllable \"squa\" to indicate doubling. For doubled vowels, the prefix becomes \"squat\" instead—thus, \"OO\" would be spoken as \"squat-oh\".\n\nWord Example: \"Tree\" becomes \"Tutrugsquatee\". \nSentence Example: \"I took a walk to the park yesterday\" becomes \"I tutsquatohkuck a wackalulkuck tuto tuthashe pubarugkuck yubesustuterugdudayub\".\n\nWhile spaces between words are always ignored, at least one \"dialect\" requires that the first syllable of the name of any given punctuation mark be spoken, thus a full stop (period) is 'Per', a question mark is 'Que' ('Kway' or 'Kay', varies), and a comma is 'Com'.\n\nThis game appears to have been invented and used by black slaves in the American south, to teach spelling and conceal what they said, at a time when literacy among slaves was forbidden.\n\nMaya Angelou mentions learning Tutnese as a child in the first volume of her autobiography, \"I Know Why the Caged Bird Sings\". She and her friend Louise \"spent tedious hours teaching ourselves the Tut language. You (yack oh you) know (kack nug oh wug) what (wack hash a tut). Since all the other children spoke Pig Latin, we were superior because Tut was hard to speak and even harder to understand.\"\n\nThere is a version used in some parts of the US called Yuckish or Yukkish, which uses more or less the same constructs.\n\n"}
{"id": "12393342", "url": "https://en.wikipedia.org/wiki?curid=12393342", "title": "Vernacular orientation", "text": "Vernacular orientation\n\nVernacular orientation refers to the status that a language is afforded by one of its mother-tongue speakers (Tiessen, 2003). This status is exhibited through the sociolinguistic behaviours of a mother-tongue speaker. A speaker who exhibits positive vernacular orientation is one who exhibits a preferred status for their mother tongue in such things as patterns of language use, language attitudes, social networks and even levels of language proficiency. Likewise, a speaker who exhibits negative vernacular orientation is one who exhibits a preferred status for a language other than their mother tongue in these areas of sociolinguistic behaviour.\n\nAn example of research into vernacular orientation as expressed in a community can be found at . This is a study on vernacular orientation in the Talysh community of the city of Sumgayit in the Republic of Azerbaijan for the purpose of gaining a greater understanding of its causes. Vernacular orientation is described in three areas of sociolinguistic behaviour: patterns of vernacular language use, vernacular language proficiency and frequency of vernacular-speaking individuals in social networks. Data was collected through personal interviews. The questionnaires for these interviews were developed using a qualitative-relational research approach. The description of vernacular orientation takes the form of a criteria-based typology of which an analysis of influential factors is ultimately made. This analysis of influential factors demonstrates the interaction between vernacular orientation as described in the typology and the contextual elements of the family, socio-economic dynamics and individual attitudes.\n"}
