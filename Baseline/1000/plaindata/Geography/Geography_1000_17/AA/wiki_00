{"id": "11686390", "url": "https://en.wikipedia.org/wiki?curid=11686390", "title": "Absolute bearing", "text": "Absolute bearing\n\nIn nautical navigation the absolute bearing is the clockwise angle between north and an object observed from the vessel. If the north used as reference is the true geographical north then the bearing is a \"true bearing\" whereas if the reference used is magnetic north then the bearing is a \"magnetic bearing\". \n\nAn absolute bearing is measured with a bearing compass.\n\nThe measurement of absolute bearings of fixed landmarks and other navigation aids is useful for the navigator because this information can be used on the nautical chart together with simple geometrical techniques to aid in determining the position of the vessel.\n\n"}
{"id": "3740489", "url": "https://en.wikipedia.org/wiki?curid=3740489", "title": "Antichthones", "text": "Antichthones\n\nAntichthones, in geography, are those peoples who inhabit the antipodes, regions on opposite sides of the Earth. The word is compounded of the Greek \"ὰντὶ\" (\"opposed\") and \"χθών\" (\"earth\").\nClassical and Medieval Europe considered the Earth to be divided by the equator into two hemispheres, the northern and southern; those who inhabited one of these hemispheres were said to be antichthones to those of the other. This idea was expounded by Mela and other Classical authors, though Christian writers, who believed that all people on earth must be descended from Adam, denied the possibility that any southern land, if it existed, could be inhabited by humans. St. Augustine, arguing from a position of scriptural inerrancy, wrote in his \"City of God\" \"it is too absurd to say, that some men might have taken ship and traversed the whole wide ocean, and crossed from this side of the world to the other, and that thus even the inhabitants of that distant region are descended from that one first man.\"\n\n"}
{"id": "12041027", "url": "https://en.wikipedia.org/wiki?curid=12041027", "title": "BC Geographical Names", "text": "BC Geographical Names\n\nThe BC Geographical Names (formerly BC Geographical Names Information System or BCGNIS) is a geographic name web service and database for British Columbia, Canada, which is run and maintained by the Base Mapping and Geomatic Services Branch of the Integrated Land Management Bureau. The database contains official names and spellings of towns, mountains, rivers, lakes, and other geographic places. The database often has other useful information, such as the history of geographic names, and their use in history.\n"}
{"id": "2654634", "url": "https://en.wikipedia.org/wiki?curid=2654634", "title": "Beating the bounds", "text": "Beating the bounds\n\nBeating the bounds is an ancient custom still observed in some English and Welsh parishes. Under the name of the Gangdays the custom of going a-ganging was kept before the Norman Conquest. A group of old and young members of the community would walk the boundaries of the parish, usually led by the parish priest and church officials, to share the knowledge of where they lay, and to pray for protection and blessings for the lands.\n\nIn former times when maps were rare it was usual to make a formal perambulation of the parish boundaries on Ascension Day or during Rogation week. Knowledge of the limits of each parish needed to be handed down so that such matters as liability to contribute to the repair of the church, and the right to be buried within the churchyard were not disputed. The relevant jurisdiction was that of the ecclesiastical courts. The priest of the parish with the churchwardens and the parochial officials headed a crowd of boys who, armed with green boughs, usually birch or willow, beat the parish boundary markers with them. Sometimes the boys were themselves whipped or even violently bumped on the boundary-stones to make them remember. The object of taking boys along is supposed to ensure that witnesses to the boundaries should survive as long as possible. Priests would pray for its protection in the forthcoming year and often Psalms 103 and 104 were recited, and the priest would say such sentences as \"Cursed is he who transgresseth the bounds or doles of his neighbour\". Hymns would be sung, indeed a number of hymns are titled for their role, and many places in the English countryside bear names such as Gospel Oak testifying to their role in the beating of the bounds.\n\nThe ceremony had an important practical purpose. Checking the boundaries was a way of preventing encroachment by neighbours; sometimes boundary markers would be moved, or lines obscured, and a folk memory of the true extent of the parish was necessary to maintain integrity of borders by embedding knowledge in oral traditions. For a village man dwelling in champion country, under the traditional open field system, George Homans remarks, \"the bounds of his village were the most important bounds he knew.\" Village and parish were coterminous. The modern system of metes and bounds operates fundamentally similarly, giving a prose definition of a property as if walking about it.\n\nAt Manchester in 1597 John Dee recorded in his diary that he with the curate, the clerk and \"diverse of the town of diverse ages\" perambulated the bounds of the parish taking six days in all.\n\nAt Turnworth in Dorset the parish register records the perambulation for 1747 thus:\nIn a few cases such as the Corporation of the City of Portsmouth the bounds were on the shoreline and the route was followed by boat rather than on foot.\n\nThe practice is still lawful and not affected by the limiting of the jurisdiction in 1860. Parish officers have the right to enter private property in carrying it out and also use the rates to cover expenses properly incurred (including refreshments, but not music, etc.). Perambulations must be at least three years apart.\n\nIn England, the custom dates from Anglo-Saxon times, as it is mentioned in laws of Alfred the Great and Æthelstan. It is thought that it may have been derived from the Roman \"Terminalia\", a festival celebrated on February 22 in honour of Terminus, the god of landmarks, to whom cakes and wine were offered while sports and dancing took place at the boundaries. Similar practices, of pagan origin, were brought by the Norsemen. \n\nIn England, a parish ale, a feast, was always held after the perambulation, which assured its popularity. In Henry VIII's reign the occasion had become an excuse for so much revelry that it attracted the condemnation of a preacher who declared, \"These solemne and accustomable processions and supplications be nowe growen into a right foule and detestable abuse.\"\n\nBeating the bounds had a religious aspect which is reflected in the rogation, where the accompanying clergy beseech (\"rogare\") the divine blessing upon the parish lands for the ensuing harvest. This feature originated in the 5th century, when Mamertus, Archbishop of Vienne, instituted special prayers, fasting and processions on these days. This clerical side of the parish bounds-beating was one of the religious functions prohibited by the Royal Injunctions of Elizabeth I in 1559; but it was then ordered that the perambulation should continue to be performed as a quasi-secular function, so that evidence of the boundaries of parishes, etc., might be preserved. \n\nBequests were sometimes made in connection with bounds-beating. For example, at Leighton Buzzard on Rogation Monday, in accordance with the will of Edward Wilkes, a London merchant who died in 1646, the trustees of his almshouses accompanied the boys. The will was read and beer and plum rolls distributed. A remarkable feature of the bequest was that while the will is read one of the boys has to stand on his head.\n\nAlthough modern surveying techniques make the ceremony obsolete, at least for its secular purpose, many English parishes carry out a regular beating of the bounds, as a way of strengthening the community and giving it a sense of place.\n\nIn 1865–66 William Robert Hicks was mayor of Bodmin in Cornwall, when he revived the custom of beating the bounds of the town. This still takes place more or less every five years and concludes with a game of Cornish hurling. Hurling survives as a traditional part of beating the bounds at Bodmin, commencing at the close of the 'Beat'. The game is organised by the Rotary club of Bodmin and was last played in 2015. The game is started by the mayor of Bodmin by throwing a silver ball into a body of water known as the \"Salting Pool\". There are no teams and the hurl follows a set route. The aim is to carry the ball from the \"Salting Pool\" via the old A30, along Callywith Road, then through Castle Street, Church Square and Honey Street to finish at the Turret Clock in Fore Street. The participant carrying the ball when it reaches the turret clock will receive a £10 reward from the Mayor. The next occurrence of the Bodmin Hurl will follow the next beating of the bounds, in 2020.\n\nPerambulation of the town borders is a traditional duty of town boards of selectmen in the American states of Massachusetts and New Hampshire.\n\nThe laws of Vermont and New Hampshire require the attorneys general of those states to meet once every seven years to perambulate the boundary between the two states. They do not walk 275 miles along the Connecticut River, but they meet at the boundary and formally reaffirm their mutual understanding of the precise location of the boundary. The location had been disputed in the United States Supreme Court in the case of \"Vermont v. New Hampshire\", decided in 1933.\n\n\nBerwick, David A. \"Beating the Bounds in Georgian Norwich\". Larks Press (www.booksatlarkspress.co.uk), Ordnance Farmhouse, Guist Bottom, Dereham, Norfolk, UK: 2007. \n\n"}
{"id": "1980869", "url": "https://en.wikipedia.org/wiki?curid=1980869", "title": "Benchmark (surveying)", "text": "Benchmark (surveying)\n\nThe term benchmark, or bench mark, originates from the chiseled horizontal marks that surveyors made in stone structures, into which an angle-iron could be placed to form a \"bench\" for a leveling rod, thus ensuring that a leveling rod could be accurately repositioned in the same place in the future. These marks were usually indicated with a chiseled arrow below the horizontal line.\n\nThe term is generally applied to any item used to mark a point as an elevation reference. Frequently, bronze or aluminum disks are set in stone or concrete, or on rods driven deeply into the earth to provide a stable elevation point. If an elevation is marked on a map, but there is no physical mark on the ground, it is a spot height.\n\nThe height of a benchmark is calculated relative to the heights of nearby benchmarks in a network extending from a \"fundamental benchmark\". A fundamental benchmark is a point with a precisely known relationship to the level datum of the area, typically mean sea level. The position and height of each benchmark is shown on large-scale maps.\n\nThe terms \"height\" and \"elevation\" are often used interchangeably, but in many jurisdictions they have specific meanings; \"height\" commonly refers to a local or relative difference in the vertical (such as the height of a building), whereas \"elevation\" refers to the difference from a nominated reference surface (such as sea-level, or a mathematical/geodetic model that approximates the sea level known as the geoid). Elevation may be specified as normal height (above a reference ellipsoid), orthometric height, or dynamic height which have slightly different definitions.\n\nTriangulation points, also known as trig points, are marks with a precisely established horizontal position. These points may be marked by disks similar to benchmark disks, but set horizontally, and are also sometimes used as elevation benchmarks. Prominent features on buildings such as the tip of a church spire or a chimney stack are also used as reference points for triangulation. In the United Kingdom triangulation points are often set in large concrete markers that, as well as functioning as triangulation points, have a benchmark set into the side. With the increasing use of GPS and electronic distance measuring devices, the same techniques and equipment are used to fix the horizontal and vertical position of a survey marker at the same moment, and therefore the marks are usually regarded as \"fixed in three dimensions\".\n\nBenchmarks are typically placed (\"monumented\") by a government agency or private survey firm, and many governments maintain a register of these marks so that the records are available to all. These records are usually in the form of a geographically searchable database (computer or map-based), with links to sketches, diagrams, photos of the marks, and any other technical details.\n\nGovernment agencies that place and maintain records of benchmarks include:\n\n\n"}
{"id": "33270129", "url": "https://en.wikipedia.org/wiki?curid=33270129", "title": "Berkeley School of Latin Americanist Geography", "text": "Berkeley School of Latin Americanist Geography\n\nThe Berkeley School of Latin Americanist Geography was founded by the American geographer Carl O. Sauer. Sauer was a professor of geography at the University of California at Berkeley from 1923 until becoming professor emeritus in 1957 and was instrumental in the early development of the geography graduate program at Berkeley and the discipline of geography in the United States. Each generation of this research school has pursued new theoretical and methodological approaches, but their study of the peoples and places of Latin America and the Caribbean has remained the common denominator since the early 20th century. Carl O. Sauer himself did not develop a particular interest in Latin America before 1925, when Oskar Schmieder, a German geographer, disciple of Alfred Hettner, and expert in Latin American regional geography, arrived at Berkeley, coming from Córdoba, Argentina, to work as an Associate Professor. Obviously, his interest awoke during Schmieder's presence between 1925 and 1930. After Schmieder's departure in 1930, Carl O. Sauer began to offer seminars on the regional geography of Latin America.\n\nSauer graduated many doctoral students, the majority completing dissertations on Latin American and Caribbean topics and thereby founding the Berkeley School of Latin Americanist Geography. Sauer's Ph.D. students who completed dissertations on Latin American and Caribbean topics are Fred Kniffen (1930), Peveril Meigs (1932), Donald Brand (1933), Henry Bruman (1940), Felix W. McBryde (1940), Robert Bowman (1941), (1944), Robert C. West (1946), James J. Parsons (1948), Edwin Doran (1953), Philip Wagner (1953), Brigham Arnold (1954), Homer Aschmann (1954), B. LeRoy Gordon (1954), Gordon Merrill (1957), Donald Innis (1958), Carl Johannessen (1959), Clinton Edwards (1962), and Leonard Sawatzky (1967).\n\nOf Sauer's doctoral students, James J. Parsons became the most prolific in terms of directing Latin Americanist doctoral dissertations. He remained at the University of California at Berkeley and produced many of the Ph.D.s in the second generation of the Berkeley School of Latin Americanist Geography: Campbell Pennington (1959), William Denevan (1963), David Harris (1963), Thomas Veblen (1975), and Karl Zimmerer (1987).\n\nOne of the second generation, William Denevan, became a professor at the University of Wisconsin-Madison and, in turn, produced the majority of the third generation. Denevan's Ph.D. students who completed dissertations on Latin American topics are, among others, Daniel W. Gade (1967; co-chaired), Bernard Nietschmann (1970), Roger Byrne (1972), Roland Bergmann (1974), Billie Lee Turner II (1974), Stuart White (1981), Hildegardo Córdova (1982), Gregory Knapp (1984), Kent Mathewson (1987), John M. Treacy (1989), and Oliver Coomes (1992).\n\nA member of the fourth generation, William E. Doolittle studied with Billie Lee Turner II, a prominent member of the third generation. Doolittle earned the Ph.D. in 1979, became a professor in the Department of Geography and the Environment at University of Texas at Austin, and has extended the school into the fifth generation. Doolittle's Ph.D. students who completed dissertations on Latin American topics are Dean P. Lambert (1992), Andrew Sluyter (1995), Emily H. Young (1995), Eric P. Perramond (1999), Phil L. Crossley (1999), Jerry O. (Joby) Bass (2003), Maria G. Fadiman (2003), and Matthew Fry (2008).\n\nSeveral of that fifth generation hold faculty positions in university departments with doctoral programs, and a sixth generation is now emerging. They are applying new approaches and research questions to the study of the peoples and places of Latin America and the Caribbean.\n\n"}
{"id": "22875274", "url": "https://en.wikipedia.org/wiki?curid=22875274", "title": "Boundary (real estate)", "text": "Boundary (real estate)\n\nA unit of real estate or immovable property is limited by a legal boundary (sometimes also referred to as a property line or a lot line). The boundary (in Latin: \"limes\") may appear as a discontinuation in the terrain: a ditch, a bank, a hedge, a wall, or similar, but essentially, a legal boundary is a conceptual entity, a social construct, adjunct to the likewise abstract entity of property rights.\n\nA cadastral map displays how boundaries subdivide land into units of ownership. However, the relations between society, owner, and land in any culture or jurisdiction is conceived of in terms more complex than a tessellation. Therefore, the society concerned has to specify the rules and means by which the boundary concept is materialized and located on the ground.\n\nA 'Western' version of the operationalization might be a legally specified procedure, performed by a chartered surveyor, supported by statements from neighbors and pertinent documents, and resulting in official recording in the cadastre as well as boundary markings in the field. Alternatively, indigenous people represent boundaries through ephemeral performances, such as song and dance, and, when in more permanent form, e.g. paintings or carvings, in artistic or metaphorical manner.\n\nLegal boundaries are usually established by a professional surveyor using a transit and or modern Global Positioning System (GPS) technology. The coordinates of the property line are often described on a drawing called a \"plot plan\" or \"plat\" by indicating the length of the boundary along a specific compass bearing in relation to a verifiable \"point of beginning\". The metes and bounds method is also used to provide a legal description of a property.\n\nOn maps, the line may be marked with .\n\nThe ⅊ symbol may also be used in architectural drawings and CAD design to show plates.\n\n\n"}
{"id": "1426430", "url": "https://en.wikipedia.org/wiki?curid=1426430", "title": "Chapman code", "text": "Chapman code\n\nChapman codes are a set of 3-letter codes used in genealogy to identify the administrative divisions in the United Kingdom, Ireland, the Isle of Man and the Channel Islands. \n\nThey were created by the historian, Dr. Colin R Chapman, in the late 1970s, and as intended, provide a widely used shorthand in genealogy which follows the common practice of describing areas in terms of the counties existing in the 19th and 20th centuries. \n\nChapman codes have no mapping, postal or administrative use. They can however be useful for disambiguation by postal services where a full county name or traditional abbreviation is not supplied after a place name which has more than one occurrence, a particular problem where these are post towns such as Richmond.\n\n"}
{"id": "58473374", "url": "https://en.wikipedia.org/wiki?curid=58473374", "title": "Charles Brown's saw mill", "text": "Charles Brown's saw mill\n\nCharles Brown's saw mill was the first saw mill in San Mateo County, California. It was built in 1847, in the style as Sutter's Mill at Coloma, California.\n"}
{"id": "133345", "url": "https://en.wikipedia.org/wiki?curid=133345", "title": "Dead reckoning", "text": "Dead reckoning\n\nIn navigation, dead reckoning is the process of calculating one's current position by using a previously determined position, or fix, and advancing that position based upon known or estimated speeds over elapsed time and course. The corresponding term in biology, used to describe the processes by which animals update their estimates of position or heading, is path integration.\n\nDead reckoning is subject to cumulative errors. Advances in navigational aids that give accurate information on position, in particular satellite navigation using the Global Positioning System, have made simple dead reckoning by humans obsolete for most purposes. However, inertial navigation systems, which provide very accurate directional information, use dead reckoning and are very widely applied.\n\nBy analogy with their navigational use, the words \"dead reckoning\" are also used to mean the process of estimating the value of any variable quantity by using an earlier value and adding whatever changes have occurred in the meantime. Often, this usage implies that the changes are not known accurately. The earlier value and the changes may be measured or calculated quantities.\n\nThe term \"dead reckoning\" was not originally used to abbreviate \"deduced reckoning,\" nor is it a misspelling of the term \"ded reckoning.\" The use of \"ded\" or \"deduced reckoning\" appeared much later in history, no earlier than 1931; in contrast to \"dead reckoning\" appearing as early as 1613 in the Oxford English Dictionary. The original intention of \"dead\" in the term is not clear however. Whether it is used to convey \"absolute\" as in \"dead ahead,\" reckoning using other objects that are \"dead in the water,\" or using reckoning properly \"you’re dead if you don’t reckon right,\" is not known.\n\nDead reckoning can give the best available information on position, but is subject to significant errors as both speed and direction must be accurately known at all instants for position to be determined accurately. For example, if displacement is measured by the number of rotations of a wheel, any discrepancy between the actual and assumed travelled distance per rotation, due perhaps to slippage or surface irregularities, will be a source of error. As each estimate of position is relative to the previous one, errors are cumulative, or compounding, multiplicatively or exponentially, if that is the co-relationship of the quanta.\n\nThe accuracy of dead reckoning can be increased significantly by using other, more reliable methods to get a new fix part way through the journey. For example, if one was navigating on land in poor visibility, then dead reckoning could be used to get close enough to the known position of a landmark to be able to see it, before walking to the landmark itself — giving a precisely known start point — and then setting off again.\n\nLocalizing a static sensor node is not a difficult task because attaching a GPS device suffices the need of localization. But a mobile sensor node, which continuously change its geographical location with time is difficult to localize. Mostly mobile sensor nodes within some particular domain for data collection can be used, \"i.e\", sensor node attached to an animal within a grazing field or attached to a soldier on a battlefield. Within these scenarios a GPS device for each sensor node cannot be afforded. Some of the reasons for this include cost, size and battery drainage of constrained sensor nodes.\nTo overcome this problem a limited number of reference nodes (with GPS) within a field is employed. These nodes continuously broadcast their locations and other nodes in proximity receive these locations and calculate their position using some mathematical technique like trilateration. For localization, at least three known reference locations are necessary to localize. Several localization algorithms based on Sequential Monte Carlo (SMC) method have been proposed in literatures. Sometimes a node at some places receives only two known locations and hence it becomes impossible to localize. To overcome this problem, dead reckoning technique is used. With this technique a sensor node uses its previous calculated location for localization at later time intervals. For example, at time instant 1 if node A calculates its position as \"loca_1\" with the help of three known reference locations; then at time instant 2 it uses \"loca_1\" along with two other reference locations received from other two reference nodes. This not only localizes a node in less time but also localizes in positions where it is difficult to get three reference locations.\n\nIn studies of animal navigation, dead reckoning is more commonly (though not exclusively) known as path integration. Animals use it to estimate their current location based on their movements from their last known location. Animals such as ants, rodents, and geese have been shown to track their locations continuously relative to a starting point and to return to it, an important skill for foragers with a fixed home.\n\nIn marine navigation a \"dead\" reckoning plot generally does not take into account the effect of currents or wind. Aboard ship a dead reckoning plot is considered important in evaluating position information and planning the movement of the vessel.\n\nDead reckoning begins with a known position, or fix, which is then advanced, mathematically or directly on the chart, by means of recorded heading, speed, and time. Speed can be determined by many methods. Before modern instrumentation, it was determined aboard ship using a chip log. More modern methods include pit log referencing engine speed (\"e.g\". in rpm) against a table of total displacement (for ships) or referencing one's indicated airspeed fed by the pressure from a pitot tube. This measurement is converted to an equivalent airspeed based upon known atmospheric conditions and measured errors in the indicated airspeed system. A naval vessel uses a device called a pit sword (rodmeter), which uses two sensors on a metal rod to measure the electromagnetic variance caused by the ship moving through water. This change is then converted to ship's speed. Distance is determined by multiplying the speed and the time. This initial position can then be adjusted resulting in an estimated position by taking into account the current (known as set and drift in marine navigation). If there is no positional information available, a new dead reckoning plot may start from an estimated position. In this case subsequent dead reckoning positions will have taken into account estimated set and drift.\n\nDead reckoning positions are calculated at predetermined intervals, and are maintained between fixes. The duration of the interval varies. Factors including one's speed made good and the nature of heading and other course changes, and the navigator's judgment determine when dead reckoning positions are calculated.\n\nBefore the 18th-century development of the marine chronometer by John Harrison and the lunar distance method, dead reckoning was the primary method of determining longitude available to mariners such as Christopher Columbus and John Cabot on their trans-Atlantic voyages. Tools such as the traverse board were developed to enable even illiterate crew members to collect the data needed for dead reckoning. Polynesian navigation, however, uses different wayfinding techniques.\n\nOn May 21, 1927 Charles Lindbergh landed in Paris, France after a successful non-stop flight from the United States in the single-engined Spirit of St. Louis. This aircraft was equipped with very basic instruments. He used dead reckoning to find his way.\n\nDead reckoning in the air is similar to dead reckoning on the sea, but slightly more complicated. The density of the air the aircraft moves through affects its performance as well as winds, weight, and power settings.\n\nThe basic formula for DR is Distance = Speed x Time. An aircraft flying at 250 knots airspeed for 2 hours has flown 500 nautical miles through the air. The wind triangle is used to calculate the effects of wind on heading and airspeed to obtain a magnetic heading to steer and the speed over the ground (groundspeed). Printed tables, formulae, or an E6B flight computer are used to calculate the effects of air density on aircraft rate of climb, rate of fuel burn, and airspeed.\n\nA course line is drawn on the aeronautical chart along with estimated positions at fixed intervals (say every ½ hour). Visual observations of ground features are used to obtain fixes. By comparing the fix and the estimated position corrections are made to the aircraft's heading and groundspeed.\n\nDead reckoning is on the curriculum for VFR (visual flight rules - or basic level) pilots worldwide. It is taught regardless of whether the aircraft has navigation aids such as GPS, ADF and VOR and is an ICAO Requirement. Many flying training schools will prevent a student from using electronic aids until they have mastered dead reckoning.\n\nInertial navigation systems (INSes), which are nearly universal on more advanced aircraft, use dead reckoning internally. The INS provides reliable navigation capability under virtually any conditions, without the need for external navigation references, although it is still prone to slight errors.\n\nDead reckoning is today implemented in some high-end automotive navigation systems in order to overcome the limitations of GPS/GNSS technology alone. Satellite microwave signals are unavailable in parking garages and tunnels, and often severely degraded in urban canyons and near trees due to blocked lines of sight to the satellites or multipath propagation. In a dead-reckoning navigation system, the car is equipped with sensors that know the wheel circumference and record wheel rotations and steering direction. These sensors are often already present in cars for other purposes (anti-lock braking system, electronic stability control) and can be read by the navigation system from the controller-area network bus. The navigation system then uses a Kalman filter to integrate the always-available sensor data with the accurate but occasionally unavailable position information from the satellite data into a combined position fix.\n\nDead reckoning is utilized in some lower-end, non mission-critical, or tightly constrained by time or weight, robotic applications. It is usually used to reduce the need for sensing technology, such as ultrasonic sensors, GPS, or placement of some linear and rotary encoders, in an autonomous robot, thus greatly reducing cost and complexity at the expense of performance and repeatability. The proper utilization of dead reckoning in this sense would be to supply a known percentage of electrical power or hydraulic pressure to the robot's drive motors over a given amount of time from a general starting point. Dead reckoning is not totally accurate, which can lead to errors in distance estimates ranging from a few millimeters (in CNC machining) to kilometers (in UAVs), based upon the duration of the run, the speed of the robot, the length of the run, and several other factors.\n\nWith the increased sensor offering in smartphones, built-in accelerometers can be used as a pedometer and built-in magnetometer as a compass heading provider. Pedestrian dead reckoning (PDR) can be used to supplement other navigation methods in a similar way to automotive navigation, or to extend navigation into areas where other navigation systems are unavailable.\n\nIn a simple implementation, the user holds their phone in front of them and each step causes position to move forward a fixed distance in the direction measured by the compass. Accuracy is limited by the sensor precision, magnetic disturbances inside structures, and unknown variables such as carrying position and stride length. Another challenge is differentiating walking from running, and recognizing movements like bicycling, climbing stairs, or riding an elevator.\n\nBefore phone-based systems existed, many custom PDR systems existed. While a pedometer can only be used to measure linear distance traveled, PDR systems have an embedded magnetometer for heading measurement. Custom PDR systems can take many forms including special boots, belts, and watches, where the variability of carrying position has been minimized to better utilize magnetometer heading. True dead reckoning is fairly complicated, as it is not only important to minimize basic drift, but also to handle different carrying scenarios and movements, as well as hardware differences across phone models.\n\nThe south-pointing chariot was an ancient Chinese device consisting of a two-wheeled horse-drawn vehicle which carried a pointer that was intended always to aim to the south, no matter how the chariot turned. The chariot pre-dated the navigational use of the magnetic compass, and could not \"detect\" the direction that was south. Instead it used a kind of directional dead reckoning: at the start of a journey, the pointer was aimed southward by hand, using local knowledge or astronomical observations e.g. of the Pole Star. Then, as it traveled, a mechanism possibly containing differential gears used the different rotational speeds of the two wheels to turn the pointer relative to the body of the chariot by the angle of turns made (subject to available mechanical accuracy), keeping the pointer aiming in its original direction, to the south. Errors, as always with dead reckoning, would accumulate as distance traveled increased.\n\nNetworked games and simulation tools routinely use dead reckoning to predict where an actor should be right now, using its last known kinematic state (position, velocity, acceleration, orientation, and angular velocity). This is primarily needed because it is impractical to send network updates at the rate that most games run, 60 Hz. The basic solution starts by projecting into the future using linear physics:\n\nThis formula is used to move the object until a new update is received over the network. At that point, the problem is that there are now two kinematic states: the currently estimated position and the just received, actual position. Resolving these two states in a believable way can be quite complex. One approach is to create a curve (ex cubic Bézier splines, centripetal Catmull–Rom splines, and Hermite curves) between the two states while still projecting into the future. Another technique is to use projective velocity blending, which is the blending of two projections (last known and current) where the current projection uses a blending between the last known and current velocity over a set time.\n\nIn computer science, dead-reckoning refers to navigating an array data structure using indexes. Since every array element has the same size, it is possible to directly access one array element by knowing any position in the array.\n\nGiven the following array:\n\nknowing the memory address where the array starts, it is easy to compute the memory address of D:\n\nLikewise, knowing D's memory address, it is easy to compute the memory address of B:\n\nThis property is particularly important for performance when used in conjunction with arrays of structures because data can be directly accessed, without going through a pointer dereference.\n\n\n"}
{"id": "13854919", "url": "https://en.wikipedia.org/wiki?curid=13854919", "title": "Deformation monitoring", "text": "Deformation monitoring\n\nDeformation monitoring (also referred to as deformation survey) is the systematic measurement and tracking of the alteration in the shape or dimensions of an object as a result of stresses induced by applied loads. Deformation monitoring is a major component of logging measured values that may be used to for further computation, deformation analysis, predictive maintenance and alarming.\n\nDeformation monitoring is primarily related to the field of applied surveying, but may be also related to civil engineering, mechanical engineering, construction, and geology. The measuring devices used for deformation monitoring depend on the application, the chosen method, and the preferred measurement interval.\n\nMeasuring devices (or sensors) can be sorted in two main groups, geodetic and geotechnical sensors. Both measuring devices can be seamlessly combined in modern deformation monitoring. \n\nDeformation monitoring can be required for the following applications:\n\nDeformation monitoring can be manual or automatic. Manual deformation monitoring is the operation of sensors or instruments by hand or manual downloading of collected data from deformation monitoring instruments such as ShapeAccelArray. Automatic deformation monitoring operation of a group of software and hardware elements for deformation monitoring that, once set up, does not require human input to function.\n\nNote that deformation analysis and interpretation of the data collected by the monitoring system is not included in this definition.\n\nAutomated deformation monitoring requires instruments to communicate with a base station. Communication methods used include:\n\nThe monitoring regularity and time interval of the measurements must be considered depending on the application and object to be monitored. Objects can undergo both rapid, high frequency movement and slow, gradual movement. For example, a bridge might oscillates with a period of a few seconds due to the influence of traffic and wind and also be shifting gradually due to tectonic changes.\n\n\nDeformation analysis is concerned with determining if a measured displacement is significant enough to warrant a response. Deformation data must be checked for statistical significance, and then checked against specified limits, and reviewed to see if movements below specified limits imply potential risks.\n\nThe software acquires data from sensors, computes meaningful values from the measurements, records results, and can notify responsible persons should threshold value be exceeded. However, a human operator must make considered decisions on the appropriate response to the movement, e.g. independent verification though on-site inspections, re-active controls such as structural repairs and emergency responses such as shut down processes, containment processes and site evacuation.\n\n\n"}
{"id": "49774665", "url": "https://en.wikipedia.org/wiki?curid=49774665", "title": "Environment and Urbanization ASIA", "text": "Environment and Urbanization ASIA\n\nEnvironment and Urbanization ASIA is a peer reviewed journal which provides information in the fields of urbanization, human settlements and the environment across Asia. It is published twice a year by SAGE Publications in association with National Institute of Urban Affairs. Its audience includes researchers, academicians, policy-makers, non-governmental organizations (NGOs), activists and students particularly in Asia.\n\n\" Environment and Urbanization Asia\" is abstracted and indexed in:\n\n"}
{"id": "21715204", "url": "https://en.wikipedia.org/wiki?curid=21715204", "title": "High water mark", "text": "High water mark\n\nA high water mark is a point that represents the maximum rise of a body of water over land. Such a mark is often the result of a flood, but high water marks may reflect an all-time high, an annual high (highest level to which water rose that year) or the high point for some other division of time. Knowledge of the high water mark for an area is useful in managing the development of that area, particularly in making preparations for flood surges. High water marks from floods have been measured for planning purposes since at least as far back as the civilizations of ancient Egypt. It is a common practice to create a physical marker indicating one or more of the highest water marks for an area, usually with a line at the level to which the water rose, and a notation of the date on which this high water mark was set. This may be a free-standing flood level sign or other marker, or it may be affixed to a building or other structure that was standing at the time of the flood that set the mark.\n\nA high water mark is not necessarily an actual physical mark, but it is possible for water rising to a high point to leave a lasting physical impression such as floodwater staining. A landscape marking left by the high water mark of ordinary tidal action may be called a strandline and is typically composed of debris left by high tide. The area at the top of a beach where debris is deposited is an example of this phenomenon. Where there are tides, this line is formed by the highest position of the tide, and moves up and down the beach on a fortnightly cycle. The debris is chiefly composed of rotting seaweed, but can also include a large amount of litter, either from ships at sea or from sewage outflows.\n\nThe strandline is an important habitat for a variety of animals. In parts of the United Kingdom, sandhoppers such as \"Talitrus saltator\" and the seaweed fly \"Coelopa frigida\" are abundant in the rotting seaweed, and these invertebrates provide food for shore birds such as the rock pipit, turnstone and pied wagtail, and mammals such as brown hares, foxes, voles and mice.\n\nOne kind of high water mark is the ordinary high water mark or average high water mark, the high water mark that can be expected to be produced by a body of water in non-flood conditions. The ordinary high water mark may have legal significance and is often being used to demarcate property boundaries. The ordinary high water mark has also been used for other legal demarcations. For example, a 1651 analysis of laws passed by the English Parliament notes that for persons granted the title Admiral of the English Seas, \"the Admirals power extended even to the high water mark, and into the main streams\".\n\nIn the United States, the high water mark is also significant because the United States Constitution gives Congress the authority to legislate for waterways, and the high water mark is used to determine the geographic extent of that authority. Federal regulations (33 CFR 328.3(e)) define the \"ordinary high water mark\" (OHWM) as \"that line on the shore established by the fluctuations of water and indicated by physical characteristics such as a clear, natural line impressed on the bank, shelving, changes in the character of soil, destruction of terrestrial vegetation, the presence of litter and debris, or other appropriate means that consider the characteristics of the surrounding areas. For the purposes of Section 404 of the Clean Water Act, the OHWM defines the lateral limits of federal jurisdiction over non-tidal water bodies in the absence of adjacent wetlands. For the purposes of Sections 9 and 10 of the Rivers and Harbors Act of 1899, the OHWM defines the lateral limits of federal jurisdiction over traditional navigable waters of the US. The OHWM is used by the United States Army Corps of Engineers, the United States Environmental Protection Agency, and other federal agencies to determine the geographical extent of their regulatory programs. Likewise, many states use similar definitions of the OHWM for the purposes of their own regulatory programs.\n\nIn 2016, the Court of Appeals of Indiana ruled that land below the OHWM (as defined by common law) along Lake Michigan is held by the state in trust for public use. \n\nIn Australia, the definition of the Mean High Water Mark is '...the line of the medium high tide between the highest tide of each\nlunar month (the springs) and the lowest each lunar month (the Neaps) averaged over the year.' (http://www.icsm.gov.au/publications/tidal_interface/compendium_full_may03.pdf)\n\n"}
{"id": "26457540", "url": "https://en.wikipedia.org/wiki?curid=26457540", "title": "International Geography Olympiad", "text": "International Geography Olympiad\n\nThe International Geography Olympiad (iGeo) is an annual competition for 16- to 19-year-old geography students from all over the world. Students chosen to represent their countries are some of the best, chosen from thousands of students who participate enthusiastically in their own National Geography Olympiads. iGeo tests the abilities of every participants in spatial patterns and processes. The iGeo consists of three parts: a written test, a multimedia test and a substantial fieldwork exercise requiring observation, leading to cartographic representation and geographical analysis. The programme also includes poster presentations by teams, cultural exchanges, and time for students to get to know their fellow students and explore the host city.\n\nThe International Geography Olympiad is organised by the International Geographical Union (IGU) Olympiad Task Force, who produce tests with reference to the local organisers and the international board.\n\nAfter the first iGeo in 1996, it was recommended that the competition was held biennially. Due to the competition growing in popularity, since 2012 the competition has been held annually, rather than biennially, as is the case with the other large International Science Olympiads.\n\nDuring the 1994 Congress of the International Geographical Union (IGU) in Prague, people from Poland and the Netherlands launched the idea of an International Geography Competition (iGeo) or Olympiad for students between 15 and 19 years of age. The first one was held in 1996 in The Hague, Netherlands, with five participating countries. The participant count grew to 24 countries with the 2008 competition in Carthage, Tunisia.\n\nBefore 2012, the International Science Olympiads were held every two years, and some regional geography Olympiads were held during intervening years. These include the Asia Pacific Regional Geography Olympiads (APRGO), which were held in 2007 (Hsinchu, Taiwan), 2009 (Tsukuba, Japan), and 2011 (Merida, Mexico), and the Central European Regional Geography Olympiads (CERIGEO). Since 2013, the International Geography Olympiad, in concordance with the other Olympiads, has been held on a yearly basis.\n\nAt the most recent iGeo, held in Quebec City, Canada between July and August 2018, there were 43 participating countries.\n\nThe next Olympiad is the 2019 iGeo, which will be held in Hong Kong, China in August 2019.\n\nThe participating countries and regions in the 2018 International Geography Olympiad are:\n\n</div>\n\nThe names used are the standard names officially used by the International Geographical Union, based on the roster list for the 2017 International Geography Olympiad in Belgrade.\n"}
{"id": "48429332", "url": "https://en.wikipedia.org/wiki?curid=48429332", "title": "Isoazimuth", "text": "Isoazimuth\n\nThe isoazimuth is the locus of the points on the Earth's surface whose initial orthodromic course with respect to a fixed point is constant.\n\nThat is, if the initial orthodromic course Z from the starting point \"S\" to the fixed point \"X\" is 80 degrees, the associated isoazimuth is formed by all points whose initial orthodromic course with respect to point \"X\" is 80° (with respect to true north). The isoazimuth is written using the notation \"isoz(X, Z)\".\n\nThe isoazimuth is of use when navigating with respect to an object of known location, such as a radio beacon. A straight line called the \"azimuth line of position\" is drawn on a map, and on most common map projections this is a close enough approximation to the isoazimuth. On the Littrow projection, the correspondence is exact. This line is then crossed with an astronomical observation called a Sumner line, and the result gives an estimate of the navigator's position.\n\nLet X be a fixed point on the Earth of coordinates latitude: B2, and longitude: L2. In a terrestrial spherical model, the equation of isoazimuth line of initial course C passing through point S(B, L) is:\nformula_1\n\nIn this case the X point is the illuminating pole of the observed star, and the angle Z is its azimuth. The equation of the \"isoazimuthal\" curve for a star with coordinates (Dec, Gha), -\"Declination\" and \"Greenwich Hour Angle\"-, observed under an azimuth Z is given by:\nwhere lha is the local hour angle, and all points with latitude B and longitude L, they define the curve.\n\n\n"}
{"id": "48504700", "url": "https://en.wikipedia.org/wiki?curid=48504700", "title": "Journal of Latin American Geography", "text": "Journal of Latin American Geography\n\nThe Journal of Latin American Geography is a triannual peer-reviewed academic journal published by the University of Texas Press on behalf of the Conference of Latin Americanist Geographers. The journal is abstracted and indexed by Scopus.\n\n"}
{"id": "40083369", "url": "https://en.wikipedia.org/wiki?curid=40083369", "title": "Land", "text": "Land\n\nLand, sometimes referred to as dry land, is the solid surface of Earth that is not permanently covered by water. The vast majority of human activity throughout history has occurred in land areas that support agriculture, habitat, and various natural resources. Some life forms (including terrestrial plants and terrestrial animals) have developed from predecessor species that lived in bodies of water.\n\nAreas where land meets large bodies of water are called coastal zones. The division between land and water is a fundamental concept to humans. The demarcation between land and water can vary by local jurisdiction and other factors. A maritime boundary is one example of a political demarcation. A variety of natural boundaries exist to help clearly define where water meets land. Solid rock landforms are easier to demarcate than marshy or swampy boundaries, where there is no clear point at which the land ends and a body of water has begun. Demarcation can further vary due to tides and weather.\n\nThe word 'land' is derived from Middle English \"land\", \"lond\" and Old English \"land\", \"lond\" (“earth, land, soil, ground; defined piece of land, territory, realm, province, district; landed property; country (not town); ridge in a ploughed field”), from Proto-Germanic \"*landą\" (“land”), and from Proto-Indo-European \"*lendʰ-\" (“land, heath”). Cognate with Scots \"land\" (“land”), West Frisian \"lân\" (“land”), Dutch \"land\" (“land”), German \"Land\" (“land, country, state”), Swedish \"land\" (“land, country, shore, territory”), Icelandic \"land\" (“land”). Non-Germanic cognates include Old Irish \"lann\" (“heath”), Welsh \"llan\" (“enclosure”), Breton \"lann\" (“heath”), Old Church Slavonic \"lędо\" from Proto-Slavic \"*lenda\" (“heath, wasteland”) and Albanian \"lëndinë\" (“heath, grassland”) from \"lëndë\" (“matter, substance”).\n\nA continuous area of land surrounded by ocean is called a \"landmass\". Although it may be most often written as one word to distinguish it from the usage \"land mass\"—the measure of land area—it is also used as two words. Landmasses include supercontinents, continents, and islands. There are four major continuous landmasses on Earth: Afro-Eurasia, the Americas, Antarctica and Australia. Land, capable of being ploughed and used to grow crops, is called arable land. A country or region may be referred to as the motherland, fatherland, or homeland of its people. Many countries and other places have names incorporating -land (e.g. New Zealand).\n\nThe earliest material found in the Solar System is dated to (billion years ago); therefore, the Earth itself must have been formed by accretion around this time. By , the primordial Earth had formed. The formation and evolution of the Solar System bodies occurred in tandem with the Sun. In theory, a solar nebula partitions a volume out of a molecular cloud by gravitational collapse, which begins to spin and flatten into a circumstellar disc, which the planets then grow out of in tandem with the star. A nebula contains gas, ice grains and dust (including primordial nuclides). In nebular theory, planetesimals commence forming as particulate matter accrues by cohesive clumping and then by gravity. The assembly of the primordial Earth proceeded for 10–.\n\nEarth's atmosphere and oceans were formed by volcanic activity and outgassing that included water vapor. The origin of the world's oceans was condensation augmented by water and ice delivered by asteroids, proto-planets, and comets. In this model, atmospheric \"greenhouse gases\" kept the oceans from freezing while the newly forming Sun was only at 70% luminosity. By , the Earth's magnetic field was established, which helped prevent the atmosphere from being stripped away by the solar wind. The atmosphere and oceans of the Earth continuously shape the land by eroding and transporting solids on the surface.\n\nThe crust, which currently forms the Earth's land, was created when the molten outer layer of the planet Earth cooled to form a solid mass as the accumulated water vapor began to act in the atmosphere. Once land became capable of supporting life, biodiversity evolved over hundreds of million years, expanding continually except when punctuated by mass extinctions.\n\nThe two models that explain land mass propose either a steady growth to the present-day forms or, more likely, a rapid growth early in Earth history followed by a long-term steady continental area. Continents formed by plate tectonics, a process ultimately driven by the continuous loss of heat from the Earth's interior. On time scales lasting hundreds of millions of years, the supercontinents have formed and broken apart three times. Roughly (million years ago), one of the earliest known supercontinents, Rodinia, began to break apart. The continents later recombined to form Pannotia, 600–, then finally Pangaea, which also broke apart .\n\n\"Land mass\" refers to the total surface area of the land of a geographical region or country (which may include discontinuous pieces of land such as islands). It is written as two words to distinguish it from the usage \"landmass\", the contiguous area of land surrounded by ocean. Earth's total land mass is approximately which is about 29.2% of its total surface. Water covers approximately 70.8% of Earth's surface, mainly in the form of oceans and ice formations.\n\nCreation myths in many religions recall a story involving the creation of the world by a supernatural deity or deities, including accounts wherein the land is separated from the oceans and the air. The Earth itself has often been personified as a deity, in particular a goddess. In many cultures, the mother goddess is also portrayed as a fertility deity. To the Aztecs, Earth was called \"Tonantzin\"—\"our mother\"; to the Incas, Earth was called \"Pachamama\"—\"mother earth\". The Chinese Earth goddess Hou Tu is similar to Gaia, the Greek goddess personifying the Earth. Bhuma Devi is the goddess of Earth in Hinduism, influenced by Graha. In Norse mythology, the Earth giantess Jörð was the mother of Thor and the daughter of Annar. Ancient Egyptian mythology is different from that of other cultures because Earth (Geb) is male and sky (Nut) is female.\n\nIn the past, there were varying levels of belief in a flat Earth. The Jewish conception of a flat earth is found in both biblical and post-biblical times.\n\nIn early Egyptian and Mesopotamian thought, the world was portrayed as a flat disk floating in the ocean. The Egyptian universe was pictured as a rectangular box with a north-south orientation and with a slightly concave surface, with Egypt in the center. A similar model is found in the Homeric account of the 8th century BC in which \"Okeanos, the personified body of water surrounding the circular surface of the Earth, is the begetter of all life and possibly of all gods.\" The biblical earth is a flat disc floating on water.\n\nThe Pyramid Texts and Coffin Texts reveal that the ancient Egyptians believed Nun (the ocean) was a circular body surrounding \"nbwt\" (a term meaning \"dry lands\" or \"islands\"), and therefore believed in a similar Ancient Near Eastern circular Earth cosmography surrounded by water.\n\nThe spherical form of the Earth was suggested by early Greek philosophers, a belief espoused by Pythagoras. Contrary to popular belief, most people in the Middle Ages did not believe the Earth was flat: this misconception is often called the \"Myth of the Flat Earth\". As evidenced by thinkers such as Thomas Aquinas, the European belief in a spherical Earth was widespread by this point in time. Prior to circumnavigation of the planet and the introduction of space flight, belief in a spherical Earth was based on observations of the secondary effects of the Earth's shape and parallels drawn with the shape of other planets.\n\nMost planets known to humans are either gaseous Jovian planets or solid terrestrial planets. Terrestrial planets include Mercury, Venus, Earth, and Mars. These inner planets have a rocky surface with metal interiors. The Jovian planets consist of Jupiter, Saturn, Uranus, and Neptune. While these planets are larger, their only land surface is a small rocky core surrounded by a large, thick atmosphere. The gas giants, Jupiter and Saturn, are thought to have surface layers composed of liquid hydrogen rather than solid land; however, their planetary geology is not well understood. The possibility of Uranus and Neptune (the ice giants) possessing hot, highly compressed, supercritical water under their thick atmospheres has been hypothesised. While their composition is still not fully understood, a 2006 study by Wiktorowicz et al. ruled out the possibility of such a water \"ocean\" existing on Neptune, though some studies have suggested that exotic oceans of liquid diamond are possible. The entire surface of a rocky planet or moon is considered land, even with a lack of seas or oceans for contrast. Planetary bodies that have a thin atmosphere often have land that is marked by impact craters since atmospheric conditions would normally break-down incoming objects and erode rough impact sites. Land on planetary bodies other than Earth can also be bought and sold although ownership of extraterrestrial real estate is not recognized by any authority.\n\nThe land of the Earth interacts with and influences climate heavily since the surface of the land heats up and cools down faster than air or water. Latitude, elevation, topography, reflectivity, and land use all have varying effects. The latitude of the land will influence how much solar radiation reaches the surface. High latitudes receive less solar radiation than low latitudes. The height of the land is important in creating and transforming airflow and precipitation on Earth. Large landforms, such as mountain ranges, divert wind energy and make the air parcel less dense and able to hold less heat. As air rises, this cooling effect causes condensation and precipitation. Reflectivity of the earth is called planetary albedo and the type of land cover that receives energy from the sun affects the amount of energy that is reflected or transferred to Earth. Vegetation has a relatively low albedo meaning that vegetated surfaces are good absorbers of the sun’s energy. Forests have an albedo of 10–15% while grasslands have an albedo of 15–20%. In comparison, sandy deserts have an albedo of 25–40%. Land use by humans also plays a role in the regional and global climate. Densely populated cities are warmer and create urban heat islands that have effects on the precipitation, cloud cover, and temperature of the region.\n\n"}
{"id": "19058442", "url": "https://en.wikipedia.org/wiki?curid=19058442", "title": "Landscape mythology", "text": "Landscape mythology\n\nLandscape mythology and anthropology of landscape (\"Landschaftsmythologie\", \"Landschaftsethnologie\") are terms for a field of study advocated since about 1990 by Kurt Derungs (born 1962 in St. Gallen, Switzerland). Derungs describes the field as an interdisciplinary approach to landscape combining archaeology, ethnology and mythology. \n\nDerungs interprets landscape features in terms of \"totemism, shamanism and matriarchal mythology\", claiming that his approach qualifies as neither esotericism nor as positivism but as a \"sound alternative\" to both. His interpretations are strongly influenced by the hypothesis of a matriarchal structure of society and a cult of the Great Goddess in Neolithic Europe, and he associates megalithic monuments and elements of traditional fairy tales with these ideas.\n\nSince 1994, Derungs manages the \"edition amalia\" publishing house, where his books appear besides publications on related topics (matriarchy, Great Goddess) by other authors. Derungs is popular in German Neopagan circles, but has received little attention in academic literature.\n\n\n\n"}
{"id": "5304865", "url": "https://en.wikipedia.org/wiki?curid=5304865", "title": "List of countries by northernmost point", "text": "List of countries by northernmost point\n\nThis is a list of countries by northernmost point on land. Where borders are contested, the northernmost point under the control of a nation is listed. A selection of dependent territories are listed in italics and are not ranked.\n"}
{"id": "43807462", "url": "https://en.wikipedia.org/wiki?curid=43807462", "title": "List of international prime ministerial trips made by Narendra Modi", "text": "List of international prime ministerial trips made by Narendra Modi\n\nThe following is a list of international prime ministerial trips made by Narendra Modi since he became the Prime Minister of India following the Indian general election, 2014.\nAs of , Narendra Modi has made 41 foreign trips on six continents, visiting 59 countries including the visits to USA to attend UN general assembly, to Asian countries, following his \"neighbourhood first\" and \"act east\" policies.\n\nPotential upcoming foreign visits for Prime Minister Narendra Modi.\n\n\n"}
{"id": "51104499", "url": "https://en.wikipedia.org/wiki?curid=51104499", "title": "List of international prime ministerial trips made by Theresa May", "text": "List of international prime ministerial trips made by Theresa May\n\nThis is a list of international prime ministerial trips made by Theresa May, the current Prime Minister of the United Kingdom. As of , Theresa May has made 60 trips to 32 countries since her premiership began on 13 July 2016.\n\nThe number of visits per country: \n\nThe following international trips are scheduled to be made by Theresa May during 2018:\n\nThe following international trips are scheduled to be made by Theresa May during 2019:\nTheresa May participated in the following summits during her premiership:\n\n"}
{"id": "9875604", "url": "https://en.wikipedia.org/wiki?curid=9875604", "title": "List of marches", "text": "List of marches\n\nThis is a list of European medieval marches.\n\nAt the beginning of his rule as king of Germany, Otto I tried to reorganize his realm to prepare an expansion to the East. At the beginning of the year 937, he created two marches: the March of the Billungen, given to Hermann Billung, later Duke of Saxony; and the Eastern march, given to Gero. In 961, when Billung became Duke of Saxony, his March was merged with the duchy. In the case of Gero, Otto I, now emperor, decided the division of his territories, greatly expanded since 937.\n\n\nIn 861, Charles the Bald, king of France, created two marches to protect his realm from warriors coming from Brittany and Normandy. Both were named March of Neustria, but will be known as March of Brittany and March of Normandy. In 863, the king created the March of Flanders.\n\n\nThree marches belonging to the Holy Roman Empire were created in the Low Countries:\n\n\n\n\n\n"}
{"id": "19152401", "url": "https://en.wikipedia.org/wiki?curid=19152401", "title": "List of political and geographic subdivisions by total area from 3,000 to 5,000 square kilometers", "text": "List of political and geographic subdivisions by total area from 3,000 to 5,000 square kilometers\n"}
{"id": "18596832", "url": "https://en.wikipedia.org/wiki?curid=18596832", "title": "List of political and geographic subdivisions by total area in excess of 1,000,000 square kilometers", "text": "List of political and geographic subdivisions by total area in excess of 1,000,000 square kilometers\n"}
{"id": "3710289", "url": "https://en.wikipedia.org/wiki?curid=3710289", "title": "List of popular place names", "text": "List of popular place names\n\nThis List of popular place names is derived from the US FIPS55 place name database (158,000 US place names) and the US GEOnet name server database (5.6 million non-US place names).\n\n\nThe data files were fetched on January 1, 2006.\n\n"}
{"id": "30471614", "url": "https://en.wikipedia.org/wiki?curid=30471614", "title": "List of presidential trips made by Barack Obama during 2011", "text": "List of presidential trips made by Barack Obama during 2011\n\nThis is a list of presidential trips made by Barack Obama during 2011, the third year of his presidency as the 44th President of the United States.\n\nThis list excludes trips made within Washington, D.C., the U.S. federal capital in which the White House, the official residence and principal workplace of the President, is located. Additionally excluded are trips to Camp David, the country residence of the President, and to the private home of the Obama family in Kenwood, Chicago, Illinois.\n"}
{"id": "46306107", "url": "https://en.wikipedia.org/wiki?curid=46306107", "title": "List of presidential trips made by Barack Obama during 2014", "text": "List of presidential trips made by Barack Obama during 2014\n\nThis is a list of presidential trips made by Barack Obama during 2014, the sixth year of his presidency as the 44th President of the United States.\n\nThis list excludes trips made within Washington, D.C., the U.S. federal capital in which the White House, the official residence and principal workplace of the President, is located. Additionally excluded are trips to Camp David, the country residence of the President, and to the private home of the Obama family in Kenwood, Chicago.\n"}
{"id": "20914874", "url": "https://en.wikipedia.org/wiki?curid=20914874", "title": "List of time zones by country", "text": "List of time zones by country\n\nThis is a list representing time zones by country. Countries are ranked by total number of time zones on their territory. Time zones of a country include that of dependent territories (except Antarctic claims). France, including its overseas territories, has the most time zones with 13. Many countries have daylight saving time, one added hour during the local summer, but this list does not include that information. The UTC offset in the list is not valid in practice during daylight saving time.\n\n"}
{"id": "11485898", "url": "https://en.wikipedia.org/wiki?curid=11485898", "title": "List of towns and cities with 100,000 or more inhabitants/cityname: D", "text": "List of towns and cities with 100,000 or more inhabitants/cityname: D\n\n\n"}
{"id": "11486186", "url": "https://en.wikipedia.org/wiki?curid=11486186", "title": "List of towns and cities with 100,000 or more inhabitants/cityname: S", "text": "List of towns and cities with 100,000 or more inhabitants/cityname: S\n\n\n"}
{"id": "11486239", "url": "https://en.wikipedia.org/wiki?curid=11486239", "title": "List of towns and cities with 100,000 or more inhabitants/cityname: W", "text": "List of towns and cities with 100,000 or more inhabitants/cityname: W\n\n\n"}
{"id": "11485569", "url": "https://en.wikipedia.org/wiki?curid=11485569", "title": "List of towns and cities with 100,000 or more inhabitants/country: L-M-N-O", "text": "List of towns and cities with 100,000 or more inhabitants/country: L-M-N-O\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "286960", "url": "https://en.wikipedia.org/wiki?curid=286960", "title": "Mainland", "text": "Mainland\n\nMainland is a contiguous landmass that is larger and often politically, economically and/or demographically more significant than politically associated remote territories, such as exclaves or oceanic islands situated outside the continental shelf. \n\nIn geography, \"mainland\" can denote the continental (i.e. non-insular) part of any polity or the main island within an island nation. In geopolitics, \"mainland\" is sometimes used interchangeably with terms like Metropole as an antonym to overseas territories. In the sense of \"heartland\", mainland is the opposite of periphery.\n\nThe term is relative- in Tasmania, continental Australia is the mainland, while to residents of Flinders Island, the main island of Tasmania is also \"the mainland\".\n\n\n"}
{"id": "1251426", "url": "https://en.wikipedia.org/wiki?curid=1251426", "title": "Microsoft Research Maps", "text": "Microsoft Research Maps\n\nMicrosoft Research Maps or MSR Maps was a free online repository of public domain aerial imagery and topographic maps provided by the U.S. Geological Survey (USGS). The site was a collaboration between Microsoft Research (MSR), Bing Maps, and the USGS. It had been in operation since June 1998. It had 30,000 to 50,000 visitors per day as of January 2010. The site was renamed in 2010, prior to which it had been known as TerraServer-USA (formerly Microsoft TerraServer).\n\nThe site had black and white USGS aerial photographs of approximately 97% of the United States. In 2000, the USGS launched the new Urban Areas program, which will ultimately take high-resolution color aerial photographs of about 100 major American cities. MSR Maps had Urban Areas data for 40 cities.\n\nMicrosoft had announced that the MSR Maps web site was going to permanently close on May 1, 2012, but later changed that decision based on requests from users of the site. As of March 2016 the site is no longer available.\n\nThough it was online as early as December 1997, the site was formally unveiled June 24, 1998, as part of an 18-month agreement between Microsoft, Compaq, and Aerial Images of Raleigh, North Carolina. It was created as a demonstration system to advertise the scalability of Microsoft's Windows NT Server and SQL Server, and used images from the United States Geological Survey (USGS) and Sovinformsputnik (the Russian Federal Space Agency).\n\nTerraServer was the brainchild of the Turing Award-winning researcher on database systems, Jim Gray. Before his death, Gray continued this work, developing Microsoft Virtual Earth and began a similar project that would become the Worldwide Telescope.\n\nIn January 2000, Microsoft and Aerial Images, now TerraServer.com, Inc., split their operations, creating two parallel TerraServer websites. The dualism caused confusion among web surfers until the Microsoft name change in 2010. TerraServer.com, Inc., which owns the trademark TERRASERVER, filed a lawsuit in 2008 in North Carolina federal court, seeking monetary damages and asking that Microsoft be stopped from using the TerraServer trademark.\n\nThe TerraServer name was a play on words, with 'Terra' referring to the 'earth' or 'land' and also to the terabytes of images stored on the site.\n\n\n"}
{"id": "7693731", "url": "https://en.wikipedia.org/wiki?curid=7693731", "title": "NavPix", "text": "NavPix\n\nNavPix is the proprietary name applied by Navman to its technology that combines an image with geographical data.\n\nThe \"NavPix\" name is used for both the software and the geo-referenced image that results from that software.\n\nThe NavPix technology enables users to take a JPEG image using the integrated digital camera on the N Series (\"N\" for NavPix), iCN 720 or iCN 750 portable Navman GPS navigation devices.\n\nThe Navman's GPS (Global Positioning System) receiver determines the latitude and longitude of where that image was taken. That information is then written into the image's Exif (Exchangeable image file format) meta data by the NavPix software. The NavPix, therefore, effectively provides a Georeference of the location where the image was taken, which is not necessarily the same georeference as the object being \"NavPix-ed\".\n\nThe NavPix image can then be used to define a destination or point of interest on compatible Navman devices.\n\nFurthermore, as the geographical information is written to the meta data, the image itself can be shared between compatible devices or uploaded to Navman's NavPix Library which offers a wide range of NavPix images that have been taken by both Navman users and sourced from professional photo providers, including Lonely Planet.\n\nThe NavPix Library also enables people to upload non-NavPix images (including other formats such as GIF) and convert them to NavPix images by using entering either the latitude and longitude they want to associate with the image or by entering the address and using the Library's software to generate the latitude and longitude values based on a Postal code look-up.\n\nUnlike some geo-referencing applications, the NavPix Library writes the georeference values to the image itself via the Exif meta data.\n\nThe photo taking abilities do not help navigation.\n\n\n"}
{"id": "7621464", "url": "https://en.wikipedia.org/wiki?curid=7621464", "title": "North Pacific Exploring and Surveying Expedition", "text": "North Pacific Exploring and Surveying Expedition\n\nThe North Pacific Exploring and Surveying Expedition, also known as the Rodgers-Ringgold Expedition was a United States scientific and exploring project from 1853 to 1856. \n\nCommander Cadwalader Ringgold (1802–1867) led the expedition until he was relieved of command in Hong Kong by a commission convened by Commodore Matthew Perry. Lt. John Rodgers (1812–1882) then commanded the expedition until its conclusion.\n\nRinggold sailed on USS \"Porpoise\", a ship he had commanded during the U.S. Exploring Expedition years before. USS \"John Hancock\", commanded by Lt. John Rodgers and three other vessels including USS \"Vincennes\" would be the other vessels in the expedition.\n\n\"Porpoise\" joined the squadron at Hampton Roads, and with it, stood out to sea 11 June 1853. After stopping at Funchal, Madeira Islands; Porto Praya; and Simonstown, False Bay; the expedition arrived Batavia, Java, 12 December and in China in March 1854. \n\nFive months were devoted to surveying the waters surrounding the large islands off the coast of Southeast Asia. Early in May 1854, \"John Hancock\", with Rodgers commanding, departed for Hong Kong, where she arrived 24 May. The squadron operated from that port as its base throughout the summer, surveying nearby coasts, islands and rivers. At this time China was plagued by rebellion and pirates endangering foreigners and threatening their property. The American ships helped protect American citizens and interests. While steaming up the Canton River, two armed boats from \"John Hancock\" were fired upon by rebel batteries, which \"Hancock\"'s cannon promptly silenced.\n\nIn July 1854, Ringgold became sick with malaria and was sent home, according to at least one source. However, Nathaniel Philbrick, in his book \"Sea of Glory\" about the U.S. Exploring Expedition, writes that in the later expedition Ringgold \"began to act strangely\" once in China, keeping his ships in port \"ceaselessly repairing his vessels\". Commodore Perry, on his own expedition, sailed in and convened an official panel which relieved Ringgold from command of the expedition and sent him home. Philbrick quotes Perry as declaring Ringgold \"insane.\" John Rodgers was given full command of the expedition and completed it.\n\nThe squadron headed north along the coast as far as the Bering Sea, surveying as it went.\nThe squadron at that time also explored islands well off the coast of Asia, including the Bonins, the Ladrones, and the Marianas. \"Porpoise\" parted company with the other vessels 21 September 1854 between Formosa and China, and was never heard from again. It is supposed that she foundered in a heavy typhoon which occurred a few days after her separation from the squadron.\n\nAt the Bering sea, the expedition turned south along the western coast of North America. In March 1856, the expedition arrived at Puget Sound to help suppress Indian uprisings which threatened to wipe out white settlements and Army outposts established in the early 1850s.\n\nBesides greatly increasing knowledge of the western and northern Pacific, stimulating commerce, and easing navigation in previously unknown seas, the expedition has been credited with helping to establish friendly relations between the United States and several nations of East Asia.\n"}
{"id": "22520", "url": "https://en.wikipedia.org/wiki?curid=22520", "title": "Orienteering", "text": "Orienteering\n\nOrienteering is a group of sports that requires navigational skills using a map and compass to navigate from point to point in diverse and usually unfamiliar terrain whilst moving at speed. Participants are given a topographical map, usually a specially prepared orienteering map, which they use to find control points. Originally a training exercise in land navigation for military officers, orienteering has developed many variations. Among these, the oldest and the most popular is foot orienteering. For the purposes of this article, foot orienteering serves as a point of departure for discussion of all other variations, but almost any sport that involves racing against a clock and requires navigation with a map is a type of orienteering.\nOrienteering is included in the programs of world sporting events including the World Games (see Orienteering at the World Games) and World Police and Fire Games.\n\nOrienteering sports combine significant navigation with a specific method of travel. Because the method of travel determines the needed equipment and tactics, each sport requires specific rules for competition and guidelines for orienteering event logistics and course design.\n\nInternational Orienteering Federation, the governing body of the sport, currently sanctions the following four disciplines as official disciplines in the sport of orienteering:\n\nMoreover, International Amateur Radio Union (IARU) sanctions the following orienteering sport:\n\nOther orienteering disciplines include, but are not limited to:\n\nAdventure racing is a combination of two or more disciplines, and usually includes orienteering as part of the race.\n\nAt international level, the International Orienteering Federation (IOF) defines rules and guidelines which govern four orienteering sports: foot orienteering, mountain bike orienteering, ski orienteering, and trail orienteering. It is based in Finland and it claims on its website to aim to \"spread the sport of orienteering, to promote its development and to create and maintain an attractive world event programme.\" Since 1977 the IOF has been recognised by the IOC\n\nThere are governing bodies for most of the individual nations that are represented in the sport of orienteering. These national bodies are the rule-making body for that nation. For example, the British Orienteering Federation is the national governing body for the United Kingdom. The federation was founded in 1967 and it is made up of 13 constituent associations. For the United States, the national governing body is Orienteering USA.\n\nMost nations have some form of regional governing bodies. These are not rule-making bodies but are there to assist in coordinating clubs within that region, e.g., they may allocate dates so that clubs do not clash with their events.\n\nClubs are usually formed at a local level and affiliated to their national governing body. It is clubs who put on events usually open to all-comers. Clubs may also put on practice, training, and social events.\nOpen clubs are open to anyone and there is usually no restriction on joining them.\nClosed clubs restrict their membership to specific groups. For example, BAOC (British Army Orienteering Club) has restrictions on who may join, principally British Army personnel.\n\n\nOrienteering terms vary within English speaking countries, and in other countries where English is the de facto international language of orienteering. Variations are set out in table below.\n\nThe history of orienteering begins in the late 19th century in Sweden, the actual term \"orientering\" (the original Swedish name for orienteering, lit. \"orientation\") was first used in 1886 and meant the crossing of unknown land with the aid of a map and a compass. In Sweden, orienteering grew from military training in land navigation into a competitive sport for military officers, then for civilians. The name is derived from a word root meaning to find the direction or location. The first orienteering competition open to the public was held in Norway in 1897.\n\nFrom the beginning, locations selected for orienteering have been chosen in part for their beauty, natural or man-made. For the first public orienteering competition in Sweden, in 1901, control points included two historic churches, Spånga kyrka and Bromma kyrka (a round church).\nWith the invention of inexpensive yet reliable compasses, the sport gained popularity during the 1930s. By 1934, over a quarter million Swedes were participants, and orienteering had spread to Finland, Switzerland, the Soviet Union, and Hungary. Following World War II, orienteering spread throughout Europe and to Asia, North America and Oceania. In Sweden in 1959, an international orienteering conference was held. Representatives from 12 countries (Austria, Bulgaria, Czechoslovakia, Denmark, Finland, East and West Germany, Hungary, Norway, Sweden, Switzerland, Yugoslavia) participated. In 1961, orienteering organizations representing 10 European nations founded the International Orienteering Federation (IOF). Since then, IOF has supported the founding of many national orienteering federations. By 2010, 71 national orienteering federations were member societies of the International Orienteering Federation. These federations enabled the development of national and world championships. World championships were held every two years until 2003, then every year.\n\nThroughout this time, orienteering has remained most popular in Scandinavia. There, the two oldest recurring orienteering meets have been held since the 1940s (Jukola relay and Tiomila), and the single largest orienteering meet has been held every year since 1965 and attracts around 15,000 competitors (O-Ringen).\n\nTypically, orienteering is run in wild terrain. In its Scandinavian origins, this typically meant in the forest, but orienteering in open fell, heathland, moorland and other mixed terrain is also common. Orienteering in towns has been common for many years. Street-O has typically been a low-key affair; score events, often at night, normally as informal training events. The Venice street-O is notable for attracting a large international participation. With Park World Tour races and other (e.g. World championships) elite sprint races often being held in urban areas, and the development of a map specification for urban areas (ISSOM), from the mid-2000s, Street-O has been rebranded as urban orienteering, and has taken itself rather more seriously, with full colour maps and electronic punching, and may now be regarded as a serious competition with inclusion in national ranking lists. Such urban races are often much longer than the sprint distance.\n\nThe competition, or race, is intended to test the navigational skill, concentration, and running ability of the competitors. High levels of fitness and running speed are required to compete successfully at an international or elite level. To ensure fairness between competitors the map is not usually provided until the start, and starts are normally staggered with competitors starting at not less than one-minute intervals.\n\nThe objective on each leg is to follow the fastest route between controls. The fastest is not always the shortest route, and can depend heavily on route choice.\n\nOrienteering competitions use specially prepared orienteering maps. They are topographic maps although much more detailed than general-purpose maps. The ISOM map scales are 1:15,000 or 1:10,000, with grids aligned to magnetic north. Map symbols are standardized by the IOF, and designed to be readable by any competitor regardless of background or native tongue.\n\nOrienteering events offer a range of courses, of varying physical and technical difficulty, to meet the needs of competitors. The orienteering course is marked in purple or red on a map. A triangle is used to indicate the start and a double circle indicates the finish. Circles are used to show the control points.\n\nAt international, national, and the larger events, courses are classified by age, e.g., M35 for men 35 years of age and older. Classes requiring similar distances and difficulties are usually combined into a smaller number of courses, e.g., M60 will normally share a course with W50, and often with M65 and W55. The results are normally arranged by class.\n\nIn the smaller events courses are provided by ability. The United States and the United Kingdom use colour coding to define the difficulty of the courses. Short, easy courses are provided for beginners and younger competitors, with technically and physically demanding courses being provided for experienced orienteers.\n\nSome orienteering clubs have set up permanent courses, which can be used for personal, or club, training. Non-standard permanent markers are used as control kites, and maps of the courses are usually available publicly for a fee. The courses are usually set up in public areas and there may be some restrictions on access, e.g., daylight hours only. Clubs also organise informal events for practice and training.\n\nControl points are placed on features on the map that can be clearly identified on the ground. Control points are marked in the terrain by white and orange \"flags\".\n\nCompetitors receive a \"control description sheet\" or \"clue sheet\" which gives a precise description of the feature and the location of the kite, e.g., boulder, 5m, north side. For experienced orienteers the descriptions use symbols (pictorial), in accordance with the \"IOF Control descriptions\".\n\nEach competitor is required to carry an electronic or paper control card, and to present it at the Start and hand it in at the Finish. The control card is marked by some means at each control point to show that the competitor has completed the course correctly. Most events now use electronic punching, although cards and needle punches are still widely used.\n\nThe winner is normally the competitor with the fastest time, but other scoring systems can be used, e.g., score events and Trail-O. Most events produce provisional results 'on the day', with draft results on the Internet that night; the final results being confirmed a few days later. With electronic punching the results can include \"split times\" for competitors. These show the times between controls and aggregate times to each control. With suitable computer software these times can be displayed in a graphical form (Progressograph).\n\nEach competitor is responsible for his or her own safety. There are no rules, but there are guidelines, which should be followed. The basic safety check was the \"stub check\". The competitor hands in his stub at the start and his control card at the finish. Event officials match the two and any unmatched stubs represent a missing competitor. This has been superseded with electronic punching in that event officials can now request a ‘still to finish’ report listing all those competitors who punched at the start but have not yet downloaded their electronic card. All competitors must report to the finish whether they have completed the course or not.\n\nIOF rule 21.1 is that the specification for clothing is delegated to the national organising body, and no specific clothing is required. UK rule 7.1.1 requires \"full body cover\": the torso and legs must be covered. The organiser may allow shorts, e.g., in park or street orienteering. In the United States, rule A.34.1 states that competitors are free to choose clothing that they are most comfortable in (full leg cover is \"not\" required), unless specifically stated in the meet announcement.\n\nThe early competitors used standard athletic clothing, i.e., shorts and an athletic vest, which provided little protection for racing through undergrowth. Purpose-made lightweight nylon full-body suits were later adopted. The early \"O-suits\" were made in muted colours but modern suits are generally multi-coloured. Clubs often organise the bulk purchase of clothing, which are then made in the club colours with the club’s name prominently displayed. Some competitors prefer lycra tights or leggings. Gaiters are also often worn. Lightweight studded (and often cleated) orienteering shoes are commonly used.\n\nThe basic equipment required for orienteering is usually listed as a compass and appropriate outdoor clothing. Most national bodies recommend that a whistle be carried for safety.\n\nCompetitive orienteers usually use specialized equipment:\n\nOrienteering events can be classified in many different aspects:\n\n\nClassic orienteering involves a race between controls in a preset order. The winner is the person who completes the course in the shortest time. This is called a \"cross-country\" course as distinct from a score course (see below). Courses are normally designed so that the fastest route is not straightforward to find on the map, or to follow on the ground. The classic race has a typical winning time of 75–90 minutes. As of 2007, the IOF have dictated that the \"classic\" course should be redesignated the \"long\".\n\nThe middle distance is a shorter cross-country race than the classic (or long), with a winning time in the region of 30 minutes and with an emphasis more on fine navigation than route-choice. When races of this distance were run in the mid-late 1990s, they were called \"short\" races, or \"sprint-O\". The short distance was introduced as a world championship discipline in 1991. More recently, though the IOF have renamed this distance as \"middle\".\n\nA relay race is run by a team of competitors each running a course, and the result is based on the team's total time. Relays usually employ a mass start instead of a staggered start. Relays are part of World Orienteering Championships both as sprint relays and as cross-country relays. Additionally, there are popular mass club races out of which Jukola relay has the highest number of participating clubs 1,787 (in 2015), while 25-manna has the highest number of legs 25. To reduce competitors following each other, various spreading methods might be used. This is called \"gaffling\", which is a Swedish word meaning \"forking\". The key principle is that every team must run every leg (between each pair of two controls), but not necessarily in the same order. The IOF have introduced the nomenclature to try to clarify the usage of the word \"leg\". In orienteering usage, leg normally refers to the part of a race between two control points. In relay (non-orienteering) usage, leg refers to the part of a race run by a single team member. The IOF prefer \"lap\" for this latter term, but despite this, in common parlance, \"leg\" is used for both terms.\n\nCompetitors visit as many controls as possible within a time limit. There is usually a mass start (rather than staggered), with a time limit. Controls may have different point values depending on difficulty, and there is a point penalty for each minute late. The competitor with the most points is the winner.\nThe large-scale, endurance-style version of a Score-O is known as a rogaine, competed by teams in events lasting (often) 24 hours. A very large area is used for competition, and the map scale is smaller. The format originated in Australia. The term ROGAINE is often said to stand for Rugged Outdoor Group Activity Involving Navigation and Endurance; this is essentially a backronym, as the name actually originates from the names of Rod, Gail and Neil Phillips, who were among Australian Rogaining's first participants.\n\nVery short races, with winning times in the region of 12–15 minutes, often held in city parks and other more urban settings. Map scales are usually 1:5,000 or 1:4,000. Control sites can include benches, litterbins, sculptures, and other objects common to urban parks. The sprint distance may also be held in the forest, when it would be called a \"forest sprint\" as opposed to an \"urban sprint\". This distance was pioneered in the late 1990s as an elite event by the Park World Tour organisation who organised an independent \"world cup\" in park sprint orienteering. In 2001 in Tampere, the IOF included a sprint distance in the orienteering world championships.\n\nUltrasprint events are held in a specially constructed labyrinth. Due to the limited area of the labyrinth, ultrasprint is a more spectator-friendly form of orienteering. Also, as the course is artificial, identical courses can be set in different geographical locations for simultaneous local competitions as parts of a larger tournament.\n\nCompetitors use a headlamp to navigate in the dark. Reflective markers often are used on control point flags, which shifts the tactics from precision navigation to searching. Competitors can travel at high speed to the vicinity of the control point, then sweep the area with the light to catch a reflection off the control flag. If a night event starts before dark, a mass start must be used so all competitors have equal time in the light and dark. The two classic club relays, Tiomila and Jukola, both include night legs. Full length (24-hour) rogaines and many adventure races run through the night, without a light period, and competitors may choose not to rest.\n\nCompetitors follow a string around a short course, noting down things that they find on the way. This is generally used by young children and people new to the sport who want to find out what it is like.\n\nPrecision orienteering generally is not a speed event, but rather a test of the competitors' ability to precisely match map and terrain. Examples include trail-O (untimed), TREC style mounted orienteering, and Radio Orienteering in a Compact Area (ROCA). Both trail-O and ROCA use decoys in the vicinity of the control point.\n\nEfforts begun in 1996 to promote the inclusion of orienteering in the Olympic Games have so far been unsuccessful, although orienteering became a sport in the World Games in 2001, and is a sport in the Summer Deaflympics. Supporters recognize that the sport is neither television- nor spectator-friendly, the venue of competition is often necessarily remote from major cities, and the duration of the event is longer than most other individual competitions. Efforts to develop a format suitable for Olympic competitions have focused on park orienteering, micro-orienteering, and short-distance relays. Sprint Orienteering on foot as a format of the sport is most likely to be included in Olympic Games, as this discipline is becoming more and more popular worldwide and can have a significant spectator interest. According to the website of a Chicago Orienteering club, \"the International Orienteering Federation is committed to entering the Olympic World.\"\n\nAlthough not an official demonstration sport, an international ski-orienteering event was held in Sugadaira Kōgen, Japan, as part of the International Cultural Festival held in conjunction with the XVIII Winter Olympic Games in Nagano in 1998. The International Orienteering Federation petitioned the International Olympic Committee in 2002 to include ski orienteering in the 2006 Winter Olympic Games, noting that it could share the venue with the biathlon competitions. In its formal recommendation that ski orienteering not be included in those games, the Olympic Programme Commission focused on a lack of participation in the sport outside Nordic countries, \"the challenges for broadcasters and spectators to easily follow the competition\", and the costs associated with new technology and a new results system. In 2005, the International Olympic Committee confirmed that ski orienteering was under consideration for inclusion in the review process of the Olympic sport program for the 2014 Winter Olympic Games. On 28 November 2006, the Executive Board of the IOC decided not to include any new sports in this review process.\n\nAs determined by the Olympic-style Gold First rankings method, applied to medals won at the World Orienteering Championships (the major international championships for Foot Orienteering). \n\n, Europe has been dominant. \n\n"}
{"id": "153095", "url": "https://en.wikipedia.org/wiki?curid=153095", "title": "Radio navigation", "text": "Radio navigation\n\nRadio navigation or radionavigation is the application of radio frequencies to determine a position of an object on the Earth. Like radiolocation, it is a type of radiodetermination.\n\nThe basic principles are measurements from/to electric beacons, especially\n\nThese systems used some form of directional radio antenna to determine the location of a broadcast station on the ground. Conventional navigation techniques are then used to take a radio fix. These were introduced prior to World War I, and remain in use today.\n\nThe first system of radio navigation was the \"Radio Direction Finder\", or RDF. By tuning in a radio station and then using a directional antenna, one could determine the direction to the broadcasting antenna. A second measurement using another station was then taken. Using triangulation, the two directions can be plotted on a map where their intersection reveals the location of the navigator. Commercial AM radio stations can be used for this task due to their long range and high power, but strings of low-power radio beacons were also set up specifically for this task, especially near airports and harbours.\n\nEarly RDF systems normally used a loop antenna, a small loop of metal wire that is mounted so it can be rotated around a vertical axis. At most angles the loop has a fairly flat reception pattern, but when it is aligned perpendicular to the station the signal received on one side of the loop cancels the signal in the other, producing a sharp drop in reception known as the \"null\". By rotating the loop and looking for the angle of the null, the relative bearing of the station can be determined. Loop antennas can be seen on most pre-1950s aircraft and ships.\n\nThe main problem with RDF is that it required a special antenna on the vehicle, which may not be easy to mount on smaller vehicles or single-crew aircraft. A smaller problem is that the accuracy of the system is based to a degree on the size of the antenna, but larger antennas would likewise make the installation more difficult.\n\nDuring the era between World War I and World War II, a number of systems were introduced that placed the rotating antenna on the ground. As the antenna rotated through a fixed position, typically due north, the antenna was keyed with the morse code signal of the station's identification letters so the receiver could ensure they were listening to the right station. Then they waited for the signal to either peak or disappear as the antenna briefly pointed in their direction. By timing the delay between the morse signal and the peak/null, then dividing by the known rotational rate of the station, the bearing of the station could be calculated.\n\nThe first such system was the German Telefunken Kompass Sender, which began operations in 1907 and was used operationally by the Zeppelin fleet until 1918. An improved version was introduced by the UK as the Orfordness Beacon in 1929 and used until the mid-1930s. A number of improved versions followed, replacing the mechanical motion of the antennas with phasing techniques that produced the same output pattern with no moving parts. One of the longest lasting examples was Sonne, which went into operation just before World War II and was used operationally under the name Consol until 1991. The modern VOR system is based on the same principles (see below).\n\nA great advance in the RDF technique was introduced in the form of phase comparisons of a signal as measured on two or more small antennas, or a single highly directional solenoid. These receivers were dramatically smaller, more accurate, and simpler to operate. Combined with the introduction of the transistor and integrated circuit, RDF systems were so reduced in size and complexity that they once again became quite common during the 1960s, and were known by the new name, automatic direction finder, or ADF.\n\nThis also led to a revival in the operation of simple radio beacons for use with these RDF systems, now referred to as \"non-directional beacons\" (NDB). As the LF/MF signals used by NDBs can follow the curvature of earth, NDB has a much greater range than VOR which travels only in \"line of sight\". NDB can be categorized as \"long range\" or \"short range\" depending on their power. The frequency band allotted to non-directional beacons is 190–1750 kHz, but the same system can be used with any common AM-band commercial station.\n\nVHF omnidirectional range, or VOR, is an implementation of the reverse-RDF system, but one that is more accurate and able to be completely automated.\n\nInstead of a single signal, the VOR transmitter sends out three signals – one is a simple voice channel that sends morse code to identify the station, another is a continuous signal sent in all directions, and the last is a signal that is rotated at 30 RPM. Like the Orfordness concept, the bearing of the station is measured by finding the rotating signal's peak or null. But instead of timing the signal, the rotating signal is changed in phase in synchronicity with its rotation, such that it is in-phase when pointed north, 90 degrees off when it points east, and so forth. By comparing the phase of the received signal with the one being broadcast omnidirectionally, the angle can be determined using simple electronics. This angle is then displayed in the cockpit of the aircraft, and can be used to take a fix just like the earlier RDF systems, although it is easier to use.\n\nAs VOR required two VHF receivers as well as a conventional radio for station identification, the system did not become popular until the era of miniaturized electronics, first with small tubes in the 1950s, and then transistorized systems in the 1960s. During this period it quickly took over from the older Radio Range system (see below). The signals from the stations could be received anywhere, as opposed to the beams which were only broadcast in certain directions, so in theory the VOR system could be used for free navigation from any to any point. In practice, the older Radio Range procedures were so widely used and standardized that VOR was used to produce a similar set of airways that remain in use today.\n\nThe US military also introduced a VOR-like system known as TACAN. It differed from VOR primarily in its modulation system, adding a Lorentz-like signal to accurately define the center of the rotating beam and thereby improve accuracy. It requires five receiver channels and additional electronics, an expensive requirement when it was introduced.\n\nBeam systems broadcast narrow signals in the sky, and navigation is accomplished by keeping the aircraft centred in the beam. A number of stations are used to create an airway, with the navigator tuning in different stations along the direction of travel. These systems were common in the era when electronics were large and expensive, as they placed minimum requirements on the receivers – they were simply voice radio sets tuned to the selected frequencies. However, they did not provide navigation outside of the beams, and were thus less flexible in use. The rapid miniaturization of electronics during and after World War II made systems like VOR practical, and most beam systems rapidly disappeared.\n\nIn the post-World War I era, the Lorenz company of Germany developed a means of projecting two narrow radio signals with a slight overlap in the center. By broadcasting different audio signals in the two beams, the receiver could position themselves very accurately down the centreline by listening to the signal in their headphones. The system was accurate to less than a degree in some forms.\n\nOriginally known as \"Ultrakurzwellen-Landefunkfeuer\" (LFF), or simply \"Leitstrahl\" (guiding beam), little money was available to develop a network of stations. Deployment was instead led by the US, where it formed the basis of a wide-area navigation system through the 1930s and 40s (see LFF, below). Development was restarted in Germany in the 1930s as a short-range system deployed at airports as a blind landing aid. Although there was some interest in deploying a medium-range system like the US LFF, deployment had not yet started when the beam system was combined with the Orfordness timing concepts to produce the highly accurate Sonne system. In all of these roles, the system was generically known simply as a \"Lorenz beam\".\n\nIn the immediate pre-World War II era the same concept was also developed as a blind-bombing system. This used very large antennas to provide the required accuracy at long distances (over England), and very powerful transmitters. Two such beams were used, crossing over the target to triangulate it. Bombers would enter one of the beams and use it for guidance until they heard the second one in a second radio receiver, using that signal to time the dropping of their bombs. The system was highly accurate, and the 'Battle of the Beams' broke out when United Kingdom intelligence services attempted, and then succeeded, in rendering the system useless through electronic warfare. Sonne, however, proved just as useful to the UK as Germany, and was left to operate unhindered throughout the war.\n\nThe low-frequency radio range (LFR, also other names) was the main navigation system used by aircraft for instrument flying in the 1930s and 1940s in the U.S. and other countries, until the advent of the VOR in the late 1940s. It was used for both en route navigation as well as instrument approaches.\n\nThe ground stations consisted of a set of four antennas that projected Lorenz beams in four cardinal directions. One of the beams was \"keyed\" with the morse code signal \"A\", dit-dah, with the second beam \"N\", dah-dit. Flying down the centreline produced a steady tone. The beams were pointed to the next station to produce a set of airways, allowing an aircraft to travel from airport to airport by following a selected set of stations. Effective course accuracy was about three degrees, which near the station provided sufficient safety margins for instrument approaches down to low minimums. At its peak deployment, there were nearly 400 LFR stations in the US.\n\nThe remaining widely used beam systems are glide path and the localizer of the \"instrument landing system\" (ILS). ILS uses a \"localizer\" to provide horizontal position, distance to the runway, and airport information, and \"glide path\" to provide vertical positioning. ILS can provide enough accuracy and redundancy to allow automated landings.\nFor more information see also: \n\nPositions can be determined with any two measures of angle or distance. The introduction of radar in the 1930s provided a way to directly determine the distance to an object even at long distances. Navigation systems based on these concepts soon appeared, and remained in widespread use until recently. Today they are used primarily for aviation, although GPS has largely supplanted this role.\n\nEarly radar systems, like the UK's Chain Home, consisted of large transmitters and separate receivers. The transmitter periodically sends out a short pulse of a powerful radio signal, which is sent into space through broadcast antennas. When the signal reflects off a target, some of that signal is reflected back in the direction of the station, where it is received. The received signal is a tiny fraction of the broadcast power, and has to be powerfully amplified in order to be used.\n\nThe same signals are also sent over local electrical wiring to the operator's station, which is equipped with an oscilloscope. Electronics attached to the oscilloscope provides a signal that increases in voltage over a short period of time, a few microseconds. When sent to the X input of the oscilloscope, this causes a horizontal line to be displayed on the scope. This \"sweep\" is triggered by a signal tapped off the broadcaster, so the sweep begins when the pulse is sent. Amplified signals from the receiver are then sent to the Y input, where any received reflection causes the beam to move upward on the display. This causes a series of \"blips\" to appear along the horizontal axis, indicating reflected signals. By measuring the distance from the start of the sweep to the blip, which corresponds to the time between broadcast and reception, the distance to the object can be determined.\n\nSoon after the introduction of radar, the radio transponder appeared. Transponders are a combination of receiver and transmitter whose operation is automated – upon reception of a particular signal, normally a pulse on a particular frequency, the transponder sends out a pulse in response, typically delayed by some very short time. Transponders were initially used as the basis for early IFF systems; aircraft with the proper transponder would appear on the display as part of the normal radar operation, but then the signal from the transponder would cause a second blip to appear a short time later. Single blips were enemies, double blips friendly.\n\nTransponder-based distance-distance navigation systems have a significant advantage in terms of positional accuracy. Any radio signal spreads out over distance, forming the fan-like beams of the Lorenz signal, for instance. As the distance between the broadcaster and receiver grows, the area covered by the fan increases, decreasing the accuracy of location within it. In comparison, transponder-based systems measure the timing between two signals, and the accuracy of that measure is largely a function of the equipment and nothing else. This allows these systems to remain accurate over very long range.\n\nThe latest transponder systems (mode S) can also provide position information, possibly derived from GNSS, allowing for even more precise positioning of targets.\n\nThe first distance-based navigation system was the German Y-Gerät blind-bombing system. This used a Lorenz beam for horizontal positioning, and a transponder for ranging. A ground-based system periodically sent out pulses which the airborne transponder returned. By measuring the total round-trip time on a radar's oscilloscope, the aircraft's range could be accurately determined even at very long ranges. An operator then relayed this information to the bomber crew over voice channels, and indicated when to drop the bombs.\n\nThe British introduced similar systems, notably the Oboe system. This used two stations in England that operated on different frequencies and allowed the aircraft to be triangulated in space. To ease pilot workload only one of these was used for navigation – prior to the mission a circle was drawn over the target from one of the stations, and the aircraft was directed to fly along this circle on instructions from the ground operator. The second station was used, as in Y-Gerät, to time the bomb drop. Unlike Y-Gerät, Oboe was deliberately built to offer very high accuracy, as good as 35 m, much better than even the best optical bombsights.\n\nOne problem with Oboe was that it allowed only one aircraft to be guided at a time. This was addressed in the later Gee-H system by placing the transponder on the ground and broadcaster in the aircraft. The signals were then examined on existing Gee display units in the aircraft (see below). Gee-H did not offer the accuracy of Oboe, but could be used by as many as 90 aircraft at once. This basic concept has formed the basis of most distance measuring navigation systems to this day.\n\nThe key to the transponder concept is that it can be used with existing radar systems. The ASV radar introduced by RAF Coastal Command was designed to track down submarines and ships by displaying the signal from two antennas side by side and allowing the operator to compare their relative strength. Adding a ground-based transponder immediately turned the same display into a system able to guide the aircraft towards a transponder, or \"beacon\" in this role, with high accuracy.\n\nThe British put this concept to use in their Rebecca/Eureka system, where battery-powered \"Eureka\" transponders were triggered by airborne \"Rebecca\" radios and then displayed on ASV Mk. II radar sets. Eureka's were provided to French resistance fighters, who used them to call in supply drops with high accuracy. The US quickly adopted the system for paratroop operations, dropping the Eureka with pathfinder forces or partisans, and then homing in on those signals to mark the drop zones.\n\nThe beacon system was widely used in the post-war era for blind bombing systems. Of particular note were systems used by the US Marines that allowed the signal to be delayed in such a way to offset the drop point. These systems allowed the troops at the front line to direct the aircraft to points in front of them, directing fire on the enemy. Beacons were widely used for temporary or mobile navigation as well, as the transponder systems were generally small and low-powered, able to be man portable or mounted on a Jeep.\n\nIn the post-war era, a general navigation system using transponder-based systems was deployed as the distance measuring equipment (DME) system.\n\nDME was identical to Gee-H in concept, but used new electronics to automatically measure the time delay and display it as a number, rather than having the operator time the signals manually on an oscilloscope. This led to the possibility that DME interrogation pulses from different aircraft might be confused, but this was solved by having each aircraft send out a different series of pulses which the ground-based transponder repeated back.\n\nDME is almost always used in conjunction with VOR, and is normally co-located at a VOR station. This combination allows a single VOR/DME station to provide both angle and distance, and thereby provide a single-station fix. DME is also used as the distance-measuring basis for the military TACAN system, and their DME signals can be used by civilian receivers.\n\nHyperbolic navigation systems are a modified form of transponder systems which eliminate the need for an airborne transponder. The name refers to the fact that they do not produce a single distance or angle, but instead indicate a location along any number of hyperbolic lines in space. Two such measurements produces a fix. As these systems are almost always used with a specific navigational chart with the hyperbolic lines plotted on it, they generally reveal the receiver's location directly, eliminating the need for manual triangulation. As these charts were digitized, they became the first true location-indication navigational systems, outputting the location of the receiver as latitude and longitude. Hyperbolic systems were introduced during World War II and remained the main long-range advanced navigation systems until GPS replaced them in the 1990s.\n\nThe first hyperbolic system to be developed was the British Gee system, developed during World War II. Gee used a series of transmitters sending out precisely timed signals, with the signals leaving the stations at fixed delays. An aircraft using Gee, RAF Bomber Command's heavy bombers, examined the time of arrival on an oscilloscope at the navigator's station. If the signal from two stations arrived at the same time, the aircraft must be an equal distance from both transmitters, allowing the navigator to determine a line of position on his chart of all the positions at that distance from both stations. More typically, the signal from one station would be received earlier than the other. The \"difference\" in timing between the two signals would reveal them to be along a curve of possible locations. By making similar measurements with other stations, additional lines of position can be produced, leading to a fix. Gee was accurate to about 165 yards (150 m) at short ranges, and up to a mile (1.6 km) at longer ranges over Germany. Gee remained in use long after World War II, and equipped RAF aircraft as late as the 1960s (approx freq was by then 68 MHz).\n\nWith Gee entering operation in 1942, similar US efforts were seen to be superfluous. They turned their development efforts towards a much longer-ranged system based on the same principles, using much lower frequencies that allowed coverage across the Atlantic Ocean. The result was LORAN, for \"LOng-range Aid to Navigation\". The downside to the long-wavelength approach was that accuracy was greatly reduced compared to the high-frequency Gee. LORAN was widely used during convoy operations in the late war period.\n\nAnother British system from the same era was Decca Navigator. This differed from Gee primarily in that the signals were not pulses delayed in time, but continuous signals delayed in phase. By comparing the phase of the two signals, the time difference information as Gee was returned. However, this was far easier to display; the system could output the phase angle to a pointer on a dial removing any need for visual interpretation. As the circuitry for driving this display was quite small, Decca systems normally used three such displays, allowing quick and accurate reading of multiple fixes. Decca found its greatest use post-war on ships, and remained in use into the 1990s.\n\nAlmost immediately after the introduction of LORAN, in 1952 work started on a greatly improved version. LORAN-C (the original retroactively became LORAN-A) combined the techniques of pulse timing in Gee with the phase comparison of Decca.\n\nThe resulting system (operating in the low frequency (LF) radio spectrum from 90 to 110 kHz) that was both long-ranged (for 60 kW stations, up to 3400 miles) and accurate. To do this, LORAN-C sent a pulsed signal, but modulated the pulses with an AM signal within it. Gross positioning was determined using the same methods as Gee, locating the receiver within a wide area. Finer accuracy was then provided by measuring the phase difference of the signals, overlaying that second measure on the first. By 1962, high-power LORAN-C was in place in at least 15 countries.\n\nLORAN-C was fairly complex to use, requiring a room of equipment to pull out the different signals. However, with the introduction of integrated circuits, this was quickly reduced further and further. By the late 1970s, LORAN-C units were the size of a stereo amplifier and were commonly found on almost all commercial ships as well as some larger aircraft. By the 1980s, this had been further reduced to the size of a conventional radio, and it became common even on pleasure boats and personal aircraft. It was the most popular navigation system in use through the 1980s and 90s, and its popularity led to many older systems being shut down, like Gee and Decca. However, like the beam systems before it, civilian use of LORAN-C was short-lived when GPS technology drove it from the market.\n\nSimilar hyperbolic systems included the US global-wide VLF/Omega Navigation System, and the similar Alpha deployed by the USSR. These systems determined pulse timing not by comparison of two signals, but by comparison of a single signal with a local atomic clock. The expensive-to-maintain Omega system was shut down in 1997 as the US military migrated to using GPS. Alpha is still in use.\n\nSince the 1960s, navigation has increasingly moved to satellite navigation systems. These are essentially DME systems located in space. The fact that the satellites are in orbit and normally move with respect to the receiver means that the calculation of the position of the satellite needs to be taken into account as well, which can only be handled effectively with a computer.\n\nThe Global Positioning System, better known simply as GPS, sends several signals that are used to decode the position and distance of the satellite. One signal encodes the satellite's \"ephemeris\" data, which is used to accurately calculate the satellite's location at any time. Space weather and other effects causes the orbit to change over time so the ephemeris has to be updated periodically. Other signals send out the time as measured by the satellite's onboard atomic clock. By measuring this signal from several satellites, the receiver can re-build an accurate clock signal of its own. Comparing the two produces the distance to the satellite, and several such measurements allows a form of triangulation to be carried out.\n\nGPS has better accuracy that any previous land-based system, is available at almost all locations on the Earth, can be implemented in a few cents of modern electronics, and requires only a few dozen satellites to provide worldwide coverage. As a result of these advantages, GPS has led to almost all previous systems falling from use. LORAN, Omega, Decca, Consol and many other systems disappeared during the 1990s and 2000s. The only other systems still in use are aviation aids, which are also being turned off for long-range navigation while new differential GPS systems are being deployed to provide the local accuracy needed for blind landings.\n\n\n\n"}
{"id": "44885218", "url": "https://en.wikipedia.org/wiki?curid=44885218", "title": "Rhumbline network", "text": "Rhumbline network\n\nA rhumbline network, or more properly called, a windrose network, is a navigational aid drawn on portolan charts. This network is like a web (see picture) forming a grid on the map. The grid can be easily spotted (as parchment is quite translucent) by observing the map from its rear face, with a light source illuminating the other side. The hole in the center of the circle, origin of the whole network, is also clearly visible from the rear.\n\nThe lines are not true rhumb lines in the modern sense (reason to put the title in italics), since these can only be drawn on modern map projections and not on 13th century charts. They were close to true rhumb lines in the Mediterranean area but highly inaccurate in the Teixeira planisphere and the other planispheres drawn in any pre-Mercator projection.\n\nAll portolan maps share this characteristic \"windrose networks\", which emanate out from compass roses located at various points on the map (or mapamundi). These better called \"windrose lines\" are generated \"by observation and the compass\", and designated today: \"lines of course\" or \"lines of rhumb\" (\"rhumb lines\" in the fourteenth century, traced on portolan's particular projection, though not to be confused with modern rhumb lines, meridians or isoazimuthals).\n\nTo understand that those lines should be better called \"windrose lines\", one has to know that portolan maps are characterized by the lack of map projection, for cartometric investigation has revealed that no projection was used in portolans, and those straight lines they could be loxodromes only if the chart was drawn on a suitable projection.\n\nAs leo Bagrow states:\"\"..the word (\"Rhumbline\") is wrongly applied to the sea-charts of this period, since a loxodrome gives an accurate course only when the chart is drawn on a suitable projection. Cartometric investigation has revealed that no projection was used in the early charts, for which we therefore retain the name 'portolan'.\"\"\n\nPujades in his book \"Les cartes portolanes\" has a chapter with all known theories and, with the aim to clarify the controversial arguments, he shows an image of Petrus Vesconte drawing a portolan in one of his maps in which it is visible how he started by drawing first the rhumbline grid. Some authors call it \"winds network\" instead of using the term \"rhumbline network\" or \"network of rhumblines\"\n\nThe circle is divided into sixteen equal parts defining an hexadecagon, then the network of sailing directions \"for a 16 winds rose\" is represented by groups of 16 \"straight lines\" called rhumblines. From each vertex, 7 rhumblines are projected towards the hexadecagon's interior connecting \"in an alternated pace\" to 7 of the vertex opposite to it, but without routing any line to connect that vertex to the other 8 intermixed vertex. The remaining 9 rhumblines (to complete the 16 winds) are projected from each vertex towards the exterior of the hexadecagon, although in some portolans those 9 lines do not appear.\n\nThe lines of the courses for the eight main directions (or winds) are drawn with black ink (or sometimes gold); the eight intermediate directions (half-winds) are drawn in green; and in the case of a 32 winds rose, the sixteen remaining (quarter-winds) are drawn in red. The intersection of this set of \"rhumblines\" determine on the portolans a varied pattern of symmetrical squares, parallelograms, trapezoids and triangles.\n\nThe process for a vellum chart creation used to be as follows:\n\n\nIn large planispheres, especially those containing the oceans (World Map), the cartographer used to draw two hexadecagons with the two opposite corners superimposed in the center of the vellum. There are plenty of mappae mundi that use the double-hexadecagon rhumbline networks but they can not be considered portolan charts since they do not have any ports indicated on them.\n\nIn the Cresques planisphere one is able to read the names of those lines which were winds: tramontana, levante, ponente, mezzogiorno, greco, sirocco, and lebegio. When limited to small seas, planispheres approximately follow both rhumb lines and great circles. But on big oceans they do not follow either of them, due to the imprecision of the map making of that time, corresponding more or less accurately to rhumb lines only in the Mediterranean portolan charts and deviating greatly in the Texeira planisfere (among others).\n\nTo calculate on a portolan chart the course to follow from a point of origin to a point of destination, one should transfer — using a parallel rule — the \"line of course\" drawn from the point of origin to the point of destination, on top of the \"Compass rose\" closest to the ship's position, obtaining on it the theoretical course to be followed when sailing towards the destination. This theoretical course may have to be modified (as many times as needed) when tacking if the wind is right ahead of you, or to correct the effects of leeway, currents, etc... that a sailor with experience should be able to calculate empirically.\n\n\n"}
{"id": "4558969", "url": "https://en.wikipedia.org/wiki?curid=4558969", "title": "Right to light", "text": "Right to light\n\nRight to light is a form of easement in English law that gives a long-standing owner of a building with windows a right to maintain the level of illumination. It is based on the Ancient Lights law. The rights are most usually acquired under the Prescription Act 1832.\n\nIn effect, the owner of a building with windows that have received natural daylight for 20 years or more is entitled to forbid any construction or other obstruction that would deprive him or her of that illumination. Neighbours cannot build anything that would block the light without permission. The owner may build more or larger windows but cannot enlarge their new windows before the new period of 20 years has expired. It is also possible for a right to light to exist if granted expressly by deed, or granted implicitly, for example under the rule in \"Wheeldon v. Burrows\" (1879).\n\nOnce a right to light exists, the owner of the right is entitled to \"sufficient light according to the ordinary notions of mankind\": \"Colls v. Home & Colonial Stores Ltd\" (1904). Courts rely on expert witnesses to define this term. Since the 1920s, experts have used a method proposed by Percy Waldram to assist them with this. Waldram suggested that ordinary people require one foot-candle of illuminance (approximately ten lux) for reading and other work involving visual discrimination. This equates to a sky factor (similar to the daylight factor) of 0.2%. Today, Waldram's methods are increasingly subject to criticism and the future of expert evidence in rights to light cases is currently the subject of much debate within the surveying profession.\n\nAfter the Second World War, owners of buildings could gain new rights by registering properties that had been destroyed in bombings and the period was temporarily increased to 27 years.\n\nIn the centre of London near Chinatown and Covent Garden, particularly in back alleyways, signs saying \"Ancient Lights\" can be seen marking individual windows. The design and construction of Broadcasting House in the early 1930s was also affected by locals declaring their right to ancient lights. It resulted in a unique asymmetrical sloped design that allowed for sunlight to pass over the building to the residential quarters eastwards, long since demolished and now home to the new Egton Wing.\n\nRecent case law from 2010, relating to a commercial development in the centre of Leeds (\"HKRUK II v Heaney\") has significantly changed the perceptions of risk associated with right-to-light, particularly in the context of commercial schemes. This case upheld an injunction against a commercial property. The result of this is that many developers are now looking to work with local authorities to try to use section 237 of the Town and Country Planning Act 1990. This potentially stops injunctions against schemes that have over-riding social or economic advantages to an area.\n\nUnder United States tort law, in \"Fontainebleau Hotel Corp. v. Forty-Five Twenty-Five, Inc.\" (1959) the Florida Appellate Court stated that the \"ancient lights\" doctrine had been unanimously repudiated in the United States.\n\nIn 1984, voters in San Francisco passed Proposition K, which prevents construction of any building over 40 feet that casts a shadow on a public park, unless the Planning Commission decides the shadow is insignificant. This proposition causes problems for a proposed 34-story building south of Market Street, which would cast a shadow on a public park ten blocks away, for one hour of the day in the fall, as well as St. Mary's Square, Justin Herman Plaza, and Union Square for significant parts of the year. Massachusetts has similar laws against the casting of shadows on Boston Common, the Public Garden, and other important public open spaces.\n\n\nDavis, Howard. \"The Future of Ancient Lights,\" Journal of Architectural and Planning Research, Vol. 6, No. 2, Summer 1989, pp. 132-153.\n"}
{"id": "549513", "url": "https://en.wikipedia.org/wiki?curid=549513", "title": "Stile", "text": "Stile\n\nA stile is a structure which provides people a passage through or over a fence or boundary via steps, ladders, or narrow gaps. Stiles are often built in rural areas along footpaths, fences, walls or hedges to prevent farm animals moving from one enclosure to another whilst allowing path users still to use the route.\n\nIn the United Kingdom many stiles were built under legal compulsion (see \"Rights of way in the United Kingdom\"). Recent changes in UK government policy towards farming has encouraged upland landowners to make access more available to the public, and this has seen an increase in the number of stiles and an improvement in their overall condition. However stiles are deprecated in British Standard BS5709:2018 Gaps Gates & Stiles () and are increasingly being replaced by gates or kissing gates or, where the field is arable, the stile removed. Many legacy stiles remain, however, in a variety of forms (as it also the case in the US, where there is no standard). As well as having a variety of forms, stiles also sometimes include a 'dog latch' or 'dog gate' to the side of them, which can be lifted to enable a dog to get through (see pictures below).\nAn alternative form of stile is a squeeze stile, which is commonly used where footpaths cross dry stone walls in England. With this type of stile there is a vertical gap in the wall, usually no more than wide, and often with stone pillars on either side to protect the structure of the wall. The gap must be narrow enough to prevent livestock getting through.\n\n"}
{"id": "646417", "url": "https://en.wikipedia.org/wiki?curid=646417", "title": "Trailhead", "text": "Trailhead\n\nA trailhead is the point at which a trail begins, where the trail is often intended for hiking, biking, horseback riding, or off-road vehicles. Modern trailheads often contain rest rooms, maps, sign posts and distribution centers for informational brochures about the trail and its features, and parking areas for vehicles and trailers.\nHistorically, the cities located at the terminus of major pathways for foot traffic such as the Natchez Trace and the Chisholm Trail were also known as trailheads.\n\nFor mountain climbing and hiking, the elevation of the trailhead above sea level is given to give an idea of how high the mountain is above the average terrain.\n\n"}
{"id": "29030725", "url": "https://en.wikipedia.org/wiki?curid=29030725", "title": "Transverse Mercator: Redfearn series", "text": "Transverse Mercator: Redfearn series\n\nThe article Transverse Mercator projection restricts itself to general features of the projection. This article describes in detail one of the (two) implementations developed by Louis Krüger in 1912; that expressed as a power series in the longitude difference from the central meridian. These series were recalculated by Lee in 1946, by Redfearn in 1948, and by Thomas in 1952. They are often referred to as the Redfearn series, or the Thomas series. This implementation is of great importance since it is widely used in the U.S. State Plane Coordinate System, in national (Britain, Ireland and many others) and also international mapping systems, including the Universal Transverse Mercator coordinate system (UTM). They are also incorporated into the Geotrans coordinate converter made available by the United States National Geospatial-Intelligence Agency. When paired with a suitable geodetic datum, the series deliver high accuracy in zones less than a few degrees in east-west extent.\n\nThe series must be used with a geodetic datum which specifies the position, orientation and shape of a Reference ellipsoid. Although the projection formulae depend only on the shape parameters of the reference ellipsoid the full set of datum parameters is necessary to link the projection coordinates to true positions in three-dimensional space. The datums and reference ellipsoids associated with particular implementations of the Redfearn formulae are listed below. A comprehensive list of important ellipsoids is given in the article on the Figure of the Earth.\n\nIn specifying ellipsoids it is normal to give the semi-major axis (equatorial axis), formula_1, along with either the inverse flattening, formula_2, or the semi-minor axis (polar axis), formula_3, or sometimes both. The series presented below use the eccentricity, formula_4, in preference to the flattening, formula_5. In addition they use the parameters formula_6, called the third flattening, and formula_7, the second eccentricity. There are only two independent shape parameters and there are many relations between them: in particular\nThe projection formulae also involve formula_9, the radius of curvature of the meridian (at latitude formula_10), and formula_11, the radius of curvature in the prime vertical.\n(The prime vertical is the vertical plane orthogonal to the meridian plane at a point on the ellipsoid). The radii of curvature are defined as follows:\nIn addition the functions formula_13 and formula_14 are defined as:\nFor compactness it is normal to introduce the following abbreviations:\n\nThe article on Meridian arc describes several methods of computing formula_17, the meridian distance from the equator to a point at latitude formula_10 : the expressions given below are those used in the \"'actual\" implementation of the Transverse Mercator projection by the OSGB. The truncation error is less than 0.1mm so the series is certainly accurate to within 1mm, the design tolerance of the OSGB implementation.\nwhere the coefficients are given to order formula_20 (order formula_21) by\nThe meridian distance from equator to pole is \nThe form of the series specified for UTM is a variant of the above exhibiting higher order terms with a truncation error of 0.03mm.\n\nNeither the OSGB nor the UTM implementations define an inverse series for the meridian distance; instead they use an iterative scheme. For a given meridian distance formula_24 first set formula_25 and then iterate using\nuntil formula_27mm.\n\nThe inversion \"can\" be effected by a series, presented here for later reference. For a given meridian distance, formula_24, define the rectifying latitude by\nThe geodetic latitude corresponding to formula_24 is (Snyder page 17):\nwhere, to formula_32,\n\nThe normal aspect of the Mercator projection of a sphere of radius formula_34 is described by the equations\nwhere formula_36, the isometric latitude, is given by\nOn the ellipsoid the isometric latitude becomes\nBy construction, the projection from the geodetic coordinates (formula_10,formula_40) to the coordinates (formula_36,formula_40) is conformal. If the coordinates (formula_36,formula_40) are used to define a point formula_45 in the complex plane, then any analytic function formula_46 will define another conformal projection. Kruger's method involves seeking the specific formula_46 which generates a uniform scale along the central meridian, formula_48. He achieved this by investigating a Taylor series approximation with the projection coordinates given by:\nwhere the real part of formula_50 must be proportional to the meridian distance function formula_17. The (complex) coefficients formula_52 depend on derivatives of formula_46 which can be reduced to derivatives of formula_17 with respect to formula_36, (not formula_10). The derivatives are straightforward to evaluate in principle but the expressions become very involved at high orders because of the complicated relation between formula_36 and formula_10. Separation of real and imaginary parts gives the series for formula_59 and formula_60 and further derivatives give the scale and convergence factors.\n\nThis section presents the eighth order series as published by Redfearn (but with formula_59 and formula_60 interchanged and the longitude difference from the central meridian denoted by formula_40 instead of formula_64). Equivalent eighth order series, with different notations, can be found in Snyder (pages 60–64) and at many web sites such as that for the Ordnance Survey of Great Britain.\n\nThe direct series are developed in terms of the longitude difference from the central meridian, expressed in radians: the inverse series are developed in terms of the ratio formula_65. The projection is normally restricted to narrow zones (in longitude) so that both of the expansion parameters are typically less than about 0.1, guaranteeing rapid convergence. For example in each UTM zone these expansion parameters are less than 0.053 and for the British national grid (NGGB) they are less than 0.09. All of the direct series giving formula_59, formula_60, scale formula_68, convergence formula_69 are functions of both latitude and longitude and the parameters of the ellipsoid: all inverse series giving formula_10, formula_40, formula_68, formula_69 are functions of both formula_59 and formula_60 and the parameters of the ellipsoid.\n\nIn the following series formula_40 is the \"difference\" of the longitude of an arbitrary point and the longitude of the chosen central meridian: formula_40 is in radians and is positive east of the central meridian. The W coefficients are functions of formula_10 listed below. The series for formula_60 reduces to the scaled meridian distance when formula_48.\n\nThe inverse series involve a further construct: the footpoint latitude. Given a point formula_82 on the projection the footpoint is defined as the point on the central meridian with coordinates formula_83. Since the scale on the central meridian is formula_84 the meridian distance from the equator to the footpoint is equal to formula_85. The corresponding footpoint latitude, formula_86, is calculated by iteration or the inverse meridian distance series as described above.\nDenoting functions evaluated at formula_86 by a subscript '1', the inverse series are:\n\nThe point scale formula_68 is independent of direction for a conformal transformation. It may be calculated in terms of geographic or projection coordinates. Note that the series for formula_68 reduce to formula_84 when either formula_48 or formula_94 . The convergence formula_69 may also be calculated (in radians) in terms of geographic or projection coordinates:\n\nThe exact solution of Lee-Thompson, implemented by Karney (2011), is of great value in assessing the accuracy of the truncated Redfearn series. It confirms that the truncation error of the (eighth order) Redfearn series is less than 1 mm out to a longitude difference of 3 degrees, corresponding to a distance of 334 km from the central meridian at the equator but a mere 35 km at the northern limit of an UTM zone.\n\nThe Redfearn series become much worse as the zone widens. Karney discusses Greenland as an instructive example. The long thin landmass is centred on 42W and, at its broadest point, is no more than 750 km from that meridian whilst the span in longitude reaches almost 50 degrees. The Redfearn series attain a maximum error of 1 kilometre.\n\nThe implementations give below are examples of the use of the Redfearn series. The defining documents in various countries differ slightly in notation and, more importantly, in the neglect of some of the small terms. The analysis of small terms depends on the latitude and longitude ranges in the various grids. There are also slight differences in the formulae utilised for meridian distance: one extra term is sometimes added to the formula specified above but such a term is less than 0.1mm.\n\nThe implementation of the transverse Mercator projection in Great Britain is fully described in the OSGB document A guide to coordinate systems in Great Britain, Appendices A.1, A.2 and C.\nThe extent of the grid is 300 km to the east and 400 km to the west of the central meridian and 1300 km north from the \"false\" origin, (OSGB Section 7.1), but with the exclusion of parts of Northern Ireland, Eire and France. A grid reference is denoted by the pair (E,N) where E ranges from slightly over zero to 800000m and N ranges from zero to 1300000m. To reduce the number of figures needed to give a grid reference, the grid is divided into 100 km squares, which each have a two-letter code. National Grid positions can be given with this code followed by an easting and a northing both in the range 0 and 99999m. \n\nThe projection formulae differ slightly from the Redfearn formulae presented here. They have been simplified by neglect of most terms of seventh and eighth order in formula_40 or formula_65: the only exception is seventh order term in the series for formula_40 in terms of formula_65. This simplification is based on the examination of the Redfearn terms over the \"actual\" extent of the grid. The only other differences are (a) the absorption of the central scale factor into the radii of curvature and meridian distance, (b) the replacement of the parameter formula_102 by the parameter formula_103 (defined ).\n\nThe OSGB manual includes a discussion of the Helmert transformations which are required to link geodetic coordinates on Airy 1830 ellipsoid and on WGS84.\n\nThe article on the Universal Transverse Mercator projection gives a general survey, but the full specification is defined in U.S. Defense Mapping Agency Technical Manuals TM8358.1 and TM8358.2. This section provides details for zone 30 as another example of the Redfearn formulae (usually termed Thomas formulae in the United States.)\nThe series adopted for the meridian distance incorporates terms of fifth order in formula_6 but the manual states that these are less than 0.03 mm (TM8358.2 Chapter 2). The projection formulae use, formula_7, the second eccentrity (defined ) instead of formula_6. The grid reference schemes are defined in the article Universal Transverse Mercator coordinate system. The accuracy claimed for the UTM projections is 10 cm in grid coordinates and 0.001 arc seconds for geodetic coordinates.\n\nThe transverse Mercator projection in Eire and Northern Ireland (an international implementation spanning one country and part of another) is currently implemented in two ways:\n\nIrish grid reference system\nThe Irish grid uses the OSGB projection formulae.\n\nIrish Transverse Mercator\nThis is an interesting example of the transition between use of a traditional ellipsoid and a modern global ellipsoid. The adoption of radically different false origins helps to prevent confusion between the two systems.\n\n"}
{"id": "639245", "url": "https://en.wikipedia.org/wiki?curid=639245", "title": "Transverse Mercator projection", "text": "Transverse Mercator projection\n\nThe transverse Mercator map projection is an adaptation of the standard Mercator projection. The transverse version is widely used in national and international mapping systems around the world, including the UTM. When paired with a suitable geodetic datum, the transverse Mercator delivers high accuracy in zones less than a few degrees in east-west extent.\n\nThe transverse Mercator projection is the transverse aspect of the standard (or \"Normal\") Mercator projection. They share the same underlying mathematical construction and consequently the transverse Mercator inherits many traits from the normal Mercator:\n\nSince the central meridian of the transverse Mercator can be chosen at will, it may be used to construct highly accurate maps (of narrow width) anywhere on the globe. The secant, ellipsoidal form of the transverse Mercator is the most widely applied of all projections for accurate large-scale maps.\n\nIn constructing a map on any projection, a sphere is normally chosen to model the Earth when the extent of the mapped region exceeds a few hundred kilometers in length in both dimensions. For maps of smaller regions, an ellipsoidal model must be chosen if greater accuracy is required; see next section. The spherical form of the transverse Mercator projection was one of the seven new projections presented, in 1772, by Johann Heinrich Lambert. (The text is also available in a modern English translation.) Lambert did not name his projections; the name \"transverse Mercator\" dates from the second half of the nineteenth century. The principal properties of the transverse projection are here presented in comparison with the properties of the normal projection.\n\nThe ellipsoidal form of the transverse Mercator projection was developed by Carl Friedrich Gauss in 1825 and further analysed by Johann Heinrich Louis Krüger in 1912. The projection is known by several names: Gauss Conformal or Gauss-Krüger in Europe; the transverse Mercator in the US; or Gauss–Krüger transverse Mercator generally. The projection is conformal with a constant scale on the central meridian. (There are other conformal generalisations of the transverse Mercator from the sphere to the ellipsoid but only Gauss-Krüger has a constant scale on the central meridian.) Throughout the twentieth century the Gauss–Krüger transverse Mercator was adopted, in one form or another, by many nations (and international bodies); in addition it provides the basis for the Universal Transverse Mercator series of projections. The Gauss–Krüger projection is now the most widely used projection in accurate large-scale mapping.\n\nThe projection, as developed by Gauss and Krüger, was expressed in terms of low order power series which were assumed to diverge in the east-west direction, exactly as in the spherical version. This was proved to be untrue by British cartographer E. H. Thompson, whose unpublished exact (closed form) version of the projection, reported by L. P. Lee in 1976, showed that the ellipsoidal projection is finite (below). This is the most striking difference between the spherical and ellipsoidal versions of the transverse Mercator projection: Gauss–Krüger gives a reasonable projection of the \"whole\" ellipsoid to the plane, although its principal application is to accurate large-scale mapping \"close\" to the central meridian.\n\n\nIn most applications the Gauss–Krüger coordinate system is applied to a narrow strip near the central meridians where the differences between the spherical and ellipsoidal versions are small, but nevertheless important in accurate mapping. Direct series for scale, convergence and distortion are functions of eccentricity and both latitude and longitude on the ellipsoid: inverse series are functions of eccentricity and both \"x\" and \"y\" on the projection. In the secant version the lines of true scale on the projection are no longer parallel to central meridian; they curve slightly. The convergence angle between projected meridians and the \"x\" constant grid lines is no longer zero (except on the equator) so that a grid bearing must be corrected to obtain an azimuth from true north. The difference is small, but not negligible, particularly at high latitudes.\n\nIn his 1912 paper, Krüger presented two distinct solutions, distinguished here by the expansion parameter:\n\nThe Krüger–\"λ\" series were the first to be implemented, possibly because they were much easier to evaluate on the hand calculators of the mid twentieth century.\n\nThe Krüger–\"n\" series have been implemented (to fourth order in \"n\") by the following nations.\n\nHigher order versions of the Krüger–\"n\" series have been implemented to seventh order by Ensager and Poder and to tenth order by Kawase. Apart from a series expansion for the transformation between latitude and conformal latitude, Karney has implemented the series to thirtieth order.\n\nAn exact solution by E. H. Thompson is described by L. P. Lee. It is constructed in terms of elliptic functions (defined in chapters 19 and 22 of the NIST handbook) which can be calculated to arbitrary accuracy using algebraic computing systems such as Maxima. Such an implementation of the exact solution is described by Karney (2011).\n\nThe exact solution is a valuable tool in assessing the accuracy of the truncated \"n\" and λ series. For example, the original 1912 Krüger–\"n\" series compares very favourably with the exact values: they differ by less than 0.31 μm within 1000 km of the central meridian and by less than 1 mm out to 6000 km. On the other hand, the difference of the Redfearn series used by Geotrans and the exact solution is less than 1 mm out to a longitude difference of 3 degrees, corresponding to a distance of 334 km from the central meridian at the equator but a mere 35 km at the northern limit of an UTM zone. Thus the Krüger–\"n\" series are very much better than the Redfearn λ series.\n\nThe Redfearn series becomes much worse as the zone widens. Karney discusses Greenland as an instructive example. The long thin landmass is centred on 42W and, at its broadest point, is no more than 750 km from that meridian while the span in longitude reaches almost 50 degrees. Krüger–\"n\" is accurate to within 1 mm but the Redfearn version of the Krüger–\"λ\" series has a maximum error of 1 kilometre.\n\nKarney's own 8th-order (in \"n\") series is accurate to 5 nm within 3900 km of the central meridian.\n\nThe normal cylindrical projections are described in relation to a cylinder tangential at the equator with axis along the polar axis of the sphere. The cylindrical projections are constructed so that all points on a meridian are projected to points with \"x\" = \"aλ\" and \"y\" a prescribed function of \"φ\". For a tangent Normal Mercator projection the (unique) formulae which guarantee conformality are:\nConformality implies that the point scale, \"k\", is independent of direction: it is a function of latitude only:\nFor the secant version of the projection there is a factor of \"k\" on the right hand side of all these equations: this ensures that the scale is equal to \"k\" on the equator.\n\nThe figure on the left shows how a transverse cylinder is related to the conventional graticule on the sphere. It is tangential to some arbitrarily chosen meridian and its axis is perpendicular to that of the sphere. The \"x\"- and \"y\"-axes defined on the figure are related to the equator and central meridian exactly as they are for the normal projection. In the figure on the right a rotated graticule is related to the transverse cylinder in the same way that the normal cylinder is related to the standard graticule. The 'equator', 'poles' (E and W) and 'meridians' of the rotated graticule are identified with the chosen central meridian, points on the equator 90 degrees east and west of the central meridian, and great circles through those points.\nThe position of an arbitrary point (\"φ\",\"λ\") on the standard graticule can also be identified in terms of angles on the rotated graticule: \"φ′\" (angle M′CP) is an effective latitude and −\"λ′\" (angle M′CO) becomes an effective longitude. (The minus sign is necessary so that (\"φ′\",\"λ′\") are related to the rotated graticule in the same way that (\"φ\",\"λ\") are related to the standard graticule). The Cartesian (\"x′\",\"y′\") axes are related to the rotated graticule in the same way that the axes (\"x\",\"y\") axes are related to the standard graticule.\n\nThe tangent transverse Mercator projection defines the coordinates (\"x′\",\"y′\") in terms of −\"λ′\" and \"φ′\" by the transformation formulae of the tangent Normal Mercator projection:\nThis transformation projects the central meridian to a straight line of finite length and at the same time projects the great circles through E and W (which include the equator) to infinite straight lines perpendicular to the central meridian. The true parallels and meridians (other than equator and central meridian) have no simple relation to the rotated graticule and they project to complicated curves.\n\nThe angles of the two graticules are related by using spherical trigonometry on the spherical triangle NM′P defined by the true meridian through the origin, OM′N, the true meridian through an arbitrary point, MPN, and the great circle WM′PE. The results are:\n\nThe direct formulae giving the Cartesian coordinates (\"x\",\"y\") follow immediately from the above. Setting \"x\" = \"y′\" and \"y\" = −\"x′\" (and restoring factors of \"k\" to accommodate secant versions)\nThe above expressions are given in Lambert and also (without derivations) in Snyder, Maling and Osborne (with full details).\n\nInverting the above equations gives\n\nIn terms of the coordinates with respect to the rotated graticule the point scale factor is given by \"k\" = sec \"φ′\": this may be expressed either in terms of the geographical coordinates or in terms of the projection coordinates:\nThe second expression shows that the scale factor is simply a function of the distance from the central meridian of the projection. A typical value of the scale factor is \"k\" = 0.9996 so that \"k\" = 1 when \"x\" is approximately 180 km. When \"x\" is approximately 255 km and \"k\" = 1.0004: the scale factor is within 0.04% of unity over a strip of about 510 km wide.\n\nThe convergence angle \"γ\" at a point on the projection is defined by the angle measured \"from\" the projected meridian, which defines true north, \"to\" a grid line of constant \"x\", defining grid north. Therefore, \"γ\" is positive in the quadrant north of the equator and east of the central meridian and also in the quadrant south of the equator and west of the central meridian. The convergence must be added to a grid bearing to obtain a bearing from true north. For the secant transverse Mercator the convergence may be expressed either in terms of the geographical coordinates or in terms of the projection coordinates:\n\nDetails of actual implementations\n\n\nThe projection coordinates resulting from the various developments of the ellipsoidal transverse Mercator are Cartesian coordinates such that the central meridian corresponds to the \"x\" axis and the equator corresponds to the \"y\" axis. Both \"x\" and \"y\" are defined for all values of \"λ\" and \"ϕ\". The projection does not define a grid: the grid is an independent construct which could be defined arbitrarily. In practice the national implementations, and UTM, do use grids aligned with the Cartesian axes of the projection, but they are of finite extent, with origins which need not coincide with the intersection of the central meridian with the equator.\n\nThe true grid origin is always taken on the central meridian so that grid coordinates will be negative west of the central meridian. To avoid such negative grid coordinates, standard practice defines a false origin to the west (and possibly north or south) of the grid origin: the coordinates relative to the false origin define eastings and northings which will always be positive. The false easting, \"E\", is the distance of the true grid origin east of the false origin. The false northing, \"N\", is the distance of the true grid origin north of the false origin. If the true origin of the grid is at latitude \"φ\" on the central meridian and the scale factor the central meridian is \"k\" then these definitions give eastings and northings by:\nThe terms \"eastings\" and \"northings\" do not mean strict east and north directions. Grid lines of the transverse projection, other than the \"x\" and \"y\" axes, do not run north-south or east-west as defined by parallels and meridians. This is evident from the global projections shown above. Near the central meridian the differences are small but measurable. The difference between the north-south grid lines and the true meridians is the angle of convergence.\n\n\n"}
{"id": "4387889", "url": "https://en.wikipedia.org/wiki?curid=4387889", "title": "Tunnel valley", "text": "Tunnel valley\n\nA tunnel valley is a large, long, U-shaped valley originally cut under the glacial ice near the margin of continental ice sheets such as that now covering Antarctica and formerly covering portions of all continents during past glacial ages.\n\nA tunnel valley can be as long as , wide, and deep (its depth may vary along its length).\n\nTunnel valleys were formed by subglacial erosion by water and served as subglacial drainage pathways carrying large volumes of melt water. Their cross-sections exhibit steep-sided flanks similar to fjord walls, and their flat bottoms are typical of subglacial glacial erosion.\n\nThey presently appear as dry valleys, lakes, seabed depressions, and as areas filled with sediment. If they are filled with sediment, their lower layers are filled primarily with glacial, glaciofluvial or glaciolacustrine sediment, supplemented by upper layers of temperate infill. They can be found in areas formerly covered by glacial ice sheets including Africa, Asia, North America, Europe, Australia and offshore in the North Sea, the Atlantic and in waters near Antarctica.\n\nTunnel valleys appear in the technical literature under several terms, including tunnel channels, subglacial valleys, iceways, snake coils and linear incisions.\n\nUnderstanding tunnel valleys is important because: \n\nTunnel valleys play a useful role in identifying oil rich areas in Arabia and North Africa. The Upper Ordovician–Lower Silurian materials there contain a roughly thick, carbon-rich layer of black shale. Approximately 30% of the world's oil is found in these shale deposits. Although the origin of these deposits is still under study, it has been established that the shale routinely overlies glacial and glacio-marine sediment deposited ~445 million years before the present by the Hirnantian glaciation. The shale has been linked to glacial meltwater nutrient enrichment of the shallow marine environment. Hence the presence of tunnel valleys is an indicator of the presence of oil in these areas.\n\nTunnel valleys represent a substantial fraction of all melt-water drainage from glaciers. Melt-water drainage influences the flow of glacial ice, which is important in understanding of the duration of glacial–interglacial periods and aids in identifying glacial cyclicity, a problem that is important to palaeoenvironmental investigations.\n\nTunnel valleys are typically eroded into bedrock and filled with glacial debris of varying sizes. This configuration makes them excellent at capturing and storing water. Hence they serve an important role as aquifers across much of Northern Europe, Canada and the United States. Examples include Oak Ridges Moraine Aquifer, Spokane Valley-Rathdrum Prairie Aquifer, Mahomet Aquifer, the Saginaw Lobe Aquifer, and the Corning Aquifer.\n\nTunnel valleys have been observed as open valleys and as partially or totally buried valleys. If buried they may be partially or totally filled with glacial outwash or other debris. The valleys may be incised in bedrock, sand, silt, or clay.\n\nA part of a tunnel valley may go uphill: water can flow uphill if it is under pressure in an enclosed pipe: for example in Doggerland (submerged land which is now part of the bed of the North Sea) are some infilled tunnel valleys that flowed from north to south across the hollow of the Outer Silver Pit.\n\nThey vary in channel depth and width; Danish examples run from wide and from deep. They vary in depth/altitude along their course, exhibiting overdeepening; overdeepened sections cut into bedrock and typically are significantly deeper than either upstream or downstream sections of the same tunnel valley. They have steep sides which are frequently asymmetric.\n\nTunnel valleys frequently include relatively straight individual segments parallel to and independent of one another. Tunnel valley courses may be periodically interrupted; the interruption may include a stretch of elevated esker, indicating the channel ran through ice for a distance. The below-grade sections typically run in length; in some cases the sections form a larger pattern of an interrupted channel composed of strings of depressions which can extend from .\n\nThe upstream portion – that section furthest into the glacier – consists of a branching system forming a network, similar to the anastomostic branching patterns of the upper reaches of a river (as contrasted with dendritic patterns). They typically exhibit the largest cross-sectional area in the center of the course and terminate over a relatively short distance in elevated outwash fans at the ice-margin.\n\nTunnel valleys are found to cross the regional gradient – as a result they may be crosscut by modern stream networks. In one example, tributaries of the Kalamazoo River cut at nearly right angles across buried tunnel channel filled with ice and debris. They frequently terminate at a recessional moraine. Tunnel valleys from successive glaciations may crosscut one another.\n\nTunnel valleys frequently run along roughly parallel courses. They originate in and run through regions which include clear evidence of glacial erosion through abrasion and may exhibit striations and roche moutonnée. Depositional forms such as terminal moraines and outwash fans are found at their terminal end. In Michigan tunnel valley channels have been observed to diverge slightly with an average spacing between the channels of and a standard deviation of . \nTunnel valley channels often start or stop abruptly. They have convex-up longitudinal profiles. They are often occupied by elongated lakes of underfit streams. They frequently show signs of subsequent depositions such as eskers.\n\nEvidence suggests that erosion in a tunnel valley is primarily the result of water flow. They erode by meltwater, which it has been argued, episodically drains in repeated jökulhlaups from subglacially stored lakes and reservoirs; examples of such motion have been observed in Antarctica. Although there is evidence of ice erosion such as linear striations in the bedrock, these are observed only in the widest valleys, and are believed to have played a secondary role.\n\nThe subglacial layout of valley tunnels/channels is predominantly oriented parallel to glacial ice flow lines – essentially they stretch from areas of thicker sheet ice toward areas of thinner sheet ice. They can exhibit reverse gradients, which result when pressurized meltwater flows over obstacles such as ridges or hills along the glacier bed.\n\nTunnel valleys can be formed under extremely thick glacial ice – examples have been observed on the bottom of Lake Superior and in the oceans offshore in Antarctica. The course of a tunnel valley typically runs from thickest glacial ice to the glacier margin; as a result the glacial ice pressurizes the water such that it runs uphill toward its end.\n\nAlthough there is agreement on the role of meltwater in creation of tunnel valleys, several theories are still under consideration for the role of that meltwater:\n\nPeriodic outbursts of subglacial water have been observed moving subglacial water between subglacial lakes beneath the East Antarctic Ice Sheet. Satellite data recorded a subglacial discharge totaling traveling ~ over a period of less than a year. As the flow subsided, the weight of ice closed the tunnel and sealed the lake again. The water flow was modeled satisfactorily with channeling in ice and in sediment. The analytic model shows that over some regions, the ice-bedrock geometry included sections which would have frozen, blocking off flow, unless erosion of the sedimentary substrate was the means of creating a channel and sustaining the discharge. Hence, combining this data and analysis with Icelandic jökulhlaup observations, there is experimental evidence that some form of the jökulhlaup hypothesis with features of the steady state model is correct.\n\nSubglacial meltwater flow is common to all theories; hence a key to understanding channel formation is an understanding of subglacial meltwater flow. Meltwater may be produced on the glacier surface (supraglacially), below the glacier (basally) or both. Meltwater may flow either supraglacially or basally as well; the signatures of supraglacial and basal water flow differ with the passage zone. Supraglacial flow is similar to stream flow in all surface environments – water flows from higher areas to lower areas under the influence of gravity. Basal flow exhibits significant differences. In basal flow the water, either produced by melting at the base or drawn downward from the surface by gravity, collects at the base of the glacier in ponds and lakes in a pocket overlain by hundreds of meters of ice. If there is no surface drainage path, water from surface melting will flow downward and collect in crevices in the ice, while water from basal melting will collect under the glacier; either source will form a subglacial lake. The hydraulic head of the water collected in a basal lake will increase as water drains through the ice until the pressure grows high enough to either develop a path through the ice or to float the ice above it.\n\nSources of water and water drainage routes through and below temperate and sub-polar glaciers are reasonably well understood and provide a basis for understanding tunnel valleys. For these glaciers, supraglacial water ponds or moves in rivers across the surface of the glacier until it drops down a vertical crevice (a moulin) in the glacier. There it joins subglacial water created by geothermal heat; some portion of the water drains into aquifers below the glacier. Excess subglacial water that cannot drain through sediment or impermeable bedrock as groundwater, moves either through channels eroded into the bed of sediment below the glacier (called Nye channels) or through channels upward into the glacial ice (called Rothlisberger channels), eventually flowing out at the ice margin. On the simplest level, the tunnel valley can be considered a larger-scale version of these phenomena.\n\nTunnel valleys or tunnel channels are produced by meltwater flows beneath glacial ice. Tunnel valleys are often buried or partially buried by sediment accumulation during periods of ice advance and retreat.\n\nAlthough attractive since it scales up the Nye channel formation which has been observed in sediments, a weakness of the steady state theory is that it requires that tunnel valleys be excavated in unconsolidated sediment, in which meltwater is initially forced through an initially narrow subglacial conduit. With progressive sediment erosion by the meltwater, ice deforms under its own weight into the cavity to creating an ever-larger tunnel valley. However the steady state theory appears not to account for erosion into bedrock, which has been extensively observed.\n\nThere is evidence that meltwater discharges are episodic. This can result because as water continues to collect, more ice is lifted, and the water moves outward in a growing under-ice lake. Areas where the ice is most easily lifted (i.e., areas with thinner overlying ice sheets) are lifted first. Hence the water may move up the terrain underlying the glacier if it moves toward areas of lower overlying ice. As water collects, additional ice is lifted until a release path is created.\n\nIf no preexisting channel is present, the water is initially released in a broad-front jökulhlaup which can have a flow front that is tens of kilometers wide, spreading out in a thin front. As the flow continues, it tends to erode the underlying materials and the overlying ice, creating a channel even as the reduced pressure allows most of the glacial ice to settle back to the underlying surface, sealing off the broad front release and channelizing the flow. The direction of the channel is defined primarily by the overlying ice thickness and secondarily by the gradient of the underlying earth, and may be observed to “run uphill” as the pressure of the ice forces the water to areas of lower ice coverage until it emerges at a glacial face. Hence the configuration of the various tunnel valleys formed by a specific glaciation provide a general mapping of the glacier thickness when the tunnel valleys were formed, particularly if the original surface relief under the glacier was limited.\n\nAnalyses by Piotrowski demonstrate that the annual production of water from one typical catchment of would normally drain through its associated tunnel valley in less than 48 hours. The debris found in tunnels and at the mouth of tunnels tends to be coarse rocks and boulders – this is indicative of high flow velocities and an extremely erosive environment. This erosive environment is consistent with creation of tunnels over deep and wide, as have been observed in the Antarctic. Piotrowski’s model predicts a cycle as follows: \n\nTunnel valleys have similar characteristics, irrespective of whether they are formed on land or in a submerged environment. This is because they are formed by high pressure water under a thick ice sheet – in a submerged environment they still have sufficient pressure to erode tunnel valleys into configurations comparable to those generated on land.\n\nTunnel valleys may remain open, partially filled or filled, as a function of the glacial recession. The filled configuration is significant because filled tunnel valleys become excellent reservoirs for either water (aquifer) or for oil. This results since relatively coarse-grained sandstones are located on the valley floors and valley margins and valley floor because the coarser-grained sediments settle out more easily and accumulate preferentially in the flowing water common to the tunnel valley fill stages.\n\nThe subglacial tunnel valley networks originally formed near the ice margin. Tunnel valleys are likely to fill with sediment as the result of meltwater release during glacial recession. Tunnel valleys fill in two main ways. In the first instance, debris carried by flow settles out and accumulates in the tunnel valley. Subsequently, once the ice has retreated sufficiently, marine deposits may be laid down, depending on the water depth at the ice front.\n\nThe tunnel valley sedimentary record is controlled by meltwater release flowrates and sediment burdens during glacial recession. The sediment found in the tunnel valley provides insight into whether it was laid down in a tidal environment, a transitional environment, or an essentially dry environment with good drainage. In the glaciomarine environment, glacially-related deposits are interbedded with to those similar to those on non-glaciated tidal areas; the tidal environment will show undertow dominated fans. The transitional environment is characterized by both mixed marine and fresh water life in a delta environment. In an essentially dry environment, the glacial flow carries sediment which accumulates much as it would in any stream bed.\n\nIce flow within glaciers results from an increase in the surface slope of the glacier, which result from geographic features combined with an imbalance between the amounts of ice accumulated through precipitation and lost through ablation. The increased gradient increases the shear stress on a glacier until it begins to flow. The flow velocity and deformation are also affected by the slope of the ice, the ice thickness and temperature.\n\nPunkari identified that continental ice sheets typically flow in fan-shaped lobes, which converge from separate sources and move at differing speeds. Lobes are separated by interlobate zones, which have thinner ice coverage. Water collects in this interlobate area. The hydraulic head (pressure) is lower in areas of thinner ice; hence subglacial water tends to converge on the interlobate joint. The separate lobes move at different speeds, generating friction at the ice boundary; the heat released melts ice to release additional water. The surface of the interlobate area is crevassed, allowing surface meltwater, which runs down the ice surface to the lower area, to penetrate into the ice. As a result, the ice-flow patterns and the debris accumulation are different in interlobate zones. Specifically, tunnel valleys and eskers indicate water flow toward the interlobate zones, which are elevated as the result of debris carried and deposited there.\n\nGlacially formed tunnel valleys have been identified on every continent.\n\nTunnel valleys associated with the Late Ordovician glaciation have been observed in north African countries, including Libya. These large-scale channel-fill sandstone bodies (tunnel valleys) are a striking sedimentological feature of the glacially related deposits on the old North Gondwanaland margin. They range from in depth, and wide. The tunnel valleys are incised into the bedrock and can be traced for in length. In one example, in Mauritania, in the western Sahara, Late Ordovician siliciclastic glacial features and deposits on the North Gondwana continental shelf include incised channels identified as tunnel valleys. The filled tunnel valley are several kilometers long and several hundred meters wide. Reconstructions conclude that these structures were located in glacier ice-margin regions; the cross-sections of the valleys are comparable to those confirmed to have formed glacially, the valleys end in outwash fans similar to tunnel valleys, and the infill is post-glacial typical of that observed for tunnel valleys.\n\nIn southern Africa a Permo-Carboniferous tunnel valley system has been identified in northern Cape Province, South Africa.\n\nThe active formation of tunnel valleys is observed in the present period beneath the Antarctic ice.\n\nDuring the late Ordovician, eastern Gondwana was covered with ice sheets. As a consequence, Jordan and Saudi Arabia exhibit regionally-extensive filled tunnel valley structures.\n\nOpen-pit gold mines near Kalgoorlie, Western Australia, expose an extensive network of glacially-eroded valleys filled with tillite and shale cut below the Late Paleozoic Pilbara ice sheet.\n\nTunnel valleys and related glacial impacts have been identified in Russia, Belarus, Ukraine, Poland, Germany, Northern France, the Netherlands, Belgium, Great Britain, Finland, Sweden, Denmark and Norway. They have been studied in detail in Denmark, north Germany and north Poland where the thick ice sheet of the Weichsel and earlier Glaciations, having flowed down from the mountains of Scandinavia, began to rise up the north-European slope, driven by the altitude of the glacial ice accumulation over Scandinavia. Their alignment indicates the direction of ice flow at the time of their formation. They are found extensively in the United Kingdom with several examples reported from Cheshire for example. They are also to be found under the North Sea.\n\nExamples of lakes formed in tunnel valleys include the Ruppiner See (a lake in Ostprignitz-Ruppin, Brandenburg), the Werbellinsee, and the Schwielochsee, all in Germany.\n\nOkanagan Lake is a large, deep ribbon lake in the Okanagan Valley of British Columbia which formed in a tunnel valley from the Okanogan lobe of the Cordilleran Ice Sheet. The lake is long, between wide, and has a surface area of . Northern Idaho and Montana show evidence of tunnel valley formation under the Purcell lobe and the Flathead Lobe of the Cordilleran Ice Sheet.\n\nTunnel valleys/channels in southeast Alberta form an interconnected, anabranching network comprising Sage Creek, the Lost River and the Milk River and generally drain southeast.\nTunnel valleys have been observed in Minnesota, Wisconsin and Michigan at the margins of the Laurentide Ice Sheet. Examples of bedrock tunnel valleys in Minnesota include River Warren Falls and several valleys which lie deep beneath till deposited by the glaciers which created them, but can be traced in many places by the Chain of Lakes in Minneapolis and lakes and dry valleys in St. Paul.\n\nThe Kawartha lakes of Ontario formed in the Late Wisconsinan glacial period. Ice melt from the Niagara Escarpment flowed through tunnel valleys beneath the ice expanded to form a west-to-east passage between the main Laurentide ice sheet and a mass of ice in the Lake Ontario basin.\n\nCedar Creek Canyon is a tunnel valley located in Allen County, Indiana. It is a very straight, narrow gorge about deep that contains part of the lower segment of Cedar Creek, the largest tributary of the St. Joseph River.\n\nIn the Laurentian Channel offshore eastern Canada, numerous tunnel valleys have been identified originating from the submerged valley of the St. Lawrence River, which is also of glacial origin. Seismic reflection profiles of the fill of tunnel valleys suggest that they are of various ages, with the youngest dating from shortly after the Late Glacial Maximum. They result from erosion by sub-glacial water crossing the eastern Scotian Shelf off Nova Scotia. They originate from the Laurentian Channel south of the Cabot Strait. Additionally, seismic profiles show deeply buried post-Miocene channels, some of which lie below modern sea level, cutting across the eastern part of the outer Laurentian Channel which have also tentatively been determined to be tunnel valleys. Seismic profiles have also mapped large tunnel valleys on Banquereau Bank and Sable Island Bank.\n\nThe Perito Moreno Glacier is located in the southern Southern Patagonian Ice Field, terminating in Lake Argentino at . It divides Lake Argentino into the Los Témpanos channel, and the Rico branch, blocking the channel and forming an ice dam. Lake Argentino periodically breaks through in outburst floods with drainage initially through a tunnel with subsequent roof collapse to form an open channel.\n\nThere have been five known ice ages in the Earth's history; the Earth is experiencing the Quaternary Ice Age during the present time. Tunnel valleys formed during four of the five have been identified.\n\n"}
{"id": "10228077", "url": "https://en.wikipedia.org/wiki?curid=10228077", "title": "UBIGEO", "text": "UBIGEO\n\nUbigeo is the coding system for geographical locations (Spanish: \"Código Ubicacíon Geográfica\") in Peru used by the National Statistics and Computing Institute (Spanish: \"Instituto Nacional de Estadística e Informática\" INEI) to code the first-level administrative subdivision: regions (Spanish: \"regiones\", singular: \"región\"), the second-level administrative subdivision: provinces (Spanish: \"provincias\", singular: \"provincia\") and the third-level administrative subdivision: districts (Spanish: \"distritos\", singular: \"distrito\").\n\nThe coding system uses two-digit numbers for each level of subdivision. The first level starts numbering at codice_1 for the Amazonas Region and continues in alphabetical order up to codice_2 for the Ucayali Region. Additional regions will be added to the end of the list, starting with the first available number.\n\nThe second level starts with codice_3 for the first province in the Amazonas region: Chachapoyas Province and continues up to codice_4 for the last province Purús in the Ucayali Region. The provinces are numbered per region with the first province always being the one in which the regions capital is located. The remaining provinces are coded in alphabetical order. Additional provinces will be added per region to the end of the list, starting with the first available province number.\n\nThe third level; starts with codice_5 for the first district in the first province in the Amazonas region: Chachapoyas District and continues up to codice_6 for the last district in the last province of the Ucayali region: Purús District. The districts are numbered per province with the first district always being the one in which the province’ capital is located. The remaining districts are coded in alphabetical order. Additional districts will be added per province to the end of the list, starting with the first available district number.\n\n\n\n\n\n"}
{"id": "53679177", "url": "https://en.wikipedia.org/wiki?curid=53679177", "title": "Valdivia Expedition", "text": "Valdivia Expedition\n\nThe Valdivia Expedition, or \"Deutschen Tiefsee-Expedition\" (German Deep Sea Expedition), was a scientific expedition organised and funded by the German Empire under Kaiser Wilhelm II and was named after the ship which was bought and outfitted for the expedition, the SS Valdivia. It was led by the marine biologist Carl Chun and the expedition ran from 1898-1899 with the purpose of exploring the depths of the oceans below 500 fathoms, which had not been explored by the earlier Challenger Expedition.\n\nThe Challenger Expedition was the expedition that established modern Oceanography, prompting many other expeditions which were either nationally and privately funded which would dredge the deep-sea in search of new and exotic species. This late 19th Century fascination with organisms found at great depths was unsurprising, because in the mid-19th century most scientists followed Abyssal Theory which stated that it was not possible for life to exist below 300 fathoms depth. Carl Chun, a famed teuthologist, held had a deep conviction that there must be life, in abundance, which existed in the unknown abyssal regions of the oceans, a belief he shared with an increasingly large number of marine scientists. This conviction along with his desire to further explore the areas of the oceans which were not covered by the Challenger Expedition that led him to propose that the German Empire organise its own expedition which was to be nationally funded with the approval of the Kaiser.\n\nChun proposed to the \"Gesellschaft Deutscher Naturforscher und Ärzte\" (Society of German Naturalists and Doctors ), which was the German equivalent of the Royal Society, that a German deep sea expedition be funded and equipped to explore the deep oceans. His proposal was well received and a resolution to approve the plan and recommend it to the German government was unanimously adopted on 24 September 1897. It was originally conceived as purely zoological expedition but Friedrich Ratzel suggested that chemical and physical observations be included in the expedition's remit and this was accepted. The German government approved the proposal and granted the expedition 300,000 marks in initial funding with promises of further grants to cover the expenses of the expedition and the publication costs of its findings.\n\nThe ship, the \"SS Valdivia\", was chartered from the \"Hamburg-Amerikanischen Packetfahrt-Actien-Gesellschaft\" (HAPAG), which fitted the ship out with equipment such as dredging gear, specimen jars, deep sea traps and oceanographic equipment, also outfitting the laboratories, while also providing the crew and provisions, all for a sum equivalent to £17,000, a sum which covered the company's expenses but did not allow for any profit.\n\nChun was the overall leader of the expedition. A captain of whaling ships, Adalbert Krech, was appointed the ship's captain while the navigator was a Herr Sachse who was an employee of HAPAG's. The scientific staff was made up of the botanist Professor W. Schimper of Bonn, the zoologists Carl Apstein, Ernst Vanhöffen and Fritz Braem, the oceanographer Gerhardt Schott, the chemist Paul Schmidt and Dr M. Bathman who was a bacteriologist and the ship's doctor, who died on the voyage. August Brauer and Otto zur Strassen who were zoologists by profession and Fritz Winter who was an artist and photographer, but these had no official status recorded.\n\nThe \"Valdivia\" set sail from Hamburg on 1 August 1898 and made its first call into the harbour of Granton, Edinburgh, where the scientists visited the offices of \"The Challenger\" Expedition Commission and were entertained by Sir John Murray. The expedition then sailed north, entering the Atlantic between the Faroe Islands and the Shetland Islands and then turning south towards the Canary Islands and the west coast of Africa, reaching Cape Town on the 26th August. They then explored a major part of the Indian Ocean and the Antarctic Ocean, covering a total of 32,000 nautical miles.\n\nThe \"Valdivia\" was among the Antarctic ice for almost four weeks in November and December 1898 in the sea between Bouvet Island, which was rediscovered by the expedition, and Enderby Land. During this time the crew observed around 180 icebergs many of which they sketched and photographed, however as the \"Valdivia\" was an ordinary steel hulled vessel the ship had to remain clear of the pack ice. As well as the biological, geological and geographic findings the expedition was also able to make significant meteorological observations.\n\nThe \"Valdivia\" returned to Hamburg on 30 April 1899.\n\nThe main aims of the expedition were to collect as many biological specimens as they could while focussing on how organisms adapted to the extreme conditions of the environment of the deep oceans. One result of this was that a number anatomical studies of light organs were carried out. One of the best known publications is \"Volume 15: Die Tiefsee-Fische\" by Brauer which has an editorial review by Chun consisting of a systematic and anatomical study of the deep sea fish specimens they collected on their voyage aboard the \"Valvidia\" which were illustrated by Friedrich Wilhelm Winter. Winter's illustrations make it clear that these deep sea fish are heavily reliant on senses other than their vision. Many are bioluminescent and in numbers these animals have the effect of making the deep, dark sea look like a night sky filled with stars.\n\nThe expeditions findings took 4 decades to be published, and they were published in 24 volumes as \"Wissenschaftliche Ergebnisse der Deutschen Tiefsee-Expedition auf dem Dampfer \"Valdivia\" 1898-1899\" (Scientific results of the German deep-sea expedition on the steamer \"Valdivia\" 1898-1899). Another much admired volume is Chun's own \"Die Cephalopoden\" in which Chun describes the vampire squid \"Vampyroteuthis infernalis\" the scientific name meaning \"the vampire squid from hell\". The type specimen was collected on the expedition.\n\nHere is a sample of some of the plates from \"Wissenschaftliche Ergebnisse der Deutschen Tiefsee-Expedition auf dem Dampfer \"Valdivia\" 1898-1899\":\n"}
{"id": "16649339", "url": "https://en.wikipedia.org/wiki?curid=16649339", "title": "Wedge prism", "text": "Wedge prism\n\nThe wedge prism is a prism with a shallow angle between its input and output surfaces. This angle is usually 3 degrees or less. Refraction at the surfaces causes the prism to deflect light by a fixed angle. When viewing a scene through such a prism, objects will appear to be offset by an amount that varies with their distance from the prism.\n\nFor a wedge prism in air, rays of light passing through the prism are deflected by the angle δ, which is approximately given by\nwhere \"n\" is the index of refraction of the prism material, and α is the angle between the prism's surfaces.\n\nThe term \"optical wedge\" refers to any shallow angle between two plane surfaces of a window. This wedge may range from a few millionths of a degree of perfect parallelism to as much as three degrees of angle. Even though high-precision optics, such as optical flats, may be lapped and polished to extremely high levels of parallelism, nearly all optics with parallel faces have some slight wedge. This margin of error is usually listed in minutes or seconds of arc. Windows manufactured with an intentional wedge are often referred to as wedge prisms, and typically come with wedge angles of one, two, or three degrees. Many applications exist for wedge prisms, including laser-beam steering, rangefinding and variable focusing.\n\nA pair of wedge prisms, called a Risley prism pair, can be used for beam steering. In this case, rotating one wedge in relation to the other will change the direction of the beam. When the wedges angle in the same direction, the angle of the refracted beam becomes greater. When the wedges are rotated to angle in opposite directions, they cancel each other out, and the beam is allowed to pass straight through.\n\nMoving a wedge either closer or farther away from the laser can also be used to steer the beam. When the wedge is moved closer to the target (farther away from the laser), the refracted beam will move across the target. When two wedges in opposite directions slide relative to each other they can be used to provide variable focusing for cameras, allowing objects at vastly different distances to be photographed, in focus, at the same focal plane. This method is common in aerial or space launch-vehicle photography, when the distance to the object is changing very rapidly. Wedges were sometimes used in rangefinding, by combining the image formed by one telescope with the image formed by another.\n\nThe wedge prism is primarily used in a similar manner as an angle gauge in variable-radius plot sampling. In this type of sampling, the wedge prism is used to estimate basal area of a group of trees by counting trees which are \"in\" or \"out\" of a plot centered on a single point. Because the wedge prism refracts light to offset the object of interest (e.g. a tree), it can be used to determine whether or not the tree should be counted from a given point, based on the diameter at breast height of the tree and its distance from that point.\n\nIn this type of sampling, the prism is held a comfortable distance away from the eye with the bottom edge parallel to the ground, and trees are sighted through the prism approximately 4.5 ft. above the ground. A tree is an \"in\" tree if the offset section of the tree overlaps the bole as viewed without the prism (Figure 1). A tree where the offset section of the trunk is perfectly aligned with the original bole is a borderline tree (Figure 2) and DBH must be measured to determine if it should be counted (or, more commonly in practice, every other borderline tree is counted). A tree where the offset section of the tree does not overlap or touch the original bole is an \"out\" tree (Figure 3) and is not counted.\n\nBasal area is estimated by multiplying the count of \"in\" trees at a given point by the 'factor' of the prism. Prism factor is based on the angle of the prism, and prisms are available in different factors, expressed in both square feet/acre (5, 10, 20 BAF are most common) and square meters/hectare (1-5 BAF are common). Prism size is chosen to yield a statistically valid estimate of basal area - 6-10 \"in\" trees per plot are required, which requires a prism of the proper factor depending on the size of the trees being cruised. Larger trees will be \"in\" from further away, and a larger factor prism (20 or 30 ft/ac, 5–8 m/ha) can be used. Smaller trees will be \"out\" in a larger factor prism unless they are very close, and consequently a smaller factor prism must be used.\n\nImportantly, the bottom edge of the prism must be roughly parallel to the ground in order to provide an accurate estimate on sloped ground. Wedge prisms can be difficult to use in wet conditions due to the effect water droplets have on the optical properties of the glass. Wedge prisms come in different colors such as clear or amber. The amber provides the same function as the clear wedge prism, only it reduces glare and is easier to use on overcast or cloudy days. Operating a wedge prism is one technique used in forestry today because the wedge prism is simple, relatively inexpensive, portable, and as accurate as other angle gauges when properly calibrated and used properly. One simply holds the prism directly over the plot center, and by focusing on a tree, the refracted light will offset the trunk of the tree. The wedge prism is used to take measurements in both land management and in timber procurement. Other tools often used to accompany the wedge prism in taking forest inventory are clinometers, Biltmore sticks, relascopes, and Diameter Tapes.\n\nA wedge prism can also be used with a target placed at plot center, to establish fixed radius plots. In this function, the size of the target is carefully calibrated to the desired plot size, and the plot is defined as all the area in which the target is \"in\" as viewed through the prism.\n"}
{"id": "5322293", "url": "https://en.wikipedia.org/wiki?curid=5322293", "title": "Western Australia border", "text": "Western Australia border\n\nThe Western Australian border was originally designated as 129th meridian east longitude (129° east). However, the border marked on the ground is some distance from this line. Kununurra is the closest town to the Western Australian border, being about 25 km west of the border. The closest settlement is Border Village, 1,734 km to the south on the South Australian side of the border, on Eyre Highway.\n\nThe Western Australian (WA) border marked on the ground, is not as straight as it looks on a map. The Northern Territory border with Western Australia and the South Australian border with Western Australia are displaced east–west by approximately 127 metres, due to errors within the limits of surveying technology available in the 1920s.\n\nWhere Western Australia meets the Northern Territory (NT) and South Australia (SA) borders is a 127-metre segment running east–west along the 26th parallel south latitude (26° south).\n\nIn June 1968, two monuments were erected to mark each end of this 127-metre segment, At the easternmost of these concrete border markers all three borders meet, at Surveyor Generals Corner.\n\nIn 1788 Governor Phillip claimed the continent of Australia only as far west as the 135th meridian east (135° east) in accordance with his commission. (26 January 1788 – MAP)\n\nIt has been suggested that the 1788 claim by the British of 135° east was in reference to Spain's claims under the Treaty of Tordesillas. Spain was seen as no longer having an interest in the area. On the other hand, the other signatories to the treaty, the Portuguese still had a presence in Macau and East Timor. Adoption of 135° east as a boundary would minimise provocation of the Portuguese. By 1825, however, Britain was powerful enough and found it convenient to adopt the original line of the Portuguese under the treaty, 129° east.\n\nThe line of 129° east first became a border in Australia as the western border of New South Wales (NSW) in 1825 (16 July 1825 – MAP).\n\nOn 16 July 1825, the western boundary of New South Wales was relocated at 129° east to take in the new settlement at Melville Island.\n\nFrom 1825 to 1829 129° east was the NSW border, except that the settlement of King George's Sound, now Albany, was part of New South Wales from its establishment on 26 December 1826, until 7 March 1831 when it was made part of the Swan River Colony.\n\nFollowing the settlement of the Swan River Colony (SRC) in 1829 (2 May 1829 – MAP), the eastern boundary was declared to be 129° east, that is coinciding with the western boundary of New South Wales at the time.\n\nThe Swan River Colony, started in 1829, was commissioned as the colony of Western Australia in March 1831.\n\nFrom 1829 to 1832 129° east was the SRC/NSW border.\n\nThe name of the Swan River Colony changed to Western Australia in 1832 (6 February 1832 – MAP).\n\nFrom 1832 to 1846 129° east was the WA/NSW border.\n\nIn 1846 the colony of North Australia (NA) was proclaimed by Letters Patent, which was all of New South Wales north of 26° south. (17 February 1846 – Map).\n\nFrom 1846 to 1847 129° east was the WA/NA border north of 26° south and the WA/NSW border south of the 26th parallel.\n\nIn 1847 the colony of North Australia was revoked and reincorporated into New South Wales. (15 April 1847 – MAP).\n\nFrom 1847 to 1860 129° east was once again the WA/NSW border.\n\nIn 1860 South Australia, which had been proclaimed a colony in 1836 (28 December 1836 – MAP), west to the 132° east, changed their western border from 132° east to 129° east (1860 – MAP).\n\nFrom 1860 to 1863 129° east was the WA/NSW border north of 26° south and the WA/SA border south of the 26th parallel.\n\nIn 1863 that part of New South Wales to the north of South Australia was annexed to South Australia by Letters Patent and became known as the Northern Territory of South Australia (NToSA). (6 July 1863 – MAP).\n\nFrom 1863 to 1911 129° east was the WA/NToSA border north of 26° south and the WA/SA border south of the 26th parallel\n\nIn 1911 the Northern Territory (NT) was split off from South Australia to be administered by the Commonwealth. (1 January 1911 – MAP).\n\nFrom 1911 to 1927 129° east was the WA/NT border north of 26° south and the WA/SA border south of the 26th parallel.\n\nIn 1927 the Northern Territory was split into two territories, North Australia (NA) and Central Australia (CA). (1 March 1927 – MAP).\n\nFrom 1927 to 1931 129° east was once again the WA/NA border and WA/CA border, both north of 26° south and the WA/SA border south of the 26th parallel.\n\nIn 1931 North Australia and Central Australia were reunited as the Northern Territory.\n(12 June 1931 – MAP).\n\nFrom 1931 to the present 129° east has been the WA/NT border north of 26° south and the WA/SA border south of the 26th parallel.\n\nFixing the position of the border of Western Australia on the ground has a rich history. In March 1920 the Western Australian Government Astronomer, H. B. Curlewis gave a talk at the WA Museum about the history of the determination of longitude, in relation to using what was at that time a new technology, by using wireless time signals to determine the position of the border between South Australia and Western Australia, as close to the 129th east meridian as possible.\n\nPreliminary work on the border determinations began in November 1920 when the Government Astronomer for South Australia, G.F. Dodwell and the Government Astronomer of Western Australia, H.B. Curlewis met at Deakin, Western Australia on the East-West Trans-Australian Railway.\n\nThe other members of the party were Messrs. Clive Melville Hambidge and J. Crabb, of the Survey Department; Warrant Officer V. D. Bowen, in charge of wireless apparatus lent by the Defence Department; and Mr. C. A. Maddern, of the Adelaide Observatory, all from Adelaide.\n\nConcrete piers for the astronomical observing instruments were erected in readiness for the final determinations that were to be held in 1921. Observations were made for the purpose of testing under field conditions the instruments and methods to be used in 1921.\n\nThis expedition, to determine 129° east on the ground, created worldwide scientific interest and involved the cooperation of the Astronomer Royal and the Royal Observatory, Greenwich, with wireless time signals sent by the French wireless Service, that were transmitted from the at Saint-Genis-Laval, near Lyons, France, between 17 and 24 November 1920. Wireless time signals were also sent from the Adelaide Observatory, transmitted by the Adelaide Radio Station, to enable the beats of the Adelaide sidereal clock to be used as a control on the rate of the chronometer used for the boundary observation.\n\nAfter these initial tests a comprehensive program was then arranged for the second stage of the border determinations, which were to take place during the following year and dates were then set for that to happen, from 20 April to 10 May 1921.\n\nOne of the concrete piers mentioned, which were cubic concrete blocks slightly smaller than a cubic metre, would later be named as the Deakin Pillar (1921), being from where the larger border marker, the Deakin Obelisk (1926), would be set out from.\n\nThe Deakin Pillar is approximately 2.82 km west of the Deakin Obelisk. The Deakin Obelisk was erected as closely as was possible with the technology of 1926 to 129° east.\n\nThe Deakin Obelisk has a copper plug embedded into the top centre of the concrete obelisk, which determines, on the ground, the South Australian border with Western Australia by a line drawn south to the coastline of the Great Australian Bight and north through this point to 26° south.\n\nShortly after the 1921 determinations of the border of South Australia and Western Australia, the Government Astronomer for South Australia, G.F. Dodwell and the Government Astronomer of Western Australia, H.B. Curlewis and party travelled by the State Ship Bambra to the port of Wyndham, Western Australia.\nFrom Wyndham they were guided by Michael Patrick (\"M.P.\") Durack to a point he perceived as the northern boundary between his Argyle Downs Station and Jack Kilfoyle's Rosewood Station, which was also Western Australia's border with the Northern Territory or 129° east. Most of Rosewood station is in the Northern Territory but some distance further south Rosewood also extends into the East Kimberley Region of Western Australia.\n\nFrom the chosen position, two concrete pillars were erected similar to those described above and portable radio masts set up, before the determinations were carried out by the scientists using the same methods of wireless time signals as were used at Deakin.\n\nOne of the concrete pillars erected, which was the one used as the point of the determinations, was marked by the expedition party to show how far east of Greenwich they were in hours, minutes and seconds, and became known as the Austral Pillar.\n\nThe Austral Pillar, the point selected for the scientific determinations of 1921 would later be found to be about 2 km east from the border of 129° east on that part of Rosewood Station, therefore inside the Northern Territory.\n\nThe Kimberley Obelisk was erected as closely as was possible with the technology of 1927 to 129° east. Over several weeks during 1927, a Western Australian survey crew from the WA Department of Lands and Surveys travelled to Wyndham, then to the Austral Pillar site to set out from that point to the border, where they then erected the much more substantial Kimberley Obelisk.\n\nThe Kimberley Obelisk has a copper plug embedded into the top of the concrete obelisk, which officially determines the WA/NT border on the ground, near 129° east, by a line drawn north to the northern coastline near the Joseph Bonaparte Gulf and south through this point at the Kimberley Obelisk to the 26th parallel.\n\n"}
