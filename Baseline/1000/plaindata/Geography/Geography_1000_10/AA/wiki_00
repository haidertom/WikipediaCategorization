{"id": "32452818", "url": "https://en.wikipedia.org/wiki?curid=32452818", "title": "America – The Freedom to Be", "text": "America – The Freedom to Be\n\nAmerica – The Freedom to Be was a thirteen-part German educational television series teaching the English language with an American and Canadian theme. Produced by WDR, the program is an extension of its \"Fast Track English\" series.\n\n"}
{"id": "1485232", "url": "https://en.wikipedia.org/wiki?curid=1485232", "title": "Baseline (surveying)", "text": "Baseline (surveying)\n\nIn surveying, a baseline is a line between two points on the earth's surface and the direction and distance between them. In a triangulation network, at least one baseline needs to be measured to calculate the size of the triangles by trigonometry.\n\nIn the United States Public Land Survey System, a baseline is the principal east-west line (i.e., a parallel) upon which all rectangular surveys in a defined area are based. The baseline meets its corresponding principal meridian at the point of origin, or \"initial point\", for the land survey. For example, the baseline for Nebraska and Kansas is shared as the border for both states, at the 40th parallel north.\n\nMore specifically a baseline may be the line that divides a survey township between north and south.\n\nMany communities in the United States have roads that run along survey baselines, many of which are named to reflect that fact. Some examples:\n\n\nIn Canadian land surveying, a base line is one of the many principal east-west lines that correspond to four tiers of townships (two tiers north and two south). The base lines are about apart, with the first base line at the 49th parallel, the western Canada–US border. It is, therefore equivalent to the \"standard parallel\" in the US system. In Ontario, a baseline forms a straight line parallel a geographical feature (mostly a lake, especially Lake Ontario or Lake Erie) that serves as a reference line for surveying a grid of property lots. The result of this surveying is the concession road and sideline system in use today.\n\n\n"}
{"id": "58891080", "url": "https://en.wikipedia.org/wiki?curid=58891080", "title": "Chak Alampur", "text": "Chak Alampur\n\nChak Alampur is a town in Budge Budge II CD Block of South 24 Parganas district in the Indian State of West Bengal. Budge Budge\npolice station serves this town.\n\nChak Alampur town is located at . It has an average elevation of .\n"}
{"id": "1527098", "url": "https://en.wikipedia.org/wiki?curid=1527098", "title": "Clairaut's theorem", "text": "Clairaut's theorem\n\nClairaut's theorem is a general mathematical law giving the surface gravity on a viscous rotating ellipsoid in equilibrium under the action of its gravitational field and centrifugal force. It was published in 1743 by Alexis Claude Clairaut in his \"Théorie de la figure de la terre, tirée des principes de l'hydrostatique\" (\"Theory of the shape of the earth, drawn from the principles of hydrostatics\") which synthesized physical and geodetic evidence that the Earth is an oblate rotational ellipsoid. It was initially used to relate the gravity at any point on the Earth's surface to the position of that point, allowing the ellipticity of the Earth to be calculated from measurements of gravity at different latitudes. Today it has been largely supplanted by the Somigliana equation.\n\nAlthough it had been known since antiquity that the Earth was spherical, by the 17th century evidence was accumulating that it was not a perfect sphere. In 1672 Jean Richer found the first evidence that gravity was not constant over the Earth (as it would be if the Earth were a sphere); he took a pendulum clock to Cayenne, French Guiana and found that it lost minutes per day compared to its rate at Paris. This indicated the acceleration of gravity was less at Cayenne than at Paris. Pendulum gravimeters began to be taken on voyages to remote parts of the world, and it was slowly discovered that gravity increases smoothly with increasing latitude, gravitational acceleration being about 0.5% greater at the poles than at the equator.\n\nBritish physicist Isaac Newton explained this in his \"Principia Mathematica\" (1687) in which he outlined his theory and calculations on the shape of the Earth. Newton theorized correctly that the Earth was not precisely a sphere but had an oblate ellipsoidal shape, slightly flattened at the poles due to the centrifugal force of its rotation. Since the surface of the Earth is closer to its center at the poles than at the equator, gravity is stronger there. Using geometric calculations, he gave a concrete argument as to the hypothetical ellipsoid shape of the Earth.\n\nThe goal of \"Principia\" was not to provide exact answer for natural phenomena, but to theorize potential solutions to these unresolved factors in science. Newton pushed for scientists to look further into the unexplained variables. Two prominent researchers that he inspired were Alexis Clairaut and Pierre Louis Maupertuis. They both sought to prove the validity of Newton's theory on the shape of the Earth. In order to do so, they went on an expedition to Lapland in an attempt to accurately measure the meridian arc. From such measurements they could calculate the eccentricity of the Earth, its degree of departure from a perfect sphere. Clairaut confirmed that Newton's theory that the Earth was ellipsoidal was correct, but his calculations were in error, and wrote a letter to the Royal Society of London with his findings. The society published an article in Philosophical Transactions the following year in 1737 that revealed his discovery. Clairaut showed how Newton's equations were incorrect, and did not prove an ellipsoid shape to the Earth. However, he corrected problems with the theory, that in effect would prove Newton's theory correct. Clairaut believed that Newton had reasons for choosing the shape that he did, but he did not support it in \"Principia.\" Clairaut's article did not provide an valid equation to back up his argument as well. This created much controversy in the scientific community.\n\nIt was not until Clairaut wrote \"Théorie de la figure de la terre\" in 1743 that a proper answer was provided. In it, he promulgated what is more formally known today as Clairaut's theorem.\n\nClairaut's formula for the acceleration due to gravity \"g\" on the surface of a spheroid at latitude φ, was:\n\nwhere formula_2 is the value of the acceleration of gravity at the equator, \"m\" the ratio of the centrifugal force to gravity at the equator, and \"f\" the flattening of a meridian section of the earth, defined as:\n(where \"a\" = semimajor axis, \"b\" = semiminor axis).\n\nClairaut derived the formula under the assumption that the body was composed of concentric coaxial spheroidal layers of constant density. \nThis work was subsequently pursued by Laplace, who relaxed the initial assumption that surfaces of equal density were spheroids.\nStokes showed in 1849 that the theorem applied to any law of density so long as the external surface is a spheroid of equilibrium. A history of the subject, and more detailed equations for \"g\" can be found in Khan.\n\nThe above expression for \"g\" has been supplanted by the Somigliana equation (after Carlo Somigliana):\n\nwhere,\n\nFor Earth, formula_2 = 9.7803253359 ms; formula_9 = 9.8321849378 ms; \"k\" = 0.00193185265241 ; \"e\" = 0.00669437999013: \n\nThe spheroidal shape of the Earth is the result of the interplay between gravity and centrifugal force caused by the Earth's rotation about its axis. In his \"Principia\", Newton proposed the equilibrium shape of a homogeneous rotating Earth was a rotational ellipsoid with a flattening \"f\" given by 1/230. As a result, gravity increases from the equator to the poles. By applying Clairaut's theorem, Laplace found from 15 gravity values that \"f\" = 1/330. A modern estimate is 1/298.25642. See Figure of the Earth for more detail.\n\nFor a detailed account of the construction of the reference Earth model of geodesy, see Chatfield.\n"}
{"id": "2884986", "url": "https://en.wikipedia.org/wiki?curid=2884986", "title": "Ex-meridian", "text": "Ex-meridian\n\nEx-meridian is a celestial navigation method of calculating an observer’s position on Earth. The method gives the observer a position line on which the observer is situated. It is usually used when the Sun is obscured at noon, and as a result, a meridian altitude is not possible. The navigator measures the altitude of the Sun as close to noon as possible and then calculates where the position line lies.\n\nThis method uses an assumed longitude and calculates the latitude that a position line crosses it. The position line obtained is actually part of a small circle, as opposed to great circle, where any observer can stand and the heavenly object would have the same altitude in the sky. When plotting the small segment of this circle on a chart it is drawn as a straight line, the resulting tiny errors are too small to be significant.\n\nThe assumed longitude is usually obtained from the DR or Dead Reckoning position run up from a morning sight taken at around 9.00 am. This is worked out by applying the distance from that position either by log or by the estimated speed over time with the course steered. A sight is taken, that is the distance above the horizon of a heavenly object, in this case nearly always the sun, is measured with a sextant and the exact time noted in UTC. The sextant angle obtained is corrected for dip (the error caused by the observers height above the sea) and refraction to obtain the true altitude of the object above the horizon. This is then subtracted from 90° to obtain the angular distance from the position directly above, the zenith. This is referred to as the True Zenith Distance. The true zenith distance of the object is also the distance (in arc) on the Earth's surface from the observer to where that object is overhead, the geographical position of the object.\n\nUsing a nautical almanac, the declination (celestial latitude), and the Greenwich hour angle (celestial longitude) are obtained of the observed object for the time of observation. The assumed longitude is now added or subtracted to the Greenwich Hour Angle of the object to obtain the local hour angle, that is the difference in longitude between the DR position and the geographical position of the object.\n\nWith this information it is possible using the haversine formula to calculate the latitude where the position line crosses the assumed longitude. The formula is:\n\nformula_1\n\nWhere\n\nformula_2 = Meridian Zenith Distance\n\nformula_3 = True Zenith Distance\n\nformula_4 = Local Hour Angle\n\nformula_5 = DR Latitude\n\nformula_6 = Declination\n\nOnce the value of the Meridian Zenith Distance is obtained the algebraic sum of it with the declination of the object gives the latitude of a point where the position line crosses the meridian of DR longitude.\n\nTo draw the position line on a chart the azimuth or bearing of the heavenly object must be known. It is usually calculated but could have been observed. A line at right angles to the azimuth is drawn through the calculated position which is where the calculated latitude and the DR longitude cross. The observer is somewhere on this line.\n\nTo obtain a fix (a position) this line must be crossed with another position line either from another sight or from elsewhere. In the case of ex-meridian the position line is usually crossed with the position line obtained earlier which has been run up.\n\nThe first of these tables applies corrections to the altitude taken with the argument of \"Change of Altitude in one minute from Meridian Passage\". Two other tables apply more corrections until the correct latitude is arrived at. \n\nThe Ex-Meridian method of calculating sights is at its most accurate when the azimuth of the object is near to south or north. As the azimuth changes towards the east or west the cross of the position line with the assumed longitude becomes more and more oblique and the position obtained is therefore less accurate. For this reason it is a less versatile method of calculating sights than the intercept method which can be used for all azimuths. The tables are a quick and easy way to correct the altitude when the object is fairly low in the sky and the observer has only missed noon by a few minutes but if noon has been missed by more than that or the sun is high in the sky it is better to work out a sight by the intercept method.\n\n\n"}
{"id": "24490545", "url": "https://en.wikipedia.org/wiki?curid=24490545", "title": "Exploration of North America", "text": "Exploration of North America\n\nThe exploration of North America by non-indigenous people was a continuing effort to map and explore the continent of North America. It spanned centuries, and consisted of efforts by numerous people and expeditions from various foreign countries to map the continent. The European colonization of the Americas followed.\n\nAccording to the Sagas of Icelanders, Norse sailors (often called Vikings) from Iceland first settled Greenland in the 980s. Erik the Red explored and settled southwestern Greenland, which he named to entice potential Icelandic settlers, eventually establishing the Eastern and Western Settlements, which were abandoned around 1350.\n\nL'Anse aux Meadows, an archaeological site on the northernmost tip of Newfoundland, and a second site in southwestern Newfoundland, are the only known sites of a Norse village in North America outside of Greenland. These sites are notable for their possible connections with the attempted colony of Vinland established by Leif Erikson in 1003.\n\nThe Viking voyages did not become common knowledge in the Old World, and Europeans remained unaware of the existence of the Americas as a whole, until the first decades following the year 1492. Many expeditions were launched from European nations in search of a Northwest Passage to East Asia (or \"the Indies\" as the region was called) in order to establish a shorter trade route to China than the Silk Road, a trade route which had become desperately needed and yet exacerbated by the Fall of Constantinople. Also, the Castilian crown needed an alternative to the Portuguese controlled eastern maritime trade route around Africa to India and East Asia.\nOn August 3, 1492, Christopher Columbus set sail from the Port of Palos de la Frontera in the Province of Huelva, from the newly \"los Reyes Católicos\" coordinated Kingdoms of Castile and Aragon, in present-day Spain, financed by Queen Isabella I of Castille. Columbus's Letter on the First Voyage of his discovery of the Bahamas, Cuba, and Hispaniola spread the news across Europe quickly. Columbus rediscovered and explored much of the Lesser Antilles in his second voyage then discovered both Trinidad and Tobago on his third voyage whilst skirting the northern South American coast. His fourth voyage was spent scanning the Central American coast. The Voyages of Christopher Columbus opened the New World.\n\nItalian navigator and explorer Giovanni Caboto (known in English as John Cabot) is credited with the discovery of continental North America on June 24, 1497, under the commission of Henry VII of England. Though the exact location of his discovery remains disputed, the Canadian and United Kingdom governments' official position is that he landed on the island of Newfoundland. The English presence through Giovanni Caboto was signaled in Juan de la Cosa's map of 1500.\n\nIn 1499 João Fernandes Lavrador was licensed by the King of Manuel I of Portugal and together with Pêro de Barcelos they reached Greenland and sighted Labrador for the first time since Leif Erikson, which was granted and named after Lavrador. After returning he possibly went to Bristol to sail in the name of England. Nearly at the same time, between 1499 and 1502 the brothers Gaspar and Miguel Corte Real explored and named the coasts of Greenland, Labrador and also Newfoundland, naming \"Terra Verde\" the explored North American coasts. Both explorations were signaled in 1502 Cantino planisphere.\n\nIt was soon understood that Columbus had not reached Asia, but rather found what was to Europeans a New World, which in 1507 was named \"America\", probably after Amerigo Vespucci, on the Waldseemüller map.\n\nIn 1500, Pedro Álvares Cabral was sent by Portugal to explore South America. He is considered to be the discoverer of Brazil.\n\nAragon King Ferdinand II sent Juan Ponce de León from the fledgling colony on Hispaniola to verify rumors of undiscovered land to the northwest. On April 2, 1513, Ponce de León disembarked on the northeast coast of what he named Florida for the crown. The exact location is disputed, but historians have offered the possibilities of St. Augustine, Ponce de León Inlet, and Melbourne Beach. He encountered the powerful Gulf Stream and found a passage through the Florida Keys to land on the southwestern Gulf Coast of Florida on the Gulf of Mexico. Again, the exact location is disputed. While it is true that Columbus visited Puerto Rico and the Virgin Islands in 1493, Ponce de Leon was the first known European to reach the present-day United States mainland.\n\nOn September 25, 1513, Spanish conquistador Vasco Núñez de Balboa was the first European to see the Pacific Ocean once he crossed the Isthmus of Panama. He claimed all the territory touching it for the Crown, later to affect colonization of Las Californias.\n\nAround 1519-1521, Portuguese explorer João Álvares Fagundes explored the coasts of Newfoundland, Labrador and Nova Scotia, with a mission to create colonies.\n\nIn 1524, Italian explorer Giovanni da Verrazzano sailed for King Francis I of France and is known as the first European since the Norse to explore the Atlantic coast of North America. Arriving near the Cape Fear River delta, he explored the coastlines of present-day states of South Carolina and North Carolina, entering the Pamlico Sound, and bypassing entrances to the Chesapeake Bay. Believing the New York Harbor to be a lake, he sailed past Long Island, exploring Narragansett Bay and Newfoundland.\n\nIn 1524-1525, Portuguese explorer Estevão Gomes, on behalf of Charles I of Spain, explored present-day Nova Scotia sailing South along the Maine coast. Gomes entered New York Harbor and saw the Hudson River(which he named the \"San Antonio River\"). Because of his expedition, the 1529 Diogo Ribeiro world map outlines the East coast of North America almost perfectly.\n\nIn 1534, Jacques Cartier planted a cross in the Gaspé Peninsula, on the Gulf Gulf of Saint Lawrence and claimed the land in the name of Francis I. In 1535 Cartier explored the St. Lawrence river and also claimed the region for France.\nAfter two failed attempts to reach East Asia by circumnavigating Siberia, Henry Hudson sailed west in 1609 under the Dutch East India Company. He, too, passed Cape Cod, Chesapeake Bay and the Delaware Bay, instead sailing up the Hudson River on September 11, 1609 in search of a fabled connection to the Pacific via what was actually the Great Lakes. In Hudson's fourth and final voyage, he discovered, mapped, and explored the Hudson Strait, Hudson Bay and James Bay.\n\nOther major sea-based explorers were Captain James Cook, George Vancouver, and Charles Wilkes.\n\nThere were numerous Spanish explorers and conquistadors who explored the Southwest of North America (including present-day west and central United States) and cross the continent (east to west) in its southern regions, mainly from the second quarter to the middle of the 16th century, such as Álvar Núñez Cabeza de Vaca and Francisco Vásquez de Coronado, but also the North American Southeast and south-central regions, s Soto]].\n\nIn 1608 Samuel de Champlain founded what is now Quebec City, which would become the first permanent settlement and the capital of New France. He took personal administration over the city and its affairs, and sent out expeditions to explore the interior. Champlain himself discovered Lake Champlain in 1609. By 1615, he had travelled by canoe up the Ottawa River through Lake Nipissing and Georgian Bay to the centre of Huron country near Lake Simcoe. During these voyages, Champlain aided the Wendat (aka 'Hurons') in their battles against the Iroquois Confederacy. As a result, the Iroquois would become enemies of the French and be involved in multiple conflicts.\n\nFrom 1679 to 1682 René-Robert Cavelier, Sieur de La Salle explored the Great Lakes region of the United States and Canada, and the entire course of Mississippi River to the Gulf of Mexico.\n\nFrom 1697 to 1702 Eusebio Kino explored the Sonoran Desert and on his journey to the Colorado River Delta discovered an overland route to Baja California that was then commonly believed to be an island. In 1683 Kino lead the first European overland crossing of Baja California.\n\nEuropean exploration of western Canada was largely motivated by the fur trade and the search for the elusive Northwest Passage. Hudson's Bay Company explorer Henry Kelsey has the distinction of being the first European to see the northern Great Plains in 1690.\n\nAnthony Henday was the first to have seen the Rocky Mountains, in 1754, but curiously did not mention it in his journals. From his westernmost geographic position (roughly near the town of Olds, Alberta, halfway between Calgary and Red Deer, Alberta) the Rockies should have been quite conspicuous, but he was likely trying to disguise the disappointing fact that an unknown range of seemingly impassible mountains now stood between the HBC and the Pacific. Samuel Hearne found the Coppermine River in 1769-71 in his failed search for copper ore deposits. Burned by these shortfalls, the HBC largely quit exploration.\n\nThe North West Company, on the other hand, used a business model that required constant expansion into untapped areas. Under the auspices of the NWC, Alexander Mackenzie discovered the Mackenzie River in 1789 and was the first European to reach the North-American Pacific overland, via the Bella Coola River, in 1793. Simon Fraser reached the Pacific in 1808 via the Fraser River.\n\nDavid Thompson, widely regarded as the greatest land geographer that ever lived, traveled over 90,000 km during his lifetime. In 1797, Thompson was sent south by his employers to survey part of the Canada-U.S. boundary along the water routes from Lake Superior to Lake of the Woods to satisfy unresolved questions of territory arising from the Jay Treaty between Great Britain and the United States. By 1798 Thompson had completed a survey of from Grand Portage, through Lake Winnipeg, to the headwaters of the Assiniboine and Mississippi Rivers, as well as two sides of Lake Superior. In 1798, the company sent him to Red Deer Lake (in present-day Alberta) to establish a trading post. The English translation of Lac La Biche-Red Deer Lake-first appeared on the Mackenzie map of 1793. Thompson spent the next few seasons trading based in Fort George (now in Alberta), and during this time led several expeditions into the Rocky Mountains. In 1811/1812 he followed the Columbia River to the Pacific, and in 1814 used his notes and measurements to draft the first European-style map of western Canada, covering 3.9 million square kilometres.\n\nLewis and Clark were the first Americans to venture into the newly acquired territory of the Louisiana Purchase, at the order of President Thomas Jefferson. They discovered many new geographical features, Indian tribes, and animal and plant species. John Colter was a member of the expedition who subsequently became a guide for others in the 'Old West,' and did some explorations of his own.\n\nJohn C. Frémont led many important explorations in the Great Plains, Great Basin, Oregon territory, and Mexican Alta California.\n\nJoseph Reddeford Walker was one of the most prominent of the explorers, and charted many new paths through the West, which often were then utilized by emigrants crossing to settle in Western towns and communities. In 1833, his exploring party discovered a route along the Humboldt River across present-day Nevada, ascending the Sierra Nevada following the Carson River and descending via Stanislaus River drainages to Monterey. His return route across the southern Sierra was via Walker Pass, named after Walker by John Charles Fremont. The approach of the Sierra via the Carson River route later became known as the California Trail, the primary route for the emigrants to the gold fields during the California gold rush.\n\nAs the American population of the West increased, the US government launched ongoing official explorations mainly through the US Army Corps of Topographical Engineers. One of the main officers and explorers in this unit was George Wheeler. In 1872, the US Congress authorized an ambitious plan to map the portion of the United States west of the 100th meridian at a scale of 8 miles to the inch. This plan necessitated what became known as the Wheeler Survey, along with the Clarence King and John Wesley Powell Surveys, and expeditions by Ferdinand Vandeveer Hayden. In 1879, all such efforts were reorganized as the United States Geological Survey.\n\n\n\n\n"}
{"id": "28341403", "url": "https://en.wikipedia.org/wiki?curid=28341403", "title": "Exploration of the Americas", "text": "Exploration of the Americas\n\nThe exploration of the Americas includes:\n"}
{"id": "32759787", "url": "https://en.wikipedia.org/wiki?curid=32759787", "title": "Exploration of the Pacific", "text": "Exploration of the Pacific\n\nPolynesians reached nearly all the Pacific islands by about 1200 AD, followed by Asian navigation in Southeast Asia and West Pacific. Around the Middle Ages Muslim traders linked the Middle East and East Africa to the Asian Pacific coasts (to southern China and much of the Malay Archipelago). The direct contact of European fleets with the Pacific began in 1512, with the Portuguese, on its western edges, followed by the Spanish discovery of the Pacific from the American coast.\n\nIn 1521 a Spanish expedition led by the Portuguese navigator Ferdinand Magellan was the first known crossing of the Pacific Ocean, who then named it the \"peaceful sea\". Starting in 1565 with the voyage of Andres de Urdaneta and for the next 250 years, the Spanish controlled the transpacific trade with the Manila galleons that crossed from Mexico to the Philippines and vice versa, until 1815. Other expeditions from Mexico and Peru discovered various archipelagos in the North and South Pacific. In the 17th and 18th centuries, other European powers sent expeditions to the Pacific, namely the Dutch Republic, England, France, and Russia.\n\nHumans reached Australia by at least 40,000 BC which implies some degree of water crossing. People were in the Americas before 10,000 BC. One theory holds that they travelled along the coast by canoe.\n\nAbout 3000 BC speakers of the Austronesian languages, probably on the island of Taiwan, mastered the art of long-distance canoe travel and spread themselves, or their languages, south to the Philippines and Indonesia and east to the islands of Micronesia and Melanesia. The Polynesians branched off and occupied Polynesia to the east. Dates and routes are uncertain, but they seem to have started from the Bismarck Archipelago, went west past Fiji to Samoa and Tonga about 1500 BC. By 100 AD they were in the Marquesas Islands and 300-800 AD in Tahiti (Tahiti is west of the Marquesas.) 300-800 AD is also given for their arrival at Easter Island, their easternmost point and the same date range for Hawaii, which is far to the north and distant from other islands. Far to the southwest, New Zealand was reached about 1250 AD. The Chatham Islands, about 500 miles east of New Zealand were reached about 1500. The fact that some Polynesians possessed the South American Sweet potato implies that they may have reached the Americas or, conversely, that people from the Americas may have reached Polynesia. Thor Heyerdahl's \"Kon-Tiki\" expedition successfully demonstrated that the trip from the Americas to Polynesia using only materials and technology available at the time was at least possible.\n\nOn the Asian side long-distance trade developed all along the coast from Mozambique to Japan. Trade, and therefore knowledge, extended to the Indonesian Islands but apparently not Australia. By at the latest 878 when there was a significant Islamic settlement in Canton much of this trade was controlled by Arabs or Muslims. In 219 BC Xu Fu sailed out into the Pacific searching for the elixir of immortality. From 1404-33 Zheng He led expeditions into the Indian Ocean.\n\nAn interesting issue is Japanese fishing boats. If one was blown out to sea and lacked proper equipment it could be carried by the current all the way to North America. Japanese boats reached Acapulco in 1617, the Aleutians in 1782, Alaska in 1805, the mouth of the Columbia River in 1820, and Cape Flattery in 1833. Such trips may have taken place before Europeans were present in those areas to make detailed records of them.\n\nThe first contact of European navigators with the western edge of the Pacific Ocean was made by the Portuguese expeditions of António de Abreu and Francisco Serrão, via the Lesser Sunda Islands, to the Maluku Islands, in 1512, and with Jorge Álvares's expedition to southern China in 1513, both ordered by Afonso de Albuquerque from Malacca.\n\nSpanish explorer Balboa was the first European to sight the Pacific from America in 1513 after his expedition crossed the Isthmus of Panama and reached a new ocean. He named it \"Mar del Sur\" (literally, \"Sea of the South\" or \"South Sea\") because the ocean was to the south of the coast of the isthmus where he first observed the Pacific. Later, Portuguese explorer Ferdinand Magellan sailed the Pacific East to West on a Castilian (\"Spanish\") expedition of world circumnavigation starting in 1519. Magellan called the ocean \"Pacífico\" (or \"Pacific\" meaning, \"peaceful\") because, after sailing through the stormy seas off Cape Horn, the expedition found calm waters. The ocean was often called the \"Sea of Magellan\" in his honor until the eighteenth century.\n\nFrom 1565 to 1815, a Spanish transpacific route known as the Manila galleons regularly crossed from Mexico to the Philippines and back. On the Asian side the Portuguese and later the Dutch built a regular trade from the East Indies to Japan. On the American side Spanish power stretched thousands of miles from Mexico to Chile. The vast central Pacific was visited only by the Manila galleons and an occasional explorer. The south Pacific was first crossed by Spanish expeditions in the 16th century who discovered many islands including Tuvalu, the Marquesas, the Cook Islands, the Solomon Islands, and the Admiralty Islands, and later the Pitcairn and Vanuatu archipelagos.\n\nThe Pacific recognized: Europeans knew that there was a vast ocean to the west, and the Chinese knew that there was one to the east. Learned Europeans thought that the world was round and that the two oceans were one. In 1492 Columbus sailed west to what he thought was Asia. When Pedro Álvares Cabral, en route to Asia via the Atlantic and the Indian oceans, reached Brazil, in 1500, the true extent of the Americas began to become known. The Martin Waldseemüller map of 1507 was the first to show the Americas separating two distinct oceans. This guess was confirmed in 1513 when Balboa crossed Panama and found salt water. The Magellan expedition of 1519-22 proved that there was one continuous ocean from the Americas to Asia. The Diogo Ribeiro map of 1529 was the first to show the Pacific at about its proper size.\n\nThe coast of Asia: The first European to see the Pacific Ocean was probably Marco Polo about 1292. The Portuguese reached India in 1498, conquered Malacca in 1511 and in 1512 António de Abreu and Francisco Serrão reached the Spice Islands. In May 1513 Jorge Álvares reached southern China and in the same year Balboa crossed Panama. In 1525 Diogo da Rocha and Gomes de Sequeira reached the Caroline Islands, and Jorge de Menezes in 1526-27 landed on the \"Islands of Don Jorge de Menezes\", in the northwest coast of New Guinea (now part of Indonesia), and named the region \"Ilhas dos Papuas\" and is thus credited with the European \"discovery\" of Papua. In 1542 Fernão Mendes Pinto reached Japan. From about 1543 until 1614, the Portuguese monopolize the trade between China and Japan, through the nanban trade. In 1589, João da Gama reached Hokkaido and possibly sighted the Kuril islands, crossing the Pacific further north of the routes usually taken until then. The land that he eventually discovered northeast of Japan, has since become a matter of legend and controversy. \n\nOne hundred years after the Spanish and Portuguese the Dutch Republic began its remarkable expansion. The Dutch reached the East Indies in 1596, the Spice Islands in 1602 and in 1619 founded Batavia. In 1600 a Dutch fleet reached Japan from the Strait of Magellan. The Dutch had little success in China but established themselves at Hirado, Nagasaki in 1609 and monopolized the Japan trade from 1639. In 1639 Matthijs Quast and Abel Tasman searched the empty ocean east of Japan looking for two islands called 'Rica de Oro' and 'Rica de Plata'. In 1643 Maarten Gerritsz Vries reached and charted Sakhalin and the Kuril Islands. In 1653 Hendrick Hamel was shipwrecked in Korea. At about this time the Russians reached the Pacific overland via Siberia (see below). It is significant that the Russian and Dutch trades were never linked since Siberian furs might easily have been exported to China at great profit.\nMagellan and the Manila Galleons: In 1519 Ferdinand Magellan sailed down the east coast of South America, found and sailed through the strait that bears his name and on 28 November 1520 entered the Pacific. He then sailed north and caught the trade winds which carried him across the Pacific to the Philippines where he was killed. One surviving ship returned west across the Indian Ocean and the other went north in the hope of finding the westerlies and reaching Mexico. Unable to find the right winds, it was forced to return to the East Indies. In 1565 (44 years later) Andrés de Urdaneta found a wind system that would reliably blow a ship eastward back to the Americas. From then until 1815 the annual Manila Galleons crossed the Pacific from Mexico to the Philippines and back, exchanging Mexican silver for spices and porcelain. Until the time of Captain Cook these were the only large ships to regularly cross the Pacific. The route was purely commercial and there was no exploration of the areas to the north and south. In 1668 the Spanish founded a colony on Guam as a resting place for west-bound galleons. For a long time this was the only non-coastal European settlement in the Pacific.\n\nSouth America: In 1513, six years before Magellan, Spanish explorer Vasco Núñez de Balboa crossed the Isthmus of Panama and saw the Pacific Ocean. In 1517-18 two ships were built on the Pacific coast. In 1522 Pascual de Andagoya sailed the coast as far as Ecuador. In 1532 Francisco Pizarro conquered Peru. A regular trade developed that carried Peruvian silver up the coast to Panama where it was carried overland to the Caribbean and part to Spain. Spanish settlement extended as far south as central Chile. In 1557-8 Juan Fernández Ladrillero discovered the Juan Fernandez islands and explored the Chilean coast down to the Strait of Magellan.\n\nThe South Pacific: Several Spanish expeditions were sent from South America across the Pacific Ocean in the 16th and early 17th centuries. They all used the southern trade winds. In 1567/68 Álvaro de Mendaña de Neira sailed from Peru to the Solomon Islands. In 1595 he tried again and reached the Santa Cruz Islands (eastern Solomons toward Fiji). He died there and the survivors reached the Philippines. In 1606 Pedro Fernandes de Queirós reached Vanuatu south of the Solomons. He continued exploring and eventually sailed back to Mexico. One of his separated ships under Luis Vaz de Torres sailed west and discovered the strait that bears his name sighting the northern tip of Australia. Other Spanish expeditions discovered Tuvalu, the Marquesas, the Cook Islands, the Admiralty Islands and the Pitcairn. In 1722 the Dutchman Jacob Roggeveen sailed from Cape Horn to Batavia and discovered Easter Island and Samoa.\n\nCape Horn: Six years after Magellan, in 1526, one of the ships of the Loaísa Expedition sailed through the Strait of Magellan and followed the coast north to Mexico. In 1578 Francis Drake passed through the Strait, sailed north raiding Spanish ships and put in somewhere on the coast of California. In 1580 Pedro Sarmiento de Gamboa, who was hunting for Drake, was the first to sail from the Strait to Europe. In 1587 Thomas Cavendish followed Drake, captured a Manila galleon and returned via the Indian Ocean. In 1599 the first Dutch ships passed through the Strait of Magellan (Will Adams, the first Englishman to reach Japan, was on board). Olivier van Noort followed and became the first Dutch circumnavigator.\n\nIn 1525 Francisco de Hoces, while trying to enter the Strait as part of the Loaisa Expedition, was blown south by a storm and saw what he thought was land's end. In 1578 Drake was blown south on the west side and saw what he thought was open water. In 1616 Willem Schouten sought a more southerly passage and rounded Cape Horn. In 1619 the Garcia de Nodal expedition followed the Dutch and proved that Tierra del Fuego was an island by circumnavigating it. Since the Strait of Magellan is narrow and hard to navigate Cape Horn became the standard route until the opening of the Panama Canal. It is a measure of the difficulty of these seas that it was not until 1820 that anyone went as far south as Antarctica.\n\nNorth America: When the Spanish conquered Mexico in 1521 they gained a stretch of Pacific coast. In 1533, Fortún Ximénez reached Baja California and in 1539 Francisco de Ulloa showed that it was a peninsula, but the myth of an Island of California continued for many years. In 1542 Juan Rodriguez Cabrillo reached a point north of San Francisco. In 1578 Drake landed somewhere on the coast. In 1587 Pedro de Unamuno, coming from the Philippines, stopped at Morro Bay, California. In 1592, Juan de Fuca may have reached Puget Sound.\n\nIn 1595, Sebastian Rodriguez Cermeño (Sebastião Rodrigues Soromenho), commander of the Manila galleon \"San Agustín\", attempted an exploration of the California coast. He reached the continent between Point St. George and Trinidad Head in California, but the galleon was later wrecked in a storm off Drake's Bay and the survivors had to sail the rest of the way back to Mexico in a small launch. The smaller vessel, however, allowed Cermeño to sail closer to the coast and to make useful observations of coastal features. In 1602, Sebastián Vizcaíno re-explored the California coast, one of his ships reaching Oregon. His was the last northward exploration for the next 150 years.\n\nThe Portolà expedition of 1769 began the land exploration of Alta California, following the coast as far north as San Francisco Bay and using the reports of Cermeño and Vizcaíno for guidance.\n\nAfter conquering Mexico the Spanish occupied the southern two thirds of Mexico, all of Central America and the South American coast down to Chile. North of this the land was too dry to support a dense population that could be ruled and taxed. The only exception was the Pueblo peoples far to the north in New Mexico. People like Francisco Vásquez de Coronado penetrated far into the interior and found nothing that the Spanish valued. The Chichimeca country of northern Mexico was slowly absorbed and Baja California began to be settled in 1687. The returning Manila galleons followed the westerlies to the coast of California, but immediately turned south, making only a few attempts to explore the coast. For more see History of the West Coast of North America and Early knowledge of the Pacific Northwest.\n\nAustralia and the southwest: Australia is remarkable for the number of explorers who missed it. There seems to be no record of Indonesian sailors reaching Australia. Some think that the Portuguese reached Australia before 1600 but these theories are difficult to prove. The 1567–1606 Spanish voyages from South America stopped at islands to the east before reaching Australia. The first European to definitely see Australia was Willem Janszoon who in February 1606 reached the Cape York Peninsula and thought it was part of New Guinea. Also in 1606 (June to October) Luis Váez de Torres of the Quiros expedition from South America followed the south coast of New Guinea and passed through the Torres Strait without recognizing Australia. His voyage, and therefore the separation between Australia and New Guinea, was not generally known until 1765. From about 1611 the standard Dutch route to the East Indies was to follow the roaring forties as far east as possible and then turn sharply north to Batavia. Since it was difficult to know longitude some ships would reach the west coast or be wrecked on it. 1616 Dirk Hartog bumped into the west coast and did some exploring. Frederick de Houtman did the same in 1619. In 1623 Jan Carstenszoon followed the south coast of New Guinea, missed Torres Strait and went along the north coast of Australia. In 1643 Abel Tasman left Mauritius, missed Australia, found Tasmania, continued east and found New Zealand, missed the strait between the north and south islands, turned northwest, missed Australia again and sailed along the north coast of New Guinea. In 1644 he followed the south coast of New Guinea, missed the Torres Strait, turned south and mapped the north coast of Australia. In 1688 the English buccaneer William Dampier beached a ship on the northwest coast. In 1696 Willem de Vlamingh explored the southwest coast. In 1699 Dampier was sent to find the east coast of Australia. He sailed along the west coast, went north to Timor, followed the north coast of New Guinea to the Bismarck Archipelago and abandoned his search because his ship had become rotten. Until Captain Cook the east coast was completely unknown and New Zealand had only been seen once.\n\nPacific Islands: See also History of the Pacific Islands\n\nMythical Lands: Europeans had long believed in a Strait of Anian somewhere near Bering Strait. A large and distorted Hokkaido was called 'Ezo', 'Jesso' and many other spellings. One of the Kuril Islands named \"Companies Landt\" by Vries grew into a large mass attached to North America. Joao-da-Gama-Land was thought to be east of Japan. There was an overgrown Puget Sound called \"Grande Mer de l'Ouest\" possibly connected to Hudson Bay. In the far south was a Terra Australis. The map published in Diderot's \"Encyclopédie\" in 1755 is filled with nonsense. In 1875 no less than 123 mythical islands were removed from the Royal Navy chart of the North Pacific.\n\nAlaska and the Russians: The modern period begins with Russian expeditions. They crossed Siberia and reached the Pacific in 1639 (Ivan Moskvitin). In 1644 Vassili Poyarkov found the Amur River. In 1648 Semyon Dezhnyov (probably) entered the Pacific from the Arctic Ocean. In 1652 Mikhail Stadukhin followed the coast of the Sea of Okhotsk. In 1697 Vladimir Atlasov entered the Kamchatka Peninsula overland from the north. In 1716 the first seagoing boats were built to reach Kamchatka from the mainland. In 1728 Vitus Bering sailed from Kamchatka through the strait that bears his name without seeing America. In 1732 Mikhail Gvozdev and Ivan Fedorov (navigator) saw the tip of Alaska from the Bering Strait. In 1741 Vitus Bering and Alexei Chirikov sailed just south of the Aleutian Islands and reached the Alaska panhandle. Peter Kuzmich Krenitzin mapped the Aleutians before 1769. The myth of a land mass north of the Aleutians took a long time to dispel. Russians fur hunters island-hopped along the Aleutians and then along the south coast of Alaska looking mainly for sea otter (Attu at the west end of the Aleutians in 1745, Unalaska Island at the east end in 1759, Kodiak Island 1784, Kenai Peninsula 1785, Yakutat, 1795, Sitka 1799, Fort Ross 1812). North of the Aleutians posts appeared on the west coast after 1819. Spaniards from Mexico met the Russians in 1788. (see below). Russian America was sold to the United States in 1867.\nCaptain Cook: On his first voyage (1768–71) James Cook went to Tahiti from Cape Horn, circumnavigated New Zealand, followed the east coast of Australia for the first time and returned via the Torres Strait and the Cape of Good Hope. On his second voyage (1772–75) he sailed from west to east keeping as far south as possible and showed that there was probably no Terra Australis. On his third voyage (1776–80) he found the Hawaiian Islands and followed the North American coast from Oregon to the Bering Strait, mapping this coast for the first time and showing that there was probably no Northwest passage. Cook was killed in Hawaii in 1779. The expedition made a second attempt at the Bering Strait, stopped at Kamchatka and China and reached England in 1780. Cook set a high standard of scientific exploration, showed that there was no large land mass in the southern ocean, mapped the two largest island groups in the Pacific and by following the east coast of Australia and the west coast of North America closed the last gaps in European knowledge of the Pacific coasts. After Cook everything was detail.\n\nCook's rivals and successors: Several governments sponsored Pacific expeditions, often in rivalry or emulation of Captain Cook. At the time of Cook's first voyage, in 1766-69 Louis Antoine de Bougainville crossed the Pacific and publicized Tahiti and in 1767 Samuel Wallis and Philip Carteret separately crossed the Pacific. In 1785-88 Jean-François de Galaup, comte de Lapérouse followed the American coast from Chile to Alaska, crossed to China, explored northern Japan and Kamchatka, went south to Australia and lost his life in the Santa Cruz Islands. The Malaspina Expedition (1789–1794) visited the American coast, Manila, New Zealand and Australia. In 1792-93 George Vancouver more thoroughly mapped the west coast of Canada. In 1803/6 Adam Johann von Krusenstern led the first Russian circumnavigation and investigated both sides of the North Pacific. In 1820 Fabian Gottlieb von Bellingshausen saw Antarctica. A number of other voyages are listed in \"European and American voyages of scientific exploration.\"\n\nSpain on the west coast of North America: For Europeans in the Age of Exploration western North America was one of the most distant places on earth (9 to 12 months of sailing). Spain had long claimed the entire west coast of the Americas. The area north of Mexico however was given little attention in the early years. This changed when the Russians appeared in Alaska. The Spanish moved north to California and built a series of missions along the Pacific coast including: San Diego in 1767, Monterey, California in 1770 and San Francisco in 1776. San Francisco Bay was discovered in 1769 by Gaspar de Portolà from the landward side because its mouth is not obvious from the sea. The Spanish settlement of San Francisco remained the northern limit of land occupation. By sea, from 1774 to 1793 the Spanish expeditions to the Pacific Northwest tried to assert Spanish claims against the Russians and British. In 1774 Juan José Pérez Hernández reached what is now the south end of the Alaska panhandle. In 1778 Captain Cook sailed the west coast and spent a month at Nootka Sound on Vancouver Island. An expedition led by Juan Francisco de la Bodega y Quadra sailed north to Nootka and reached Prince William Sound. In 1788 Esteban José Martínez went north and met the Russians for the first time (Unalaska and Kodiak Island) and heard that the Russians were planning to occupy Nootka Sound. In 1789 Martinez went north to build a fort at Nootka and found British and American merchant ships already there. He seized a British ship which led to the Nootka Crisis and Spanish recognition of non-Spanish trade on the northwest coast. In 1791 the Malaspina expedition mapped the Alaska coast. In 1792 Dionisio Alcalá Galiano circumnavigated Vancouver Island. In 1792-93 George Vancouver also mapped the complex coast of British Columbia. Vancouver Island was originally named Quadra's and Vancouver's Island in commemoration of the friendly negotiations held by the Spanish commander of the Nootka Sound settlement, Juan Francisco de la Bodega y Quadra and British naval captain George Vancouver in Nootka Sound in 1792. In 1793 Alexander Mackenzie reached the Pacific overland from Canada. By this time Spain was becoming involved in the French wars and increasingly unable to assert its claims on the Pacific coast. In 1804 the Lewis and Clark expedition reached the Pacific overland from the Mississippi River. By the Adams–Onís Treaty of 1819 Spain gave up its claims north of California. Canadian fur traders, and later a smaller number of Americans, crossed the mountains and built posts on the coast. In 1846 the Oregon Treaty divided the Oregon country between Britain and the United States. The United States conquered California in 1848 and purchased Alaska in 1867.\n\nNortheast: The Russians moved south and the Japanese moved north and explored the Kuril Islands and Sakhalin. About 1805 Adam Johann von Krusenstern was apparently the first Russian to reach eastern Siberia by sea from European Russia. In 1808 Mamiya Rinzo explored the coast of Sakhalin. During the Crimean War a British fleet failed to capture Petropavlovsk-Kamchatsky. In 1860 Russia annexed the southeast corner of Siberia from China.\n\nThe Pacific opened to trade and imperialism: After Captain Cook large numbers of European merchant vessels began to enter the Pacific. The reasons for this are not completely clear. On Cook's third voyage furs bought at Nootka were sold in China at a 1,800 percent profit - enough to pay for a trading voyage. The first to do this was James Hanna from Macao in 1785. Robert Gray in 1787 was the first American. This Maritime fur trade reached its peak about 1810, drew many ships into the Pacific and drew Canadians and Americans to the coast. The first Pacific whaling ship left London in 1788 and by the nineteenth century there were hundreds of whaleships in the Pacific each year. Clipper ships cut the sailing time from Europe to the Pacific. England founded a colony in Australia in 1788 and New Zealand in 1840. After about 1800 England began to replace the Dutch Republic along the Asian coast. Hong Kong became a colony in 1839 during the First Opium War, which was also the first time that a large European military and naval force appeared in the Pacific. European ships and sailors disrupted life on the Pacific islands. Most of the Pacific islands were soon claimed by one European power or another.\n\n"}
{"id": "3280844", "url": "https://en.wikipedia.org/wiki?curid=3280844", "title": "Fictional geography", "text": "Fictional geography\n\nFictional geography is the use of maps, text and imagery to create lands and territories to accompany works of fiction. Depending on the completeness and complexity of the work, varying media, levels of collaboration and a number of other factors, the depiction of geographical components to works of fiction can range from simple drawings of a small area as in \"The Twenty-One Balloons\" by William Pène du Bois to an entire fictional world as in \"The Lord of the Rings\" by Tolkien or even an entire galaxy as in \"Star Trek\" and its variants.\n\nOne of the most notable examples of fictional geography is that created by J. R. R. Tolkien to produce the Shire and its expansion to include all of Middle-earth.\n\n"}
{"id": "15203034", "url": "https://en.wikipedia.org/wiki?curid=15203034", "title": "First Geography Congress, Turkey", "text": "First Geography Congress, Turkey\n\nThe First Geography Congress \"(Turkish: Birinci Türk Coğrafya Kongresi)\", which was held in Ankara in 1941, separated Turkey into seven geographical regions, which are still used today.\n\nThe congress took numerous factors into consideration when defining these regions, including the fact that Turkey is surrounded by sea on three sides and the presence of mountain ranges lying parallel to the length of the coastline that isolate the central section from the influence of the sea. Based on these factors and the resulting differences in the climate, natural plant cover and the distribution of types of agriculture, as well as the influences of these on the transportation systems and types of housing, the congress divided Turkey into four coastal and three central regions.\n\nThe coastal regions were named after the seas to which they are adjacent (the Black Sea, the Marmara, the Aegean and the Mediterranean Regions). The central regions were named according to their location in the whole of Anatolia (Central, Eastern and Southeastern Anatolia Regions).\n\n"}
{"id": "1508112", "url": "https://en.wikipedia.org/wiki?curid=1508112", "title": "Four continents", "text": "Four continents\n\nEuropeans in the 16th century divided the world into four continents: Africa, America, Asia and Europe. Each of the four continents was seen to represent its quadrant of the world—Europe in the north, Asia in the east, Africa in the south, and America in the west. This division fit the Renaissance sensibilities of the time, which also divided the world into four seasons, four classical elements, four cardinal directions, four classical virtues, etc.\n\nThe four parts of the world or the four corners of the world refers to the Americas (the \"west\"), Europe (the \"north\"), Asia (the \"east\"), and Africa (the \"south\"). \n\nBefore the discovery of the New World a commonplace of classical and medieval geography had been the \"three parts\" in which, from Mediterranean and European perspectives, the world was divided: Europe, Asia and Africa. As Laurent de Premierfait, the pre-eminent French translator of Latin literature in the early fifteenth century, informed his readers:\nAsia is one of the three parts of the world, which the authors divide in Asia, Africa and Europe. Asia extends towards the Orient as far as the rising sun (\"devers le souleil levant\"), towards the south (\"midi\") it ends at the great sea, towards the occident it ends at our sea, and towards the north (\"septentrion\") it ends in the Maeotian marshes and the river named \"Thanaus\".\n\nFor Laurent's French readers, Asia ended at \"our sea\", the Mediterranean; Europeans were only dimly aware of the Ural Mountains, which divide Europe from Asia in the eyes of the modern geographer, and which represent the geological suture between two fragmentary continents, or cratons. Instead, the division between these continents in the European-centered picture was the Hellespont, which neatly separated Europe from Asia. From the European perspective, into the Age of Discovery, Asia began beyond the Hellespont with Asia Minor, where the Roman province of Asia had lain, and stretched away to unimaginably exotic and distant places— \"the Orient\".\n\nIn the sixteenth century America too was full of exotic promise: the \"New World\".\n\nIn 1603, Cesare Ripa published a book of emblems for the use of artists and artisans who might be called upon to depict allegorical figures. He covered an astonishingly wide variety of fields, and his work was reprinted many times. It was still being brought up-to-date in the 18th century. The illustrations reveal fixed Eurocentric perceptions of the nature of the \"four corners of the world.\" Ripa's \"Europe\" (\"illustration, left\") is the land of abundance (cornucopia) of kings and the pope, whose crowns and the papal tiara lie at her feet, and of cities.\n\n\"Africa\", by contrast (\"illustration, below right\") wears the elephant headdress (worn by rulers depicted on Hellenistic Bactrian coins) and is accompanied by a lion, the scorpion of the desert sands and Cleopatra's asps. \"Asia\" (\"illustration, right\"), the seat of Religion, carries a smoking censer as a camel takes its ease.\n\nAnd the iconic image of \"America\" (\"illustration, below left\") shows a Native American maiden in a feathered headdress, with bow and arrow. Perhaps she represents a fabled Amazon from the river that already carried the name.\n\nThe American millionaire philanthropist James Hazen Hyde, who inherited a majority share in Equitable Life Assurance Society, formed a collection of allegorical prints illustrating the Four Continents that are now at the New-York Historical Society; Hyde's drawings and a supporting collection of sets of porcelain table ornaments and other decorative arts illustrating the Four Continents were shared by various New York City museums.\nThe Renaissance associated one major river to each of the continents.\nThe Four Rivers theme appears for example in the Fontana dei Quattro Fiumi in the Piazza Navona in Rome.\n\nWith the confirmed discovery that Australia was an island continent, the theme of the \"Four Continents\" lost much of its drive, long before a sixth continent, Antarctica, was discovered. The iconography survived as the Four Corners of the World, however, generally in self-consciously classicizing contexts: for instance, in New York, in front of the Beaux-Arts Alexander Hamilton U.S. Custom House (1907), four sculptural groups by Daniel Chester French symbolize the \"Four Corners of the World.\"\n\n\n\n"}
{"id": "11750132", "url": "https://en.wikipedia.org/wiki?curid=11750132", "title": "GeoJournal", "text": "GeoJournal\n\nGeoJournal is a peer-reviewed international academic journal on all aspects of geography founded in 1977. Twelve issues (three volumes) a year were published by Springer Netherlands (formerly Kluwer) until December 2009 and can be accessed via SpringerLink. Starting February 2010, \"GeoJournal\" was relaunched as an international journal for spatially integrated social sciences and humanities with six issues a year. The journal's editor-in-chief is currently Daniel Z. Sui (Center for Urban and Regional Analysis, Department of Geography, The Ohio State University).\n\n"}
{"id": "54095081", "url": "https://en.wikipedia.org/wiki?curid=54095081", "title": "Goseck (monastery)", "text": "Goseck (monastery)\n\nGoseck, a monastery built on the foundations of a castle, as well as the vineyard of Dechantenberg is located in the municipality of Goseck of Saxony-Anhalt in Germany. It has been proposed by Germany for inscription in the List of World Heritage. The World Heritage nomination Naumburg Cathedral and the High Medieval Cultural Landscape of the Rivers Saale and Unstrut is representative for the processes that shaped the continent during the High Middle Ages between 1000 and 1300: Christianization, the so-called “Landesausbau” and the dynamics of cultural exchange and transfer characteristic for this very period.\nGoseck and its vineyard is one of the eleven components of the cultural landscape Naumburg Cathedral and the High Medieval Cultural Landscape of the Rivers Saale and Unstrut. Together with the agricultural features on the northern slopes of the Saale and the sandstone quarries used for the building of the monastery, this ensemble conveys the different forms of land use of the medieval monastery structures.\n\nGoseck Castle was part of a network of Frankish castles on the Saale River. It was founded around the year 800. The counts of Goseck were one of the noblest aristocratic families of the empire in the 10th and 11th century. Count Frederick I of Goseck had his center of power in Goseck . In 1041, Adalbert (archbishop of Hamburg-Bremen from 1043) founded a Benedictine monastery in the eastern part of the noble castle of Goseck. The minster was erected in 1046.\n\nIt is situated 9 kilometers northeast of Naumburg across the Saale Valley on the opposite bank. This monastery of the 11th century is a preserved and documented structure of the High Middle Ages. It was built to be visible from afar, offering lines of sight to most of the monuments in the nominated areas.\n\nThe crypt and choir of the monastery church display the very best of Salian architecture. Goseck is an example for the transformation of a noble family’s hereditary seat into a monastery with dynastic memorial tasks.\n\nIn the chronicles of the Benedictines of the Goseck monastery the terraced vineyard below the site is dated back to the year 1093; it is the oldest vineyard in continuous use in the nominated region. The Dechantenberg vineyard is exposed to the south. \nAround 1540, the monastery was secularized. Since 1997, Goseck is owned by the »Landesstiftung Dome und Schlösser Sachsen-Anhalt«, a state foundation endowed by the State of Saxony-Anhalt . Today, a European Centre for Music and Culture (“Europäisches Musik und Kulturzentrum”) resides in Goseck and offers a range of cultural activities. \n\n"}
{"id": "501118", "url": "https://en.wikipedia.org/wiki?curid=501118", "title": "Hermit kingdom", "text": "Hermit kingdom\n\nThe term hermit kingdom can be used to refer to any country, organization or society which willfully walls itself off, either metaphorically or physically, from the rest of the world - The country of North Korea is a prime example of a hermit kingdom.\n\nKorea in the age of Joseon dynasty was the subject of the first use of the term, in William Elliot Griffis' 1882 book \"Corea: The Hermit Nation\", and Korea was frequently described as a hermit kingdom until 1905 when it became a protectorate of Japan. The term is still commonplace throughout Korea and it is often used by Koreans themselves to describe pre-modern Korea. Today, the term is often applied to North Korea in news and social media, and in 2009 it was used by United States former Secretary of State Hillary Clinton. \n"}
{"id": "5949047", "url": "https://en.wikipedia.org/wiki?curid=5949047", "title": "Hjulström curve", "text": "Hjulström curve\n\nThe Hjulström curve, named after Filip Hjulström (1902–1982), is a graph used by hydrologists and geologists to determine whether a river will erode, transport, or deposit sediment. It was originally published in his doctoral thesis \"Studies of the morphological activity of rivers as illustrated by the River Fyris.\" in 1935. The graph takes sediment particle size and water velocity into account. \n\nThe upper curve shows the critical erosion velocity in cm/s as a function of particle size in mm, while the lower curve shows the deposition velocity as a function of particle size. Note that the axes are logarithmic. \n\nThe plot shows several key concepts about the relationships between erosion, transportation, and deposition. For particle sizes where friction is the dominating force preventing erosion, the curves follow each other closely and the required velocity increases with particle size. However, for cohesive sediment, mostly clay but also silt, the \"erosion\" velocity increases with decreasing grain size, as the cohesive forces are relatively more important when the particles get smaller. The critical velocity for deposition, on the other hand, depends on the settling velocity, and that decreases with decreasing grainsize. The Hjulström curve shows that sand particles of a size around 0.1 mm require the lowest stream velocity to erode.\n\nThe curve was expanded by Åke Sundborg in 1956. He significantly improved the level of detail in the cohesive part of the diagram, and added lines for different modes of transportation. The result is called the \"Sundborg diagram\", or the \"Hjulström-Sundborg Diagram\", in the academic literature.\n\nThis curve dates back to early 20th century research on river geomorphology and has no more than a historical value nowadays, although its simplicity is still attractive. Among the drawbacks of this curve are that it does not take the water depth into account and more importantly, that it does not show that sedimentation is caused by flow velocity \"deceleration\" and erosion is caused by flow \"acceleration\". The dimensionless Shields Diagram is now unanimously accepted for initiation of sediment motion in rivers. Much work was done on river sediment transport formulae in the second half of the 20th century and that work should be used preferably to Hjulström's curve.\n\n"}
{"id": "167741", "url": "https://en.wikipedia.org/wiki?curid=167741", "title": "Hydrographic survey", "text": "Hydrographic survey\n\nHydrographic survey is the science of measurement and description of features which affect maritime navigation, marine construction, dredging, offshore oil exploration/offshore oil drilling and related activities. Strong emphasis is placed on soundings, shorelines, tides, currents, seabed and submerged obstructions that relate to the previously mentioned activities. The term \"hydrography\" is used synonymously to describe \"maritime cartography\", which in the final stages of the hydrographic process uses the raw data collected through hydrographic survey into information usable by the end user.\n\nHydrography is collected under rules which vary depending on the acceptance authority. Traditionally conducted by ships with a sounding line or echo sounding, surveys are increasingly conducted with the aid of aircraft and sophisticated electronic sensor systems in shallow waters.\n\nHydrographic offices evolved from naval heritage and are usually found within national naval structures, for example Spain's Instituto Hidrográfico de la Marina. Coordination of those organizations and product standardization is voluntarily joined with the goal of improving hydrography and safe navigation is conducted by the International Hydrographic Organization (IHO). The IHO publishes Standards and Specifications followed by its Member States as well as Memoranda of Understanding and Co-operative Agreements with hydrographic survey interests.\n\nThe product of such hydrography is most often seen on nautical charts published by the national agencies and required by the International Maritime Organization (IMO), the Safety of Life at Sea (SOLAS) and national regulations to be carried on vessels for safety purposes. Increasingly those charts are provided and used in electronic form unders IHO standards.\n\nGovernmental entities below the national level conduct or contract for hydrographic surveys for waters within their jurisdictions with both internal and contract assets. Such surveys commonly are conducted by national organizations or under their supervision or the standards they have approved, particularly when the use is for the purposes of chart making and distribution or the dredging of state-controlled waters.\n\nIn the United States, there is coordination with the National Hydrography Dataset in survey collection and publication. State environmental organizations publish hydrographic data relating to their mission.\n\nCommercial entities also conduct large-scale hydrographic and geophysical surveying, particularly in the dredging, marine construction, oil exploration, and drilling industries. Industrial entities installing submarine communications cables or power require detailed surveys of cable routes prior to installation and increasingly use acoustic imagery equipment previously found only in military applications when conducting their surveys. Specialized companies exist that haveboth the equipment and expertise to contract with both commercial and governmental entities to perform such surveys .\n\nCompanies, universities, and investment groups will often fund hydrographic surveys of public waterways prior to developing areas adjacent those waterways. Survey firms are also contracted to survey in support of design and engineering firms that are under contract for large public projects. Private surveys are also conducted before dredging operations and after these operations are completed. Companies with large private slips, docks, or other waterfront installations have their facilities and the open water near their facilities surveyed regularly, as do islands in areas subject to variable erosion such as in the Maldives.\n\nCrowdsourcing also is entering hydrographic surveying, with projects such as OpenSeaMap, TeamSurv and ARGUS. Here, volunteer vessels record position, depth, and time data using their standard navigation instruments, and then the data is post-processed to account for speed of sound, tidal, and other corrections. With this approach there is no need for a specific survey vessel, or for professionally qualified surveyors to be on board, as the expertise is in the data processing that occurs once the data is uploaded to the server after the voyage. Apart from obvious cost savings, this also gives a continuous survey of an area, but the drawbacks are time in recruiting observers and getting a high enough density and quality of data. Although sometimes accurate to 0.1 - 0.2m, this approach cannot substitute for a rigorous systematic survey, where this is required. Nevertheless, the results are often more than adequate for many requirements where high resolution, high accuracy surveys are not required or are unaffordable.\n\nThe history of hydrographic surveying dates almost as far back as that of sailing. For many centuries, a hydrographic survey required the use of lead lines – ropes or lines with depth markings attached to lead weights to make one end sink to the bottom when lowered over the side of a ship or boat – and sounding poles, which were poles with depth markings which could be thrust over the side until they touched bottom. In either case, the depths measured had to be read manually and recorded, as did the position of each measurement with regard to mapped reference points as determined by three-point sextant fixes. The process was labor-intensive and time-consuming and, although each individual depth measurement could be accurate, even a thorough survey as a practical matter could include only a limited number of sounding measurements relative to the area being surveyed, inevitably leaving gaps in coverage between single soundings.\n\nSingle-beam echosounders and fathometers began to enter service in the 1930s which used sonar to measure the depth beneath a vessel. This greatly increased the speed of acquiring sounding data over that possible with lead lines and sounding poles by allowing information on depths beneath a vessel to be gathered in a series of lines spaced at a specified distance. However, it shared the weakness of earlier methods by lacking depth information for areas in between the strips of sea bottom the vessel sounded.\n\nIn 1904, wire-drag surveys were introduced into hydrography, and the United States Coast and Geodetic Survey′s Nicholas H. Heck played a prominent role in developing and perfecting the technique between 1906 and 1916. In the wire-drag method, a wire attached to two ships or boats and set at a certain depth by a system of weights and buoys was dragged between two points. If the wire encountered an obstruction, it would become taut and form a \"V\" shape. The location of the \"V\" revealed the position of submerged rocks, wrecks, and other obstructions, while the depth at which the wire was set showed the depth at which the obstruction was encountered. This method revolutionized hydrographic surveying, as it allowed a quicker, less laborious, and far more complete survey of an area than did the use of lead lines and sounding poles.\n\nPrior to the advent of sidescan sonar, wire-drag surveying was the only method for searching large areas for obstructions and lost vessels and aircraft. Between 1906 and 1916, Heck expanded the capability of wire-drag systems from a relatively limited area to sweeps covering channels two to three nautical miles (3.7 to 5.6 km) in width. The wire-drag technique was a major contribution to hydrographic surveying during much of the rest of the 20th century. So valuable was wire-drag surveying in the United States that for decades the U.S. Coast and Geodetic Survey, and later the National Oceanic and Atmospheric Administration, fielded a pair of sister ships of identical design specifically to work together on such surveys. USC&GS \"Marindin\" and USC&GS \"Ogden\" conducted wire-drag surveys together from 1919 to 1942, USC&GS \"Hilgard\" (ASV 82) and USC&GS \"Wainwright\" (ASV 83) took over from 1942 to 1967, and USC&GS \"Rude\" (ASV 90) (later NOAAS \"Rude\" (S 590)) and USC&GS \"Heck\" (ASV 91) (later NOAAS \"Heck\" (S 591)) worked together on wire-drag operations from 1967.\n\nThe rise of new electronic technologies – sidescan sonar and multibeam swath systems – in the 1950s, 1960s and 1970s eventually made the wire-drag system obsolete. Sidescan sonar could create images of underwater obstructions with the same fidelity as aerial photography, while multibeam systems could generate depth data for 100 percent of the bottom in a surveyed area. These technologies allowed a single vessel to do what wire-drag surveying required two vessels to do, and wire-drag surveys finally came to an end in the early 1990s. Vessels were freed from working together on wire-drag surveys, and in the U.S. National Oceanic and Atmospheric Administration (NOAA), for example, \"Rude\" and \"Heck\" operated independently in their later years.\n\nIn suitable shallow-water areas lidar (light detection and ranging) may be used. Equipment can be installed on inflatable craft, such as Zodiacs, small craft, autonomous underwater vehicles (AUVs), unmanned underwater vehicles (UUVs) or large ships, and can include sidescan, single-beam and multibeam equipment. At one time different data collection methods and standards were used in collecting hydrographic data for maritime safety and for scientific or engineering bathymetric charts, but increasingly, with the aid of improved collection techniques and computer processing, the data is collected under one standard and extracted for specific use.\n\nAfter data is collected, it has to undergo post-processing. A massive amount of data is collected during the typical hydrographic survey, often several soundings per square foot. Depending on the final use intended for the data (for example, navigation charts, Digital Terrain Model, volume calculation for dredging, topography, or bathymetry) this data must be thinned out. It must also be corrected for errors (i.e., bad soundings,) and for the effects of tides, waves/heave, water level and thermoclines (water temperature differences). Usually the surveyor has additional data collection equipment on site to record the data required for correcting the soundings. The final output of charts can be created with a combination of specialty charting software or a computer-aided design (CAD) package, usually Autocad.\n\nAlthough the accuracy of crowd-sourced surveying can rarely reach the standards of traditional methods, the algorithms used rely on a high data density to produce final results that are more accurate than single measurements. A comparison of crowd-sourced surveys with multibeam surveys indicates an accuracy of crowd-sourced surveys of around plus or minus 0.1 to 0.2 meter (about 4 to 8 inches).\n\n\n\nNOAA maintains a massive database of survey results, charts, and data on the NOAA site.\n"}
{"id": "5266320", "url": "https://en.wikipedia.org/wiki?curid=5266320", "title": "Indices of deprivation 2004", "text": "Indices of deprivation 2004\n\nThe Indices of deprivation 2004 (ID 2004) is a deprivation index at the small area level, created by the British Department for Communities and Local Government(DCLG).\n\nIt is unusual in its inclusion of a measure of geographical access as an element of deprivation and in its direct measure of poverty (through data on benefit receipts). The ID 2004 is based on the idea of distinct dimensions of deprivation which can be recognised and measured separately. These are then combined into a single overall measure. The Index is made up of seven distinct dimensions of deprivation called Domain Indices. Whilst it is known as the ID2004, most of the data actually dates from 2001.\n\nCommunities and Local Government (previously the Office of Deputy Prime Minister) commissioned the Social Disadvantage Research Centre (SDRC) at the Department of Social Policy and Social Work at the University of Oxford to update the Indices of deprivation 2004 (ID 2004) for England. Following an extensive public consultation (see Annex A), an independent academic peer review and a significant programme of work, the new Indices of Deprivation 2007 were produced in December 2007.\n\nThe new Index of Multiple Deprivation 2007 (IMD 2007) is a Lower layer Super Output Area (LSOA) level measure of multiple deprivation, and is made up of seven LSOA level domain indices. There are also two supplementary indices (Income Deprivation Affecting Children and Income Deprivation Affecting Older People). Summary measures of the IMD 2007 are presented at local authority district level and county council level. The LSOA level Domain Indices and IMD 2007, together with the local authority district and county summaries are referred to as the Indices of Deprivation 2007 (ID 2007).(Rusty 2009)\n\nThe ID 2007 are based on the approach, structure and methodology that were used to create the previous ID 2004. The ID 2007 updates the ID 2004 using more up-to-date data. The new IMD 2007 contains seven domains which relate to income deprivation, employment deprivation, health deprivation and disability, education skills and training deprivation, barriers to housing and services, living environment deprivation, and crime.\n\n\n\n\n\n\n\n\nEach Domain contains a number of indicators, totalling 37. Two supplementary indexes have been created as a subset of the Income domain. These relate to income deprivation affecting children and income deprivation affecting older people.\n\nThe Indices of deprivation 2004 are measured at the Lower Layer Super Output Area level. Super Output Areas were developed by the Office for National Statistics (ONS) from the Census 2001 Output Areas. There are two levels, the lowest (which the Index is based upon) being smaller than wards and containing a minimum of 1,000 people and 400 households. The middle layer contains a minimum of 5,000 people and 2,000 households. Earlier proposals to introduce Upper Layer Super Output Areas were dropped due to lack of demand. \n\nIn addition to Super Output Areas, Summaries of the ID 2004 are presented at District level, County level and Primary Care Trust (PCT) level.\n\nWhile each SOA is of higher resolution than the highest resolution \"ward\" index data of the IMD2000 and therefore better at identifying \"pockets\" of deprivation within wards the 2004 system has its problems. Some areas of deprivation can still be hidden because of the size of SOAs. Examples of this can be found by comparing central areas of Keighley using the Bradford District Deprivation Index (a Deprivation index developed by Bradford Council produced at 1991 Census Enumeration District level) with the ID2004.\nAdditionally SOAs were tasked with providing complete coverage of England and Wales - this combined with the minimum population and household counts within each SOA means that large areas of agricultural, commercial and industrial land have to be included within a residential area that borders them - thus when some very deprived residential areas are mapped, a large area of supposed deprivation emerges, however most of it may not be so but rather has a wide area of relative affluence around it - these can appear to be a greater problem than many smaller completely residential SOAs in which higher concentrations of deprived people live but mixed with more affluent neighbours.\n\n"}
{"id": "35697221", "url": "https://en.wikipedia.org/wiki?curid=35697221", "title": "Initial point", "text": "Initial point\n\nIn surveying, an initial point is a datum (a specific point on the surface of the earth) that marks the beginning point for a cadastral survey. The initial point establishes a local geographic coordinate system for the surveys that refer to that point.\n\nAn initial point is defined by the intersection of a principal meridian and a base line.\n\nA principal meridian and base line are usually established based on a preselected initial point, often some distinct geographical feature. As an example, the first established initial point in California was the Mount Diablo meridian. It was chosen because the summit of Mount Diablo could be seen for many miles around and could be referenced for surveys.\n\nIn other cases, a meridian and a base line were chosen separately based on other geographical features. For example, the Fifth principal meridian in the new Louisiana Purchase was established in 1815, with its southern end based on the confluence of the Arkansas and Mississippi Rivers, and extended northward from that point. The eastern end of the base line was chosen as the confluence of the St. Francis and Mississippi Rivers and extended westward. The initial point would be established where the meridian and the base line crossed, which turned out to be in the middle of a swamp in eastern Arkansas. This point is now located in the Louisiana Purchase State Park.\n\nSome initial points were chosen based on existing markers. The initial point for the Gila and Salt River meridian was established based on an existing marker that had been set up in 1851 to mark a point on the Mexico–United States border before the Gadsden Purchase.\n\nMany of the initial points in the United States have been listed on the National Register of Historic Places.\n\nNotable initial points include:\n\n"}
{"id": "39416417", "url": "https://en.wikipedia.org/wiki?curid=39416417", "title": "International Journal of Geographical Information Science", "text": "International Journal of Geographical Information Science\n\nInternational Journal of Geographical Information Science is a monthly peer-reviewed scientific journal published by Taylor & Francis. The editor-in-chief is Brian Lees (University of New South Wales). The journal covers original research in fundamental and computational geographic information science, including applying geographical information science to monitoring, prediction, and decision making, as well as natural resources, social systems, computer science, cartography, surveying, geography, and engineering, in both developed and developing countries. \n\nThe journal is abstracted and indexed in:\n\nAccording to the \"Journal Citation Reports\", the journal has a 2012 impact factor of 1.614.\n"}
{"id": "48359065", "url": "https://en.wikipedia.org/wiki?curid=48359065", "title": "La Cartografía Mallorquina", "text": "La Cartografía Mallorquina\n\nLa Cartografía Mallorquina (\" The Majorcan cartography \") is a book of essays on the Majorcan portolans written by Professor Julio Rey Pastor with the collaboration of Ernesto García Camarero. It is a scholarly essay, a key element in the study of portolans, especially those made by Majorcans as half of the book is devoted to the study of more than 400 Majorcan portolans existing worldwide.\n\nRey Pastor before explaining how to identify the works of this school for its unmistakable traits, he says:\n\"\".. In the monumental Periplus of the unsurpassed Adolf Erik Nordenskiöld, I saw with pleasant surprise that the most varicoloured parchments, ornamented with fabulous effigies of monarchs and naive legends, \" written in Catalan \" with lots of information, physical, biological and political, of each region, they originate in Majorca -in an unknown date-, being designated as \"catalan maps\"...\"'\n\nDr. Julio in his book, gives an explanation of why no Spanish scholar had touched the subject, referring to the unjust appropriation of some portolans by some Italian scholars: \"Our geographers, insufficiently armed, they stayed timidly neutral; and the militant vindicator of Spanish science, Dr. Gumersindo Laverde -who had organized a phalanx defending the flag hoisted by the young scholar Menéndez y Pelayo-, they remained silent, for the great scholar had forgotten this chapter of the medieval science \"..\n\nRey Pastor -a great mathematician and lover of the cartography- entered into this profile, in fact cartographers were apart from being artists they had to master mathematics -at least some of them- as the projection of the sphere on a plane it needs them.\n\nJulio Rey Pastor, was able to make the point defending the catalan authorship of many Majorcan portolans against both, the Portuguese scholars, and some Italian \"scholars\", and in fact he could not be more impartial, for he was not catalan, he was from La Rioja.\n\n\nRey Pastor says.. \"..That Jehuda Cresques (c. 1415) acted as founder and director of the Escola de Sagres, was known to historians for over a century, with doubts on which \"mestre Jacome\" from Majorca corresponded to the \"mestre Jacome\" contracted by Prince Henry, (although he was the only cartographer with that name).. But it's unforgivable that some scholars arrived to the point (based in a high cartographic ignorance), to attribute the invention of portolans to the school of the Infant, if not to him personally .. but how could that make sense, being the school founded by the emigrated Cresques (about 1400), when at his seventies he was tired of manufacturing planispheres, during half a century, for the insatiable Peter the Ceremonious and for his son, the also map-maniac DON JOAN.. On top of that one should not forget to include the testimony of Pacheco Pereira...:\n\nAnd he continues.. It's unforgivable as well, that those scholars, could dare to write on the subject without reading João de Barros, which clearly states: \"..mándou vir da ilha de Mallorca um mestre Jacome, hornera mui douto na arte de navegar, que fasia e instrumentos náuticos e que Ihe custou muito pelo trazer a este reino para ensinar sua sciencia aos officiaes portuguezes d'aquella mester..\"\n\n\n\n<br>\n"}
{"id": "38262946", "url": "https://en.wikipedia.org/wiki?curid=38262946", "title": "Land systems", "text": "Land systems\n\nLand systems constitute the terrestrial component of the Earth system and encompass all processes and activities related to the human use of land, including socioeconomic, technological and organizational investments and arrangements, as well as the benefits gained from land and the unintended social and ecological outcomes of societal activities. Changes in land systems have large consequences for the local environment and human well-being and are at the same time pervasive factors of global environmental change. Land provides vital resources to society, such as food, fuel, fibres and many other ecosystem services that support production functions, regulate risks of natural hazards, or provide cultural and spiritual services. By using the land, society alters and modifies the quantity and quality of the provision of these services.\n\nLand system changes are the direct result of human decision making at multiple scales ranging from local land owners decisions to national scale land use planning and global trade agreements. The aggregate impact of many local land system changes has far reaching consequences for the Earth System, that feedback on ecosystem services, human well-being and decision making. As a consequence, land system change is both a cause and consequence of socio-ecological processes.\n\nThe Global Land Programme (GLP) of Future Earth is an interdisciplinary community of science and practice fostering the study of land systems and the co-design of solutions for global sustainability.\n"}
{"id": "5227737", "url": "https://en.wikipedia.org/wiki?curid=5227737", "title": "Landscape manager", "text": "Landscape manager\n\nLandscape managers are professionally trained and qualified experts in landscaping management for conservation and recreation stewardship of designed and natural landscapes.\n\nLandscape managers work with designed landscapes, such as public parks, private gardens and public botanic gardens, and golf courses and sports centers. They also work with natural landscapes, such as nature reserves, natural open space parks, and national parks.\n\nThe United Kingdom Landscape Institute has a landscape management division whose members describe themselves as landscape architects. There are undergraduate degree programs leading to qualifications in landscape management and membership of professional institutes.\n\nIn the United States 4-year undergraduate degrees are offered for dual majors of Construction management and Ornamental horticulture or Landscape architecture.\n\n"}
{"id": "5348986", "url": "https://en.wikipedia.org/wiki?curid=5348986", "title": "Landscape of agriculture", "text": "Landscape of agriculture\n\nThe primary purpose of agriculture is food production but concern for other objectives (e.g., wildlife, conservation, biodiversity, recreation and scenery) have a long history and are of increasing importance in wealthy and urbanized countries. The European Union Set-Aside Policy was designed as a means of giving money to farmers to produce non-food environmental goods from farmland. Landscape planners are involved with the preparation of agricultural landscape plans for the achievement of non-food objectives from agricultural land.\n\n\n"}
{"id": "7757539", "url": "https://en.wikipedia.org/wiki?curid=7757539", "title": "List of hot springs", "text": "List of hot springs\n\nThere are hot springs on all continents and in many countries around the world. Countries that are renowned for their hot springs include Honduras, Canada, Chile, Hungary, Iceland, Israel, Japan, New Zealand, Romania, Fiji and the United States, but there are interesting and unique hot springs in many other places as well.\n\n\n\n\n\n\nThere lies a hot spring in the city of Uvira.\n\n\nA scholarly paper with a map of over twenty geothermal areas in Uganda.\n\n\nBrandvlei, Worcester area, Western Cape\nGoudini Spa, Worcester area, Western Cape\n\nThere are eleven developed and undeveloped hot spring pools in the Swaziland:\nMkoba spring,\nMvuntshini spring,\nEzulwini spring,\nLobamba spring,\nMawelawela spring,\nNgwempisi spring,\nMpopoma spring,\nMbondela spring,\nMadubula spring,\nFairview spring, and\nSiphofaneni spring.\nAll are sulphur springs with temperatures ranging from 26 °C to 52 °C.\n\nTermales del Nevado del Ruiz, Manizales\n\nBrazil is home of the world's largest hot spring resort in the city of Caldas Novas.\n\n\n\n\n\n\nThere are more than 275 hot springs registered in Chile.\n\n\n\n\n\nThere are numerous hot springs in Greenland:\n\n\n\n\n\nA list of 1661 hot springs in the United States can be found on the Thermal Springs List for the United States. The same list with added notes and links can be found on the USA Hotsprings Database.\n\n\n\n\n\n\nIndonesia is an island nation located on the point where the Pacific, Eurasian, and Australian tectonic plates meet, making it the site of at least 150 active volcanoes and frequent earthquakes. The islands of Sumatra, Java, Bali, the lesser Sunda Islands, and Celebes – part of the Pacific Ring of Fire – are the site of numerous geothermal-related features, including hot springs. Many hot springs are re-purposed for tourism, especially those that are located in the densely-populated Java island. Some hot springs were imbued with local legends or belief such as those in Bali and Java. Hot springs outside the island of Java, such as those on the Lesser Sunda Islands, are often pristine.\n\nBelow are lists of notable hot springs in Indonesia that is re-purposed for tourism:\n\n\n\n\n\n\n\nBeing located in the \"Pacific Ring of Fire\", Japan is in a volcanic region, and is home to many hot springs. The onsen (a Japanese word for \"hot spring\") plays a notable role in Japanese culture.\n\nIn March 2003 it was reported that there were 3,102 spa resorts in 2,292 municipalities in Japan. There were also 15,400 lodging facilities with 6,740 public hot spring baths. About 138 million people a year visit these facilities.\n\nNoted hot springs areas in Japan\n\n\n\nVarious hot springs, all nonvolcanic. They include –\n\n\n\n\nThere are about 9 recognized hot springs in Sri Lanka.\n\nSee Taiwanese hot springs.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n123 hot springs with temperature above 25 degrees C (77 degrees F).\n\n\nMany of the hot springs in Slovakia are currative or healthing springs.\n\n\n\n\nThere are many geothermal springs in the UK, but the hot springs found in the town of Bath are the only true hot springs (defined as those hotter than 37 degrees C):\n\n\nThere are other thermal or warm springs in the U.K and include;\n\n\nHot springs can be found in all six states of Australia as well as the Northern Territory; but apparently not Australian Capital Territory.\n\nHot springs are in the town of Savusavu where local people use the hot springs to cook their food. Some of the springs are situated on the beach and steam can be seen rising from the water at low tide.\n\nThere are numerous hot springs in New Zealand, predominantly in the Taupo Volcanic Zone, and in particular around Rotorua. Well known springs outside the Taupo Volcanic Zone include The Lost Spring in Whitianga, Coromandel Peninsula, Hot Water Beach, Waiwera, Morere Hotsprings in Wairoa District, Hawke's Bay and Hanmer Springs.\n\nIt is common to create parks around hot springs:\n\n\n\n"}
{"id": "9875604", "url": "https://en.wikipedia.org/wiki?curid=9875604", "title": "List of marches", "text": "List of marches\n\nThis is a list of European medieval marches.\n\nAt the beginning of his rule as king of Germany, Otto I tried to reorganize his realm to prepare an expansion to the East. At the beginning of the year 937, he created two marches: the March of the Billungen, given to Hermann Billung, later Duke of Saxony; and the Eastern march, given to Gero. In 961, when Billung became Duke of Saxony, his March was merged with the duchy. In the case of Gero, Otto I, now emperor, decided the division of his territories, greatly expanded since 937.\n\n\nIn 861, Charles the Bald, king of France, created two marches to protect his realm from warriors coming from Brittany and Normandy. Both were named March of Neustria, but will be known as March of Brittany and March of Normandy. In 863, the king created the March of Flanders.\n\n\nThree marches belonging to the Holy Roman Empire were created in the Low Countries:\n\n\n\n\n\n"}
{"id": "11485782", "url": "https://en.wikipedia.org/wiki?curid=11485782", "title": "List of towns and cities with 100,000 or more inhabitants/cityname: B", "text": "List of towns and cities with 100,000 or more inhabitants/cityname: B\n\n\n"}
{"id": "11486041", "url": "https://en.wikipedia.org/wiki?curid=11486041", "title": "List of towns and cities with 100,000 or more inhabitants/cityname: K", "text": "List of towns and cities with 100,000 or more inhabitants/cityname: K\n\n\n"}
{"id": "11486275", "url": "https://en.wikipedia.org/wiki?curid=11486275", "title": "List of towns and cities with 100,000 or more inhabitants/cityname: Z", "text": "List of towns and cities with 100,000 or more inhabitants/cityname: Z\n\n\n"}
{"id": "37695547", "url": "https://en.wikipedia.org/wiki?curid=37695547", "title": "List of tumps", "text": "List of tumps\n\nTump means a hillock, mound, barrow or tumulus. The Welsh words \"twmp\" and \"Twmpath\" may be related. Although some may appear similar to glacial drumlins, for the most part they are man-made, e.g. remains from mineral extraction, burial mounds (tumuli and especially bowl barrows) or motte-and-bailey castle mounds. The following geographical features in the UK are referred to using the word:\n\n"}
{"id": "286960", "url": "https://en.wikipedia.org/wiki?curid=286960", "title": "Mainland", "text": "Mainland\n\nMainland is a contiguous landmass that is larger and often politically, economically and/or demographically more significant than politically associated remote territories, such as exclaves or oceanic islands situated outside the continental shelf. \n\nIn geography, \"mainland\" can denote the continental (i.e. non-insular) part of any polity or the main island within an island nation. In geopolitics, \"mainland\" is sometimes used interchangeably with terms like Metropole as an antonym to overseas territories. In the sense of \"heartland\", mainland is the opposite of periphery.\n\nThe term is relative- in Tasmania, continental Australia is the mainland, while to residents of Flinders Island, the main island of Tasmania is also \"the mainland\".\n\n\n"}
{"id": "32374980", "url": "https://en.wikipedia.org/wiki?curid=32374980", "title": "Nautical measured mile", "text": "Nautical measured mile\n\nA nautical measured mile is a nautical mile which is marked by two pairs of towers. A mile is measure by sailing on a given bearing and lining up the pairs of towers. The start of the mile is recorded when the first pair of towers line up and the end of the mile recorded when the second pair line up.\n\nTo accurately measure performance ships must make at least four to six runs in both directions to allow for the wind and tide. \nThere are several nautical measured miles around the British Isles:\n\n"}
{"id": "12103386", "url": "https://en.wikipedia.org/wiki?curid=12103386", "title": "North American Vertical Datum of 1988", "text": "North American Vertical Datum of 1988\n\nThe North American Vertical Datum of 1988 (NAVD 88) is the vertical control datum of orthometric height established for vertical control surveying in the United States of America based upon the General Adjustment of the North American Datum of 1988.\n\nNAVD 88 was established in 1991 by the minimum-constraint adjustment of geodetic leveling observations in Canada, the United States, and Mexico. It held fixed the height of the primary tidal bench mark, referenced to the International Great Lakes Datum of 1985 local mean sea level height value, at Rimouski, Quebec, Canada. Additional tidal bench mark elevations were not used due to the demonstrated variations in sea surface topography, i.e., that mean sea level is not the same equipotential surface at all tidal bench marks.\n\nThe definition of NAVD 88 uses the Helmert orthometric height, which calculates the location of the geoid (which approximates sea level) from modeled local gravity. The NAVD 88 model is based on then-available measurements, and remains fixed despite later improved geoid models.\n\nNAVD 88 replaced the National Geodetic Vertical Datum of 1929 (NGVD 29), previously known as the Sea Level Datum of 1929. The elevation difference between points in a local area will show negligible change from one datum to the other, even though the elevation of both does change. NGVD 29 used a simple model of gravity based on latitude to calculate the geoid and did not take into account other variations. Thus, the elevation difference for points across the country does change between datums.\n\n\n"}
{"id": "305109", "url": "https://en.wikipedia.org/wiki?curid=305109", "title": "Northeast Passage", "text": "Northeast Passage\n\nThe Northeast Passage (abbreviated as NEP) is, from the European and northern Atlantic point of view, the shipping route to the Pacific Ocean, along the Arctic Ocean coasts of Norway and Russia. The western route through the islands of Canada is accordingly called Northwest Passage (NWP).\n\nThe NEP traverses (from East to West) the Barents Sea, Kara Sea, Laptev Sea, East Siberian Sea, and Chukchi Sea, and it includes the Northern Sea Route (NSR). The Northern Sea Route is a portion of the NEP; it is defined in Russian law and does not include the Barents sea and therefore does not reach the Atlantic Ocean. However, since the NSR has a significant overlap over the majority of the NEP, sometimes the NSR term has been used to refer to the entirety of the Northeast Passage.\n\nThe Northeast Passage is one of several Arctic maritime routes, the others being the Northwest Passage (going along Canada's and Alaska's coasts) and the Transpolar Route (going through the North Pole).\n\nThe first confirmed complete passage, from west to east, was made by the Finnish explorer Adolf Erik Nordenskiöld, with the ship \"Vega\" in 1878–79 (he was forced to wintering just a few days' sailing distance from Bering Strait, due to pack ice).\n\nThe motivation to navigate the Northeast passage was initially economic. In Russia, the idea of a possible seaway connecting the Atlantic and the Pacific Oceans was first proposed by the diplomat Gerasimov in 1525. However, Russian settlers and traders on the coast of the White Sea, the Pomors, had been exploring parts of the route as early as the 11th century.\n\nDuring a voyage across the Barents Sea in search of the Northeast Passage in 1553, English explorer Hugh Willoughby thought he saw islands to the north, and islands called Willoughby's Land were shown on maps published by Plancius and Mercator in the 1590s, and they continued to appear on maps by Jan Janssonius and Willem Blaeu into the 1640s.\n\nBy the 17th century, traders had established a continuous sea route from Arkhangelsk to the Yamal Peninsula, where they portaged to the Gulf of Ob. This route, known as the \"Mangazeya seaway\", after its eastern terminus, the trade depot of Mangazeya, was an early precursor to the Northern Sea Route.\n\nEast of the Yamal, the route north of the Taimyr Peninsula proved impossible or impractical. East of the Taimyr, from the 1630s, Russians began to sail the Arctic coast from the mouth of the Lena River to a point beyond the mouth of the Kolyma River. Both Vitus Bering (in 1728) and James Cook (in 1778) entered the Bering Strait from the south and sailed some distance northwest, but from 1648 (Semyon Dezhnev) to 1879 (Adolf Erik Nordenskiöld) no one is recorded as having sailed eastward between the Kolyma and Bering Strait.\nThe western parts of the passage were explored by northern European countries such as England, the Netherlands, Denmark, and Norway, looking for an alternative seaway to China and India. Although these expeditions failed, new coasts and islands were discovered. The most notable was the 1596 expedition led by Dutch navigator Willem Barentsz, who discovered Spitsbergen and Bear Island, and rounded the north end of Novaya Zemlya.\n\nFearing English and Dutch penetration into Siberia, Russia closed the Mangazeya seaway in 1619. Pomor activity in Northern Asia declined and most Arctic exploration in the 17th century was carried out by Siberian Cossacks, sailing from one river mouth to another in their Arctic-worthy \"kochs\". In 1648, the most famous of these expeditions, led by Fedot Alekseev and Semyon Dezhnev, sailed east from the mouth of the Kolyma River to the Pacific Ocean, and rounded the Chukchi Peninsula, thus proving that no land connection existed between Asia and North America.\n\nEighty years after Dezhnev, in 1728, another Russian explorer, Danish-born Vitus Bering on \"Svyatoy Gavriil\" (Saint Gabriel) made a similar voyage in reverse, starting in Kamchatka and going north to the passage that now bears his name; the Bering Strait. It was Bering who named the Diomede Islands, which Dezhnev had vaguely mentioned.\n\nBering's explorations of 1725–30 were part of a larger scheme of Peter the Great, known as the \"Great Northern Expedition\".\n\nThe \"Second Kamchatka Expedition\" took place in 1735–42, with two ships, \"Svyatoy Pyotr\" and \"Svyatoy Pavel\", the latter commanded by Bering's deputy in the first expedition, Captain Aleksey Chirikov. During the Second Expedition Bering became the first Westerner to sight the coast of northwestern North America, and Chirikov was the first Westerner to land there (a storm had separated the two ships earlier). On his return leg, Bering discovered the Aleutian Islands but fell ill, and \"Svyatoy Pyotr\" had to take shelter on an island off Kamchatka, where Bering died (Bering Island).\n\nIndependent of Bering and Chirikov, other Russian Imperial Navy parties took part in the Second Great Northern Expedition. One of these, led by Semyon Chelyuskin, in May 1742 reached Cape Chelyuskin, the northernmost point of both the Northeast Passage and the Eurasian continent.\n\nLater expeditions to explore the North East Passage took place in the 1760s (Vasiliy Chichagov), 1785–95 (Joseph Billings and Gavril Sarychev), the 1820s and 1830s (Ferdinand Petrovich Wrangel, Pyotr Fyodorovich Anjou, Count Fyodor Litke and others). The possibility of navigating the length of the passage was proved by the mid-19th century.\n\nHowever, it was only in 1878-79 that Fenno-Swedish explorer Adolf Erik Nordenskiöld (born in Finland but exiled to Sweden many years before the expedition) made the first complete passage of the Northeast Passage, leading the Vega expedition from west to east. The ship's captain on this expedition was Lieutenant Louis Palander of the Swedish Royal Navy. \n\nOne year before Nordenskiöld's voyage, commercial exploitation of a section of the route started with the so-called \"Kara expeditions\", exporting Siberian agricultural produce via the Kara Sea. Of 122 convoys between 1877 and 1919 only 75 succeeded, transporting as little as 55 tons of cargo. From 1911 the Kolyma River steamboats ran from Vladivostok to the Kolyma once a year.\nIn 1912, two Russian expeditions set out; Captain Georgy Brusilov and the Brusilov Expedition in the \"Santa Anna\", and Captain Alexander Kuchin with Vladimir Rusanov in the \"Gerkules\"; each with a woman on board. Both expeditions were hastily arranged, and both disappeared. The German Arctic Expedition of 1912, led by Herbert Schröder-Stranz, ended disastrously with only 7 of 15 crew members surviving the preliminary expedition to Nordaustlandet.\n\nIn 1913 Jonas Lied organized a successful expedition through the Kara Sea to Yenisei. Explorer and scientist Fridtjof Nansen and Siberian industrialist Stephan Vostrotin were prominent passengers. Lied had founded The Siberian company with the purpose of exporting and importing goods through the great Siberian rivers and the Kara Sea. The 1913 trip is recorded in Nansen's \"Through Siberia\".\n\nIn 1915, a Russian expedition led by Boris Vilkitskiy made the passage from east to west with the icebreakers \"Taymyr\" and \"Vaygach\".\n\nNordenskiöld, Nansen, Amundsen, DeLong, Makarov and others also led expeditions, mainly for scientific and cartographic purposes.\n\nThe introduction of radio, steamboats, and icebreakers made running the Northern Sea Route viable. After the Russian Revolution of 1917, the Soviet Union was isolated from the western powers, which made it imperative to use this route. Besides being the shortest seaway between the western and far eastern USSR, it was the only one that lay completely inside Soviet internal waters and did not impinge on waters of opposing countries.\n\nIn 1932, a Soviet expedition led by Professor Otto Yulievich Schmidt was the first to sail all the way from Arkhangelsk to the Bering Strait in the same summer without wintering en route. After trial runs in 1933 and 1934, the \"Northern Sea Route\" was officially defined and open and commercial exploitation began in 1935. The next year, part of the Baltic Fleet made the passage to the Pacific where armed conflict with Japan was looming.\n\nA special governing body \"Glavsevmorput\" (Chief Directorate of the Northern Sea Route) was set up in 1932, with Otto Schmidt as its director. It supervised navigation and built Arctic ports.\n\nDuring the early part of World War II, the Soviets allowed the German auxiliary cruiser \"Komet\" to use the Northern Sea Route in the summer of 1940 to evade the British Royal Navy and break out into the Pacific Ocean. \"Komet\" was escorted by Soviet icebreakers during her journey. After the start of the Soviet-German War, the Soviets transferred several destroyers from the Pacific Fleet to the Northern Fleet via the Arctic. The Soviets also used the Northern Sea Route to transfer materials from the Soviet Far East to European Russia, and the Germans launched Operation Wunderland to interdict this traffic.\n\nIn July 1965, USCGC \"Northwind\" (WAGB-282), commanded by Captain Kingdrel N. Ayers USCG, conducted an oceanographic survey between Greenland, Iceland, and Scotland and was the first western vessel to operate in the Kara Sea of the Soviet Union, for which she received the Coast Guard Unit Commendation with Operational Distinguishing Device. The real, (then) classified mission of \"Northwind\" was to attempt a transit of the \"Northeast Passage\". The effort was not successful due to diplomatic reasons and caused an international incident between the U.S.S.R. and U.S.A.\n\nA January 2013 \"Reuters News\" report on expanding Russian arctic natural gas shipments to Asia, stated that while shipping traffic on the NSR surged in 2012 to around 1 million tons of various kinds of cargoes, \"it pales by comparison with the 1987 peak of 6.6 million tons.\" It also reported that the Finnish crude oil tanker \"Uikku\" was the first non-Russian energy vessel to brave the NSR in 1997.\n\nAfter the Soviet Union dissolved in the early 1990s, commercial navigation in the Siberian Arctic went into decline. Regular shipping is found only from Murmansk to Dudinka in the west and between Vladivostok and Pevek in the east. Ports between Dudinka and Pevek see virtually no shipping. Logashkino and Nordvik were abandoned and are now ghost towns.\n\nRenewed interest led to several demonstration voyages in 1997 including the passage of the Finnish product tanker \"Uikku\".\n\nA similar route to the NEP is the Northern Sea Route (NSR). The NSR is a shipping route defined in Russian legislation as extending from the Novaya Zhelaniya straits (at the Novaya Zemlya archipelago, connecting the Barents Sea to the West and the Kara Sea to the East), to Cape Dezhnev by the Bering Strait. Therefore, the NEP encompasses all the East Arctic seas, and the NSR all the seas except the Barents Sea. Since the NSR constitutes the majority of the NEP, sometimes the term NSR has been used to refer to the entirety of the NEP.\n\nThe governance of the NEP has developed considerably in the late 20th and early 21st centuries. The main sources of governance are the United Nations Convention on the Law of the Sea (UNCLOS), the Arctic Council (AC), the International Maritime Organization (IMO), and the domestic legislation of the Russian Federation. In combination, they cover territorial claims, economic exploitation, technical shipping requirements, environmental protection, and search and rescue responsibilities.\n\nThe Northeast Passage is a shorter route to connect Northeast Asia with Western Europe, compared to the existing routes through the Suez Canal, the Panama Canal, or around the Cape of Good Hope. The table below shows the sailing distances between the major East Asia sea ports, and Rotterdam in Europe (these distances assume no route diversions owing to ice conditions).\n\nA usable Northern Sea Route between northern Europe to North Pacific ports would cut time at sea (and resultant fuel consumption) by more than half. For the corporate players in bulk shipping of relative low-value raw materials, cost savings for fuel may appear as a driver to explore the Northern Sea Route for commercial transits, and not necessarily reduced lead time. The Northern Sea Route allows economies of scale compared to coastal route alternatives, with vessel draught and beam limitation. Environmental demands faced by the maritime shipping industry may emerge as a driver for developing the Northern Sea Route. Increased awareness of environmental benefits and costs for both the Northern Sea Route and Suez routes will probably be important factors in this respect.\n\nIn 2011, four ships sailed the length of the Northern Sea Route and Northeast Passage, from the Atlantic to Pacific Oceans. In 2012, 46 ships sailed the NSR.\n\nIn August 2012, Russian media reported that 85% of vessels transiting the Northern Sea Route in 2011 were carrying gas or oil, and 80% were high-capacity tankers.\n\nIn September 2012, Inuit Circumpolar Conference Chair Jimmy Stotts was reported as saying there is concern that increased shipping could adversely affect indigenous hunting of marine mammals. Also concerning is the lack of infrastructure on the Western Alaska coast to deal with a spill or a wrecked vessel.\n\nUnlike the similar latitudes in Alaska and Canada (along the Northwest Passage), parts of the NEP remain ice-free year-round. This is mostly the case of the Barents Sea, by the northern coast of Norway and Northwestern coast of Russia. The Barents sea is affected by the currents of warm water from the Gulf Stream, feeding into the North Atlantic.\n\nOther parts of the NEP (mostly the NSR part), freeze in winter and partially melt in the summer months, especially along the coasts. Since the early 2000s the summer melting has been stronger, and the winter freezing has been weaker, opening the waters to the possibility of more non-ice breaking ships taking advantage of the route for longer periods of time.\n\nOnly one Russian seaport in the Barents Sea along the officially defined Northern Sea Route (which begins at the Kara Gates Strait) is ice-free year-round, Murmansk on the Kola Peninsula. Other Arctic ports are generally usable from July to October, or, such as Dudinka, are served by nuclear-powered icebreakers. Beyond the Bering Strait, the end of the Northern Sea Route, and south along Russia's Pacific seaboard Petropavlovsk in Kamchatka, Vanino, Nakhodka, and Vladivostok are accessible year-round.\n\nDue to its harsh climactic conditions and the low population density, the NEP has had relatively little activity. The NSR portion of the NEP experienced its highest levels of activity during the rule of the USSR. The NSR greatly developed as a heavily subsidized domestic route, with traffic peaking in 1987 with 6.58 million tons of cargo carried by 331 ships over 1306 voyages. With the end of the Soviet Union and its subsidies, the NSR traffic collapsed to 1.5–2 M tons of cargo.\n\nSince the early 2000s, the thickness and area extent of the Arctic sea ice has experienced significant reduction, compared to the recorded averages. This has led to an increase in transit shipping. In 2011, four ships sailed the entire length of the NEP, 46 in 2012, and 19 in 2013. The number of trips is still very small compared to the thousands of ships each year through the Suez Canal. Mainstream container shipping is expected to continue to overwhelmingly use the Suez route, while niche activities like bulk shipping is expected to grow, driven by the mining industries of the Arctic.\n\nThe term \"ice free\" generally refers to the absence of fast ice, i.e. continuously frozen surface ice sheet cover. Under common usage \"ice free\" does not mean that there is no Arctic sea ice. \"Ice free\" regions can contain broken ice cover of varying density, often still requiring appropriately strengthened hulls or icebreaker support for safe passage.\n\nFrench sailor Eric Brossier made the first passage by sailboat in only one season in the summer of 2002. He returned to Europe the following summer through the Northwest Passage.\n\nThe Northern Sea Route was opened by receding ice in 2005 but was closed by 2007. The amount of polar ice had receded to 2005 levels in August 2008. In late August 2008, it was reported that images from the NASA Aqua satellite had revealed that the last ice blockage of the Northern Sea Route in the Laptev Sea had melted. This would have been the first time since satellite records began that both the Northwest Passage and Northern Sea Route had been open simultaneously. However, other scientists suggested that the satellite images may have been misread and that the sea route was not yet passable.\n\nIn 2009, the Bremen-based Beluga Group claimed they were the first Western company to attempt to cross the Northern Sea Route for shipping without assistance from icebreakers, cutting 4000 nautical miles off the journey between Ulsan, Korea and Rotterdam. The voyage was widely covered and sometimes incorrectly said to be the first time that non-Russian ships made the transit. In 1997, a Finnish oil tanker, \"Uikku\", sailed the length of the Northern Sea Route from Murmansk to the Bering Strait, becoming the first Western ship to complete the voyage.\n\nHowever, the new (2008) ice-strengthened heavy lift vessels \"Beluga Fraternity\" and \"Beluga Foresight\" commenced an East-to-West passage of the Northern Sea Route in August 2009\nas part of a small convoy escorted by the Russian nuclear icebreaker \"NS 50 Let Pobedy\", westward through the Bering, Sannikov, and Vilkitskiy Straits. The two vessels embarked Russian ice pilots for the voyage to the western Siberian port of Novyy, in the Yamburg region in the delta of the Ob River. The ships arrived at Novyy on 7 September, discharged their cargo to barges and departed on 12 September, bound for the Kara Gates and Rotterdam. They were the first non-Russian commercial vessels to complete this journey, but not without Russian assistance. The captain of the \"Beluga Foresight\", Valeriy Durov, described the achievement as \"...great news for our industry.\" The president of Beluga Shipping claimed the voyage saved each vessel about 300,000 euros, compared to the normal Korea-to-Rotterdam route by way of the Suez Canal. The company did not disclose how much they paid for the escort service and the Russian pilots. An 18 September 2009 press release stated that the company was planning for six vessels to make Arctic deliveries in 2010. It is not clear that this plan was followed up on.\n\nIn 2009, the first two international commercial cargo vessels traveled north of Russia between Europe and Asia. In 2011, 18 ships made the now mostly ice-free transit. During 2011, 34 ships made the transit up from a total of 6 ships in 2010. In 2012, 46 commercial ships made the transit. Petroleum products constituted the largest cargo group. In 2013 71 commercial ships made the transit.\n\nOn 28 July 2009, the sailing yacht RX II (36-foot length), with expedition leader Trond Aasvoll and crew Hans Fredrik Haukland and Finn Andreassen left Vardø in Norway on a quest to circumnavigate the North Pole. The northern sea route proved ice free and the three Norwegians sailed into the Bering Strait on 24 September. But Russian bureaucracy managed to do what the arctic waters didn't – to stop their effort to sail around in one season. The boat over-wintered in Nome, and finished the trip through the Northwest passage the following summer.\n\nIn September 2010, two yachts circumnavigated the Arctic: Børge Ousland's team aboard \"The Northern Passage\", and Sergei Murzayev's team in the \"Peter I\". These were the first recorded instances of the circumnavigation of the Arctic by sailing yachts in one season.\n\nThe largest ship as of 2011 is the 117,000 tonne SCF Baltica loaded with natural-gas condensate.\n\nIn 2012, the LNG carrier \"Ob River\" became the first ship of its kind to transit the Northern Sea Route. The vessel completed the westbound voyage in ballast in only six days and planned to sail back in Asia in November with a full load of liquified natural gas. The growth in traffic has been startling. 46 ships sailed the entire length from Europe to East Asia during 2012. By July 2013, the administrators of the Northern Sea Route had granted permission to 204 ships to sail during the season. By that time, Arctic sea ice had declined substantial especially on the Atlantic side of the Arctic. \"On July 15 extent came within 540,000 square kilometers (208,000 square miles) of that seen in 2012 on the same date... (Compared to the 1981 to 2010 average, ice extent on July 15, 2013 was 1.06 million square kilometers (409,000 square miles) below average.)\" (Summer 2012 Arctic sea ice volume reached a record low.)\n\nDuring early September 2013 the Russian battlecruiser \"Petr Velikiy\" led a flotilla of Russian navy ships with icebreaker support along the Northern Sea Route to the New Siberian Islands. About 400 ships were expected to transit the Russian portion of the route during the 2013 season, up from about 40 during 2012.\n\nOn 15 September 2015, the Chinese trimaran \"Qingdao China\" set a speed record by sailing from Murmansk to the Bering Strait in 13 days.\n\nIn 2007, Finland issued a €10 Adolf Erik Nordenskiöld and Northeast Passage commemorative coin to celebrate the 175th anniversary of Nordenskiöld's birth and his discovery of the northern sea route. The obverse features an abstract portrait of Nordenskiöld at the helm of his ship. The reverse is dominated by a pattern resembling the labyrinth formed by adjacent ice floes. The coin is one of the Europa Coins 2007 series, which celebrates European achievements in history.\n\n"}
{"id": "25313082", "url": "https://en.wikipedia.org/wiki?curid=25313082", "title": "Pan-region", "text": "Pan-region\n\nA pan-region is a geographic region or state’s sphere of economic, political and cultural influence extending beyond that state's borders. For example, the pan-region of the United States of America (USA) regions both bordering the USA and its close neighbors including, Canada, Mexico, and many South America other states.\n\nThe idea of pan-regions or spheres of economic and cultural influence was first developed by Karl Ernst Haushofer (8/27/1869-3/10/1946), a German General, geographer and geo-politician. Pan-regions contributed to Geopolitik or the German theories of foreign policy during the interwar period (1918–1939) or the time from the end of World War I and the beginning of World War II. Haushofer’s pan-regions divided the world under three supreme leading states in economy, politics and culture. Those three states included the USA who controlled North America and much of South America, Germany who controlled Europe, much of Africa and western Asia and Japan who controlled central, eastern, and the islands of southern Asia. These leading states could expect their regions to develop economic and political alliance with their leading state as well as yield to sanctions and major cultural designations.\n\nHistorically, the world was divided into three spheres of control, however after the end of World War II, Germany and Japan’s control over their various regions have diminished with the success of other nations. For example, German control over Europe has suffered with the development of the European Union and emergence of other foreign powers. Japan also is beginning to lose economic dominance over its pan-region with the emergence of a thriving Chinese economy.\n"}
{"id": "44706428", "url": "https://en.wikipedia.org/wiki?curid=44706428", "title": "Prismatic compass (surveying)", "text": "Prismatic compass (surveying)\n\nA prismatic compass is a navigation and surveying instrument which is extensively used to find out the bearing of the traversing and included angles between them, waypoints (an endpoint of the lcourse) and direction. Compass surveying is a type of surveying in which the directions of surveying lines are determined with a magnetic compass, and the length of the surveying lines are measured with a tape or chain or laser range finder. The compass is generally used to run a traverse line. The compass calculates bearings of lines with respect to magnetic north. The included angles can then be calculated using suitable formulas in case of clockwise and anti-clockwise traverse respectively. For each survey line in the traverse, surveyors take two bearings that is fore bearing and back bearing which should exactly differ by 180 if local attraction is negligible. The name \"Prismatic compass\" is given to it because it essentially consists of a prism which is used for taking observations more accurately.\n\nLeast count means the minimum value that an instrument can read which is 15 minutes in case of prismatic compass. It means compass can read only those observations which are multiples of 30 minutes, 5 25, 15 55, 35 45 30\n\nThe compass calculates the bearings in whole circle bearing system which determines the angle which the survey line makes with the magnetic north in the clockwise direction. The included angles can be calculated by the formulas F-P ±180 in case of anti-clocwise traverse and P-F ±180 in case of clockwise traverse, where 'F' is the fore bearing of forward line in the direction of survey work and 'P' is the fore bearing of previous line.\n\nThe essential parts of the prismatic compass are listed below:-\n\n"}
{"id": "17660060", "url": "https://en.wikipedia.org/wiki?curid=17660060", "title": "RINEX", "text": "RINEX\n\nIn the field of geodesy, Receiver Independent Exchange Format (RINEX) is a data interchange format for raw satellite navigation system data. This allows the user to post-process the received data to produce a more accurate result — usually with other data unknown to the original receiver, such as better models of the atmospheric conditions at time of measurement.\n\nThe final output of a navigation receiver is usually its position, speed or other related physical quantities. However, the calculation of these quantities are based on a series of measurements from one or more satellite constellations. Although receivers calculate positions in real time, in many cases it is interesting to store intermediate measures for later use. RINEX is the standard format that allows the management and disposal of the measures generated by a receiver, as well as their off-line processing by a multitude of applications, whatever the manufacturer of both the receiver and the computer application.\n\nThe RINEX format is designed to evolve over time, adapting to new types of measurements and new satellite navigation systems. The first RINEX version was published by W. Gurtner and G. Mader in the CSTG GPS Bulletin of September/October 1990. Since 1993 the RINEX 2 is available, which has been revised and adopted several times. RINEX enables storage of measurements of pseudorange, carrier-phase, Doppler and signal-to-noise from GPS (including GPS modernization signals e.g. L5 and L2C), GLONASS, Galileo, Beidou, along with data from EGNOS and WAAS satellite based augmentation systems (SBAS), QZSS, simultaneously. RINEX version 3.02 was submitted in April 2013 and is capable of new measurements from GPS or Galileo systems. The most recent version is RINEX 3.03 from July 2015 with update 1 to 3.03 published in 2017.\n\nAlthough not part of the RINEX format, the \"Hatanaka compression scheme \" is commonly used to reduced the size of RINEX files, resulting in an ASCII-based CompactRINEX format.. It uses higher-order time differences to reduce the number of characters needed to store time data.\n\n"}
{"id": "43756597", "url": "https://en.wikipedia.org/wiki?curid=43756597", "title": "Repetition method", "text": "Repetition method\n\nIn surveying, the repetition method is used to improve precision and accuracy of measurements of horizontal angles. The same angle is measured multiple times, with the survey instrument rotated so that systematic errors tend to cancel. The arithmetic mean of these observations gives true value of an angle. The precision of the measurement can exceed the least count of the instrument. used.\n\nThe repetition method is used when high accuracy is required. For rough or approximate survey work, the ordinary method of measuring horizontal angles is used as it is less time consuming.\n\n"}
{"id": "4558969", "url": "https://en.wikipedia.org/wiki?curid=4558969", "title": "Right to light", "text": "Right to light\n\nRight to light is a form of easement in English law that gives a long-standing owner of a building with windows a right to maintain the level of illumination. It is based on the Ancient Lights law. The rights are most usually acquired under the Prescription Act 1832.\n\nIn effect, the owner of a building with windows that have received natural daylight for 20 years or more is entitled to forbid any construction or other obstruction that would deprive him or her of that illumination. Neighbours cannot build anything that would block the light without permission. The owner may build more or larger windows but cannot enlarge their new windows before the new period of 20 years has expired. It is also possible for a right to light to exist if granted expressly by deed, or granted implicitly, for example under the rule in \"Wheeldon v. Burrows\" (1879).\n\nOnce a right to light exists, the owner of the right is entitled to \"sufficient light according to the ordinary notions of mankind\": \"Colls v. Home & Colonial Stores Ltd\" (1904). Courts rely on expert witnesses to define this term. Since the 1920s, experts have used a method proposed by Percy Waldram to assist them with this. Waldram suggested that ordinary people require one foot-candle of illuminance (approximately ten lux) for reading and other work involving visual discrimination. This equates to a sky factor (similar to the daylight factor) of 0.2%. Today, Waldram's methods are increasingly subject to criticism and the future of expert evidence in rights to light cases is currently the subject of much debate within the surveying profession.\n\nAfter the Second World War, owners of buildings could gain new rights by registering properties that had been destroyed in bombings and the period was temporarily increased to 27 years.\n\nIn the centre of London near Chinatown and Covent Garden, particularly in back alleyways, signs saying \"Ancient Lights\" can be seen marking individual windows. The design and construction of Broadcasting House in the early 1930s was also affected by locals declaring their right to ancient lights. It resulted in a unique asymmetrical sloped design that allowed for sunlight to pass over the building to the residential quarters eastwards, long since demolished and now home to the new Egton Wing.\n\nRecent case law from 2010, relating to a commercial development in the centre of Leeds (\"HKRUK II v Heaney\") has significantly changed the perceptions of risk associated with right-to-light, particularly in the context of commercial schemes. This case upheld an injunction against a commercial property. The result of this is that many developers are now looking to work with local authorities to try to use section 237 of the Town and Country Planning Act 1990. This potentially stops injunctions against schemes that have over-riding social or economic advantages to an area.\n\nUnder United States tort law, in \"Fontainebleau Hotel Corp. v. Forty-Five Twenty-Five, Inc.\" (1959) the Florida Appellate Court stated that the \"ancient lights\" doctrine had been unanimously repudiated in the United States.\n\nIn 1984, voters in San Francisco passed Proposition K, which prevents construction of any building over 40 feet that casts a shadow on a public park, unless the Planning Commission decides the shadow is insignificant. This proposition causes problems for a proposed 34-story building south of Market Street, which would cast a shadow on a public park ten blocks away, for one hour of the day in the fall, as well as St. Mary's Square, Justin Herman Plaza, and Union Square for significant parts of the year. Massachusetts has similar laws against the casting of shadows on Boston Common, the Public Garden, and other important public open spaces.\n\n\nDavis, Howard. \"The Future of Ancient Lights,\" Journal of Architectural and Planning Research, Vol. 6, No. 2, Summer 1989, pp. 132-153.\n"}
{"id": "16458069", "url": "https://en.wikipedia.org/wiki?curid=16458069", "title": "Solid image", "text": "Solid image\n\nThe Solid image is a geomatic (Geomatics) product giving the possibility to mesures 3D coordinates from a simple 2D image. The solid image is an easy and complete way to describe 3D objects.\n\nA photo image can be considered, from a photogrammetric (photogrammetry) point of view, a central perspective of the acquired object with good approximation. If the internal and external orientation of the camera are known, it is possible to establish the direction in the space of each object point represented by a pixel in the digital image. If only one image is available, it is impossible to determine the spatial X,Y,Z position of such object points, because the simple direction is insufficient: all the points along that direction would give the same image point.\n\nBy means of a DDEM (Dense Digital elevation model) of the acquired object, every pixel (and therefore every direction in the space)can be associated to the value of distance between the center of perspectivity and the object point represented by the pixel itself. In this way each pixel can be referred to the 3D position of the corresponding object point in an absolute reference system.\nThe DDEM can be derived from an existing map, or by the use of surveying instruments and procedures. A series of instruments, based on the laser technology (3D scanner), have been introduced on the market, giving the possibility to obtain a DDEM in a quick and cheap way.\n\nDefinition, first results and applications of the solid image was presented in the ISPRS (International Society for Photogrammetry and Remote Sensing - ) Comm.V, WG V/4 meeting in Ancona, July 2003 and in the CIPA 2003 XIXth Symposium – Antalya, Turkey 30 September - 04 October2003.\nThe Solid Image have been ideated by Prof. Sergio Dequal, DITAG - Dipartimento di Ingegneria del Territorio, dell'Ambiente e delle Geotecnlogie del Politecnico di Torino (), and developed by a DITAG Politecnico di Torino research group (Prof. Fulvio Rinaudo, Prof. Andrea Lingua, Dott. Leandro Bornaz).\n\n"}
{"id": "12979739", "url": "https://en.wikipedia.org/wiki?curid=12979739", "title": "Stadia mark", "text": "Stadia mark\n\nStadia marks, also called stadia lines or stadia hairs, are crosshairs on the reticle of a theodolite or other surveying instrument that allow stadiametric rangefinding.\n\nThe term stadia mark derives from the obsolete unit of distance, the stadia derived from the Greek measurement of a stadium. There were several different stadia defined such as the Greek stadia and Egyptian stadia.\n\nA typical surveyor's instrument reticle has two pairs of stadia marks. One pair are on the horizontal centreline and the other on the vertical cross hair. Each functions in the same manner and are placed for measuring on either axis.\n\nThe stadia marks are set a specific distance apart. The distance is chosen so that there is a fixed, integer ratio between the distance observed between the marks and the distance from the telescope to the measuring device observed. This is known as the \"stadia constant\" or \"stadia interval factor\". For example, a typical stadia mark pair are set so that the ratio is 100. If one observes a stadia rod, rule or levelling rod with the telescope and sees that the rod spans 0.5m between the marks (the \"stadia interval\"), then the distance from the instrument to the rod is:\n\nIn the adjacent image, the upper stadia mark is at 1.5 m and the lower at 1.345 m. The difference is 0.155 m. Thus the distance from the instrument to the levelling rod is:\n\n\n"}
{"id": "23003745", "url": "https://en.wikipedia.org/wiki?curid=23003745", "title": "Standard Interchange Format", "text": "Standard Interchange Format\n\nStandard Interchange Format, called SIF, is a geospatial data exchange format. A standard or neutral format used to move graphics files between DOD Project 2851 and is currently codified in Content Standard for Digital Geospatial Metadata maintained by the Federal Geographic Data Committee.\n\nUnit 69 of the NCGIA Core Corriculum in GIS states that SIF is a \"popular data exchange format for many GIS packages\" and was \"developed to support exchange of data between Intergraph and other systems.\"\n\nNavteq uses Standard Interchange Format (SIF) \n\nAnother example of data available in SIF format can be found online from the NASA's BOREAS project that also claims that the SIF format is \"not well documented.\"\n\nAdditional criticism of SIF, along with recognition of SIF's ubiquity and utility for exchanging data, is acknowledged in the online journal article \"Is a Standard Terrain Data Format Necessary?\"\n\n"}
{"id": "15753093", "url": "https://en.wikipedia.org/wiki?curid=15753093", "title": "Surgical segment navigator", "text": "Surgical segment navigator\n\nThe surgical segment navigator (SSN) is a computer-based system for use in surgical navigation. It is integrated into a common platform, together with the surgical tool navigator (STN), the surgical microscope navigator (SMN) and the 6DOF manipulator (MKM), developed by Carl Zeiss.\n\nThe SSN has been developed as a computer system for bone segment navigation in oral and maxillofacial surgery. It allows a very precise repositioning of bone fragments, with the advent of preoperative simulation and surgical planning.The system has been developed since 1997 at the University of Regensburg, Germany, with the support of the Carl Zeiss Company. Its principle is based on an infrared localisation system, composed of an infrared camera and at least three infrared transmitters attached to each bony fragment. The SSN is mainly used in orthognatic surgery (surgical correction of dysgnathia), but also for the surgical reconstruction of the orbit, or other surgical interventions to the midface.\n\nSince 2001, at the University of Heidelberg, Germany, the SSN++ has been developed, a markerless-registration navigation system, based on a native (=markerless) CT or MRI. In this case, the patient registration is obtained on the operating table, using a surface scanner. The SSN++ correlates the surface scan data (gathered on the operating table) with the skin surface reconstruction from the dataset obtained preoperatively by CT or MRI. This principle complies with the terrain contour matching principle described for flying objects. The advantage of the new method is that the registration of the patient's position becomes a simple automated procedure; on the other hand, the radiation load for the patient is reduced, compared to the method using markers.\n\n\n"}
{"id": "57495096", "url": "https://en.wikipedia.org/wiki?curid=57495096", "title": "Surveying and Mapping Act", "text": "Surveying and Mapping Act\n\nThe Surveying and Mapping Act was assented to by the President of Pakistan in May 2014 after being passed by the National Assembly in order to regulate geospatial data.\n\nIn 2012, the Land Surveying and Mapping Bill was proposed to entrust all mapping responsibilities in Pakistan to the Survey of Pakistan. The proposed bill would require all government and private agencies involved in surveying and mapping to register with the Survey of Pakistan; failure to comply would be punished with one year of imprisonment and a fine of up to one million rupees. The Ministry of Defence argued that the mapping activities of unauthorised firms could go unchecked without a law or regulatory authority. The objectives of the proposed bill would be to prevent the unauthorised mapping of sensitive areas (a potential security risk), prevent damage to survey markers, avoid duplication of mapping efforts, and to make the Survey of Pakistan a National Mapping Agency.\n\nThe bill was passed by Pakistan's National Assembly in 2014.\n\nSyed Ali Asjad Naqvi, Research and Training Director at the Center for Economic Research in Pakistan (CERP), expressed bafflement towards the proposed bill, stating that it will hinder ongoing humanitarian efforts which employ mapping. Naqvi added that bills should be proposed by public representatives rather than the military.\n\n"}
{"id": "5284746", "url": "https://en.wikipedia.org/wiki?curid=5284746", "title": "Sustainable city", "text": "Sustainable city\n\nSustainable cities, urban sustainability, or eco-city (also \"ecocity\") is a city designed with consideration for social, economic, environmental impact , and resilient habitat for existing populations, without compromising the ability of future generations to experience the same. These cities are inhabited by people whom are dedicated towards minimization of required inputs of energy, water, food, waste, output of heat, air pollution - CO, methane, and water pollution. Richard Register first coined the term \"ecocity\" in his 1987 book, \"Eco city Berkeley: Building Cities for a Healthy Future\". Other leading figures who envisioned the sustainable city are architect Paul F Downton, who later founded the company Ecopolis Pty Ltd, as well as authors Timothy Beatley and Steffen Lehmann, who have written extensively on the subject. The field of industrial ecology is sometimes used in planning these cities.\n\nThere remains no completely agreed upon definition for what a sustainable city should be or completely agreed upon paradigm for what components should be included. Generally, developmental experts agree that a sustainable city should meet the needs of the present without sacrificing the ability of future generations to meet their own needs. The ambiguity within this idea leads to a great deal of variation in terms of how cities carry out their attempts to become sustainable.\n\nIdeally, a sustainable city creates an enduring way of life across the four domains of ecology, economics, politics and culture. However, minimally a sustainable city should firstly be able to feed itself with a sustainable reliance on the surrounding countryside. Secondly, it should be able to power itself with renewable sources of energy. The core of this is to create the smallest conceivable ecological footprint, while producing the lowest quantity of pollution achievable. All while efficiently using the land; composting used materials, and recycling or converting waste-to-energy. All of these contributions will lead to the city's overall impacts on climate change to be minimal and with as little impact. The Adelaide City Council states that socially sustainable cities should be equitable, diverse, connected, and democratic and provide a good quality of life. \n\nA sustainable city can feed itself with minimal reliance on the surrounding countryside, and power itself with renewable sources of energy. The crux of this is to create the smallest possible ecological footprint, and to produce the lowest quantity of pollution possible, to efficiently use land; compost used materials, recycle it or convert waste-to-energy, and thus the city's overall contribution to climate change will be minimal, if such practices are adhered to. \n\nIt is estimated that over 50% of the world’s population now lives in cities and urban areas. These large communities provide both challenges and opportunities for environmentally-conscious developers. There are distinct advantages to further defining and working towards the goals of sustainable cities. Humans are social creatures and thrive in urban spaces that foster social connections. Richard Florida, an urban studies theorist, focuses on the social impact of sustainable cities and states that cities need to be more than a competitive business climate; they need to be a great people climate that appeals to individuals and families of all types. Because of this, a shift to more dense, urban living would provide an outlet for social interaction and conditions under which humans can prosper. These types of urban areas would also promote the use of public transit, walkability and biking which would benefit citizens health wise but also be environmentally beneficial.\n\nContrary to common belief, urban systems can be more environmentally sustainable than rural or suburban living. With people and resource located so close to one another it is possible to save energy for transportation and mass transit systems, and resources such as food. Cities benefit the economy by locating human capital in one relatively small geographic area where ideas can be generated. Having a more dense, urban space would also increase people's efficiency since they wouldn't have to spend as much time commuting to places if resources are located close together, which in turn would benefit the economy since people can use this extra time on other matters; like work.\n\nThese ecological cities are achieved through various means, such as:\n\nBuildings provide the infrastructure for a functioning city and allow for many opportunities to demonstrate a commitment to sustainability. A commitment to sustainable architecture encompasses all phases of building including the planning, building, and restructuring. Sustainable Site Initiatives is used by landscape architects, designers, engineers, architects, developers, policy-makers and others to align land development and management with innovative sustainable design.\n\nThe purpose of an eco-industrial park is to connect a number of firms and organizations to work together to decrease their environmental impact while simultaneously improving their economic performance. The community of businesses accomplishes this goal through collaboration in managing environmental and resource issues, such as energy, water, and materials. The components for building an eco-industrial park include natural systems, more efficient use of energy, and more efficient material and water flows Industrial parks should be built to fit into their natural settings in order to reduce environmental impacts, which can be accomplished through plant design, landscaping, and choice of materials. For instance, there is an industrial park in Michigan built by Phoenix Designs that is made almost entirely from recycled materials. The landscaping of the building will include native trees, grasses, and flowers, and the landscaping design will also act as climate shelter for the facility. In choosing the materials for building an eco-industrial park, designers must consider the life-cycle analysis of each medium that goes into the building to assess their true impact on the environment and to ensure that they are using it from one plant to another, steam connections from firms to provide heating for homes in the area, and using renewable energy such as wind and solar power. In terms of material flows, the companies in an eco-industrial park may have common waste treatment facilities, a means for transporting by-products from one plant to another, or anchoring the park around resource recovery companies that are recruited to the location or started from scratch. To create more efficient water flows in industrial parks, the processed water from one plant can be reused by another plant and the parks infrastructure can include a way to collect and reuse storm water runoff.\n\nSee also: Urban Agriculture\n\nUrban farming is the process of growing and distributing food, as well as raising animals, in and around a city or in urban area. According to the RUAF Foundation, urban farming is different from rural agriculture because \"it is integrated into the urban economic and ecological system: urban agriculture is embedded in -and interacting with- the urban ecosystem. Such linkages include the use of urban residents as labourers, use of typical urban resources (like organic waste as compost and urban wastewater for irrigation), direct links with urban consumers, direct impacts on urban ecology (positive and negative), being part of the urban food system, competing for land with other urban functions, being influenced by urban policies and plans, etc.\" There are many motivations behind urban agriculture, but in the context of creating a sustainable city, this method of food cultivation saves energy in food transportation and saves costs. In order for urban farming to be a successful method of sustainable food growth, cities must allot a common area for community gardens or farms, as well as a common area for a farmers market in which the foodstuffs grown within the city can be sold to the residents of the urban system.\nBerms of fava beans have been planted at Hayes Valley Farm, a community-built farm on the former Central freeway ramps of San Francisco.\n\nMany cities are currently in a shift from the suburban sprawl model of development to a return to urban dense living. This shift in geographic distribution of population leads to a denser core of city residents. These residents provide a growing demand in many sectors that is reflected in the architectural fabric of the city. This new demand can be supplied by new construction or historic rehabilitation. Sustainable cities will opt for historical rehabilitation wherever possible. Having people live in higher densities not only gives economies of scale but also allows for infrastructure to be more efficient.\n\nWalkable urbanism is a development strategy in opposition to suburban sprawl. It advocates housing for a diverse population, a full mix of uses, walkable streets, positive public space, integrated civic and commercial centers, transit orientation and accessible open space. It also advocates for density and accessibility of commercial and government activity.\n\nThe most clearly defined form of walkable urbanism is known as the Charter of New Urbanism. It is an approach for successfully reducing environmental impacts by altering the built environment to create and preserve smart cities which support sustainable transport. Residents in compact urban neighborhoods drive fewer miles, and have significantly lower environmental impacts across a range of measures, compared with those living in sprawling suburbs. The concept of circular flow land use management has also been introduced in Europe to promote sustainable land use patterns that strive for compact cities and a reduction of greenfield land taken by urban sprawl.\n\nIn sustainable architecture the recent movement of New Classical Architecture promotes a sustainable approach towards construction, that appreciates and develops smart growth, walkability, architectural tradition and classical design. This in contrast to modernist and globally uniform architecture, as well as opposing solitary housing estates and suburban sprawl. Both trends started in the 1980s.\n\nMain article: Leadership in Energy and Environmental Design\n\nThe Leadership in Energy and Environmental Design (LEED) Green Building Rating System® encourages and accelerates global adoption of sustainable green building and development practices through the creation and implementation of universally understood and accepted tools and performance criteria.\n\nLEED, or Leadership in Energy and Environmental Design, is an internationally recognized green building certification system. LEED recognizes whole building sustainable design by identifying key areas of excellence including: Sustainable Sites, Water Efficiency, Energy and Atmosphere, Materials and Resources, Indoor Environmental Quality, Locations & Linkages, Awareness and Education, Innovation in Design, Regional Priority. In order for a building to become LEED certified sustainability needs to be prioritized in design, construction, and use. One example of sustainable design would be including a certified wood like bamboo. Bamboo is fast growing and has an incredible replacement rate after being harvested. By far the most credits are rewarded for optimizing energy performance. This promotes innovative thinking about alternative forms of energy and encourages increased efficiency.\n\nSustainable Sites Initiative, a combined effort of the American Society of Landscape Architects, The Lady Bird Johnson Wildflower Center at The University of Texas at Austin, and the United States Botanic Garden, is a voluntary national guideline and performance benchmark for sustainable land design, construction and maintenance practices. The building principles of SSI are to design with nature and culture, use a decision-making hierarchy of preservation, conservation, and regeneration, use a system thinking approach, provide regenerative systems, support a living process, use a collaborative and ethical approach, maintain integrity in leadership and research, and finally foster environmental stewardship. All of these help promote solutions to common environmental issues such as greenhouse gases, urban climate issues, water pollution and waste, energy consumption, and health and wellbeing of site users. The main focus is hydrology, soils, vegetation, materials, and human health and well being.\n\nIn SSI, the main goal for hydrology in sites is to protect and restore existing hydrologic functions. To design storm water features to be accessible to site users, and manage and clean water on site. For site design of soil and vegetationmany steps can be done during the construction process to help minimize the urban heat island effects, to and minimize the building heating requirements by using plants.\n\nAs major focus of the sustainable cities, sustainable transportation attempts to reduce a city’s reliance and use of greenhouse emitting gases by utilizing eco friendly urban planning, low environmental impact vehicles, and residential proximity to create an urban center that has greater environmental responsibility and social equity.\n\nDue to the significant impact that transportation services have on a city’s energy consumption, the last decade has seen an increasing emphasis on sustainable transportation by developmental experts. Currently, transportation systems account for nearly a quarter of the world’s energy consumption and carbon dioxide emission. In order to reduce the environmental impact caused by transportation in metropolitan areas, sustainable transportation has three widely agreed upon pillars that it utilizes to create more healthy and productive urban centers.\n\nThe Carbon Trust states that there are three main ways cities can innovate to make transport more sustainable without increasing journey times - better land use planning, modal shift to encourage people to choose more efficient forms of transport, and making existing transport modes more efficient.\n\nThe concept of car free cities or a city with large pedestrian areas is often part of the design of a sustainable city. A large part of the carbon footprint of a city is generated by cars so the car free concept is often considered an integral part of the design of a sustainable city.\n\nCreated by eco friendly urban planning, the concept of urban proximity is an essential element of current and future sustainable transportation systems. This requires that cities be built and added onto with appropriate population and landmark density so that destinations are reached with reduced time in transit. This reduced time in transit allows for reduced fuel expenditure and also opens the door to alternative means of transportation such as bike riding and walking.\nTransportation in downtown Chicago\nFurthermore, close proximity of residents and major landmarks allows for the creation of efficient public transportation by eliminating long sprawled out routes and reducing commute time. This in turn decreases the social cost to residents who choose to live in these cities by allowing them more time with families and friends instead by eliminating part of their commute time.\n\nSee also: Compact city and Pocket neighborhood\n\nSustainable transportation emphasizes the use of a diversity of fuel-efficient transportation vehicles in order to reduce greenhouse emissions and diversity fuel demand. Due to the increasingly expensive and volatile cost of energy, this strategy has become very important because it allows a way for city residents to be less susceptible to varying highs and lows in various energy prices.\n\nAmong the different modes of transportation, the use alternative energy cars and widespread installation of refueling stations has gained increasing importance, while the creation of centralized bike and walking paths remains a staple of the sustainable transportation movement.\n\nIn order to maintain the aspect of social responsibility inherent within the concept of sustainable cities, implementing sustainable transportation must include access to transportation by all levels of society. Due to the fact that car and fuel cost are often too expensive for lower income urban residents, completing this aspect often revolves around efficient and accessible public transportation.\n\nIn order to make public transportation more accessible, the cost of rides must be affordable and stations must be located no more than walking distance in each part of the city. As studies have shown, this accessibility creates a great increase in social and productive opportunity for city residents. By allowing lower income residents cheap and available transportation, it allows for individuals to seek employment opportunities all over the urban center rather than simply the area in which they live. This in turn reduces unemployment and a number of associated social problems such as crime, drug use, and violence.\n\nAlthough there is not an international policy regarding sustainable cities and there are not established international standards, there is an organization, the United Cities and Local Governments (UCLG) that is working to establish universal urban strategic guidelines. The UCLG a democratic and decentralized structure that operates in Africa, Asia, Eurasia, Europe, Latin America, North America, Middle East, West Asian and a Metropolitan section work to promote a more sustainable society. The 60 members of the UCLG committee evaluate urban development strategies and debate theses experiences to make the best recommendations. Additionally, the UCLG accounts for differences in regional and national context. All the organizations are making a great effort to promote this concept by media and internet, and in conferences and workshops. An International conference was held in Italy at Università del Salento and Università degli Studi della Basilicata, called 'Green Urbanism', from 12–14 October 2016.\n\nRecently, local and national governments and regional bodies such as the European Union have recognized the need for a holistic understanding of urban planning. This is instrumental to establishing an international policy that focuses on cities challenges and the role of the local authorities responses. Generally, in terms of urban planning, the responsibility of local governments are limited to land use and infrastructure provision excluding inclusive urban development strategies. The advantages of urban strategic planning include an increase in governance and cooperation that aids local governments in establishing performance based-management, clearly identifying the challenges facing local community and more effectively responding on a local level rather than national level, and improves institutional responses and local decision making. Additionally, it increases dialogue between stakeholders and develops consensus-based solutions, establishing continuity between sustainability plans and change in local government; it places environmental issues as the priority for the sustainable development of cities and serves as a platform to develop concepts and new models of housing, energy and mobility.\n\nThe City Development Strategies (CDS) addresses new challenges and provides space for innovative policies that involves all stakeholders. The inequality in spatial development and socio-economic classes paired with concerns of poverty reduction and climate change are factors in achieving global sustainable cities. According to the UCLG there are differences between regional and national conditions, framework and practice that are overcome in the international commitment to communication and negotiation with other governments, communities and the private sector to continual to develop through innovative and participatory approaches in strategic decisions, building consensus and monitoring performance management and raising investment.\n\nAccording to UN Habitat, around half of the world's population is concentrated in cities, which is set to rise to 60% within a couple decades. The UCLG has specifically identified 13 global challenges to establishing sustainable cities: demographic change and migration, globalisation of the job market, poverty and unmet Millennium Development Goals, segregation, spatial patterns and urban growth, metropolisation and the rise of urban regions, more political power for local authories, new actors for developing a city and providing services, decline in public funding for development, the environment and climate change, new and accessible building technologies, preparing for uncertainty and limits of growth and global communications and partnerships.\n\nUrban forests\n\nIn Adelaide, South Australia (a city of 1.3 million people) Premier Mike Rann (2002 to 2011) launched an urban forest initiative in 2003 to plant 3 million native trees and shrubs by 2014 on 300 project sites across the metro area. The projects range from large habitat restoration projects to local biodiversity projects. Thousands of Adelaide citizens have participated in community planting days. Sites include parks, reserves, transport corridors, schools, water courses and coastline. Only trees native to the local area are planted to ensure genetic integrity. Premier Rann said the project aimed to beautify and cool the city and make it more liveable; improve air and water quality and reduce Adelaide's greenhouse gas emissions by 600,000 tonnes of C02 a year. He said it was also about creating and conserving habitat for wildlife and preventing species loss.\n\nSolar power\n\nThe Rann government also launched an initiative for Adelaide to lead Australia in the take-up of solar power. In addition to Australia's first 'feed-in' tariff to stimulate the purchase of solar panels for domestic roofs, the government committed millions of dollars to place arrays of solar panels on the roofs of public buildings such as the museum, art gallery, Parliament, Adelaide Airport, 200 schools and Australia's biggest rooftop array on the roof of Adelaide Showgrounds' convention hall which was registered as a power station.\n\nWind power\n\nSouth Australia went from zero wind power in 2002 to wind power, making up 26% of its electricity generation by October 2011. In the five years preceding 2011 there was a 15% drop in emissions, despite strong economic growth.\n\nWaste recycling\n\nFor Adelaide the South Australian government also embraced a Zero Waste recycling strategy, achieving a recycling rate of nearly 80% by 2011 with 4.3 million tonnes of materials diverted from landfill to recycling. On a per capita basis this was the best result in Australia, the equivalent of preventing more than a million tonnes of C02 entering the atmosphere. In the 1970s container deposit legislation was introduced. Consumers are paid a 10 cent rebate on each bottle, can, or container they return to recycling. In 2009 non-reusable plastic bags used in supermarket checkouts were banned by the Rann Government, preventing 400 million plastic bags per year entering the litter stream. In 2010 Zero Waste SA was commended by a UN Habitat Report entitled 'Solid Waste Management in the World Cities'.\n\nMelbourne\n\n\nThe City of Greater Taree north of Sydney has developed a masterplan for Australia's first low-to-no carbon urban development.\n\nBelo Horizonte, Brazil was created in 1897 and is the third largest metropolis in Brazil, with 2.4 million inhabitants. The Strategic Plan for Belo Horizonte (2010–2030) is being prepared by external consultants based on similar cities' infrastructure, incorporating the role of local government, state government, city leaders and encouraging citizen participation. The need for environmental sustainable development is led by the initiative of new government following planning processes from the state government. Overall, the development of the metropolis is dependent on the land regularization and infrastructure improvement that will better support the cultural technology and economic landscape.Southern cities of Porto Alegre and Curitiba are often cited as examples of urban sustainability.\n\n\nThe GreenScore City Index studies the ecological footprints of Canadian cities and splits them into three population categories: large, medium, and small. The index studies 50 cities in Canada.\n\n\nMost cities in Canada have sustainability action plans which are easily searched and downloaded from city websites.\n\nIn 2010, Calgary ranked as the top eco-city in the planet for it's, \"excellent level of service on waste removal, sewage systems, and water drinkability and availability, coupled with relatively low air pollution.” The survey was performed in conjunction with the reputable Mercer Quality of Living Survey.\n\n\nTwo comprehensive studies were carried out for the whole of Denmark in 2010 (The IDA Climate Plan 2050) and 2011 (The Danish Commission on Climate Change Policy). The studies analysed the benefits and obstacles of running Denmark on 100% renewable energy from the year 2050. There is also a larger, ambitious plan in action: the Copenhagen 2025 Climate Plan.\n\nOn a more local level, the industrial park in Kalundborg is often cited as a model for industrial ecology. However, projects have been carried out in several Danish cities promoting 100% renewable energy. Examples include Aalborg, Ballerup and Frederikshavn. Aalborg University has launched a master education program on sustainable cities (Sustainable Cities @ Aalborg University Copenhagen). See also the Danish Wikipedia.\n\n\nLoja, Ecuador won three international prizes for the sustainability efforts begun by its mayor Dr. Jose Bolivar Castillo.\n\nOxford Residences for four seasons in Estonia, winning a prize for Sustainable Company of the Year, is arguably one of the most advanced sustainable developments, not only trying to be carbon neutral, but already carbon negativeGermany \n\nFreiburg im Breisgau is often referred to as green city. It is known for its strong solar economy. Vauban, Freiburg is a sustainable model district. All houses are built to a low energy consumption standard and the whole district is designed to be carfree. \n\nThe Finnish city of Turku has adopted a \"Carbon Neutral Turku by 2040\" strategy to achieve carbon neutrality via combining the goal with circular economy.\n\nNo other country has built more eco-city projects than Germany. Freiburg im Breisgau is often referred to as a green city. It is one of the few cities with a Green mayor and is known for its strong solar energy industry. Vauban, Freiburg is a sustainable model district. All houses are built to a low energy consumption standard and the whole district is designed to be carfree. Another green district in Freiburg is Rieselfeld, where houses generate more energy than they consume. There are several other green sustainable city projects such as Kronsberg in Hannover and current developments around Munich, Hamburg and Frankfurt.\n\n\nThe government portrays the proposed Hung Shui Kiu new town as an eco-city. The same happened with the urban development plan on the site of the former Kai Tak Airport.\n\nSouth Dublin County Council announced plans in late 2007 to develop Clonburris, a new suburb of Dublin to include up to 15,000 new homes, to be designed to achieve the highest of international standards. The plans for Clonburris include countless green innovations such as high levels of energy efficiency, mandatory renewable energy for heating and electricity, the use of recycled and sustainable building materials, a district heating system for distributing heat, the provision of allotments for growing food, and even the banning of tumble driers, with natural drying areas being provided instead.\n\nIn 2012 a energy plan was carried out by the Danish Aalborg University for the municipalities of Limerick and Clare. The project was a short-term 2020 renewable energy strategy giving a 20% reduction in CO emissions, while ensuring that short-term actions are beneficial to the long-term goal of 100% renewable energy.\n\nIndia is working on Gujarat International Finance Tec-City or GIFT which is an under-construction world-class city in the Indian state of Gujarat. It will come up on 500 acres (2.0 km) land. It will also be first of its kind fully Sustainable City.\nAuroville was founded in 1968 with the intention of realizing human unity, and is now home to approximately 2,000 individuals from over 45 nations around the world. Its focus is its vibrant community culture and its expertise in renewable energy systems, habitat restoration, ecology skills, mindfulness practices, and holistic education.\nAndhra Pradesh state New capital also coming up with a future sustainable city.\n\nHacienda - Mombasa, Kenya. It is the largest development of eco-friendly residential properties in East Africa; construction is currently ongoing, and it will eventually be one of Africa’s first self-sustaining estates.\n\nSongdo IBD is a planned city in Incheon which has incorporated a number of eco-friendly features. These include a central park irrigated with seawater, a subway line, bicycle lanes, rainwater catchment systems, and pneumatic waste collection system. 75% of the waste generated by the construction of the city will be recycled.\n\nGwanggyo City Centre is another planned sustainable city.\n\nAs of 2014 a Low Carbon Cities programme is being piloted in Malaysia by KeTTHA, the Malaysian Ministry of Energy, Green Technology and Water, Malaysian Green Technology Corporation (GreenTech Malaysia) and the Carbon Trust.\n\nMalacca has a stated ambition to become a carbon-free city, taking steps towards creating a smart electricity grid. This is being done as part of an initiative to create a Green Special Economic Zone, where it is intended that as many as 20 research and development centers will be built focusing on renewable energy and clean technology, creating up to 300,000 new green jobs. \n\nThe Federal Department of Town and Country Planning (FDTCP) in peninsular Malaysia is a focal point for the implementation of the Malaysian Urban Rural National Indicators Network for Sustainable Development (MURNInets)MURNInets includes 36 sets of compulsory indicators grouped under 21 themes under six dimensions. Most of the targets and standards for the selected indicators were adjusted according to hierarchy of local authorities. In MURNInets at least three main new features are introduced. These include the Happiness Index, an indicator under the quality of life theme to meet the current development trend that emphasizes on the well-being of the community. Another feature introduced is the customer or people satisfaction level towards local authorities' services. Through the introduction of these indicators the bottom-up approach in measuring sustainability is adopted.\n\nThe city of Waitakere, the Western part of the greater Auckland urban region, was New Zealand's first eco-city, working from the Greenprint, a guiding document that the City Council developed in the early 1990s.\n\nClark Freeport Zone is a former United States Air Force base in the Philippines. It is located on the northwest side of Angeles City and on the west side of Mabalacat City in the province of Pampanga, about 40 miles (60 km) northwest of Metro Manila. A multi-billion project will convert the 36,000 hectare former Clark Air Force Base into a mix of industrial, commercial and institutional areas of green environment. The heart of the project is a 9,450-hectare metropolis dubbed as the \"Clark Green City\". Builders will use the green building system for environmentally-friendly structures. Its facilities will tap renewable energy such as solar and hydro power.\n\nThe organization Living PlanIT is currently constructing a city from scratch near Porto, Portugal. Buildings will be electronically connected to vehicles giving the user a sense of personal eco-friendliness.\n\n\n\n\n\n\nSee also the Sustainability navigational box at the bottom of the page.\n\n\n\n"}
{"id": "27919989", "url": "https://en.wikipedia.org/wiki?curid=27919989", "title": "Timeline of European exploration", "text": "Timeline of European exploration\n\nThe following timeline covers European exploration from 1418 to 1957.\n\nThe 15th century witnessed the rounding of the feared Cape Bojador and Portuguese exploration of the west coast of Africa, while in the last decade of the century the Spanish sent expeditions to the New World, focusing on exploring the Caribbean Sea, and the Portuguese discovered the sea route to India. In the 16th century, various countries sent exploring parties into the interior of the Americas, as well as to their respective west and east coasts north to California and Labrador and south to Chile and Tierra del Fuego. In the 17th century, the Russians explored and conquered Siberia in search of sables, while the Dutch roughly worked on the chart for Australia. The 18th century saw the first extensive exploration of the South Pacific and the discovery of Alaska, while the nineteenth was dominated by exploration of the polar regions (not to mention excursions into the heart of Africa). By the 20th century, the poles themselves had been reached.\n\n\n\n\n \n\n\n\n"}
{"id": "3154072", "url": "https://en.wikipedia.org/wiki?curid=3154072", "title": "Tracking system", "text": "Tracking system\n\nA tracking system is used for the observing of persons or objects on the move and supplying a timely ordered sequence of location data for further processing.\n\nIn virtual space technology, a tracking system is generally a system capable of rendering virtual space to a human observer while tracking the observer's coordinates. For instance, in dynamic virtual auditory space simulations, a real-time head tracker provides feedback to the central processor, allowing for selection of appropriate head-related transfer functions at the estimated current position of the observer relative to the environment.\n\nThere are myriads of tracking systems. Some are 'lag time' indicators, that is, the data is collected after an item has passed a point for example a bar code or choke point or gate. Others are 'real-time' or 'near real-time' like Global Positioning Systems (GPS) depending on how often the data is refreshed. There are bar-code systems which require a person to scan items and automatic identification (RFID auto-id). For the most part, the tracking worlds are composed of discrete hardware and software systems for different applications. That is, bar-code systems are separate from Electronic Product Code (EPC) systems, GPS systems are separate from active real time locating systems or RTLS for example, a passive RFID system would be used in a warehouse to scan the boxes as they are loaded on a truck - then the truck itself is tracked on a different system using GPS with its own features and software. The major technology “silos” in the supply chain are:\n\nIndoors assets are tracked repetitively reading e.g. a barcode, any passive and active RFID and feeding read data into Work in Progress models (WIP) or Warehouse Management Systems (WMS) or ERP software. The readers required per choke point are meshed auto-ID or hand-held ID applications.\n\nHowever tracking could also be capable of providing monitoring data without binding to a fixed location by using a cooperative tracking capability, e.g. an RTLS.\n\nOutdoors mobile assets of high value are tracked by choke point,\n802.11, Received Signal Strength Indication (RSSI), Time Delay on Arrival (TDOA), active RFID or GPS Yard Management; feeding into either third party yard management software from the provider or to an existing system. Yard Management Systems (YMS) couple location data collected by RFID and GPS systems to help supply chain managers to optimize utilization of yard assets such as trailers and dock doors. YMS systems can use either active or passive RFID tags.\n\nFleet management is applied as a tracking application using GPS and composing tracks from subsequent vehicle's positions. Each vehicle to be tracked is equipped with a GPS receiver and relays the obtained coordinates via cellular or satellite networks to a home station. Fleet management is required by:\n\nOne such use of the RFID technology is in tracking IDs of students. Using GPS IDs would resolve the decreasing attendance in schools by monitoring the whereabouts of students when they did not attend class (Jensen, 2008). It is also used to efficiently check attendance. Perks of this tracking system is allowing students to check out library books buy food in the cafeterias (Jensen, 2008). The GPS IDs also act as a security measure to monitor any unwanted visitors or an emergency locator if a student cannot be found (Jensen, 2008). In the Spring Independent School District, students have been using for many years in check that students are staying in school during the day. Since they have instigated the system, attendance has increased thus schooling funding has increased as well (Jensen, 2008).\n\nRecently, debates over the Fourth Amendment have come up. Conservative students wish to keep their privacy and forbid to wear tracking devices, especially hackers can break into these systems to find out students’ information. Since many schools, such as those in the Spring Independent School District, require students to wear the tracking IDs, students argue that it is an immediate violation of their privacy (Jensen, 2008). Yet, the Fourth Amendment is not violated in these cases since students are not tracked in their homes (Warner, 2007). Each school’s decision over GPS IDs varies as states develop laws against these IDs in schools and as students protest for their privacy rights.\n\nLocation-based services or LBS is a term that is derived from the telematics and telecom world. The combination of A-GPS, newer GPS and cellular locating technology is what has enabled the latest “LBS” for handsets and PDAs. Line of sight is not necessarily required for a location fix. This is a significant advantage in certain applications since a GPS signal can still be lost indoors. As such, A-GPS enabled cell phones and PDAs can be located indoors and the handset may be tracked more precisely. This enables non-vehicle centric applications and can bridge the indoor location gap, typically the domain of RFID and RTLS systems, with an off the shelf cellular device.\n\nCurrently, A-GPS enabled handsets are still highly dependent on the LBS carrier system, so handset device choice and application requirements are still not apparent. Enterprise system integrators need the skills and knowledge to correctly choose the pieces that will fit the application and geography.\n\nRegardless of the tracking technology, for the most part the end-users just want to locate themselves or wish to find points of interest. The reality is that there is no \"one size fits all\" solution with locating technology for all conditions and applications.\n\nApplication of tracking is a substantial basis for vehicle tracking in fleet management, asset management, individual navigation, social networking, or mobile resource management and more. Company, group or individual interests can benefit from more than one of the offered technologies depending on the context.\n\nGPS has global coverage but can be hindered by line-of-sight issues caused by buildings and urban canyons. RFID is excellent and reliable indoors or in situations where close proximity to tag readers is feasible, but has limited range and still requires costly readers. RFID stands for Radio Frequency Identification. This technology uses electromagnetic waves to receive the signal from the targeting object to then save the location on a reader that can be looked at through specialized software (Warner, 2007).\n\nRTLS are enabled by Wireless LAN systems (according to IEEE 802.11) or other wireless systems (according to IEEE 802.15) with multilateration. Such equipment is suitable for certain confined areas, such as campuses and office buildings. RTLS require system-level deployments and server functions to be effective.\n\n\n"}
{"id": "2857072", "url": "https://en.wikipedia.org/wiki?curid=2857072", "title": "Triangulated irregular network", "text": "Triangulated irregular network\n\nA triangulated irregular network (TIN) is a representation of a continuous surface consisting entirely of triangular facets, used mainly as Discrete Global Grid in primary elevation modeling. \n\nThe vertices of these triangles are created from field recorded spot elevations through a variety of means including surveying through conventional, Global Positioning System Real-Time Kinematic (GPS RTK), photogrammetry, or some other means. Associated with three-dimensional data (\"x\", \"y\", and \"z\") and topography, TINs are useful for the description and analysis of general horizontal (\"x\" and \"y\") distributions and relationships.\n\nDigital TIN data structures are used in a variety of applications, including geographic information systems (GIS), and computer aided drafting (CAD) for the visual representation of a topographical surface. A TIN is an vector-based representation of the physical land surface or sea bottom, made up of irregularly distributed nodes and lines with three-dimensional coordinates (\"x\", \"y\", and \"z\") that are arranged in a network of non-overlapping triangles.\n\nA TIN comprises a triangular network of vertices, known as mass points, with associated coordinates in three dimensions connected by edges to form a triangular tessellation. Three-dimensional visualizations are readily created by rendering of the triangular facets. In regions where there is little variation in surface height, the points may be widely spaced whereas in areas of more intense variation in height the point density is increased.\n\nA TIN used to represent terrain is often called a digital elevation model (DEM), which can be further used to produce digital surface models (DSM) or digital terrain models (DTM). An advantage of using a TIN over a rasterized digital elevation model (DEM) in mapping and analysis is that the points of a TIN are distributed variably based on an algorithm that determines which points are most necessary to create an accurate representation of the terrain. Data input is therefore flexible and fewer points need to be stored than in a raster DEM, with regularly distributed points. While a TIN may be considered less suited than a raster DEM for certain kinds of GIS applications, such as analysis of a surface's slope and aspect, it is often used in CAD to create contour lines. A DTM and DSM can be formed from a DEM. A DEM can be interpolated from a TIN.\n\nTIN are based on a Delaunay triangulation or constrained Delaunay. Delaunay conforming triangulations are recommended over constrained triangulations. This is because the resulting TINs are likely to contain fewer long, skinny triangles, which are undesirable for surface analysis. Additionally, natural neighbor interpolation and Thiessen (Voronoi) polygon generation can only be performed on Delaunay conforming triangulations. A constrained Delaunay triangulation can be considered when you need to explicitly define certain edges that are guaranteed not to be modified (that is, split into multiple edges) by the triangulator. Constrained Delaunay triangulations are also useful for minimizing the size of a TIN, since they have fewer nodes and triangles where breaklines are not densified.\n\nThe TIN model was developed in the early 1970s as a simple way to build a surface from a set of irregularly spaced points. The first triangulated irregular network program for GIS was written by W. Randolph Franklin, under the direction of David Douglas and Thomas Peucker (Poiker), at Simon Fraser University in 1973.\n\n"}
{"id": "18315951", "url": "https://en.wikipedia.org/wiki?curid=18315951", "title": "Visual odometry", "text": "Visual odometry\n\nIn robotics and computer vision, visual odometry is the process of determining the position and orientation of a robot by analyzing the associated camera images. It has been used in a wide variety of robotic applications, such as on the Mars Exploration Rovers.\n\nIn navigation, odometry is the use of data from the movement of actuators to estimate change in position over time through devices such as rotary encoders to measure wheel rotations. While useful for many wheeled or tracked vehicles, traditional odometry techniques cannot be applied to mobile robots with non-standard locomotion methods, such as legged robots. In addition, odometry universally suffers from precision problems, since wheels tend to slip and slide on the floor creating a non-uniform distance traveled as compared to the wheel rotations. The error is compounded when the vehicle operates on non-smooth surfaces. Odometry readings become increasingly unreliable as these errors accumulate and compound over time.\n\nVisual odometry is the process of determining equivalent odometry information using sequential camera images to estimate the distance traveled. Visual odometry allows for enhanced navigational accuracy in robots or vehicles using any type of locomotion on any surface.\n\nThere are various types of VO.\n\nDepend on the camera setup, VO can be categorized as Monocular VO (single camera), Stereo VO (two camera in stereo setup).\n\nTraditional VO's visual information is obtained by Feature Based Method, which extract image feature points and tracking them in the image sequence. Recent development in VO research provided an alternative, called Direct Method, which uses pixel intensity in the image sequence directly as visual input. There are also hybrid methods.\n\nIf an inertial measurement unit (IMU) is used within the VO system, it is commonly referred to as Visual Inertial Odometry (VIO).\n\nMost existing approaches to visual odometry are based on the following stages.\n\n\nAn alternative to feature-based methods is the \"direct\" or appearance-based visual odometry technique which minimizes an error directly in sensor space and subsequently avoids feature matching and extraction.\n\nAnother method, coined 'visiodometry' estimates the planar roto-translations between images using Phase correlation instead of extracting features.\n\nEgomotion is defined as the 3D motion of a camera within an environment. In the field of computer vision, egomotion refers to estimating a camera's motion relative to a rigid scene. An example of egomotion estimation would be estimating a car's moving position relative to lines on the road or street signs being observed from the car itself. The estimation of egomotion is important in autonomous robot navigation applications.\n\nThe goal of estimating the egomotion of a camera is to determine the 3D motion of that camera within the environment using a sequence of images taken by the camera. The process of estimating a camera's motion within an environment involves the use of visual odometry techniques on a sequence of images captured by the moving camera. This is typically done using feature detection to construct an optical flow from two image frames in a sequence generated from either single cameras or stereo cameras. Using stereo image pairs for each frame helps reduce error and provides additional depth and scale information.\n\nFeatures are detected in the first frame, and then matched in the second frame. This information is then used to make the optical flow field for the detected features in those two images. The optical flow field illustrates how features diverge from a single point, the \"focus of expansion\". The focus of expansion can be detected from the optical flow field, indicating the direction of the motion of the camera, and thus providing an estimate of the camera motion.\n\nThere are other methods of extracting egomotion information from images as well, including a method that avoids feature detection and optical flow fields and directly uses the image intensities.\n\n"}
