{"id": "5395439", "url": "https://en.wikipedia.org/wiki?curid=5395439", "title": "Cave survey", "text": "Cave survey\n\nA cave survey is a map of all or part of a cave system, which may be produced to meet differing standards of accuracy depending on the cave conditions and equipment available underground. Cave surveying and cartography, i.e. the creation of an accurate, detailed map, is one of the most common technical activities undertaken within a cave and is a fundamental part of speleology. Surveys can be used to compare caves to each other by length, depth and volume, may reveal clues on speleogenesis, provide a spatial reference for other areas of scientific study and assist visitors with route-finding.\n\nTraditionally, cave surveys are produced in two-dimensional form due to the confines of print, but given the three-dimensional environment inside a cave, modern techniques using computer aided design are increasingly used to allow a more realistic representation of a cave system.\n\nThe first known plan of a cave dates from 1546, and was of a man-made cavern in tufa called the Stufe di Nerone (Nero's Oven) in Pozzuoli near Naples in Italy. The first natural cave to be mapped was the Baumannshöhle in Germany, of which a sketch from 1656 survives.\n\nAnother early survey dates from before 1680, and was made by John Aubrey of Long Hole in the Cheddar Gorge. It consists of an elevational section of the cave. Numerous other surveys of caves were made in the following years, though most are sketches and are limited in accuracy. The first cave that is likely to have been accurately surveyed with instruments is the Grotte de Miremont in France. This was surveyed by a civil engineer in 1765 and includes numerous cross-sections. Édouard-Alfred Martel was the first person to describe surveying techniques. His surveys were made by having an assistant walk down the passage until they were almost out of sight. Martel would then take a compass bearing to the assistant's light, and measure the distance by pacing up to the assistant. This would equate to a modern-day BCRA Grade 2 survey.\n\nThe first cave to have its centreline calculated by a computer is the Fergus River Cave in Ireland, which was plotted by members of the UBSS in 1964. The software was programmed onto a large university mainframe computer and a paper plot was produced.\n\nThere are many variations to surveying methodology, but most are based on a similar set of steps which haven't changed fundamentally in 250 years, although the instruments (compass and tape) have got smaller and more accurate. Since the late 1990s digital instruments such as distometers have started to change the process, leading to the advent of fully paperless surveying around 2007. The main variation on the normal methodology detailed below have been devices such as LIDAR and SONAR surveyors that produce a point cloud rather than a series of linked stations. Video-based surveying also exists in prototype form.\n\nA survey team begins at a fixed point (such as the cave entrance) and measures a series of consecutive line-of-sight measurements between stations. The stations are temporary fixed locations chosen chiefly for their ease of access and clear sight along the cave passage. In some cases, survey stations may be permanently marked to create a fixed reference point to which to return at a later date.\n\nThe measurements taken between the stations include:\n\nCoincident with recording straight-line data, details of passage dimensions, shape, gradual or sudden changes in elevation, the presence or absence of still or flowing water, the location of notable features and the material on the floor are recorded, often by means of a sketch map.\n\nLater, the cartographer analyses the recorded data, converting them into two-dimensional measurements by way of geometrical calculations. From them he/she creates a \"line-plot\"; a scaled geometrical representation of the path through the cave.\n\nThe cartographer then draws details around the line-plot, using the additional data of passage dimensions, water flow and floor/wall topography recorded at the time, to produce a completed cave survey. Cave surveys drawn on paper are often presented in two-dimensional \"plan\" and/or \"profile\" views, while computer surveys may simulate three dimensions. Although primarily designed to be functional, some cavers consider cave surveys as an art form.\n\nHydrolevelling is an alternative to measuring depth with clinometer and tape that has a long history of use in Russia. The technique is regularly used in building construction for finding two points with the same height, as in levelling a floor. In the simplest case, a tube with both ends open is used, attached to a strip of wood, and the tube is filled with water and the depth at each end marked. In Russia, measuring the depth of caves by hydrolevelling began in the 1970s, and was considered to be the most accurate means of measuring depth despite the difficulties in using the cumbersome equipment of the time. Interest in the method has been revived following the discovery of Voronja on the Arabica Massif in the Caucasus – currently the world's deepest cave.\n\nThe hydrolevel device used in recent Voronja expeditions comprises a transparent tube filled with water, which is coiled or placed on a reel. A rubber glove which acts as a reservoir is placed on one end of the tube, and a metal box with a transparent window is placed on the other. A diver's digital wristwatch with a depth gauge function is submerged in the box. If the rubber glove is placed on one station and the box with the depth gauge is placed on a lower one, then the hydrostatic pressure between the two points depends only on the difference in heights and the density of the water, i.e. the route of the tube does not affect the pressure in the box. Reading the depth gauge gives the apparent depth change between the higher and lower station. Depth changes are 'apparent' because depth gauges are calibrated for sea water, and the hydrolevel is filled with fresh water. Therefore, a coefficient must be determined to convert apparent depth changes to true depth changes. Adding the readings for consecutive pairs of stations gives the total depth of the cave.\n\nThe accuracy, or \"grade\", of a cave survey is dependent on the methodology of measurement. A common survey grading system is that created by the British Cave Research Association in the 1960s, which uses a scale of six grades.\n\n\n\n\n\nThe equipment used to undertake a cave survey continues to improve. The use of computers, inertia systems, and electronic distance finders has been proposed, but few practical underground applications have evolved at present.\n\nDespite these advances, faulty instruments, imprecise measurements, recording errors or other factors may still result in an inaccurate survey, and these errors are often difficult to detect. Some cave surveyors measure each station twice, recording a \"back-sight\" to the previous station in the opposite direction. A back-sight compass reading that is different by 180 degrees and a clinometer reading that is the same value but with the reverse direction (positive rather than negative, for example) indicates that the original measurement was accurate.\n\nWhen a loop within a cave is surveyed back to its starting point, the resulting line-plot should also form a closed loop. Any gap between the first and last stations is called a \"loop-closure error\". If no single error is apparent, one may assume the loop-closure error is due to cumulative inaccuracies, and cave survey software can 'close the loop' by averaging possible errors throughout the loop stations. Loops to test survey accuracy may also be made by surveying across the surface between multiple entrances to the same cave.\n\nThe use of a low-frequency cave radio can also verify survey accuracy. A receiving unit on the surface can pinpoint the depth and location of a transmitter in a cave passage by measurement of the geometry of its radio waves. A survey over the surface from the receiver back to the cave entrance forms an artificial loop with the underground survey, whose loop-closure error can then be determined.\n\nIn the past, cavers were reluctant to redraw complex cave maps after detecting survey errors. Today, computer cartography can automatically redraw cave maps after data has been corrected.\n\nThere are a large number of surveying packages available on various computer platforms, most of which have been developed by cavers with a basis in computer programming. Many of the packages perform particularly well for specific tasks, and as such many cave surveyors will not solely choose one product over another for all cartographic tasks.\n\nA popular program for producing a centerline survey is Survex, which was originally developed by members of the Cambridge University Caving Club for processing survey data from club expeditions to Austria. It was released to the public in 1992. The centerline data can then be exported in various formats and the cave detail drawn in with various other programmes such as AutoCAD, Adobe Illustrator and Inkscape. Other programmes such as 'Tunnel' and Therion have full centerline and map editing capabilities. Therion notably, when it closes survey loops, warps the passages to fit over their length, meaning that entire passages do not have to be redrawn.\n\nTerrestrial LiDAR units are increasing significantly in accuracy and decreasing in price. Several Caves have been \"scanned\" using both \"time of flight\" and \"phase shift\" LiDAR units. The differences are in the relative accuracies available to each. The Oregon Caves National Park, was LiDAR scanned in August 2011, as were the Paisley Caves Archaeological dig sigte in SE Oregon. Both were scanned with a FARO Focus Phase shift scanner with +/-2mm accuracy. The Oregon Caves were scanned from the main public entrance to the 110 exit and were loop surveyed to the point of beginning. The data is not yet available for public use, but copies are retained by both the US Park Service and i-TEN Associates in Portland, Oregon.\n\nIn recent years an underground geographic positioning technology called HORTA has been utilized in the mining industry. The technology utilizes a gyroscope and an accelerometer to aid in 3D-position determination.\n\nSuch automated methods have provided a more than fifty-fold increase in underground surveying productivity with more accurate and finer detail maps as well.\n\n\n"}
{"id": "143335", "url": "https://en.wikipedia.org/wiki?curid=143335", "title": "Celestial navigation", "text": "Celestial navigation\n\nCelestial navigation, also known as astronavigation, is the ancient and modern practice of position fixing that enables a navigator to transition through a space without having to rely on estimated calculations, or dead reckoning, to know their position. Celestial navigation uses \"sights\", or angular measurements taken between a celestial body (e.g. the Sun, the Moon, a planet, or a star) and the visible horizon. The Sun is most commonly used, but navigators can also use the Moon, a planet, Polaris, or one of 57 other navigational stars whose coordinates are tabulated in the nautical almanac and air almanacs.\n\nCelestial navigation is the use of angular measurements (sights) between celestial bodies and the visible horizon to locate one's position in the world, on land as well as at sea. At a given time, any celestial body is located directly over one point on the Earth's surface. The latitude and longitude of that point is known as the celestial body's geographic position (GP), the location of which can be determined from tables in the nautical or air almanac for that year.\n\nThe measured angle between the celestial body and the visible horizon is directly related to the distance between the celestial body's GP and the observer's position. After some computations, referred to as sight reduction, this measurement is used to plot a line of position (LOP) on a navigational chart or plotting work sheet, the observer's position being somewhere on that line. (The LOP is actually a short segment of a very large circle on Earth that surrounds the GP of the observed celestial body. An observer located anywhere on the circumference of this circle on Earth, measuring the angle of the same celestial body above the horizon at that instant of time, would observe that body to be at the same angle above the horizon.) Sights on two celestial bodies give two such lines on the chart, intersecting at the observer's position (actually, the two circles would result in two points of intersection arising from sights on two stars described above, but one can be discarded since it will be far from the estimated position—see the figure at example below). Most navigators will use sights of three to five stars, if available, since that will result in only one common intersection and minimizes the chance of error. That premise is the basis for the most commonly used method of celestial navigation, referred to as the 'altitude-intercept method'.\n\nThere are several other methods of celestial navigation that will also provide position-finding using sextant observations, such as the noon sight, and the more archaic lunar distance method. Joshua Slocum used the lunar distance method during the first recorded single-handed circumnavigation of the world. Unlike the altitude-intercept method, the noon sight and lunar distance methods do not require accurate knowledge of time. The altitude-intercept method of celestial navigation requires that the observer know exact Greenwich Mean Time (GMT) at the moment of his observation of the celestial body, to the second—since for every four seconds that the time source (commonly a chronometer or, in aircraft, an accurate \"hack watch\") is in error, the position will be off by approximately one nautical mile.\n\nAn example illustrating the concept behind the intercept method for determining one’s position is shown to the right. (Two other common methods for determining one’s position using celestial navigation are the longitude by chronometer and ex-meridian methods.) In the adjacent image, the two circles on the map represent lines of position for the Sun and Moon at 1200 GMT on October 29, 2005. At this time, a navigator on a ship at sea measured the Moon to be 56 degrees above the horizon using a sextant. Ten minutes later, the Sun was observed to be 40 degrees above the horizon. Lines of position were then calculated and plotted for each of these observations. Since both the Sun and Moon were observed at their respective angles from the same location, the navigator would have to be located at one of the two locations where the circles cross.\n\nIn this case the navigator is either located on the Atlantic Ocean, about west of Madeira, or in South America, about southwest of Asunción, Paraguay. In most cases, determining which of the two intersections is the correct one is obvious to the observer because they are often thousands of miles apart. As it is unlikely that the ship is sailing across South America, the position in the Atlantic is the correct one. Note that the lines of position in the figure are distorted because of the map’s projection; they would be circular if plotted on a globe.\n\nAn observer in the Gran Chaco point would see the Moon at the left of the Sun, and an observer in the Madeira point would see the Moon at the right of the Sun.\n\nAccurate angle measurement evolved over the years. One simple method is to hold the hand above the horizon with one's arm stretched out. The width of the little finger is an angle just over 1.5 degrees elevation at extended arm's length and can be used to estimate the elevation of the sun from the horizon plane and therefore estimate the time until sunset. The need for more accurate measurements led to the development of a number of increasingly accurate instruments, including the kamal, astrolabe, octant and sextant. The sextant and octant are most accurate because they measure angles from the horizon, eliminating errors caused by the placement of an instrument's pointers, and because their dual mirror system cancels relative motions of the instrument, showing a steady view of the object and horizon.\n\nNavigators measure distance on the globe in degrees, arcminutes and arcseconds. A nautical mile is defined as 1852 meters, but is also (not accidentally) one minute of angle along a meridian on the Earth. Sextants can be read accurately to within 0.2 arcminutes, so the observer's position can be determined within (theoretically) 0.2 miles, about 400 yards (370 m). Most ocean navigators, shooting from a moving platform, can achieve a practical accuracy of 1.5 miles (2.8 km), enough to navigate safely when out of sight of land.\n\nPractical celestial navigation usually requires a marine chronometer to measure time, a sextant to measure the angles, an almanac giving schedules of the coordinates of celestial objects, a set of sight reduction tables to help perform the height and azimuth computations, and a chart of the region. </small> With sight reduction tables, the only calculations required are addition and subtraction. Small handheld computers, laptops and even scientific calculators enable modern navigators to \"reduce\" sextant sights in minutes, by automating all the calculation and/or data lookup steps. Most people can master simpler celestial navigation procedures after a day or two of instruction and practice, even using manual calculation methods.\n\nModern practical navigators usually use celestial navigation in combination with satellite navigation to correct a dead reckoning track, that is, a course estimated from a vessel's position, course and speed. Using multiple methods helps the navigator detect errors, and simplifies procedures. When used this way, a navigator will from time to time measure the sun's altitude with a sextant, then compare that with a precalculated altitude based on the exact time and estimated position of the observation. On the chart, one will use the straight edge of a plotter to mark each position line. If the position line indicates a location more than a few miles from the estimated position, more observations can be taken to restart the dead-reckoning track.\n\nIn the event of equipment or electrical failure, taking sun lines a few times a day and advancing them by dead reckoning allows a vessel to get a crude running fix sufficient to return to port. One can also use the Moon, a planet, Polaris, or one of 57 other navigational stars to track celestial positioning.\n\nLatitude was measured in the past either by measuring the altitude of the Sun at noon (the \"noon sight\"), or by measuring the altitudes of any other celestial body when crossing the meridian (reaching its maximum altitude when due north or south), and frequently by measuring the altitude of Polaris, the north star (assuming it is sufficiently visible above the horizon, which it is not in the Southern Hemisphere). Polaris always stays within 1 degree of the celestial north pole. If a navigator measures the angle to Polaris and finds it to be 10 degrees from the horizon, then he is about 10 degrees north of the equator. This approximate latitude is then corrected using simple tables or almanac corrections to determine a latitude theoretically accurate to within a fraction of a mile. Angles are measured from the horizon because locating the point directly overhead, the zenith, is not normally possible. When haze obscures the horizon, navigators use artificial horizons, which are horizontal mirrors of pans of reflective fluid, especially mercury historically. In the latter case, the angle between the reflected image in the mirror and the actual image of the object in the sky is exactly twice the required altitude.\n\nLongitude can be measured in the same way. If the angle to Polaris can be accurately measured, a similar measurement to a star near the eastern or western horizons will provide the longitude. The problem is that the Earth turns 15 degrees per hour, making such measurements dependent on time. A measure a few minutes before or after the same measure the day before creates serious navigation errors. Before good chronometers were available, longitude measurements were based on the transit of the moon, or the positions of the moons of Jupiter. For the most part, these were too difficult to be used by anyone except professional astronomers. The invention of the modern chronometer by John Harrison in 1761 vastly simplified longitudinal calculation.\n\nThe longitude problem took centuries to solve and was dependent on the construction of a non-pendulum clock (as pendulum clocks cannot function accurately on a tilting ship, or indeed a moving vehicle of any kind). Two useful methods evolved during the 18th century and are still practised today: lunar distance, which does not involve the use of a chronometer, and use of an accurate timepiece or chronometer.\n\nPresently, lay-person calculations of longitude can be made by noting the exact local time (leaving out any reference for Daylight Saving Time) when the sun is at its highest point in the sky. The calculation of noon can be made more easily and accurately with a small, exactly vertical rod driven into level ground—take the time reading when the shadow is pointing due north (in the northern hemisphere). Then take your local time reading and subtract it from GMT (Greenwich Mean Time) or the time in London, England. For example, a noon reading (1200 hours) near central Canada or the US would occur at approximately 6 pm (1800 hours) in London. The six-hour differential is one quarter of a 24-hour day, or 90 degrees of a 360-degree circle (the Earth). The calculation can also be made by taking the number of hours (use decimals for fractions of an hour) multiplied by 15, the number of degrees in one hour. Either way, it can be demonstrated that much of central North America is at or near 90 degrees west longitude. Eastern longitudes can be determined by adding the local time to GMT, with similar calculations.\n\nThe older method, called \"lunar distances\", was refined in the 18th century and employed with decreasing regularity at sea through the middle of the 19th century. It is only used today by sextant hobbyists and historians, but the method is theoretically sound, and can be used when a timepiece is not available or its accuracy is suspect during a long sea voyage. The navigator precisely measures the angle between the moon and the sun, or between the moon and one of several stars near the ecliptic. The observed angle must be corrected for the effects of refraction and parallax, like any celestial sight. To make this correction the navigator would measure the altitudes of the moon and sun (or star) at about the same time as the lunar distance angle. Only rough values for the altitudes were required. Then a calculation with logarithms or graphical tables requiring ten to fifteen minutes' work would convert the observed angle to a geocentric lunar distance. The navigator would compare the corrected angle against those listed in the almanac for every three hours of Greenwich time, and interpolate between those values to get the actual Greenwich time aboard ship. Knowing Greenwich time and comparing against local time from a common altitude sight, the navigator can work out his longitude.\n\nThe considerably more popular method was (and still is) to use an accurate timepiece to directly measure the time of a sextant sight. The need for accurate navigation led to the development of progressively more accurate chronometers in the 18th century (see John Harrison). Today, time is measured with a chronometer, a quartz watch, a shortwave radio time signal broadcast from an atomic clock, or the time displayed on a GPS. A quartz wristwatch normally keeps time within a half-second per day. If it is worn constantly, keeping it near body heat, its rate of drift can be measured with the radio and, by compensating for this drift, a navigator can keep time to better than a second per month. Traditionally, a navigator checked his chronometer from his sextant, at a geographic marker surveyed by a professional astronomer. This is now a rare skill, and most harbourmasters cannot locate their harbour's marker.\n\nTraditionally, three chronometers were kept in gimbals in a dry room near the centre of the ship. They were used to set a hack watch for the actual sight, so that no chronometers were ever exposed to the wind and salt water on deck. Winding and comparing the chronometers was a crucial duty of the navigator. Even today, it is still logged daily in the ship's deck log and reported to the Captain before eight bells on the forenoon watch (shipboard noon). Navigators also set the ship's clocks and calendar.\n\nThe celestial line of position concept was discovered in 1837 by Thomas Hubbard Sumner when, after one observation, he computed and plotted his longitude at more than one trial latitude in his vicinity – and noticed that the positions lay along a line. Using this method with two bodies, navigators were finally able to cross two position lines and obtain their position – in effect determining both latitude and longitude. Later in the 19th century came the development of the modern (Marcq St. Hilaire) intercept method; with this method the body height and azimuth are calculated for a convenient trial position, and compared with the observed height. The difference in arcminutes is the nautical mile \"intercept\" distance that the position line needs to be shifted toward or away from the direction of the body's subpoint. (The intercept method uses the concept illustrated in the example in the “How it works” section above.) Two other methods of reducing sights are the longitude by chronometer and the ex-meridian method.\n\nWhile celestial navigation is becoming increasingly redundant with the advent of inexpensive and highly accurate satellite navigation receivers (GPS), it was used extensively in aviation until the 1960s, and marine navigation until quite recently. However; since a prudent mariner never relies on any sole means of fixing his position, many national maritime authorities still require deck officers to show knowledge of celestial navigation in examinations, primarily as a backup for electronic/satellite navigation. One of the most common current usages of celestial navigation aboard large merchant vessels is for compass calibration and error checking at sea when no terrestrial references are available.\n\nThe U.S. Air Force and U.S. Navy continued instructing military aviators on celestial navigation use until 1997, because:\n\nThe United States Naval Academy announced that it was discontinuing its course on celestial navigation (considered to be one of its most demanding non-engineering courses) from the formal curriculum in the spring of 1998. In October 2015, citing concerns about the reliability of GPS systems in the face of potential hostile hacking, the USNA reinstated instruction in celestial navigation in the 2015–16 academic year.\n\nAt another federal service academy, the US Merchant Marine Academy, there was no break in instruction in celestial navigation as it is required to pass the US Coast Guard License Exam to enter the Merchant Marine. It is also taught at Harvard, most recently as Astronomy 2.\n\nCelestial navigation continues to be used by private yachtsmen, and particularly by long-distance cruising yachts around the world. For small cruising boat crews, celestial navigation is generally considered an essential skill when venturing beyond visual range of land. Although GPS (Global Positioning System) technology is reliable, offshore yachtsmen use celestial navigation as either a primary navigational tool or as a backup.\n\nCelestial navigation was used in commercial aviation up until the early part of the jet age; early Boeing 747s had a \"sextant port\" in the roof of the cockpit. It was only phased out in the 1960s with the advent of inertial navigation and doppler navigation systems, and today's satellite-based systems which can locate the aircraft's position accurate to a 3-meter sphere with several updates per second.\n\nA variation on terrestrial celestial navigation was used to help orient the Apollo spacecraft en route to and from the Moon. To this day, space missions such as the Mars Exploration Rover use star trackers to determine the attitude of the spacecraft.\n\nAs early as the mid-1960s, advanced electronic and computer systems had evolved enabling navigators to obtain automated celestial sight fixes. These systems were used aboard both ships and US Air Force aircraft, and were highly accurate, able to lock onto up to 11 stars (even in daytime) and resolve the craft's position to less than . The SR-71 high-speed reconnaissance aircraft was one example of an aircraft that used a combination of automated celestial and inertial navigation. These rare systems were expensive, however, and the few that remain in use today are regarded as backups to more reliable satellite positioning systems.\n\nIntercontinental ballistic missiles use celestial navigation to check and correct their course (initially set using internal gyroscopes) while flying outside the Earth's atmosphere. The immunity to jamming signals is the main driver behind this seemingly archaic technique.\n\nX-ray pulsar-based navigation and timing (XNAV) is an experimental navigation technique whereby the periodic X-ray signals emitted from pulsars are used to determine the location of a vehicle, such as a spacecraft in deep space. A vehicle using XNAV would compare received X-ray signals with a database of known pulsar frequencies and locations. Similar to GPS, this comparison would allow the vehicle to triangulate its position accurately (±5 km). The advantage of using X-ray signals over radio waves is that X-ray telescopes can be made smaller and lighter. On 9 November 2016 the Chinese Academy of Sciences launched an experimental pulsar navigation satellite called XPNAV 1. SEXTANT (Station Explorer for X-ray Timing and Navigation Technology) is a NASA-funded project developed at the Goddard Space Flight Center that is testing XNAV on-orbit on board the International Space Station in connection with the NICER project, launched on 3 June 2017 on the SpaceX CRS-11 ISS resupply mission.\n\nCelestial navigation trainers for aircraft crews combine a simple flight simulator with a planetarium.\n\nAn early example is the Link Celestial Navigation Trainer, used in the Second World War. Housed in a high building, it featured a cockpit accommodating a whole bomber crew (pilot, navigator and bombardier). The cockpit offered a full array of instruments which the pilot used to fly the simulated aeroplane. Fixed to a dome above the cockpit was an arrangement of lights, some collimated, simulating constellations from which the navigator determined the plane's position. The dome's movement simulated the changing positions of the stars with the passage of time and the movement of the plane around the earth. The navigator also received simulated radio signals from various positions on the ground. Below the cockpit moved \"terrain plates\" – large, movable aerial photographs of the land below – which gave the crew the impression of flight and enabled the bomber to practise lining up bombing targets. A team of operators sat at a control booth on the ground below the machine, from which they could simulate weather conditions such as wind or cloud. This team also tracked the aeroplane's position by moving a \"crab\" (a marker) on a paper map.\n\nThe Link Celestial Navigation Trainer was developed in response to a request made by the Royal Air Force (RAF) in 1939. The RAF ordered 60 of these machines, and the first one was built in 1941. The RAF used only a few of these, leasing the rest back to the US, where eventually hundreds were in use.\n\n"}
{"id": "316410", "url": "https://en.wikipedia.org/wiki?curid=316410", "title": "Compass rose", "text": "Compass rose\n\nA compass rose, sometimes called a windrose or Rose of the Winds, is a figure on a compass, map, nautical chart, or monument used to display the orientation of the cardinal directions (north, east, south, and west) and their intermediate points. It is also the term for the graduated markings found on the traditional magnetic compass. Today, the idea of a compass rose is found on, or featured in, almost all navigation systems, including nautical charts, non-directional beacons (NDB), VHF omnidirectional range (VOR) systems, global-positioning systems (GPS), and similar equipment.\nThe modern compass rose has eight principal winds. Listed clockwise, these are:\nAlthough modern compasses use the names of the eight principal directions (N, NE, E, SE, etc.), older compasses use the traditional Italianate wind names of Medieval origin (Tramontana, Greco, Levante, etc.)\n\n4-point compass roses use only the four \"basic winds\" or \"cardinal directions\" (North, East, South, West), with angles of difference at 90°.\n\n8-point compass roses use the eight principal winds—that is, the four cardinal directions (N, E, S, W) plus the four \"intercardinal\" or \"ordinal directions\" (NE, SE, SW, NW), at angles of difference of 45°.\n\n16-point compass roses are constructed by bisecting the angles of the principal winds to come up with intermediate compass points, known as half-winds, at angles of difference of 22°. The names of the half-winds are simply combinations of the principal winds to either side, principal then ordinal. E.g. North-northeast (NNE), East-northeast (ENE), etc.\n\n32-point compass roses are constructed by bisecting these angles, and coming up with quarter-winds at 11° angles of difference. Quarter-wind names are constructed with the names \"X by Y\", which can be read as \"one quarter wind from X toward Y\", where X is one of the eight principal winds and Y is one of the two adjacent cardinal directions. For example, North-by-east (NbE) is one quarter wind from North towards East, Northeast-by-north (NEbN) is one quarter wind from Northeast toward North. Naming all 32 points on the rose is called \"boxing the compass\".\n\nThe 32-point rose has the uncomfortable number of 11° between points, but is easily found by halving divisions and may have been easier for those not using a 360° circle. Using gradians, of which there are 400 in a circle, the sixteen-point rose will have twenty-five gradians per point.\n\nLinguistic anthropological studies have shown that most human communities have four points of cardinal direction. The names given to these directions are usually derived from either locally-specific geographic features (e.g. \"towards the hills\", \"towards the sea\") or from celestial bodies (especially the sun) or from atmospheric features (winds, temperature). Most mobile populations tend to adopt sunrise and sunset for East and West and the direction from where different winds blow to denote North and South.\n\nThe ancient Greeks originally maintained distinct and separate systems of points and winds. The four Greek cardinal points (arctos, anatole, mesembria and dusis) were based on celestial bodies and used for orientation. The four Greek winds (Boreas, Notos, Eurus, Zephyrus) were confined to meteorology. Nonetheless, both systems were gradually conflated, and wind names came to eventually denote cardinal directions as well.\n\nIn his meteorological studies, Aristotle identified ten distinct winds: two north-south winds (Aparctias, Notos) and four sets of east-west winds blowing from different latitudes—the Arctic circle (Meses, Thrascias), the summer solstice horizon (Caecias, Argestes), the equinox (Apeliotes, Zephyrus) and the winter solstice (Eurus, Lips). However, Aristotle's system was asymmetric. To restore balance, Timosthenes of Rhodes added two more winds to produce the classical 12-wind rose, and began using the winds to denote geographical direction in navigation. Eratosthenes deducted two winds from Aristotle's system, to produce the classical 8-wind rose.\n\nThe Romans (e.g. Seneca, Pliny) adopted the Greek 12-wind system, and replaced its names with Latin equivalents, e.g. Septentrio, Subsolanus, Auster, Favonius, etc. Uniquely, Vitruvius came up with a 24-wind rose.\n\nAccording to the chronicler Einhard (c. 830), the Frankish king Charlemagne himself came up with his own names for the classical 12 winds. He named the four cardinal winds on the roots \"Nord\" (etymology uncertain, could be \"wet\", meaning from the rainy lands), \"Ost\" (shining place, sunrise), \"Sund\" (sunny lands) and \"Vuest\" (dwelling place, meaning evening). Intermediate winds were constructed as simple compound names of these four (e.g. \"Nordostdroni\", the \"northeasterly\" wind). These Carolingian names are the source of the modern compass point names found in nearly all modern west European languages. (e.g. North, East, South and West in English; Nord, Est, Sud, Ouest in French, etc.)\n\nThe following table gives a rough equivalence of the classical 12-wind rose with the modern compass directions (Note: the directions are imprecise since it is not clear at what angles the classical winds are supposed to be with each other; some have argued that they should be equally spaced at 30 degrees each; for more details, see the article on Classical compass winds). \n\nThe \"sidereal\" compass rose demarcates the compass points by the position of stars in the night sky, rather than winds. Arab navigators in the Red Sea and the Indian Ocean, who depended on celestial navigation, were using a 32-point sidereal compass rose before the end of the 10th century. In the northern hemisphere, the steady Pole Star (Polaris) was used for the N-S axis; the less-steady Southern Cross had to do for the southern hemisphere, as the southern pole star, Sigma Octantis, is too dim to be easily seen from Earth with the naked eye. The other thirty points on the sidereal rose were determined by the rising and setting positions of fifteen bright stars. Reading from North to South, in their rising and setting positions, these are:\n\nThe western half of the rose would be the same stars in their setting position. The true position of these stars is only approximate to their theoretical equidistant rhumbs on the sidereal compass. Stars with the same declination formed a \"linear constellation\" or \"kavenga\" to provide direction as the night progressed.\n\nA similar sidereal compass was used by Polynesian and Micronesian navigators in the Pacific Ocean, although different stars were used in a number of cases, clustering around the East-West axis.\n\nIn Europe, the Classical 12-wind system continued to be taught in academic settings during the Medieval era, but seafarers in the Mediterranean came up with their own distinct 8-wind system. The mariners used names derived from the Mediterranean lingua franca—the Italian-tinged patois among Medieval sailors, composed principally of Ligurian, mixed with Venetian, Sicilian, Provençal, Catalan, Greek and Arabic terms from around the Mediterranean basin. \n\nThe exact origin of the mariner's eight-wind rose is obscure. Only two of its point names (\"Ostro\", \"Libeccio\") have Classical etymologies, the rest of the names seem to be autonomously derived. Two Arabic words stand out: \"Scirocco\" (SE) from \"al-Sharq\" (الشرق – east in Arabic) and the variant \"Garbino\" (SW), from \"al-Gharb\" (الغرب – west in Arabic). This suggests the mariner's rose was probably acquired by southern Italian seafarers not from their classical Roman ancestors, but rather from Norman Sicily in the 11th to 12th centuries. The coasts of the Maghreb and Mashriq are SW and SE of Sicily respectively; the \"Greco\" (a NE wind), reflects the position of Byzantine-held Calabria-Apulia to the northeast of Arab Sicily, while the \"Maestro\" (a NW wind) is a reference to the Mistral wind that blows from the southern French coast towards northwest Sicily.\n\nThe 32-point compass used for navigation in the Mediterranean by the 14th century, had increments of 11° between points. Only the eight principal winds (N, NE, E, SE, S, SW, W, NW) were given special names. The eight half-winds just combined the names of the two principal winds, e.g. Greco-Tramontana for NNE, Greco-Levante for ENE, and so on. Quarter-winds were more cumbersomely phrased, with the closest principal wind named first and the next-closest principal wind second, e.g. \"Quarto di Tramontana verso Greco\" (literally, \"one quarter wind from North towards Northeast\", i.e. North by East), and \"Quarto di Greco verso Tramontana\" (\"one quarter wind from NE towards N\", i.e. Northeast by North). Boxing the compass (naming all 32 winds) was expected of all Medieval mariners.\n\nIn the earliest Medieval portolan charts of the 14th century, compass roses were depicted as mere collections of color-coded compass rhumb lines: black for the eight main winds, green for the eight half-winds and red for the sixteen quarter-winds. The average portolan chart had sixteen such roses (or confluence of lines), spaced out equally around the circumference of a large implicit circle.\n\nThe cartographer Cresques Abraham of Majorca, in his Catalan Atlas of 1375, was the first to draw an ornate compass rose on a map. By the end of the 15th century, Portuguese cartographers began drawing multiple ornate compass roses throughout the chart, one upon each of the sixteen circumference roses (unless the illustration conflicted with coastal details).\n\nThe points on a compass rose were frequently labeled by the initial letters of the mariner's principal winds (T, G, L, S, O, L, P, M). However, from the outset, the custom also began to distinguish the north from the other points by a specific visual marker. Medieval Italian cartographers typically used a simple arrowhead or circumflex-hatted T (an allusion to the compass needle) to designate the north, while the Majorcan cartographic school typically used a stylized Pole Star for its north mark. The use of the fleur-de-lis as north mark was introduced by Pedro Reinel, and quickly became customary in compass roses (and is still often used today). Old compass roses also often used a Christian cross at Levante (E), indicating the direction of Jerusalem from the point of view of the Mediterranean sea.\n\nThe twelve Classical winds (or a subset of them) were also sometimes depicted on portolan charts, albeit not on a compass rose, but rather separately on small disks or coins on the edges of the map.\n\nThe compass rose was also depicted on traverse boards used on board ships to record headings sailed at set time intervals.\n\nThe contemporary compass rose appears as two rings, one smaller and set inside the other. The outside ring denotes true cardinal directions while the smaller inside ring denotes magnetic cardinal directions. True north refers to the geographical location of the north pole while magnetic north refers to the direction towards which the north pole of a magnetic object (as found in a compass) will point. The angular difference between true and magnetic north is called variation, which varies depending on location. The angular difference between magnetic heading and compass heading is called deviation which varies by vessel and its heading.\n\n\n\n\n"}
{"id": "2497747", "url": "https://en.wikipedia.org/wiki?curid=2497747", "title": "Cottage garden", "text": "Cottage garden\n\nThe cottage garden is a distinct style that uses informal design, traditional materials, dense plantings, and a mixture of ornamental and edible plants. English in origin, it depends on grace and charm rather than grandeur and formal structure. Homely and functional gardens connected to working-class cottages go back centuries, but their stylized reinvention occurred in 1870s England, as a reaction to the more structured, rigorously maintained estate gardens with their formal designs and mass plantings of greenhouse annuals.\n\nThe earliest cottage gardens were more practical than today's, with emphasis on vegetables and herbs, fruit trees, perhaps a beehive, and even livestock. Flowers, used to fill spaces, gradually became more dominant. The traditional cottage garden was usually enclosed, perhaps with a rose-bowered gateway. Flowers common to early cottage gardens included traditional florists' flowers such as primroses and violets, along with flowers with household use such as calendula and various herbs. Others were the richly scented old-fashioned roses that bloomed once a year, and simple flowers like daisies. In time, cottage-garden sections were added to some large estate gardens as well.\n\nModern cottage gardens include countless regional and personal variations and embrace plant materials, such as ornamental grasses or native plants not seen in the rural gardens of cottagers. Traditional roses, with their full fragrance and lush foliage, continue to be a cottage-garden mainstay—along with modern disease-resistant varieties that retain traditional attributes. Informal climbing plants, whether traditional or modern hybrids, are also common, as are the self-sowing annuals and freely spreading perennials favoured in traditional cottagers' gardens.\n\nCottage gardens, which emerged in Elizabethan times, appear to have originated as a local source for herbs and fruits. One theory is that they arose out of the Black Death of the 1340s, when the death of so many laborers made land available for small cottages with personal gardens. According to the late 19th-century legend of origin, these gardens were originally created by the workers that lived in the cottages of the villages, to provide them with food and herbs, with flowers planted in for decoration. Helen Leach analysed the historical origins of the romanticised cottage garden, subjecting the garden style to rigorous historical analysis, along with the ornamental potager and the herb garden. She concluded that their origins were less in workingmen's gardens in the 19th century and more in the leisured classes' discovery of simple hardy plants, in part through the writings of John Claudius Loudon. Loudon helped to design the estate at Great Tew, Oxfordshire, where farm workers were provided with cottages that had architectural quality set in a smallholding or large garden—about an acre—where they could grow food and keep pigs and chickens.\n\nAuthentic gardens of the yeoman cottager would have included a beehive and livestock, and frequently a pig and sty, along with a well. The peasant cottager of medieval times was more interested in meat than flowers, with herbs grown for medicinal use and cooking, rather than for their beauty. By Elizabethan times there was more prosperity, and thus more room to grow flowers. Even the early cottage garden flowers typically had their practical use—violets were spread on the floor (for their pleasant scent and keeping out vermin); calendulas and primroses were both attractive and used in cooking. Others, such as sweet william and hollyhocks were grown entirely for their beauty.\n\nThe \"naturalness\" of informal design began to be noticed and developed by the British leisured class. Alexander Pope was an early proponent of less formal gardens, calling in a 1713 article for gardens with the \"amiable simplicity of unadorned nature\". Other writers in the 18th century who encouraged less formal, and more natural, gardens included Joseph Addison and Lord Shaftesbury. The evolution of cottage gardens can be followed in the issues of \"The Cottage Gardener\" (1848–61), edited by George William Johnson, where the emphasis is squarely on the \"florist's flowers\", carnations and auriculas in fancy varieties that were originally cultivated as a highly competitive blue-collar hobby.\nWilliam Robinson and Gertrude Jekyll helped to popularise less formal gardens in their many books and magazine articles. Robinson's \"The Wild Garden\", published in 1870, contained in the first edition an essay on \"The Garden of British Wild Flowers\", which was eliminated from later editions. In his \"The English Flower Garden\", illustrated with cottage gardens from Somerset, Kent and Surrey, he remarked, \"One lesson of these little gardens, that are so pretty, is that one can get good effects from simple materials.\" From the 1890s his lifelong friend Jekyll applied cottage garden principles to more structured designs in even quite large country houses. Her \"Colour in the Flower Garden\" (1908) is still in print today.\n\nRobinson and Jekyll were part of the Arts and Crafts Movement, a broader movement in art, architecture, and crafts during the late 19th century which advocated a return to the informal planting style derived as much from the Romantic tradition as from the actual English cottage garden. The Arts and Crafts Exhibition of 1888 began a movement toward an idealised natural country garden style. The garden designs of Robinson and Jekyll were often associated with Arts and Crafts style houses. Both were influenced by William Morris, one of the leaders of the Arts and Crafts Movement—Robinson quoted Morris's views condemning carpet bedding; Jekyll shared Morris's mystical view of nature and drew on the floral designs in his textiles for her gardening style. When Morris built his Red House in Kent, it influenced new ideas in architecture and gardening—the \"old-fashioned\" garden suddenly became a fashion accessory among the British artistic middle class, and the cottage garden esthetic began to emigrate to America.\nIn the early 20th century the term \"cottage garden\" might be applied even to as large and sophisticated a garden as Hidcote Manor, which Vita Sackville-West described as \"a cottage garden on the most glorified scale\" but where the colour harmonies were carefully contrived and controlled, as in the famous \"Red Borders\". Sackville-West had taken similar models for her own \"cottage garden\", one of many \"garden rooms\" at Sissinghurst Castle—her idea of a cottage garden was a place where \"the plants grow in a jumble, flowering shrubs mingled with Roses, herbaceous plants with bulbous subjects, climbers scrambling over hedges, seedlings coming up wherever they have chosen to sow themselves\". The cottage garden ideal was also spread by artists such as water-colourist Helen Allingham (1848–1926). Another influence was Margery Fish (1892–1969), whose garden survives at East Lambrook Manor.\n\nThe cottage garden in France is a development of the early 20th century. Monet's garden at Giverny is a prominent example, a sprawling garden full of varied plantings, rich colors, and water gardens. In modern times, the term 'cottage garden' is used to describe any number of informal garden styles, using design and plants very different from their traditional English cottage garden origins. Examples include regional variations using a grass prairie scheme (in the American midwest) and California chaparral cottage gardens.\n\nWhile the classic cottage garden is built around a cottage, many cottage-style gardens are created around houses and even estates such as Hidcote Manor, with its more intimate \"garden rooms\". The cottage garden design is based more on principles than formulae: it has an informal look, with a seemingly casual mixture of flowers, herbs, and vegetables often packed into a small area. In spite of their appearances, cottage gardens have a design and formality that help give them their grace and charm. Due to space limitations, they are often in small rectangular plots, with practical functioning paths and hedges or fences. The plants, layout, and materials are chosen to give the impression of casualness and a country feel. Modern cottage gardens frequently use local flowers and materials, rather than those of the traditional cottage garden. What they share with the tradition is the unstudied look, the use of every square inch, and a rich variety of flowers, herbs, and vegetables. \n\nThe cottage garden is designed to appear artless, rather than contrived or pretentious. Instead of artistic curves, or grand geometry, there is an artfully designed irregularity. Borders can go right up to the house, lawns are replaced with tufts of grass or flowers, and beds can be as wide as needed. Instead of the discipline of large scale color schemes, there is the simplicity of harmonious color combinations between neighbouring plants. The overall appearance can be of \"a vegetable garden that has been taken over by flowers.\" The method of planting closely packed plants was supposed to reduce the amount of weeding and watering required, but planted stone pathways or turf paths, and clipped hedges overgrown with wayward vines, are cottage garden features requiring well-timed maintenance.\n\nPaths, arbors, and fences use traditional or antique looking materials. Wooden fences and gates, paths covered with locally made bricks or stone, and arbors using natural materials all give a more casual—and less formal—look and feel to a cottage garden. Pots, ornaments, and furniture also use natural looking materials with traditional finishes—everything is chosen to give the impression of an old-fashioned country garden.\n\nUntil the late 19th century, cottage gardens mainly grew vegetables for household consumption. Typically half the garden would be used for cultivating potatoes and half for a mix of other vegetables. John Claudius Loudon wrote extensively on cottage gardens in his book \"An Encyclopædia of Gardening\" (1822) and in \"Gardener's Magazine\" from 1826. In 1838 he wrote \"I seldom observe any thing in a cottage garden but potatoes, cabbages, beans, and French beans; in a few instances onions and parsneps, and very seldom a few peas\". An 1865 issue of \"The Farmer's Magazine\" noted that in \"Ireland and much of the Highlands of Scotland, potatoes are the only thing grown in the cottage-garden\".\n\nModern cottage garden plants are typically flowers chosen for their old-fashioned and informal appeal. Many modern day gardeners use heirloom or 'old-fashioned' plants and varieties—even though these may not have been authentic or traditional cottage garden plants. In addition, there are modern varieties of flowers that fit into the cottage garden look. For example, modern roses developed by David Austin have been chosen for cottage gardens because of their old-fashioned look (multi-petaled form and rosette-shaped flowers) and fragrance—combined with modern virtues of hardiness, repeat blooming, and disease-resistance. Modern cottage gardens often use native plants and those adapted to the local climate, rather than trying to force traditional English plants to grow in an incompatible environment—though many of the old favorites thrive in cottage gardens throughout the world.\n\nCottage gardens are always associated with roses: shrub roses, climbing roses, and old garden roses with lush foliage, in contrast to the gangly modern hybrid tea roses. Old cottage garden roses include cultivated forms of \"Rosa gallica\", which form dense mounded shrubs 3–4 ft high and wide, with pale pink to purple flowers—with single form to full double form blooms. They are also very fragrant, and include the ancient Apothecary's rose (\"R. gallica\" 'Officinalis'), whose magenta flowers were preserved solely for their fragrance. Another old fragrant cottage garden rose is the Damask rose, which is still grown in Europe for use in perfumes. Cultivated forms of this grow 4 to 6 ft or higher, with gently arching canes that help give an informal look to a garden. Even taller generally are the Alba roses, which are not always white, and which bloom well even in partial shade.\n\nThe Provence rose or \"Rosa centifolia\" is the full and fat \"cabbage rose\" made famous by Dutch masters in their 17th-century paintings. These very fragrant shrub roses grow 5 ft tall and wide, with a floppy habit that is aided by training on an arch or pillar. The centifolia roses have produced many descendants that are also cottage garden favorites, including varieties of moss rose (roses with attractive 'mossy' growth on their flower stalks and flower buds). Unlike most modern hybrids, the older roses bloom on the previous year's wood, so they aren't pruned back severely each year. Also as they don't bloom continuously, they can share their branches with later-flowering climbers such as Clematis vines, which use the rose branches for support. A rose in the cottage garden is not segregated with other roses, with bare earth or mulch underneath', but is casually blended with other flowers, vines, and groundcover.\n\nWith the introduction of China roses (derived from \"Rosa chinensis\") late in the 18th century, many hybrids were introduced that had the remontant (repeat-blooming) nature of the China roses, but maintained the informal old rose shape and flower. These included the Bourbon rose and the Noisette rose, which were added to the rose repertoire of the cottage garden, and, more recently, hybrid \"English\" roses introduced by David Austin.\n\nMany of the old roses had cultivars that grew very long canes, which could be tied to trellises or against walls. These older varieties are called \"ramblers\", rather than \"climbers\". Climbing plants in the traditional cottage garden included European honeysuckle (\"Lonicera periclymenum\") and Traveller's Joy (\"Clematis vitalba\"). The modern cottage garden includes many Clematis hybrids that have the old appeal, with sparse foliage that allows them to grow through roses and trees, and along fences and arbors. There are also many Clematis species used in the modern cottage garden, including \"Clematis armandii\", \"Clematis chrysocoma\", and \"Clematis flammula\". Popular honeysuckles for cottage gardens include Japanese honeysuckle and \"Lonicera tragophylla\".\n\nIn the traditional cottage garden, hedges served as fences on the perimeter to keep out marauding livestock and for privacy, along with other practical uses. Hawthorn leaves made a tasty snack or tea, while the flowers were used for making wine. The fast-growing Elderberry, in addition to creating a hedge, provided berries for food and wine, with the flowers being fried in batter or made into lotions and ointments. The wood had many uses, including toys, pegs, skewers, and fishing poles. Holly was another hedge plant, useful because it quickly spread and self-seeded. Privet was also a convenient and fast-growing hedge. Over time, more ornamental and less utilitarian plants became popular cottage garden hedges, including laurel, lilac, snowberry, japonica, and others.\n\nPopular flowers in the traditional cottage garden included florist's flowers which were grown by enthusiasts—such as violets, pinks, and primroses—and those grown with a more practical purpose. For example, the calendula, grown today almost entirely for its bright orange flowers, was primarily valued for eating, for adding color to butter and cheese, for adding smoothness to soups and stews, and for all kinds of healing salves and preparations. Like many old cottage garden annuals and herbs, it freely self-sowed, making it easier to grow and share. Other popular cottage garden annuals included violets, pansies, stocks, and mignonette. \n\nPerennials were the largest group of traditional cottage garden flowers—those with a long cottage garden history include hollyhocks, carnations, sweet williams, marguerites, marigolds, lilies, peonies, tulips, crocus, daisies, foxglove, monkshood, lavender, campanulas, Solomon's seal, evening primrose, lily-of-the-valley, primrose, cowslips, and many varieties of roses. \n\nToday herbs are typically thought of as culinary plants, but in the traditional cottage garden they were considered to be any plant with household uses. Herbs were used for medicine, toiletries, and cleaning products. Scented herbs would be spread on the floor along with rushes to cover odors. Some herbs were used for dyeing fabrics. Traditional cottage garden herbs included sage, thyme, southernwood, wormwood, catmint, feverfew, lungwort, soapwort, hyssop, sweet woodruff, and lavender.\n\nFruit in the traditional cottage garden would have included an apple and a pear, for cider and perry, gooseberries and raspberries. The modern cottage garden includes many varieties of ornamental fruit and nut trees, such as crabapple and hazel, along with non-traditional trees like dogwood.\n\n\n\n"}
{"id": "20620848", "url": "https://en.wikipedia.org/wiki?curid=20620848", "title": "Depth sounding", "text": "Depth sounding\n\nDepth sounding refers to the act of measuring depth. It is often referred to simply as sounding. Data taken from soundings are used in bathymetry to make maps of the floor of a body of water, and were traditionally shown on nautical charts in fathoms and feet. The National Oceanic and Atmospheric Administration (NOAA), the agency responsible for bathymetric data in the United States, still uses fathoms and feet on nautical charts. In other countries, the International System of Units (metres) has become the standard for measuring depth.\n\n\"Sounding\" derives from the Old English \"sund\", meaning swimming, water, sea; it is not related to the word sound in the sense of noise or tones, but to sound, a geographical term.\n\nTraditional terms for soundings are a source for common expressions in the English language, notably \"deep six\" (a sounding of 6 fathoms): see John Ehrlichman. On the Mississippi River in the 1850s, the leadsmen also used old-fashioned words for some of the numbers; for example instead of \"two\" they would say \"twain\". Thus when the depth was two fathoms, they would call \"by the mark twain!\". The American writer Mark Twain, a former river pilot, likely took his pen name from this cry. The term lives on in today's world in echo sounding, the technique of using sonar to measure depth.\n\nA \"sounding line\" or \"lead line\" is a length of thin rope with a plummet, generally of lead, at its end. Regardless of the actual composition of the plummet, it is still called a \"lead\". Leads were swung, or cast, by a leadsman, usually standing in the chains of a ship, up against the shrouds.\n\nMeasuring the depth of water by lead and line dates back to ancient civilization. It continues in widespread use today in recreational boating and as a backup to electronic echo sounding devices which are prone to failure and inaccuracy. Greek and Roman navigators are known to have used sounding leads, some of which have been uncovered by archaeologists. Sounding by lead and line continued throughout the medieval and early modern periods and is still commonly used today. The Bible describes lead and line sounding in Acts, whilst the Bayeux Tapestry documents the use of a sounding lead during William the Conqueror's 1066 landing in Normandy. Lead and line sounding operates alongside sounding poles, and/or echo sounding devices particularly when navigating in shallower waters and on rivers.\n\nAt sea, in order to avoid repeatedly hauling in and measuring the wet line by stretching it out with one's arms, it is common practice to tie marks at intervals along the line. These marks are made of leather, calico, serge and other materials, and so shaped and attached that it is possible to \"read\" them by eye during the day or by feel at night. Traditionally the marks were at every second or third fathom: at 2, 3, 5, 7, 10, 13, 15, 17, and 20 fathoms. The \"leadsman\" called out the depth as he read it off the line. If the depth was at a mark he would call \"by the mark\" followed by the number, while if it was between two marks, he would call \"by the deep\" followed by the estimated number; thus \"by the mark five,\" since there is a five-fathom mark, but \"by the deep six,\" since there is no six-fathom mark. Fractions would be called out by preceding the number with the phrases \"and a half,\" \"and a quarter,\" or \"a quarter less\"; thus 4 3/4 fathoms would be called as \"a quarter less five,\" 3 1/2 as \"and a half three,\" and so on.\n\nSoundings may also be taken to establish the ship's position as an aid in navigation, not merely for safety. Soundings of this type were usually taken using leads that had a wad of tallow in a concavity at the bottom of the plummet. The tallow would bring up part of the bottom sediment (sand, pebbles, clay, shells) and allow the ship's officers to better estimate their position by providing information useful for pilotage and anchoring. If the plummet came up clean, it meant the bottom was rock. Nautical charts provide information about the seabed materials at particular locations. Nautical charts also include depth contour lines. It is thus sometimes possible to navigate in poor visibility by noting which contour line one is closest to.\n\nDuring the nineteenth century, a number of attempts were made to mechanise depth sounding. Designs ranged from complex brass machines to relatively simple pulley systems. Navies around the world, particularly the Royal Navy in Britain, were concerned about the reliability of lead and line sounding. The introduction of new machines was understood as a way to introduce standardised practices for sounding in a period in which naval discipline was of great concern.\n\nOne of the most widely adopted sounding machines was developed in 1802 by Edward Massey, a clockmaker from Staffordshire. The machine was designed to be fixed to a sounding lead and line. It featured a rotor which turned a dial as the lead sank to the sea floor. On striking the sea floor, the rotor would lock. Massey’s sounding machine could then be hauled in and the depth could be read off the dials in fathoms. By 1811, the Royal Navy had purchased 1,750 of these devices: one for every ship in commission during the Napoleonic Wars. The Board of Longitude was instrumental in convincing the Royal Navy to adopt Massey's machine.\n\nMassey’s was not the only sounding machine adopted during the nineteenth century. The Royal Navy also purchased a number of Peter Burt’s buoy and nipper device. This machine was quite different from Massey’s. It consisted of an inflatable canvas bag (the buoy) and a spring-loaded wooden pulley block (the nipper). Again, the device was designed to operate alongside a lead and line. In this case, the buoy would be pulled behind the ship and the line threaded through the pulley. The lead could then be released. The buoy ensured that the lead fell perpendicular to the sea floor even when the ship was moving. The spring-loaded pulley would then catch the rope when the lead hit the sea bed, ensuring an accurate reading of the depth.\n\nBoth Massey and Burt’s machines were designed to operate in relatively shallow waters (up to 150 fathoms). With the growth of seabed telegraphy in the later nineteenth century, new machines were introduced to measure much greater depths of water. The most widely adopted deep-sea sounding machine in the nineteenth century was Kelvin’s sounding machine, designed by William Thomson (Lord Kelvin) and patented in 1876. This operated on the same principle as lead and line sounding. In this case, the line consisted of a drum of piano wire whilst the lead was of a much greater weight. Later versions of Kelvin’s machine also featured a motorised drum in order to facilitate the winding and unwinding of the line. These devices also featured a dial which recorded the length of line let out.\n\nBoth lead-and-line technology and sounding machines were used during the twentieth century, but by the twenty-first, echo sounding has increasingly displaced both of those methods. A sounding line can still be found on many vessels as a backup to electronic depth sounding in the event of malfunction. GPS has largely replaced the sextant and chronometer to establish one's position at sea, but many mariners still carry a sextant and chronometer as a backup. So too with sounding lines. While the echo sounder is used so long as it works, the sounding line is there when it doesn't work. Many small craft still rely solely on a sounding line. \n\nThe first practical fathometer (literally \"fathom measurer\"), which determined water depth by measuring the time required for an echo to return from a high-pitched sound sent through the water and reflected from the sea floor, was invented by Herbert Grove Dorsey and patented in 1928.\n\n\n"}
{"id": "2866264", "url": "https://en.wikipedia.org/wiki?curid=2866264", "title": "Early world maps", "text": "Early world maps\n\nThe earliest known world maps date to classical antiquity, the oldest examples of the 6th to 5th centuries BCE still based on the flat Earth paradigm.\nWorld maps assuming a spherical Earth first appear in the Hellenistic period.\nThe developments of Greek geography during this time, notably by Eratosthenes and Posidonius culminated in the Roman era, with Ptolemy's world map (2nd century CE), which would remain authoritative throughout the Middle Ages.\n\nSince Ptolemy, knowledge of the approximate size of the globe allowed cartographers to estimate the extent of their geographical knowledge, and to indicate parts of the globe known to exist but not yet explored as \"terra incognita\".\nWith the Age of Discovery, during the 15th to 18th centuries, world maps became increasingly accurate; exploration of Antarctica and the interior of Africa by western mapmakers was left to the 19th and early 20th century.\n\nA Babylonian world map, known as the \"Imago Mundi\", is commonly dated to the 6th century BCE.\nThe map as reconstructed by Eckhard Unger shows Babylon on the Euphrates, surrounded by a circular landmass showing Assyria, Urartu (Armenia) and several cities, in turn surrounded by a \"bitter river\" (Oceanus), with eight outlying regions (\"nagu\") arranged around it in the shape of triangles, so as to form a star. The accompanying text mentions a distance of seven \"beru\" between the outlying regions.\nThe descriptions of five of them have survived:\nA final paragraph summarises, \"In all eight \"regions\" (nagu) of the four shores (kibrati) of the ea[rth ...], their interior no-one knows\".\n\nAnaximander (died c. 546 BCE) is credited with having created one of the first maps of the world, which was circular in form and showed the known lands of the world grouped around the Aegean Sea at the center. This was all surrounded by the ocean.\n\nHecataeus of Miletus (died BCE) is credited with a work entitled \"Ges Periodos\" (\"Travels round the Earth\" or \"World Survey'), in two books each organized in the manner of a \"periplus\", a point-to-point coastal survey. One on Europe, is essentially a periplus of the Mediterranean, describing each region in turn, reaching as far north as Scythia. The other book, on Asia, is arranged similarly to the \"Periplus of the Erythraean Sea\" of which a version of the 1st century CE survives. Hecataeus described the countries and inhabitants of the known world, the account of Egypt being particularly comprehensive; the descriptive matter was accompanied by a map, based upon Anaximander's map of the earth, which he corrected and enlarged. The work only survives in some 374 fragments, by far the majority being quoted in the geographical lexicon \"Ethnika\" compiled by Stephanus of Byzantium.\n\nEratosthenes (276–194 BCE) drew an improved world map, incorporating information from the campaigns of Alexander the Great and his successors. Asia became wider, reflecting the new understanding of the actual size of the continent. Eratosthenes was also the first geographer to incorporate parallels and meridians within his cartographic depictions, attesting to his understanding of the spherical nature of the earth.\n\nPosidonius (or Poseidonius) of Apameia (c. 135–51 BCE), was a Greek Stoic philosopher who traveled throughout the Roman world and beyond and was a celebrated polymath throughout the Greco-Roman world, like Aristotle and Eratosthenes. His work \"about the ocean and the adjacent areas\" was a general geographical discussion, showing how all the forces had an effect on each other and applied also to human life. He measured the Earth's circumference by reference to the position of the star Canopus. His measure of 240,000 stadia translates to , close to the actual circumference of .\nHe was informed in his approach by Eratosthenes, who a century earlier used the elevation of the Sun at different latitudes. Both men's figures for the Earth's circumference were uncannily accurate, aided in each case by mutually compensating errors in measurement. However, the version of Posidonius' calculation popularised by Strabo was revised by correcting the distance between Rhodes and Alexandria to 3,750 stadia, resulting in a circumference of 180,000 stadia, or . Ptolemy discussed and favored this revised figure of Posidonius over Eratosthenes in his \"Geographia\", and during the Middle Ages scholars divided into two camps regarding the circumference of the Earth, one side identifying with Eratosthenes' calculation and the other with Posidonius' 180,000 stadion measure.\n\nStrabo is mostly famous for his 17-volume work \"Geographica\", which presented a descriptive history of people and places from different regions of the world known to his era. The \"Geographica\" first appeared in Western Europe in Rome as a Latin translation issued around 1469. Although Strabo referenced the antique Greek astronomers Eratosthenes and Hipparchus and acknowledged their astronomical and mathematical efforts towards geography, he claimed that a descriptive approach was more practical. \"Geographica\" provides a valuable source of information on the ancient world, especially when this information is corroborated by other sources. Within the books of \"Geographica\" is a map of Europe. Whole world maps according to Strabo are reconstructions from his written text.\n\nPomponius is unique among ancient geographers in that, after dividing the earth into five zones, of which two only were habitable, he asserts the existence of antichthones, people inhabiting the southern temperate zone inaccessible to the folk of the northern temperate regions due to the unbearable heat of the intervening torrid belt. On the divisions and boundaries of Europe, Asia and Africa, he repeats Eratosthenes; like all classical geographers from Alexander the Great (except Ptolemy) he regards the Caspian Sea as an inlet of the Northern Ocean, corresponding to the Persian (Persian Gulf) and Arabian (Red Sea) gulfs on the south.\n\nMarinus of Tyre's world maps were the first in the Roman Empire to show China. Around 120 CE, Marinus wrote that the habitable world was bounded on the west by the Fortunate Islands. The text of his geographical treatise however is lost. He also invented the equirectangular projection, which is still used in map creation today. A few of Marinus' opinions are reported by Ptolemy. Marinus was of the opinion that the \"Okeanos\" was separated into an eastern and a western part by the continents (Europe, Asia and Africa). He thought that the inhabited world stretched in latitude from Thule (Shetland) to Agisymba (Tropic of Capricorn) and in longitude from the Isles of the Blessed to Shera (China). Marinus also coined the term Antarctic, referring to the opposite of the Arctic Circle. His chief legacy is that he first assigned to each place a proper latitude and longitude; he used a \"Meridian of the Isles of the Blessed (Canary Islands or Cape Verde Islands)\" as the zero meridian.\n\nSurviving texts of Ptolemy's \"Geography\", first composed , note that he continued the use of Marinus's equirectangular projection for its regional maps while finding it inappropriate for maps of the entire known world. Instead, in Book VII of his work, he outlines three separate projections of increasing difficulty and fidelity. Ptolemy followed Marinus in underestimating the circumference of the world; combined with accurate absolute distances, this led him to also overestimate the length of the Mediterranean Sea in terms of degrees. His prime meridian at the Fortunate Isles was therefore around 10 actual degrees further west of Alexandria than intended, a mistake that was corrected by Al-Khwārizmī following the translation of Syriac editions of Ptolemy into Arabic in the 9th century. The oldest surviving manuscripts of the work date to Maximus Planudes's restoration of the text a little before 1300 at Chora Monastery in Constantinople (Istanbul); surviving manuscripts from this era seem to preserve separate recensions of the text which diverged as early as the 2nd or 4th century. A passage in some of the recensions credits an Agathodaemon with drafting a world map, but no maps seem to have survived to be used by Planude's monks. Instead, he commissioned new world maps calculated from Ptolemy's thousands of coordinates and drafted according to the text's 1st and 2nd projections, along with the equirectangular regional maps. A copy was translated into Latin by Jacobus Angelus at Florence around 1406 and soon supplemented with maps on the 1st projection. Maps using the 2nd projection were not made in Western Europe until Nicolaus Germanus's 1466 edition. Ptolemy's 3rd (and hardest) projection does not seem to have been used at all before new discoveries expanded the known world beyond the point where it provided a useful format.\n\nCicero's \"Dream of Scipio\" described the Earth as a globe of insignificant size in comparison to the remainder of the cosmos. Many medieval manuscripts of Macrobius' \"Commentary on the Dream of Scipio\" include maps of the Earth, including the antipodes, zonal maps showing the Ptolemaic climates derived from the concept of a spherical Earth and a diagram showing the Earth (labeled as \"globus terrae\", the sphere of the Earth) at the center of the hierarchically ordered planetary spheres.\n\nThe Tabula Peutingeriana (\"Peutinger table\") is an itinerarium showing the \"cursus publicus\", the road network in the Roman Empire. It is a 13th-century copy of an original map dating from the 4th century, covering Europe, parts of Asia (India) and North-Africa. The map is named after Konrad Peutinger, a German 15th-16th-century humanist and antiquarian. The map was discovered in a library in Worms by Conrad Celtes, who was unable to publish his find before his death, and bequeathed the map in 1508 to Peutinger. It is conserved at the Österreichische Nationalbibliothek, Hofburg, Vienna.\n\nAround 550 Cosmas Indicopleustes wrote the copiously illustrated \"Christian Topography\", a work partly based on his personal experiences as a merchant on the Red Sea and Indian Ocean in the early 6th century. Though his cosmogony is refuted by modern science, he has given a historic description of India and Sri Lanka during the 6th century, which is invaluable to historians. Cosmas seems to have personally visited the Kingdom of Axum in modern Ethiopia and Eritrea, as well as India and Sri Lanka. In 522 CE, he visited the Malabar Coast (South India). A major feature of his \"Topography\" is Cosmas' worldview that the world is flat, and that the heavens form the shape of a box with a curved lid, a view he took from unconventional interpretations of Christian scripture. Cosmas aimed to prove that pre-Christian geographers had been wrong in asserting that the earth was spherical and that it was in fact modelled on the tabernacle, the house of worship described to Moses by God during the Jewish Exodus from Egypt.\n\nThe medieval T and O maps originate with the description of the world in the \"Etymologiae\" of Isidore of Sevilla (died 636). This qualitative and conceptual type of medieval cartography represents only the top-half of a spherical Earth. It was presumably tacitly considered a convenient projection of the inhabited portion of the world known in Roman and Medieval times (that is, the northern temperate half of the globe). The \"T\" is the Mediterranean, dividing the three continents, Asia, Europe and Africa, and the \"O\" is the surrounding Ocean. Jerusalem was generally represented in the center of the map. Asia was typically the size of the other two continents combined. Because the sun rose in the east, Paradise (the Garden of Eden) was generally depicted as being in Asia, and Asia was situated at the top portion of the map.\n\nIbn Hawqal was an Arab scientist of the 10th century who developed a world map, based on his own travel experience and probably the works of Ptolemy. Another such cartographer was Al-Istakhri.\n\nThis map appears in a copy of a classical work on geography, the Latin version by Priscian of the \"Periegesis\", that was among the manuscripts in the Cotton library (MS. Tiberius B.V., fol. 56v), now in the British Library. It is not intended purely as an illustration to that work, for it contains much material gathered from other sources, including some which would have been the most up-to-date available, although it is based on a distant Roman original (similar to the source of another 11th-century world map, illustrating an edition of Isidore of Seville)—on which the network of lines appears to indicate the boundaries of imperial provinces. The date of drawing was formerly estimated at about CE 992–994, based on suggested links to the journey of Archbishop Sigeric of Canterbury from Rome but more recent analysis indicates that, although the information was revised about that time, the map was probably drawn between 1025 and 1050.\n\nLike the later map by al-Idrisi (see below) this map is clearly outside the largely symbolic early medieval mapping tradition, but equally it is not based on the famous Ptolemaic co-ordinate system. East is at the top, but Jerusalem is not in the centre, and the Garden of Eden is nowhere to be seen. Unusually, all the waterways of Africa, not just the Red Sea, are depicted in red (mountains are green). The depiction of the far East is ambitious, including India and Taprobane (Sri Lanka)—the latter depicted according to the exaggerated classical conception of its size. Unsurprisingly, Britain itself is depicted in some detail. Great Britain, unusually by medieval standards, is shown as one island, albeit with an exaggerated Cornish promontory, and Mona, Ireland and the many Scottish islands are all indicated. The cartographer is slightly confused by Iceland, depicting it both by a version of its classical name 'Thule', north-west of Britain, and as 'Island', logically linked with Scandinavia.\n\nAn open-access high-resolution digital image of the map with place and name annotations is included among the thirteen medieval maps of the world edited in the Virtual Mappa project.\n\nBeatus of Liébana (c. 730–798) was an Asturian monk and theologian. He corresponded with Alcuin, and took part in the Adoptionist controversy, criticizing the views of Felix of Urgel and Elipandus of Toledo. He is best remembered today as the author of his \"Commentary on the Apocalypse\", published in 776. An illustrated manuscript known as the Saint-Sever Beatus, featuring the \"Commentary\", was produced around 1050 at the Abbey of Saint-Sever, Aquitaine, France. It contains one of the oldest Christian world maps as an illustration of the \"Commentary\". Although the original manuscript and map has not survived, copies of the map survive in several of the extant manuscripts.\n\nQarakhanid Uyghur scholar Mahmud al-Kashgari compiled a \"Compendium of the languages of the Turks\" in the 11th century. The manuscript is illustrated with a \"Turkocentric\" world map, oriented with east (or rather, perhaps, the direction of midsummer sunrise) on top, centered on the ancient city of Balasagun in what is now Kyrgyzstan, showing the Caspian Sea to the north, and Iraq, Armenia, Yemen and Egypt to the west, China and Japan to the east, Hindustan, Kashmir, Gog and Magog to the south. Conventional symbols are used throughout—blue lines for rivers, red lines for mountain ranges etc. The world is shown as encircled by the ocean. The map is now kept at the Pera Museum in Istanbul.\n\nThe Arab geographer, Muhammad al-Idrisi, incorporated the knowledge of Africa, the Indian Ocean and the Far East gathered by Arab merchants and explorers with the information inherited from the classical geographers to create the most accurate map of the world at the time. It remained the most accurate world map for the next three centuries.\nThe Tabula Rogeriana was drawn by Al-Idrisi in 1154 for the Norman King Roger II of Sicily, after a stay of eighteen years at his court, where he worked on the commentaries and illustrations of the map. The map, written in Arabic, shows the Eurasian continent in its entirety, but only shows the northern part of the African continent.\n\nThe Ebstorf Map was an example of a European mappa mundi, made by Gervase of Ebstorf, who was possibly the same man as Gervase of Tilbury, some time in the thirteenth century. It was a very large map: painted on 30 goatskins sewn together, it measured about . The head of Christ was depicted at the top of the map, with his hands on either side and his feet at the bottom. The Map was a greatly elaborated version of the medieval tripartite or T and O map; it was centred on Jerusalem with east on top of the map. It represented Rome in the shape of a lion, and had an evident interest in the distribution of bishoprics. The original was destroyed during World War II, but some photographs and colour copies remain.\n\nThe Hereford Mappa Mundi is a detailed mappa mundi based on the T and O map style, dating to . The map is signed by one \"Richard of Haldingham or Lafford\". Drawn on a single sheet of vellum, it measures . The writing is in black ink, with additional red and gold, and blue or green for water (with the Red Sea coloured red). The captions demonstrate clearly the multiple functions of these large medieval maps, conveying a mass of information on Biblical subjects and general history, in addition to geography.\n\nJerusalem is drawn at the centre of the circle, east is on top, showing the Garden of Eden in a circle at the edge of the world (1). Great Britain is drawn at the northwestern border (bottom left, 22 & 23). Curiously, the labels for Africa and Europe are reversed, with Europe scribed in red and gold as 'Africa', and vice versa.\n\nAn open-access high-resolution digital image of the map with more than 1,000 place and name annotations is included among the thirteen medieval maps of the world edited in the Virtual Mappa project.\n\nItalian geographer Pietro Vesconte was a pioneer of the field of the portolan chart. His nautical charts are among the earliest to map the Mediterraean and Black Sea regions accurately. He also produced progressively more accurate depictions of the coastlines of northern Europe. In his world map of 1321 he brought his experience as a maker of portolans to bear; the map introduced a previously unheard of accuracy to the mappa mundi genre. The world map, as well as a map of the Holy Land and plan of Acre and Jerusalem were made for inclusion in Marino Sanuto's \"Liber secretorum fidelium cruces\".\n\nThe Catalan World Atlas was produced by the Majorcan cartographic school and is attributed to Cresques Abraham. It has been in the royal library of France (now the Bibliothèque nationale de France) since the time of Charles V. The Catalan Atlas originally consisted of 6 vellum leaves folded down the middle painted in various colors including gold and silver. The first two leaves contain texts in Catalan language covering cosmography, astronomy, and astrology. These texts are accompanied by illustrations. The texts and illustration emphasize the Earth's spherical shape and the state of the known world. They also provide information to sailors on tides and how to tell time at night.\n\nUnlike many other nautical charts, the Catalan Atlas is read with the north at the bottom. As a result of this the maps are oriented from left to right, from the Far East to the Atlantic. The first two leaves, forming the oriental portion of the Catalan Atlas, illustrate numerous religious references as well as a synthesis of medieval mappae mundi (Jerusalem located close to the centre) and the travel literature of the time, notably Marco Polo's Book of Marvels and the Travels and Voyage of Sir John Mandeville. Many Indian and Chinese cities can be identified.\n\nThe \"Da Ming Hunyi Tu\" () world map, likely made in the late 14th or the 15th century,\nshows China at the centre and Europe, half-way round the globe, depicted very small and horizontally compressed at the edge. The coast of Africa is also mapped from an Indian Ocean perspective, showing the Cape of Good Hope area.\nIt is believed that maps of this type were made since about the 1320s, but all earlier specimens have been lost, so the earliest survivor is the elaborate, colourful \"Da Ming Hun Yi Tu\", painted on of silk.\n\nThe \"Kangnido\" (the full Hanja name means \"Map of Integrated Lands and Regions of Historical Countries and Capitals\") is a map of the world made in Korea in 1402. Created under the supervision of Korean officials as part of a cultural project of the newly founded Joseon Dynasty, it is the most familiar example of the known-world maps based on Chinese cartographic techniques with additional input from western sources, via Islamic scholarship in the Mongol Empire. Superficially similar to the \"Da Ming Hun Yi Tu\" (which has been less well known in the West because it is kept in closed archive storage) the Kangnido shows its Korean origin in the enlargement of that country, and incorporates vastly improved (though wrongly positioned, scaled and oriented) mapping of Japan. Elsewhere, the map betrays a decorative rather than practical purpose, particularly in the portrayal of river systems, which form unnatural loops rarely seen on Chinese maps. Nonetheless, it is considered as \"superior to anything produced in Europe prior to the end of the fifteenth century\".\n\nThe De Virga world map was made by Albertinus de Virga between 1411 and 1415. Albertin de Virga, a Venetian, is also known for a 1409 map of the Mediterranean, also made in Venice. The world map is circular, drawn on a piece of parchment . It consists of the map itself, about in diameter, and an extension containing a calendar and two tables.\n\nAndrea Bianco's atlas of 1436 comprises ten leaves of vellum, measuring , in an 18th-century binding. The first leaf contains a description of the \"Rule of marteloio\" for resolving the course, with the \"circle and square\", two tables and two other diagrams. The next eight leaves contain various navigation charts. The ninth leaf contains a circular world map measuring in circumference. And the final leaf contains the Ptolemaic world map on Ptolemy's first projection, with graduation. Some believe Bianco's maps were the first to correctly portray the coast of Florida, as a macro-peninsula is attached to a large island labeled Antillia. Bianco also collaborated with Fra Mauro on the Fra Mauro world map of 1459.\n\nMainly a decoration piece, the Borgia map is a world map made sometime in the early 15th century, and engraved on a metal plate.\n\nThe Genoese map of 1457 is a world map that relied extensively on the account of the traveler to Asia Niccolo da Conti, rather than the usual source of Marco Polo. The author is unknown, but is a more modern development than the Fra Mauro world map, less intricate and complete, with fairly good proportions given to each of the continents. The map depicts the main landmarks of the time: Prester John in Africa, the Great Khan in China, \"Xilam\" (Ceylom) and Sumatra, and the design of a three-masted European ship in the Indian Ocean, something which had not occurred, suggesting that a sealane was a possibility.\n\nThe Fra Mauro map was made between 1457 and 1459 by the Venetian monk Fra Mauro. It is a circular planisphere drawn on parchment and set in a wooden frame, about in diameter.\nThe original world map was made by Fra Mauro and his assistant Andrea Bianco, a sailor-cartographer, under a commission by king Afonso V of Portugal. The map was completed on April 24, 1459, and sent to Portugal, but did not survive to the present day. Fra Mauro died the next year while he was making a copy of the map for the Seignory of Venice, and the copy was completed by Andrea Bianco.\n\nThe map is preserved in the Museo Correr in Venice.\n\nThe world map of Henricus Martellus Germanus (Heinrich Hammer), c. 1490, was remarkably similar to the terrestrial globe later produced by Martin Behaim in 1492, the \"Erdapfel\". Both show heavy influences from Ptolemy, and both possibly derive from maps created around 1485 in Lisbon by Bartolomeo Columbus. Although Martellus is believed to have been born in Nuremberg, Behaim's home town, he lived and worked in Florence from 1480 to 1496.\n\nThe \"Erdapfel\" () produced by Martin Behaim in 1492 is considered to be the oldest surviving terrestrial globe. It is constructed of a laminated linen ball reinforced with wood and overlaid with a map painted by Georg Glockendon. The Americas are not included yet, as Columbus returned to Spain no sooner than March 1493. It shows a rather enlarged Eurasian continent and an empty ocean between Europe and Asia. The Caribbean islands may already be represented as well, even before Colombus's return, under the name of the mythical Saint Brendan's Island. Japan and Asian islands are disproportionately large. The idea to call the globe \"apple\" may be related to the Reichsapfel (\"Imperial Apple\", Globus cruciger) which was also kept in Nuremberg along with the Imperial Regalia (Reichskleinodien). In 1907, it was transferred to the Germanic Museum in Nuremberg.\nThe Juan de la Cosa, a Spanish cartographer, explorer and conquistador, born in Santoña in the northern autonomous region of Cantabria, made several maps of which the only survivor is the \"Mappa Mundi\" of 1500. It is the first known European cartographic representation of the Americas. It is now in the Museo Naval in Madrid. Reproductions of it are given by Humboldt in his \"Atlas géographique et physique\".\nThe \"Cantino planisphere\" or Cantino world map is the earliest surviving map showing Portuguese discoveries in the east and west. It is named after Alberto Cantino, an agent for the Duke of Ferrara, who successfully smuggled it from Portugal to Italy in 1502. It shows the islands of the Caribbean and the Florida coastline, as well as Africa, Europe and Asia. The map is particularly notable for portraying a fragmentary record of the Brazilian coast, discovered in 1500 by Portuguese explorer Pedro Álvares Cabral who conjectured whether it was merely an island or part of the continent that several Spanish expeditions had just encountered farther north (cf. Amerigo Vespucci).\nThe Caverio Map, also known as the Caveri Map or Canerio Map, is a map drawn by Nicolay de Caveri, circa 1505. It is hand drawn on parchment and coloured, being composed of ten sections or panels, measuring . Historians believe that this undated map signed with \"Nicolay de Caveri Januensis\" was completed in 1504–05. It was probably either made in Lisbon by the Genoese Canveri, or copied by him in Genoa from the very similar Cantino map. It shows the east coast of North America with surprising detail and was one of the primary sources used to make the Waldseemüller map in 1507. The Caverio map is currently at Bibliothèque Nationale de France in Paris.\n\nJohannes Ruysch an explorer, cartographer, astronomer and painter from the Low Countries produced the second oldest known printed representation of the New World. The Ruysch map was published and widely distributed in 1507. It uses Ptolemy's coniform projection, as does the Contarini-Rosselli 1506 map. Both document Christopher Columbus' discoveries as well as that of John Cabot, including information from Portuguese sources and Marco Polo's account. There are notes on his map that clearly were from Portuguese sources. Newfoundland and Cuba are shown connected to Asia, as Columbus and Cabot believed. “Sipganus” (Marco Polo’s Japan) is identical with “Spagnola” (Hispaniola) on the Ruysch map. The presence of codfish is noted on the Ruysch map in the area of the Grand Banks of Newfoundland and shows the discoveries the Portuguese had made along the African coast and shows India as a triangular peninsula with Ceylon in the correct proportion and position.\nGreenland is shown connected to Newfoundland and Asia on Ruysch's map, and not Europe as earlier maps had showed. Around the north pole, Ruysch drew islands, based on reports in the book \"Inventio Fortunata\" of the English friar Nicholas of Lynne. The island above Norway shows remarkable similarities to Svalbard, which was not discovered until 1597 (by Willem Barents). Ruysch calls it 'European Hyberborea' and a peninsula stretching out towards it is clearly marked with the church of 'Sancti Odulfi', St Olaf's church in Vardø on the Finnmark coast.\n\nThe cartographers Martin Waldseemüller and Matthias Ringmann from southern Germany, supported by the mapping friend René II, Duke of Lorraine, collected map data over several years, including information on the most recent discoveries, to build up a new collective work of geography and cartography. Along with a book they further incorporated, for the first time in history, the name \"America\" on a map, holding the strong opinion that it was a new continent that Amerigo Vespucci had discovered on his voyage and not only a few smaller islands as Christopher Columbus did in the \"West Indies\".\nThe Piri Reis map is a famous world map created by 16th-century Ottoman Turkish admiral and cartographer Piri Reis. The surviving third of the map shows part of the western coasts of Europe and North Africa with reasonable accuracy, and the coast of Brazil is also easily recognizable. Various Atlantic islands including the Azores and Canary Islands are depicted, as is the mythical island of Antillia. The map is noteworthy for its apparent south-eastward extension of the American continent to depict a southern landmass that some controversially claim is evidence for early awareness of the existence of Antarctica. Alternatively, it has been suggested that this is actually a record of the coast as far as Cape Horn, explored secretly by Portuguese navigators before 1507 (when it appeared on the Waldseemüller map) and bent south-eastward simply to fit on the parchment.\n\nThe map by Pietro Coppo was one of the last world maps to feature the \"Dragon's Tail\" extending southwards from the far eastern extremity of Asia, the last vestige of Ptolemy's landlocked depiction of the Indian Ocean, nearly 1,500 years earlier.\n\nDiogo Ribeiro, a Portuguese cartographer working for Spain, made what is considered the first scientific world map: the 1527 Padrón real, the first world map based on empiric latitude observations. There are 6 copies attributed to Ribeiro, including at the Weimar Grand Ducal Library (1527 \"Mundus Novus\") and at the Biblioteca Apostolica Vaticana, in Vatican City (1529 \"Propaganda Map\" or \"Carta Universal\"). The layout of the map (\"Mapamundi\") is strongly influenced by the information obtained during the Magellan-Elcano trip around the world. Diogo's map delineates very precisely the coasts of Central and South America. However, neither Australia nor Antarctica appear, and the Indian subcontinent is too small. The map shows, for the first time, the real extension of the Pacific Ocean. It also shows, for the first time, the North American coast as a continuous one (probably influenced by the Estêvão Gomes exploration in 1525). It also shows the demarcation of the Treaty of Tordesillas.\nFlemish geographer and cartographer Gerardus Mercator world map of 1569 introduced a cylindrical map projection that became the standard map projection known as the Mercator projection. It was a large planisphere measuring , printed in eighteen separate sheets. While the linear scale is constant in all directions around any point, thus preserving the angles and the shapes of small objects (which makes the projection conformal), the Mercator projection distorts the size and shape of large objects, as the scale increases from the Equator to the poles, where it becomes infinite. The title (\"Nova et Aucta Orbis Terrae Descriptio ad Usum Navigatium Emendate\": \"new and augmented description of Earth corrected for the use of navigation\") and the map legends show that the map was expressly conceived for the use of marine navigation. The principal feature of the projection is that Rhumb lines, sailing courses at a constant bearing, are mapped to straight lines on the map. The development of the Mercator projection represented a major breakthrough in the nautical cartography of the 16th century although it was only slowly adopted by seafaring nations.\nThe \"Theatrum Orbis Terrarum\" (or \"Theatre of the World\") is considered to be the first true modern atlas. Written by Abraham Ortelius and originally printed on May 20, 1570, in Antwerp, it consisted of a collection of uniform map sheets and sustaining text bound to form a book for which copper printing plates were specifically engraved. The Ortelius atlas is sometimes referred to as the summary of sixteenth-century cartography. Many of his atlas' maps were based upon sources that no longer exist or are extremely rare. Ortelius appended a unique source list (the \"Catalogus Auctorum\") identifying the names of contemporary cartographers, some of whom would otherwise have remained obscure. Three Latin editions of this (besides a Dutch, a French and a German edition) appeared before the end of 1572; twenty-five editions came out before Ortelius' death in 1598; and several others were published subsequently, for the atlas continued to be in demand until approximately 1612.\nThe Bünting Clover Leaf Map, also known as The World in a Cloverleaf, (German title: \"Die ganze Welt in einem Kleberblat/Welches ist der Stadt Hannover meines lieben Vaterlandes Wapen\") is an historic mappa mundi drawn by the German Protestant pastor, theologist, and cartographer Heinrich Bünting. The map was published in his book \"Itinerarium Sacrae Scripturae\" (Travel through Holy Scripture) in 1581. \n\nToday the map is found within the Eran Laor maps collection in the National Library of Israel in Jerusalem. A mosaic model of the map is installed on the fence of Safra Square at the site of Jerusalem's city hall.\n\nThe map is a figurative illustration, in the manner of the medieval mappa mundi format, depicting the world via a clover shape. The shape is a symbolisation of the Christian Trinity and a component at the symbolisation of the German city Hanover, where Bünting was born. The city of Jerusalem is represented as the centre, surrounded by three central continents, with some more areas of the world being accordingly illustrated separately from the clover.\n\nKunyu Wanguo Quantu (; , \"Complete Geographical Map of all the Kingdoms of the World\"), printed by Italian Jesuit missionary Matteo Ricci at the request by Wanli Emperor in 1602, is the first known European-styled Chinese world map (and the first Chinese map to show the Americas). The map is in Classical Chinese, with detailed annotations and descriptions of various regions of the world, a brief account of the discovery of the Americas, polar projections, scientific explanation of parallels and meridians, and proof that the sun is bigger than the moon. Following Chinese cartographical convention, Ricci placed China (\"the Middle Kingdom\") at the centre of the world. This map is a significant mark of the expansion Chinese knowledge of the world, and an important example of cultural syncretism directly between Europe and China. It was also exported to Korea and Japan as well. \n\n\"Nova Totius Terrarum Orbis Geographica ac Hydrographica Tabula\" is a map of the world created by Hendrik Hondius in 1630, and published the following year at Amsterdam, in the atlas \"Atlantis Maioris\" Appendix. Illustrations of the four elements of fire, air, water, and land are included. In the four corners, there are portraits of Julius Caesar, Claudius Ptolemy, and the atlas's first two publishers, Gerard Mercator and Jodocus Hondius, the father of Hendrik. Among its claims to notability is the fact that it was the first dated map published in an atlas, and therefore the first widely available map, to show any part of Australia, the only previous map to do so being Hessel Gerritsz' 1627 \"Caert van't Landt van d'Eendracht\" (\"Chart of the Land of Eendracht\"), which was not widely distributed or recognised. The Australian coastline shown is part of the west coast of Cape York Peninsula, discovered by Jan Carstensz in 1623. Curiously, the map does not show the west coast features shown in Gerritsz' Caert.\n\nThis engraved double hemisphere map, \"Orbis Terrarum Nova et Accuratissima Tabula\", was created by Nicolaes Visscher in 1658 in Amsterdam. It also contains smaller northern and southern polar projections. The border is decorated with mythological scenes, one in each corner, drawn by the painter Nicolaes Berchem, showing Zeus, Neptune, Persephone and Demeter. It is an early example of highly decorated Dutch world maps.\n\nGerard van Schagen (ca. 1642–1724?) was a cartographer from Amsterdam, known for his exquisite reproductions of maps, particularly of those by Nicolaes Visscher I and Frederick de Wit. The map is of 1689. The original size is and was produced using copper engraving. There is only one known example, which is in the Amsterdam University.\nSamuel Dunn (died 1794) was a British mathematician and amateur astronomer. His map covers the entire world in a double hemisphere projection. This map follows shortly after the explorations of Captain Cook in the Arctic and Pacific Northwest, so the general outline of North America is known. However, when this map was made, few inland expeditions had extended westward beyond the Mississippi River.\n\n\n"}
{"id": "1195462", "url": "https://en.wikipedia.org/wiki?curid=1195462", "title": "Environmental studies", "text": "Environmental studies\n\nEnvironmental studies is a multidisciplinary academic field which systematically studies human interaction with the environment in the interests of solving complex problems. Environmental studies brings together the principles of the physical sciences, commerce/economics and social sciences so as to solve contemporary environmental problems. It is a broad field of study that includes the natural environment, the built environment, and the sets of relationships between them. The field encompasses study in basic principles of ecology and environmental science, as well as associated subjects such as ethics, geography, anthropology, policy, politics, urban planning, law, economics, philosophy, sociology and social justice, planning, pollution control and natural resource management. There are also many degree programs in Environmental Studies including the Master of Environmental Studies and the Bachelor of Environmental Studies.\n\nThe New York State College of Forestry at Syracuse University established a BS in environmental studies degree in the 1950s, awarding its first degree in 1956. Middlebury College established the major there in 1965.\n\nThe Environmental Studies Association of Canada (ESAC) was established in 1993 \"to further research and teaching activities in areas related to environmental studies in Canada\". ESAC's magazine, \"\" was first published by Robert A. Paehlke on 4 July 1971.\n\nThe Association for Environmental Studies and Sciences (AESS) was founded in 2008 as the first professional association in the interdisciplinary field of environmental studies in the United States. In 2010, the National Council for Science and the Environment (NCSE) agreed to advise and support the Association. The Association's scholarly journal, the \"Journal of Environmental Studies and Sciences\" (JESS), commenced publication in March 2011.\n\nIn the United States, many high school students are able to take environmental science as a college-level course. Over 500 colleges and universities in the United States offer environmental studies as a degree.\n\n"}
{"id": "219878", "url": "https://en.wikipedia.org/wiki?curid=219878", "title": "Exploration", "text": "Exploration\n\nExploration is the act of searching for the purpose of discovery of information or resources. Exploration occurs in all non-sessile animal species, including humans. In human history, its most dramatic rise was during the Age of Discovery when European explorers sailed and charted much of the rest of the world for a variety of reasons. Since then, major explorations after the Age of Discovery have occurred for reasons mostly aimed at information discovery.\n\nIn scientific research, exploration is one of three purposes of empirical research (the other two being description and explanation). The term is often used metaphorically. For example, an individual may speak of exploring the Internet, sexuality, etc.\n\nThe Phoenicians (1550 BCE–300 BCE) traded throughout the Mediterranean Sea and Asia Minor though many of their routes are still unknown today. The presence of tin in some Phoenician artifacts suggests that they may have traveled to Britain. According to Virgil's Aeneid and other ancient sources, the legendary Queen Dido was a Phoenician from Tyre who sailed to North Africa and founded the city of Carthage.\n\nHanno the Navigator (500 BC), a Carthaginean navigator explored the Western Coast of Africa.\n\n\nThe Romans organized expeditions to cross the Sahara desert with five different routes:\n\n\nAll these expeditions were supported by legionaries and had mainly a commercial purpose. Only the one done by emperor Nero seemed to be a preparative for the conquest of Ethiopia or Nubia: in 62 AD two legionaries explored the sources of the Nile river.\n\nOne of the main reasons of the explorations was to get gold using the camel to transport it.\n\nThe explorations near the African western and eastern coasts were supported by Roman ships and deeply related to the naval commerce (mainly toward the Indian Ocean).\nRomans organized several explorations also in Northern Europe, and as far as Asia up to China .\n\n\n\n\n\n\nDuring the 2nd century BC, the Han dynasty explored much of the Eastern Northern Hemisphere. Starting in 139 BC, the Han diplomat Zhang Qian traveled west in an unsuccessful attempt to secure an alliance with the Da Yuezhi against the Xiongnu (the Yuezhi had been evicted from Gansu by the Xiongnu in 177 BC); however, Zhang's travels discovered entire countries which the Chinese were unaware of, including the remnants of the conquests of Alexander the Great (r. 336–323 BC). When Zhang returned to China in 125 BC, he reported on his visits to Dayuan (Fergana), Kangju (Sogdiana), and Daxia (Bactria, formerly the Greco-Bactrian Kingdom which had just been subjugated by the Da Yuezhi). Zhang described Dayuan and Daxia as agricultural and urban countries like China, and although he did not venture there, described Shendu (the Indus River valley of Northwestern India) and Anxi (Arsacid territories) further west.\n\nFrom about 800 AD to 1040 AD, the Vikings explored Europe and much of the Western Northern Hemisphere via rivers and oceans. For example, it is known that the Norwegian Viking explorer, Erik the Red (950–1003), sailed to and settled in Greenland after being expelled from Iceland, while his son, the Icelandic explorer Leif Ericson (980–1020), reached Newfoundland and the nearby North American coast, and is believed to be the first European to land in North America.\n\nPolynesians were a maritime people, who populated and explored the central and south Pacific for around 5,000 years, up to about 1280 when they discovered New Zealand. The key invention to their exploration was the outrigger canoe, which provided a swift and stable platform for carrying goods and people. Based on limited evidence, it is thought that the voyage to New Zealand was deliberate. It is unknown if one or more boats went to New Zealand, or the type of boat, or the names of those who migrated. 2011 studies at Wairau Bar in New Zealand show a high probability that one origin was Ruahine Island in the Society Islands. Polynesians may have used the prevailing north easterly trade winds to reach New Zealand in about three weeks. The Cook Islands are in direct line along the migration path and may have been an intermediate stopping point. There are cultural and language similarities between Cook Islanders and New Zealand Maori. Early Maori had different legends of their origins, but the stories were misunderstood and reinterpreted in confused written accounts by early European historians in New Zealand trying to present a coherent pattern of Maori settlement in New Zealand.\n\nMathematical modelling based on DNA genome studies, using state-of-the-art techniques, have shown that a large number of Polynesian migrants (100–200), including women, arrived in New Zealand around the same time, in about 1280. Otago University studies have tried to link distinctive DNA teeth patterns, which show special dietary influence, with places in or nearby the Society Islands.\n\nThe Chinese explorer, Wang Dayuan (fl. 1311–1350) made two major trips by ship to the Indian Ocean. During 1328–1333, he sailed along the South China Sea and visited many places in Southeast Asia and reached as far as South Asia, landing in Sri Lanka and India. Then in 1334–1339, he visited North Africa and East Africa. Later, the Chinese admiral Zheng He (1371–1433) made seven voyages to Arabia, East Africa, India, Indonesia and Thailand.\n\nThe Age of Discovery, also known as the Age of Exploration, is one of the most important periods of geographical exploration in human history. It started in the early 15th century and lasted until the 17th century. In that period, Europeans discovered and/or explored vast areas of the Americas, Africa, Asia and Oceania. Portugal and Spain dominated the first stages of exploration, while other European nations followed, such as England, Netherlands, and France.\nThe most important explorers of this period include: Diogo Cão (c.1452 –c.1486) who discovered and ascended the Congo River and reached the coasts of the present-day Angola and Namibia; Bartolomeu Dias (c. 1450–1500), who was the first European to reach the Cape of Good Hope and other parts of the South African coast; Christopher Columbus (1451–1506), who led a Castilian (Spanish) expedition across the Atlantic, discovering America; Vasco da Gama (1460–1524), a navigator who made the first trip from Europe to India and back by the Cape of Good Hope, discovering the ocean route to the East; Pedro Alvares Cabral (c. 1467/68–c.1520) who, following the path of Gama, claimed Brazil and led the first expedition that linked Europe, Africa, America, and Asia; Diogo Dias, who discovered the eastern coast of Madagascar and rounded the corner of Africa; explorers such as Diogo Fernandes Pereira and Pedro Mascarenhas (1470–1555), among others, who discovered and mapped the Mascarene Islands and other archipelagos; António de Abreu (c.1480–c.1514) and Francisco Serrão (14?–1521), who led the first direct European fleet into the Pacific Ocean (on its western edges), through the Sunda Islands, reaching the Moluccas; Juan Ponce de León (1474–1521), who discovered and mapped the coast of Florida; Vasco Núñez de Balboa (c. 1475–1519), who was the first European to view the Pacific Ocean from American shores (after crossing the Isthmus of Panama) confirming that America was a separate continent from Asia; Ferdinand Magellan (1480–1521), who was the first navigator to cross the Pacific Ocean, discovering the Strait of Magellan, the Tuamotus and Mariana Islands, achieving a nearly complete circumnavigation of the Earth, in multiple voyages, for the first time; Juan Sebastian Elcano (1476–1526), who completed the first global circumnavigation; Aleixo Garcia (14?–1527), who explored the territories of present-day southern Brazil, Paraguay and Bolivia, crossing the Chaco and reaching the Andes (near Sucre); Jorge de Menezes (c. 1498–?), who discovered Papua New Guinea; García Jofre de Loaísa (1490–1526), who discovered the Marshall Islands; Álvar Núñez Cabeza de Vaca (1490–1558), who discovered the Mississippi River and was the first European to sail the Gulf of Mexico and cross Texas; Jacques Cartier (1491–1557), who drew the first maps of part of central and maritime Canada; Andres de Urdaneta (1498–1568), who discovered the maritime route from Asia to the Americas; Francisco Vázquez de Coronado (1510–1554), who discovered the Grand Canyon and the Colorado River; Francisco de Orellana (1511–1546), who was the first European to navigate the length of the Amazon River.\nContinuing in the second half of the 16th century and the 17th century with explorers such as Andrés de Urdaneta (1498–1568), who discovered the maritime route from Asia to the Americas; Álvaro de Mendaña (1542–1595), who discovered the Tuvalu archipelago, the Marquesas, the Solomon Islands and Wake Island; Willem Janszoon (1570–1630), who made the first recorded European landing in Australia; Pedro Fernandes de Queirós (1565–1614), who discovered the Pitcairn Islands and the Vanuatu archipelago; Yñigo Ortiz de Retez, who discovered and reached eastern and northern New Guinea; Luis Váez de Torres (1565–1613), who discovered the Torres Strait between Australia and New Guinea; Henry Hudson (156?–1611), who explored the Hudson Bay in Canada; Samuel de Champlain (1574–1635), who explored St. Lawrence River and the Great Lakes (in Canada and northern United States); Abel Tasman (1603–1659), who explored North Australia, discovered Tasmania and New Zealand; and René-Robert Cavelier, Sieur de La Salle (1643–1687), who explored the Great Lakes region of the United States and Canada, and the entire length of the Mississippi River.\n\nLong after the golden age of discovery, other explorers \"completed\" the world map, such as various Russians explorers, reaching the Siberian Pacific coast and the Bering Strait, at the extreme edge of Asia and Alaska (North America); Vitus Bering (1681–1741) who in the service of the Russian Navy, explored the Bering Strait, the Bering Sea, the North American coast of Alaska, and some other northern areas of the Pacific Ocean; and James Cook, who explored the east coast of Australia, the Hawaiian Islands, and circumnavigated the Antarctic continent.\n\nHumanity is continuing to follow the impulse to explore, moving beyond Earth. Space exploration started in the 20th century with the invention of exo-atmospheric rockets. This has given humans the opportunity to travel to the moon, and to send robotic explorers to other planets and far beyond.\n\nBoth of the Voyager probes have left the Solar System, bearing imprinted gold discs with multiple data types.\n\nA 2015 study, performed on mobile phone data and on GPS tracks of private vehicles in Italy, demonstrated that individuals naturally split into two well-defined categories according to their mobility habits, dubbed \"returners\" and \"explorers\". \n\"Explorers\" showed a star-like mobility pattern: they have a central core of locations (composed by home and work places) around which distant core of locations gravitates.\n\n\n"}
{"id": "28341466", "url": "https://en.wikipedia.org/wiki?curid=28341466", "title": "Exploration of Antarctica", "text": "Exploration of Antarctica\n\nThe exploration of the Antarctica includes:\n"}
{"id": "16953152", "url": "https://en.wikipedia.org/wiki?curid=16953152", "title": "Extreme environment", "text": "Extreme environment\n\nAn extreme environment contains conditions that are hard to survive for most known life forms. These conditions may be extremely high or low temperature or pressure; high or low content of oxygen or carbon dioxide in the atmosphere; high levels of radiation, acidity, or alkalinity; absence of water; water containing a high concentration of salt or sugar; presence of sulphur, petroleum, and other toxic substances.\n\nExamples of extreme environments include the geographical poles, very arid deserts, volcanoes, deep ocean trenches, upper atmosphere, Mt Everest, outer space, and the environments of every planet in the Solar System except the Earth. Any organisms living in these conditions are often very well adapted to their living circumstances, which is usually a result of long-term evolution. Physiologists have long known that organisms living in extreme environments are especially likely to exhibit clear examples of evolutionary adaptation because of the presumably intense past natural selection they have experienced.\n\nThe distribution of extreme environments on Earth has varied through geological time. Humans generally do not inhabit extreme environments. There are organisms referred to as extremophiles that do live in such conditions and are so well-adapted that they readily grow and multiply.\n\nMost of the moons and planets in the Solar System are also extreme environments. Astrobiologists have not yet found life in any environments beyond Earth, though experiments have shown that tardigrades can survive the harsh vacuum and intense radiation of outer space. The conceptual modification of conditions in locations beyond Earth, to make them more habitable by humans and other terrestrial organisms, is known as terraforming.\n\nAmong extreme environments are alkaline, acidic, extremely cold, extremely hot, hyper-saline, places without water or oxygen, and places altered by humans, such as mine tailings or oil impacted habitats.\n\n\n\n"}
{"id": "5388940", "url": "https://en.wikipedia.org/wiki?curid=5388940", "title": "Farther India", "text": "Farther India\n\nFarther India, or Ultraindia, is an old term, now rarely used, for Southeast Asia, seen in colonial days from Europe as the part of the Far East beyond the Indian subcontinent, but south of China.\n\nIt refers to Indochina (Cambodia, Laos, Myanmar (aka Burma), Peninsular Malaysia, Thailand (former Siam), and Vietnam) and the Malay states (Brunei, East Malaysia, Indonesia, and Singapore), but usually not including East Timor or the Philippines, these neighbouring predominantly Malay states usually belong to the wider East Indies (which includes all of the above as well as the Indian subcontinent).\n\nFarther India is also a title of a book written by Sir Hugh Clifford.\n\n\n"}
{"id": "15203034", "url": "https://en.wikipedia.org/wiki?curid=15203034", "title": "First Geography Congress, Turkey", "text": "First Geography Congress, Turkey\n\nThe First Geography Congress \"(Turkish: Birinci Türk Coğrafya Kongresi)\", which was held in Ankara in 1941, separated Turkey into seven geographical regions, which are still used today.\n\nThe congress took numerous factors into consideration when defining these regions, including the fact that Turkey is surrounded by sea on three sides and the presence of mountain ranges lying parallel to the length of the coastline that isolate the central section from the influence of the sea. Based on these factors and the resulting differences in the climate, natural plant cover and the distribution of types of agriculture, as well as the influences of these on the transportation systems and types of housing, the congress divided Turkey into four coastal and three central regions.\n\nThe coastal regions were named after the seas to which they are adjacent (the Black Sea, the Marmara, the Aegean and the Mediterranean Regions). The central regions were named according to their location in the whole of Anatolia (Central, Eastern and Southeastern Anatolia Regions).\n\n"}
{"id": "15516115", "url": "https://en.wikipedia.org/wiki?curid=15516115", "title": "Geo-replication", "text": "Geo-replication\n\nGeo-replication systems are designed to improve the distribution of data across geographically distributed data networks. This is intended to improve the response time for applications such as web portals. Geo-replication can be achieved using software, hardware or a combination of the two. \n\nGeo-replication software is a network performance-enhancing technology that is designed to provide improved access to portal or intranet content for uses at the most remote parts of large organizations. It is based on the principle of storing complete replicas of portal content on local servers, and then keeping the content on those servers up-to-date using heavily compressed data updates.\n\nGeo-replication technologies are used to provide replication of the content of portals, intranets, web applications, content and data between servers, across wide area networks WAN to allow users at remote sites to access central content at LAN speeds. \n\nGeo-replication software can improve the performance of data networks that suffer limited bandwidth, latency and periodic disconnection. Terabytes of data can be replicated over a wide area network, giving remote sites faster access to web applications.\n\nGeo-replication software uses a combination of data compression and content caching technologies. differencing technologies can also be employed to reduce the volume of data that has to be transmitted to keep portal content accurate across all servers. This update compression can reduce the load that portal traffic place on networks, and improve the response time of a portal.\n\nRemote users of web portals and collaboration environments will frequently experience network bandwidth and latency problems which will slow down their experience of opening and closing files, and otherwise interacting with the portal. Geo-replication technology is deployed to accelerate the remote end user portal performance to be equivalent to that experienced by users locally accessing the portal in the central office.\n\nTo deliver this reduction in the size of the required data updates across a portal, geo-replication systems often use differencing engine technologies. These systems are able to difference the content of each portal server right down to the byte level. This knowledge of the content that is already on each server enables the system to rebuild any changes to the content on one server, across each of the other servers in the deployment from content already hosted on those other servers. This type of differencing system ensures that no content, at the byte level, is ever sent to a server twice.\n\nGeo-replication systems are often extended to deliver local replication beyond the server and down to the laptop used by a single user. Server to laptop replication enables mobile users to have access to a local replica of their business portal on a standard laptop. This technology may be employed to provide in the field access to portal content by, for example, sales forces and combat forces.\n\n\n"}
{"id": "43146001", "url": "https://en.wikipedia.org/wiki?curid=43146001", "title": "GeoPlanet", "text": "GeoPlanet\n\nGeoPlanet is a computer platform for coordinating world-wide geographic information, and providing both text and cartographic output, such as digital maps for any location in the world. It provides a location infrastructure for search engines, portals and both Web and WAP sites. It was developed by GDC, a London-based geographic information company, which was acquired by Whereonearth in 1998. When Whereonearth spun off GDC in 2002, it kept GeoPlanet. When Yahoo! purchased Whereonearth in 2005, it acquired GeoPlanet.\n\nAn integral part of GeoPlanet is the WOEID (Where On Earth IDentifier), a unique 32-bit reference identifier, now assigned by Yahoo!, that identifies any feature on Earth. In addition to the strict numerical WOEID, GeoPlanet also has a hierarchical structure that allows accessing surrounding locations, and zooming up and down administrative divisions. In 2009, Yahoo! released GeoPlanet's WOEID data to the public, but the last release was on 1 June 2012 after which Yahoo! decided to cease making the data downloadable until they \"determine a better way to surface the data as a part of the service\".\n\nIn June 2015 Yahoo announced that the GeoPlanet APIs would be dropped as the functionality is now available through their Yahoo Query Language and BOSS APIs. The GeoPlanet APIs stopped responding to requests in late August 2016.\n\n"}
{"id": "27656285", "url": "https://en.wikipedia.org/wiki?curid=27656285", "title": "Geo URI scheme", "text": "Geo URI scheme\n\nThe geo URI scheme is a Uniform Resource Identifier (URI) scheme defined by the Internet Engineering Task Force's RFC 5870 (published 8 June 2010) as:\n\na Uniform Resource Identifier (URI) for geographic locations using the 'geo' scheme name. A 'geo' URI identifies a physical location in a two- or three-dimensional coordinate reference system in a compact, simple, human-readable, and protocol-independent way.\n\nThe current revision of the vCard specification supports geo URIs in a vCard's \"GEO\" property, and the GeoSMS standard uses geo URIs for geotagging SMS messages. Android based devices support geo URIs, although that implementation is based on a draft revision of the specification, and supports a different set of URI parameters and query strings.\n\nA geo URI is not to be confused with the site GeoUrl (which implements ICBM address).\n\nA simple geo URI might look like:\n\nwhere the two numerical values represent latitude and longitude respectively, and are separated by a comma. They are coordinates of an horizontal grid (2D). If a third comma-separated value is present, it represents altitude; so, coordinates of a 3D grid. Coordinates in the Southern and Western hemispheres as well as altitudes below the coordinate reference system (depths) are signed negative with a leading dash. \n\nThe geo URI also allows for an optional \"uncertainty\" value, separated by a semicolon, representing the uncertainty of the location in meters, and is described using the \"u\" URI parameter. A geo URI with an uncertainty parameter looks as follows:\n\nA geo URI may, for example, be included on a web page, as HTML:\n\nso that a geo URI-aware user agent such as a web browser could launch the user's chosen mapping service; or it could be used in an Atom feed or other XML file.\n\nThe values of the coordinates only make sense when a coordinate reference system (CRS) is specified. The default CRS is the World Geodetic System 1984 (WGS-84), and it is not recommended to use any other:\n\nThe only justified use of other CRS today is, perhaps, to preserve projection in large-scale maps, as local UTM, or for non-terrestrial coordinates such as those on the Moon or Mars. The syntax and semantic of the CRS parameter, separated by a semicolon, is described at section 8.3 of RFC 5870. Examples:\n\n\nThe order in which the semicolon-separated parameters occur is partially significant. Whilst the labeltext parameter and future parameters may be given in any order, the codice_6 and the codice_7 parameters must come first. If both are used, the codice_6 must precede the codice_7. All parameters are case-insensitive, so, imagining a future new parameter codice_10, it can be ignored by simpler applications, and the above example is exactly equivalent to:\nBeing in doubt, remember that use of the lowercase representation of parameter names (codice_6 codice_7 and codice_10) is preferred.\n\n\n"}
{"id": "23668992", "url": "https://en.wikipedia.org/wiki?curid=23668992", "title": "Geocriticism", "text": "Geocriticism\n\nGeocriticism is a method of literary analysis and literary theory that incorporates the study of geographic space. The term designates a number of different critical practices. In France, Bertrand Westphal has elaborated the concept of \"géocritique\" in several works. In the United States, Robert Tally has argued for a geocriticism as a critical practice suited to the analysis of what he has termed \"literary cartography\".\n\nSome of the first expressly \"geocritical\" writings emerged from symposia organized by Westphal at the University of Limoges. Westphal's foundational essay, \"Pour une approche géocritique des textes\" constitutes a manifesto for geocriticism. Westphal's theory is elaborated in greater detail in his \"Geocriticism: Real and Fictional Spaces\", translated by Tally, who also provides a brief introduction. But there are also many works addressing similar themes and using similar methods that might be considered geocritical, even if the term \"geocriticism\" is not used.\n\nIn Westphal's theory, geocriticism is based on three theoretical concepts: spatio-temporality, transgressivity, and referentiality. \n\nThe idea that space and time form a continuum (space-time) is a tenet of modern physics. In the field of literary theory, geocriticism is an interdisciplinary method of literary analysis that focuses not only on such temporal data as relations between the life and times of the author (as in biographical criticism), the history of the text (as in textual criticism), or the story (as studied by narratology), but also on spatial data. Geocriticism therefore has affinities with geography, architecture, urban studies, and so on; it also correlates to philosophical concepts such as deterritorialization.\nFollowing the work of Michel Foucault, Gilles Deleuze, Henri Lefebvre and Mikhail Bakhtin, among others, a geocritical approach to literature recognizes that representations of space are often transgressive, crossing the boundaries of established norms while also reestablishing new relations among people, places, and things. Cartography is no longer seen as the exclusive province of the state or the government; rather, various agents or groups may be responsible for representing the geographic spaces at the same time and with different effects. In practice, therefore, geocriticism is multifocal, examining a variety of topics at once, thus differentiating itself from practices that focus on the singular point of view of the traveler or protagonist. \n\nGeocriticism also assumes a literary referentiality between world and text, or, in other words, between the referent and its representation. By questioning the relations between a given space's nature and its actually existing condition, the geocritical approach allows for a study of fiction that points also to the theory of possible worlds, such as may be seen in the work on third space by the American geographer Edward Soja (\"Thirdspace\"). Tally's book \"Spatiality\", an introduction to spatiality studies in literature and critical theory, includes a chapter on geocriticism.\n\nGeocriticism frequently involves the study of places described in the literature by various authors, but it can also study the effects of literary representations of a given space. An example of the range of geocritical practices can be found in Tally's collection \"Geocritical Explorations: Space, Place, and Mapping in Literary and Cultural Studies\".\n\nGeocriticism derives some of its practices from precursors whose theoretical work helped establish space as a valid topic for literary analysis. For example, in \"The Poetics of Space\" and elsewhere, Gaston Bachelard studied literary works to develop a typology of places according to their connotations. Maurice Blanchot's writings have legitimized the idea of literary space, an imaginary place for the creation of the work of literature. One might also look at the developments of cultural studies and especially postcolonial studies, such as Raymond Williams's \"The Country and the City\" or Edward Said's \"Culture and Imperialism\", which employ what Said has called a \"geographical inquiry into historical experience.\" Fredric Jameson's concept of cognitive mapping and his theoretical engagement with the postmodern condition also highlight the importance of spatial representation and aesthetic productions, including literature, film, architecture, and design. In \"The Atlas of European Novel, 1800-1900\", Franco Moretti has examined the diffusion of literary spaces in Europe, focusing on the complex relationship between the text and space. Moretti has also promulgated a theory of literary history, or literary geography, that would use maps to bring to light new connections between the texts studied and their social spaces. And, in his study of Herman Melville's literary cartography, Robert Tally has offered a geocritical approach to certain texts. \n\nGeocriticism has intellectual and methodological affiliations with such fields as Literature and the Environment or ecocriticism, regional literature, urban studies, sociological and philosophical approaches to literature, and utopian studies.\n\nNotes\nFurther reading\n"}
{"id": "925715", "url": "https://en.wikipedia.org/wiki?curid=925715", "title": "Geographic Data Files", "text": "Geographic Data Files\n\nGeographic Data Files (GDF) is an interchange file format for geographic data.\nIn contrast with generic GIS formats, GDF provides detailed rules for data capture and representation, and an extensive catalog of standard features, attributes and relationships. The most recent extension expanded applicability further towards pedestrian navigation, 3-D map rendering, and advanced driver-assistance systems (ADAS).\n\nGDF is commonly used for data interchange in many industries such as automotive navigation systems, fleet management, dispatch management, road traffic analysis, , and automatic vehicle location.\n\nOriginated as a flat plain-text file, GDF is not intended to be used directly for any large scale geographic application and normally requires conversion into a more efficient format. Consumability has been increased with most-recent developments for XML and SQL renditions.\n\nThe maps in GDF format are provided by many map vendors such as HERE, TomTom, Mapscape BV, GeoSmart, Automotive Navigation Data, AutoNavi and NavInfo.\n\nGDF is an international standard that is used to model, describe and transfer road networks and other geographic data.\n\nThe standard was initially drawn up by CEN in co-operation with digital map providers, automotive and electronic equipment manufacturers. The outcome of these standardisation efforts (CEN GDF 3.0, or ENV14825:1996) has formed the major input to a global standard created by ISO/TC204 Sub Working group 3:\n\nHowever, despite the existence of an ISO GDF standard, the nature of model abstractions as well as semantic interpretations and proprietary content extensions lead to interoperability issues between flavors of GDF map products from different vendors. In practice the GDF files are not fully interchangeable due to vendor specific extensions. To this end, GDF5.0 provides major improvements in terms of extended meta data and flags for signalling implementation choices.\n\nThe specifications of GDF5.0 were developed and compiled between 2001 and 2008, involving experts from Australia, Canada, Czech Republic, France, Germany, Japan, Republic of Korea, the Netherlands, and the United States of America. Extensive activities towards harmonization with ISO/TC211 standards were undertaken. GDF 5.0 was published in July 2011.\n\nMajor GDF5.0 enhancements include UML model migration & refinements; harmonization with linear referencing and geo-spatial web standards; support for 3-D content and time coordinates; comprehensive character set and phonetic representations; and new XML and SQL based delivery formats.\n\nBy the late 1980s, producers and users of digital road map data became increasingly aware of the need for a common data interchange standard. Lack of such a standard was seen as an impediment to the commercial growth and success of industries using such data. Before the advent of the Intelligent Transport Systems (ITS) industry, development of spatial data interchange standards was done mostly on a regional basis and not designed for the specialised requirements of road transport-related applications.\n\nIn the 1990s, the GDF standard was instrumental in enabling the European business-to-business (B2B) market for in-vehicle navigation in that it provided interoperability for exchanging digital map data between map manufacturers and navigation system integrators. The GDF specifications provided a base for both the capturing of geographic content and the exchanging of it. Its original design foresaw a powerful, application-independent model, while its initial rendition as a standard specifically addressed the requirements for the richness of navigable map databases. Since then, GDF has evolved in terms of data modelling capabilities, broadened international applicability, expanded geographic domains, and diversified exchange formats. As a result, GDF covers a wide range of application domains and has been adapted to many geo-spatial technologies.\n\n\n"}
{"id": "50569433", "url": "https://en.wikipedia.org/wiki?curid=50569433", "title": "Geospatial Information Regulation Bill", "text": "Geospatial Information Regulation Bill\n\nThe Geospatial Information Regulation Bill, 2016 was introduced in Parliament of India in 2016.\n\nThe Geospatial Information Regulation Bill, 2016 was introduced in Parliament of India in 2016.\n"}
{"id": "711728", "url": "https://en.wikipedia.org/wiki?curid=711728", "title": "Governmentality", "text": "Governmentality\n\nGovernmentality is a concept first developed by the French philosopher Michel Foucault in the later years of his life, roughly between 1977 and his death in 1984, particularly in his lectures at the Collège de France during this time.\n\nThe concept has been elaborated further from an \"Anglo-Neo Foucauldian\" perspective in the social sciences, especially by authors such as Peter Miller, Nikolas Rose, and Mitchell Dean. Governmentality can be understood as:\n\nGovernmentality may also be understood as:\n\nThis term was thought by some commentators to be made by the \"...linking of governing (\"gouverner\") and modes of thought (\"mentalité\")\". In fact, it was not coined by uniting words \"gouvernement\" and \"mentalité\", but simply by making \"gouvernement\" into \"gouvernementalité\" just like \"musical\" into \"musicalité\" [i.e. government + -al- \"adjective\" + -ité \"abstract noun\"] (see Michel Senellart's \"Course Context\" in Foucault's \"Security, territory, population\" lectures). To fully understand this concept, it is important to realize that in this case, Foucault does not only use the standard, strictly political definition of \"governing\" or government used today, but he also uses the broader definition of governing or government that was employed until the eighteenth century. That is to say, that in this case, for Foucault, \"...'government' also signified problems of self-control, guidance for the family and for children, management of the household, directing the soul, etc.\" In other words, for our purposes, government is \"...the conduct of conduct...\"\n\nIn his lectures at the Collège de France, Foucault often defines governmentality as the \"art of government\" in a wide sense, i.e. with an idea of \"government\" that is not limited to state politics alone, that includes a wide range of control techniques, and that applies to a wide variety of objects, from one's control of the self to the \"biopolitical\" control of populations. In the work of Foucault, this notion is indeed linked to other concepts such as biopolitics and power-knowledge. The genealogical exploration of the modern state as \"problem of government\" does not only deepen Foucault's analyses on sovereignty and biopolitics; it offers an analytics of government which refines both Foucault's theory of power and his understanding of freedom.\n\nThe concept of \"governmentality\" develops a new understanding of power. Foucault encourages us to think of power not only in terms of hierarchical, top-down power of the state. He widens our understanding of power to also include the forms of social control in disciplinary institutions (schools, hospitals, psychiatric institutions, etc.), as well as the forms of knowledge. Power can manifest itself positively by producing knowledge and certain discourses that get internalised by individuals and guide the behaviour of populations. This leads to more efficient forms of social control, as knowledge enables individuals to govern themselves.\n\n\"Governmentality\" applies to a variety of historical periods and to different specific power regimes. However, it is often used (by other scholars and by Foucault himself) in reference to \"neoliberal governmentality\", i.e. to a type of governmentality that characterizes advanced liberal democracies. In this case, the notion of governmentality refers to societies where power is de-centered and its members play an active role in their own self-government, e.g. as posited in neoliberalism. Because of its active role, individuals need to be regulated from 'inside'. A particular form of governmentality is characterized by a certain form of knowledge (\"savoir\" in French). In the case of neoliberal governmentality (a kind of governmentality based on the predominance of market mechanisms and of the restriction of the action of the state) the knowledge produced allows the construction of auto-regulated or auto-correcting selves.\n\nIn his lecture titled Governmentality, Foucault gives us a definition of governmentality:\nAs Foucault's explicit definition is rather broad, perhaps further examination of this definition would be useful.\n\nWe shall begin with a closer inspection of the first part of Foucault's definition of governmentality:\n\nThis strand of the three-part definition states that governmentality is, in other words, all of the components that make up a government that has as its end the maintenance of a well-ordered and happy society (population). The government's means to this end is its \"apparatuses of security,\" that is to say, the techniques it uses to provide this society a feeling of economic, political, and cultural well-being. The government achieves these ends by enacting \"political economy,\" and in this case, the meaning of economy is the older definition of the term, that is to say, \"economy at the level of the entire state, which means exercising towards its inhabitants, and the wealth and behavior of each and all, a form of surveillance and control as attentive as that of the head of a family over his household and his goods\". Thus, we see that this first part of the definition states that governmentality is a government with specific ends, means to these ends, and particular practices that should lead to these ends.\n\nThe second part of Foucault's definition (the \"resulting, on the one hand, in formation of a whole series of specific governmental apparatuses, and, on the other, in the development of a whole complex of savoirs\") presents governmentality as the long, slow development of Western governments which eventually took over from forms of governance like sovereignty and discipline into what it is today: bureaucracies and the typical methods by which they operate.\n\nThe next and last part of Foucault's definition of governmentality can be restated as the evolution from the Medieval state, which maintained its territory and an ordered society within this territory through a blunt practice of simply imposing its laws upon its subjects, to the early Renaissance state, which became more concerned with the \"disposing of things\", and so began to employ strategies and tactics to maintain a content and thus stable society, or in other words to \"render a society governable\".\n\nThus, if one takes these three definitions together, governmentality may be defined as the process through which a form of government with specific ends (a happy and stable society), means to these ends (\"apparatuses of security\"), and with a particular type of knowledge (\"political economy\"), to achieve these ends, evolved from a medieval state of justice to a modern administrative state with complex bureaucracies.\n\nThe concept of governmentality segues from Foucault's ethical, political and historical thoughts from the late 1970s to the early 1980s. His most widely known formulation of this notion is his lecture entitled \"Security, territory and population\" (1978). A deeper and richer reflection on the notion of governmentality is provided in Foucault's course on \"The Birth of Biopolitics\" at the Collège de France in 1978-1979. The course was first published in French in 2004 as \"Naissance de la biopolitique: Cours au Collège de France (1978-1979)\" (Paris: Gallimard & Seuil). This notion is also part of a wider analysis on the topic of disciplinary institutions, on neoliberalism and the \"Rule of Law\", the \"microphysics of power\" and also on what Foucault called biopolitics. In the second and third volumes of \"The History of Sexuality\", namely, \"The Use of Pleasure\" (1984) and \"The Care of the Self\" (1984), and in his lecture on \"Technologies of the Self\" (1982), Foucault elaborated a distinction between subjectivation and forms of subjectification by exploring how selves were fashioned and then lived in ways which were both heteronomously and autonomously determined. Also, in a series of lectures and articles, including \"The Birth of Biopolitics\" (1979), \"\"Omnes et Singulatim\": Towards a Criticism of Political Reason\" (1979), \"The Subject and Power\" (1982) and \"What is Enlightenment?\" (1984), he posed questions about the nature of contemporary social orders, the conceptualization of power, human freedom and the limits, possibilities and sources of human actions, etc. that were linked to his understanding of the notion of \"governmentality\".\n\nThe notion of governmentality (not to confuse with governance) gained attention in the English-speaking academic world mainly through the edited book \"The Foucault Effect\" (1991), which contained a series of essays on the notion of governmentality, together with a translation of Foucault's 1978 short text on \"gouvernementalité\".\n\nHunt and Wickham, in their work \"Foucault and Law\" [1994] begin the section on governmentality with a very basic definition derived from Foucault's work. They state, \"governmentality is the dramatic expansion in the scope of government, featuring an increase in the number and size of the governmental calculation mechanisms\" [1994:76]. In other words, governmentality describes the new form of governing that arose in the mid-eighteenth century that was closely allied with the creation and growth of the modern bureaucracies. In giving this definition, Hunt and Wickham conceive of the term as consisting of two parts 'governmental' and '–ity' - governmental meaning pertaining to the government of a country; and the suffix –ity meaning the study of. They acknowledge that this definition lacks some of Foucault's finer nuances and try to redress this by explaining some more of Foucault's ideas, including reason of state, the problem of population, modern political economy, liberal securitisation, and the emergence of the human sciences\" [1994:77].\n\nKerr's approach to the term is more complex. He conceives of the term as an abbreviation of \"governmental rationality\" [1999:174]. In other words, it is a way of thinking about the government and the practices of the government. To him it is not \"a zone of critical-revolutionary study, but one that conceptually reproduces capitalist rule\" [1999:197] by asserting that some form of government (and power) will always be necessary to control and constitute society. By defining governmentality only in terms of the state, Kerr fails to take account of other forms of governance and the idea of mentalities of government in this broader sense.\n\nDean's understanding of the term incorporates both other forms of governance and the idea of mentalities of government, as well as Hunt and Wickham's, and Kerr's approaches to the term. In line with Hunt and Wickham's approach, Dean acknowledges that in a very narrow sense, governmentality can be used to describe the emergence of a government that saw that the object of governing power was to optimise, use and foster living individuals as members of a population [1999:19]. He also includes the idea of government rationalities, seeing governmentality as one way of looking at the practices of government. In addition to the above, he sees government as anything to do with conducting oneself or others. This is evident in his description of the word in his glossary: \"Governmentality: How we think about governing others and ourselves in a wide variety of contexts...\" [1999:212]. This reflects that the term government to Foucault meant not so much the political or administrative structures of the modern state as the way in which the conduct of individuals or of groups may be directed. To analyse government is to analyse those mechanisms that try to shape, sculpt, mobilise and work through the choices, desires, aspirations, needs, wants and lifestyles of individuals and groups [Dean, 1999:12].\n\nDean's main contribution to the definition of the term, however, comes from the way he breaks the term up into 'govern' 'mentality', or mentalities of governing—mentality being a mental disposition or outlook. This means that the concept of governmentality is not just a tool for thinking about government and governing but also incorporates how and what people who are governed think about the way they are governed. He defines thinking as a \"collective activity\" [1999:16], that is, the sum of the knowledge, beliefs and opinions held by those who are governed. He also raises the point that a mentality is not usually \"examined by those who inhabit it\" [1999:16]. This raises the interesting point that those who are governed may not understand the unnaturalness of both the way they live and the fact that they take this way of life for granted—that the same activity in which they engage in \"can be regarded as a different form of practice depending on the mentalities that invest it\" [1999:17]. Dean highlights another important feature of the concept of governmentality—its reflexivity. He explains:\n\"On the one hand, we govern others and ourselves according to what we take to be true about who we are, what aspects of our existence should be worked upon, how, with what means, and to what ends. On the other hand, the ways in which we govern and conduct ourselves give rise to different ways of producing truth. [1999:18]\n\nBy drawing attention to the 'how and why', Dean connects \"technologies of power\" [Lemke, 2001:191] to the concept of governmentality. According to Dean any definition of governmentality should incorporate all of Foucault's intended ideas. A complete definition of the term governmentality must include not only government in terms of the state, but government in terms of any \"conduct of conduct\" [Dean, 1999:10]. It must incorporate the idea of mentalities and the associations that go with that concept: that it is an attitude towards something, and that it is not usually understood \"from within its own perspective\" [1999:16], and that these mentalities are collective and part of a society's culture. It must also include an understanding of the ways in which conduct is governed, not just by governments, but also by ourselves and others.\n\nThe semantic linking of governing and mentalities in governmentality indicates that it is not possible to study technologies of power without an analysis of the mentality of rule underpinning them. The practice of going to the gym, expounded below, is a useful example because it shows how our choices, desires, aspirations, needs, wants and lifestyles have been mobilised and shaped by various technologies of power.\n\nA mentality of rule is any relatively systematic way of thinking about government. It delineates a discursive field in which the exercise of power is 'rationalised' [Lemke, 2001:191]. Thus Neo-liberalism is a mentality of rule because it represents a method of rationalising the exercise of government, a rationalisation that obeys the internal rule of maximum economy [Foucault, 1997:74]. Fukuyama [in Rose, 1999: 63] writes \"a liberal State is ultimately a limited State, with governmental activity strictly bounded by the sphere of individual liberty\". However, only a certain type of liberty, a certain way of understanding and exercising freedom is compatible with Neo-liberalism. If Neo-liberalist government is to fully realize its goals, individuals must come to recognize and act upon themselves as both free and responsible [Rose, 1999:68]. Thus Neo-liberalism must work to create the social reality that it proposes already exists. For as Lemke states, a mentality of government \"is not pure, neutral knowledge that simply re-presents the governing reality\" [Lemke, 2001:191] instead, Neo-liberalism constitutes an attempt to link a reduction in state welfare services and security systems to the increasing call for subjects to become free, enterprising, autonomous individuals. It can then begin to govern its subjects, not through intrusive state bureaucracies backed with legal powers, the imposition of moral standards under a religious mandate, but through structuring the possible field of action in which they govern themselves, to govern them through their freedom. Through the transformation of subjects with duties and obligations, into individuals, with rights and freedoms, modern individuals are not merely 'free to choose' but obliged to be free, \"to understand and enact their lives in terms of choice\" [Rose, 1999:87]. This freedom is a different freedom to that offered in the past. It is a freedom to realize our potential and our dreams through reshaping the way in which we conduct our lives.\n\nCartographic mapping has historically been a key strategy of governmentality. Harley, drawing on Foucault, affirms that State-produced maps \"extend and reinforce the legal statutes, territorial imperatives, and values stemming from the exercise of political power\". Typically, State-led mapping conforms to Bentham's concept of a panopticon, in which 'the one views the many'. From a Foucauldian vantage point, this was the blueprint for disciplinary power.\n\nThrough processes of neoliberalism, the State has \"hollowed out\" some of its cartographic responsibilities and delegated power to individuals who are at a lower geographical scale. 'People's cartography' is believed to deliver a more democratic spatial governance than traditional top-down State-distribution of cartographic knowledge. Thus subverting Harley's theory that mapping is uniquely a source of power for the powerful. Joyce challenges Foucauldian notions of Panopticism, contending that neoliberal governmentality is more adequately conceptualised by an omniopticon - 'the many surveilling the many'. Collaborative mapping initiatives utilising GPS technology are arguably omniopticons, with the ability to reverse the panoptic gaze.\n\nThrough our freedom, particular self-governing capabilities can be installed in order to bring our own ways of conducting and evaluating ourselves into alignment with political objectives [Rose, 1996:155]. These capabilities are enterprise and autonomy. Enterprise here designates an array of rules for the conduct of one's everyday existence: energy, initiative, ambition, calculation, and personal responsibility. The enterprising self will make an enterprise of its life, seek to maximize its own human capital, project itself a future, and seek to shape life in order to become what it wishes to be. The enterprising self is thus both an active self and a calculating self, a self that calculates about itself and that acts upon itself in order to better itself [Rose, 1996:154]. Autonomy is about taking control of our undertakings, defining our goals, and planning to achieve our needs through our own powers [Rose, 1996:159]. The autonomy of the self is thus not the eternal antithesis of political power, but one of the objectives and instruments of modern mentalities for the conduct of conduct [Rose, 1996:155].\n\nThese three qualities: freedom, enterprise and autonomy are embodied in the practice of going to the gym. It is our choice to go the gym, our choice which gym to go to. By going to the gym we are working on ourselves, on our body shape and our physical fitness. We are giving ourselves qualities to help us perform better than others in life, whether to attract a better mate than others, or to be able to work more efficiently, more effectively and for longer without running out of steam to give us an advantage over our competitors. When we go to the gym, we go through our own discipline, on our own timetable, to reach our own goals. We design and act out our routine by ourselves. We do not need the ideas or support of a team, it is our self that makes it possible. The practice of going to the gym, of being free, enterprising, autonomous, is imbued with particular technologies of power.\n\nTechnologies of power are those \"technologies imbued with aspirations for the shaping of conduct in the hope of producing certain desired effects and averting certain undesired ones\" [Rose, 1999:52]. The two main groups of technologies of power are technologies of the self, and technologies of the market. Foucault defined technologies of the self as techniques that allow individuals to effect by their own means a certain number of operations on their own bodies, minds, souls, and lifestyle, so as to transform themselves in order to attain a certain state of happiness, and quality of life. Technologies of the market are those technologies based around the buying and selling of goods that enable us to define who we are, or want to be. These two technologies are not always completely distinct, as both borrow bits of each other from time to time.\n\nTechnologies of the self refer to the practices and strategies by which individuals represent to themselves their own ethical self-understanding. One of the main features of technologies of self is that of expertise. Expertise has three important aspects. First, its grounding of authority in a claim to scientificity and objectivity creates distance between self-regulation and the state that is necessary with liberal democracies. Second, expertise can \"mobilise and be mobilised within political argument in distinctive ways, producing a new relationship between knowledge and government. Expertise comes to be accorded a particular role in the formulation of programs of government and in the technologies that seek to give them effect\" [Rose, 1996:156]. Third, expertise operates through a relationship with the self-regulating abilities of individuals. The plausibility inherent in a claim to scientificity binds \"subjectivity to truth and subjects to experts\" [Rose, 1996:156]. Expertise works through a logic of choice, through a transformation of the ways in which individuals constitute themselves, through \"inculcating desires for self-development that expertise itself can guide and through claims to be able to allay the anxieties generated when the actuality of life fails to live up to its image [Rose, 1999:88].\n\nThe technologies of the self involved in the practice of, for example, going to the gym are the: technology of responsibilisation, technology of healthism, technology of normalisation and technology of self-esteem.\n\nIn line with its desire to reduce the scope of government (e.g. welfare) Neo-liberalism characteristically develops indirect techniques for leading and controlling individuals without being responsible for them. The main mechanism is through the technology of responsibilisation. This entails subjects becoming responsibilised by making them see social risks such as illness, unemployment, poverty, etc. not as the responsibility of the state, but actually lying in the domain for which the individual is responsible and transforming it into a problem of 'self-care' [Lemke, 2001:201] and of 'consumption'. The practice of going to the gym can be seen as a result of responsibilisation, our responsibility to remain free of illness so as to be able to work and to care for our dependants (children, elderly parents etc.) This technology somewhat overlaps with the technology of healthism.\n\nHealthism links the \"public objectives for the good health and good order of the social body with the desire of individuals for health and well-being\" [Rose, 1999:74]. Healthy bodies and hygienic homes may still be objectives of the state, but it no longer seeks to discipline, instruct, moralise or threaten us into compliance. Rather \"individuals are addressed on the assumption that they want to be healthy and enjoined to freely seek out the ways of living most likely to promote their own health\" [Rose, 1999:86-87] such as going to the gym. However while the technology of responsibilisation may be argued to be a calculated technique of the state, the wave of Healthism is less likely to be a consequence of state planning, but arising out of the newer social sciences such as nutrition and human movement. Healthism assigns, as do most technologies of the self, a key role to experts. For it is experts who can tell us how to conduct ourselves in terms of safe, precise techniques to improve cardiovascular fitness, muscle strength, and overall health. The borrowing from technologies of the market by technologies of the self can be clearly seen in the area of healthism. The idea of health, the goal of being healthy, the joys brought by good health and the ways of achieving it are advertised to us in the same manner as goods and services are marketed by sales people. By adhering to the principles of healthism, our personal goals are aligned with political goals and we are thus rendered governable.\n\nAnother technology of power arising from the social sciences is that of normalisation. The technology of norms was given a push by the new methods of measuring population. A norm is that \"which is socially worthy, statistically average, scientifically healthy and personally desirable\". The important aspect of normality, is that while the norm is natural, those who wish to achieve normality will do so by working on themselves, controlling their impulses in everyday conduct and habits, and inculcating norms of conduct into their children, under the guidance of others. Norms are enforced through the calculated administration of shame. Shame entails an anxiety over the exterior behaviour and appearance of the self, linked to an injunction to care for oneself in the name of achieving quality of life [Rose, 1999:73]. Norms are usually aligned with political goals, thus the norm would be fit, virile, energetic individuals, able to work, earn money, and spend it and thus sustain the economy. For instance, the practice of going to the gym allows one to achieve this 'normality'. Through shame we are governed into conforming with the goals of Neo-liberalism.\n\nSelf-esteem is a practical and productive technology linked to the technology of norms, which produces of certain kinds of selves. Self-esteem is a technology in the sense that it is a specialised knowledge of how to esteem ourselves to estimate, calculate, measure, evaluate, discipline, and to judge our selves. The 'self-esteem' approach considers a wide variety of social problems to have their source in a lack of self-esteem on the part of the persons concerned. 'Self-esteem' thus has much more to do with self-assessment than with self-respect, as the self continuously has to be measured, judged and disciplined in order to gear personal 'empowerment' to collective yardsticks. These collective yardsticks are determined by the norms previously discussed. Self-esteem is a technology of self for \"evaluating and acting upon ourselves so that the police, the guards and the doctors do not have to do so\". By taking up the goal of self-esteem, we allow ourselves to be governable from a distance. The technology of self-esteem and other similar psychological technologies also borrow from technologies of the market, namely consumption. A huge variety of self-help books, tapes, videos and other paraphernalia are available for purchase by the individual.\n\nThe technologies of the market that underlie the practice of going to the gym can be described as the technology of desire, and the technology of identity through consumption. The technology of desire is a mechanism that induces in us desires that we work to satisfy. Marketers create wants and artificial needs in us through advertising goods, experiences and lifestyles that are tempting to us. These advertisements seek to convey the sense of individual satisfaction brought about by the purchase or use of this product. We come to desire these things and thus act in a manner that allows us to achieve these things, whether by working harder and earning more money or by employing technologies of the self to shape our lifestyle to the manner we desire . The borrowing of technologies of the self by technologies of the market extends even further in this case. Marketers use the knowledge created by psyche- discourses, especially psychological characteristics as the basis of their market segmentation. This allows them to appeal more effectively to each individual. Thus we are governed into purchasing commodities through our desire.\n\nThe technology of identity through consumption utilises the power of goods to shape identities. Each commodity is imbued with a particular meaning, which is reflected upon those who purchase it, illuminating the kind of person they are, or want to be. Consumption is portrayed as placing an individual within a certain form of life. The technology of identity through consumption can be seen in the choices that face the gym attendee. To go to an expensive gym because it demonstrates wealth/success or to go to a moderately priced gym so as to appear economical. The range of gym wear is extensive. Brand name to portray the abilities portrayed in its advertising, expensive to portray commitment, or cheap to portray your unconcern for other people's opinions. All of these choices of consumption are used to communicate our identity to others, and thus we are governed by marketers into choosing those products that identify with our identity.\n\nThese technologies of the market and of the self are the particular mechanisms whereby individuals are induced into becoming free, enterprising individuals who govern themselves and thus need only limited direct governance by the state. The implementation of these technologies is greatly assisted by experts from the social sciences. These experts operate a regime of the self, where success in life depends on our continual exercise of freedom, and where our life is understood, not in terms of fate or social status, but in terms of our success or failure in acquiring the skills and making the choices to actualise ourself. If we engage in the practice of going to the gym, we are undertaking an exercise in self-government. We do so by drawing upon certain forms of knowledge and expertise provided by gym instructors, health professionals, of the purveyors of the latest fitness fad. Depending on why we go to the gym, we may calculate number of calories burned, heart-rate, or muscle size. In all cases, we attend the gym for a specific set of reasons underpinned by the various technologies of the self and the market. The part of ourselves we seek to work upon, the means by which we do so, and who we hope to become, all vary according to the nature of the technology of power by which we are motivated [Dean, 1999:17]. All of these various reasons and technologies are underpinned by the mentality of government that seeks to transform us into a free, enterprising, autonomous individual: Neo-liberalism. Furthermore, Neo-liberalism seeks to create and disseminate definitions of freedom, autonomy and what it means to be enterprising that re-create forms of behavior amenable to neo-liberal goals.\n\nEcogovernmentality (or eco-governmentality) is the application of Foucault's concepts of biopower and governmentality to the analysis of the regulation of social interactions with the natural world. Timothy W. Luke theorized this as environmentality and green governmentality. Ecogovernmentality began in the mid-1990s with a small body of theorists (Luke, Darier, and Rutherford) the literature on ecogovernmentality grew as a response to the perceived lack of Foucauldian analysis of environmentalism and in environmental studies.\n\nFollowing Michel Foucault, writing on ecogovernmentality focuses on how government agencies, in combination with producers of expert knowledge, construct \"The Environment.\" This construction is viewed both in terms of the creation of an object of knowledge and a sphere within which certain types of intervention and management are created and deployed to further the government's larger aim of managing the lives of its constituents. This governmental management is dependent on the dissemination and internalization of knowledge/power among individual actors. This creates a decentered network of self-regulating elements whose interests become integrated with those of the State.\n\nAccording to Foucault, there are several instances where the Western, \"liberal art of government\" enters into a period of crisis, where the logic of ensuring freedom (which was defined against the background of risk or danger) necessitates actions \"which potentially risk producing exactly the opposite.\"\n\nThe inherently contradictory logics that lead to such contradictions are identified by Foucault as:\n\n1. Liberalism depends on the socialization of individuals to fear the constant presence of danger, e.g., public campaigns advocating savings banks, public hygiene, and disease prevention, the development of detective novels as a genre and of news stories of crime, and sexual anxieties surrounding \"degeneration.\"\n\n2. Liberal freedom requires disciplinary techniques that manage the individual's behaviour and everyday life so as to ensure productivity and the increase in profit through efficient labour, e.g., Bentham's Panopticon surveillance system. Liberalism claims to supervise the natural mechanisms of behaviour and production, but must intervene when it notices \"irregularities.\"\n\n3. Liberalism must force individuals to be free: control and intervention becomes the entire basis of freedom. Freedom must ultimately be manufactured by control rather than simply \"counterweighted\" by it.\n\nExamples of this contradictory logic which Foucault cites are the policies of the Keynesian welfare state under F.D. Roosevelt, the thought of the German liberals in the Freiburg school, and the thought of American libertarian economists such as the Chicago School which attempt to free individuals from the lack of freedom perceived to exist under socialism and fascism, but did so by using state interventionist models.\n\nThese governmental crises may be triggered by phenomena such as a discursive concern with increasing economic capital costs for the exercise of freedom, e.g., prices for purchasing resources, the need for excessive state coercion and interventionism to protect market freedoms, e.g., anti-trust and anti-monopoly legislation that leads to a \"legal strait-jacket\" for the state, local protests rejecting the disciplinary mechanisms of the market society and state. and finally, the destructive and wasteful effects of ineffective mechanisms for producing freedom.\n\nScholars have recently suggested that the concept of governmentality may be useful in explaining the operation of evidence-based health care and the internalization of clinical guidelines relating to best practice for patient populations, such as those developed by the American Agency for Health Care Research and Quality and the British National Institute for Health and Clinical Excellence (NICE). Recent research by Fischer and colleagues at the University of Oxford has renewed interest in Foucault's exploration of potential resistance to governmentality, and its application to health care, drawing on Foucault's recently published final lectures at the College de France.\n\nJeffreys and Sigley (2009) highlight that governmentality studies have focused on advanced liberal democracies, and preclude considerations of non-liberal forms of governmentality in both western and non-western contexts. Recent studies have broken new ground by applying Foucault's concept of governmentality to non-western and non-liberal settings, such as China. Jeffreys (2009) for example provides a collection of essay on China's approach to governance, development, education, the environment, community, religion, and sexual health where the notion of 'Chinese governmentally' is based not on the notion of 'freedom and liberty' as in the western tradition but rather, on a distinct rational approach to planning and administration. Such new studies thus use Foucault's Governmentalities to outline the nature of shifts in governance and contribute to emerging studies of governmentality in non-western contexts.\n\n\nhttp://www.inderscience.com/info/inarticle.php?artid=67421\nhttps://eurasianpublications.com/Eurasian-Journal-of-Economics-and-Finance/Vol.4-No.2-2016.aspx\nhttps://eurasianpublications.com/Eurasian-Journal-of-Economics-and-Finance/Vol.4-No.2-2016.aspx\n"}
{"id": "20290597", "url": "https://en.wikipedia.org/wiki?curid=20290597", "title": "Grassed waterway", "text": "Grassed waterway\n\nA grassed waterway consists in a to 48-metre-wide (157 ft) native grassland strip of green belt. It is generally installed in the thalweg, the deepest continuous line along a valley or watercourse, of a cultivated dry valley in order to control erosion. A study carried out on a grassed waterway during 8 years in Bavaria showed that it can lead to several other types of positive impacts, e.g. on biodiversity.\n\nConfusion between \"grassed waterway\" and \"vegetative filter strips\" should be avoided. The latter are generally narrower (only a few metres wide) and rather installed along rivers as well as along or within cultivated fields. However, buffer strip can be a synonym, with shrubs and trees added to the plant component, as does a riparian zone.\n\nRunoff generated on cropland during storms or long winter rains concentrates in the thalweg where it can lead to rill or gully erosion. \n\nRills and gullies further concentrate runoff and speed up its transfer, which can worsen damage occurring downstream. This can result in a muddy flood. \n\nIn this context, a grassed waterway allows increasing soil cohesion and roughness. It also prevents the formation of rills and gullies. Furthermore, it can slow down runoff and allow its re-infiltration during long winter rains. In contrast, its infiltration capacity is generally not sufficient to reinfiltrate runoff produced by heavy spring and summer storms. It can therefore be useful to combine it with extra measures, like the installation of earthen dams across the grassed waterway, in order to buffer runoff temporarily.\n\n"}
{"id": "23499524", "url": "https://en.wikipedia.org/wiki?curid=23499524", "title": "Hansen's problem", "text": "Hansen's problem\n\nHansen's problem is a problem in planar surveying, named after the astronomer Peter Andreas Hansen (1795–1874), who worked on the geodetic survey of Denmark. There are two known points \"A\" and \"B\", and two unknown points \"P\" and \"P\". From \"P\" and \"P\" an observer measures the angles made by the lines of sight to each of the other three points. The problem is to find the positions of \"P\" and \"P\". See figure; the angles measured are (\"α\", \"β\", \"α\", \"β\").\n\nSince it involves observations of angles made at unknown points, the problem is an example of resection (as opposed to intersection).\n\nDefine the following angles: \n\"γ\" = \"P\"\"AP\", \"δ\" = \"P\"\"BP\", \"φ\" = \"P\"\"AB\", \"ψ\" = \"P\"\"BA\".\nAs a first step we will solve for \"φ\" and \"ψ\".\nThe sum of these two unknown angles is equal to the sum of \"β\" and \"β\", yielding the equation\n\nA second equation can be found more laboriously, as follows. The law of sines yields\n\nCombining these, we get\n\nEntirely analogous reasoning on the other side yields\n\nSetting these two equal gives\n\nUsing a known trigonometric identity this ratio of sines can be expressed as the tangent of an angle difference:\n\nThis is the second equation we need. Once we solve the two equations for the two unknowns formula_8 and formula_9, we can use either of the two expressions above for formula_10 to find \"P\"\"P\" since \"AB\" is known. We can then find all the other segments using the law of sines.\n\nWe are given four angles (\"α\", \"β\", \"α\", \"β\") and the distance \"AB\". The calculation proceeds as follows:\n\n\n"}
{"id": "27782581", "url": "https://en.wikipedia.org/wiki?curid=27782581", "title": "Horizontal position representation", "text": "Horizontal position representation\n\nA position representation is the parameters used to express a position relative to a reference. Representing position in three dimensions is often done by a Euclidean vector. However, when representing position relative to the Earth it is often more convenient to represent vertical position as altitude or depth, and to use some other parameters to represent horizontal position. There are also several applications where only the horizontal position is of interest, this might e.g. be the case for ships and ground vehicles/cars.\n\nThere are several options for horizontal position representations, each with different properties which makes them appropriate for different applications. Latitude/longitude and UTM are common horizontal position representations.\n\nThe horizontal position has two degrees of freedom, and thus two parameters are sufficient to uniquely describe such a position. However, similarly to the use of Euler angles as a formalism for representing rotations, using only the minimum number of parameters gives singularities, and thus three parameters are required for the horizontal position to avoid this.\n\nThe most common horizontal position representation is latitude and longitude. The parameters are intuitive and well known, and are thus suited for communicating a position to humans, e.g. using a position plot.\n\nHowever, latitude and longitude should be used with care in mathematical expressions (including calculations in computer programs). The main reason is the singularities at the Poles, which makes longitude undefined at these points. Also near the poles the latitude/longitude grid is highly non-linear, and several errors may occur in calculations that are sufficiently accurate on other locations.\nAnother problematic area is the meridian at ±180° longitude, where the longitude has a discontinuity, and hence specific program code must often be written to handle this. An example of the consequences of omitting such code is the crash of the navigation systems of twelve F-22 Raptor fighter aircraft while crossing this meridian.\n\n\"n\"-vector is a three parameter non-singular horizontal position representation that can replace latitude and longitude. Geometrically, it is a unit vector which is normal to the reference ellipsoid. The vector is decomposed in an Earth centered earth fixed coordinate system. It behaves the same at all Earth positions, and it holds the mathematical one-to-one property. The vector formulation makes it possible to use standard 3D vector algebra, and thus \"n\"-vector is well-suited for mathematical calculations, e.g. adding, subtracting, interpolating and averaging positions.\n\nUsing three parameters, \"n\"-vector is inconvenient for communicating a position directly to humans and before showing a position plot, a conversion to latitude/longitude might be needed.\n\nWhen carrying out several calculations within a limited area, a Cartesian coordinate system might be defined with the origin at a specified Earth-fixed position. The origin is often selected at the surface of the reference ellipsoid, with the \"z\"-axis in the vertical direction. Hence (three dimensional) position vectors relative to this coordinate frame will have two horizontal and one vertical parameter. The axes are typically selected as North-East-Down or East-North-Up, and thus this system can be viewed as a linearization of the meridians and parallels.\n\nFor small areas a local coordinate system can be convenient for relative positioning, but with increasing (horizontal) distances, errors will increase and repositioning of the tangent point may be required. The alignment along the north and east directions is not possible at the Poles, and near the Poles these directions might have significant errors (here the linearization is valid only in a very small area).\n\nInstead of one local Cartesian grid, that needs to be repositioned as the position of interest moves, a fixed set of map projections covering the Earth can be defined. UTM is one such system, dividing the Earth into 60 longitude zones (and with UPS covering the Polar regions).\n\nUTM is widely used, and the coordinates approximately corresponds to meters north and east. However, as a set of map-projections it has inherent distortions, and thus most calculations based on UTM will not be exact. The crossing of zones gives additional complexity.\n\nWhen deciding which parameters to use for representing position in a specific application, there are several properties that should be considered. The following table gives a summary of what to consider.\n\n"}
{"id": "6084894", "url": "https://en.wikipedia.org/wiki?curid=6084894", "title": "Human settlement", "text": "Human settlement\n\nIn geography, statistics and archaeology, a settlement, locality or populated place is a community in which people live. The complexity of a settlement can range from a small number of dwellings grouped together to the largest of cities with surrounding urbanized areas. Settlements may include hamlets, villages, towns and cities. A settlement may have known historical properties such as the date or era in which it was first settled, or first settled by particular people.\n\nIn the field of geospatial predictive modeling, settlements are \"a city, town, village or other agglomeration of buildings where people live and work\".\n\nA settlement conventionally includes its constructed facilities such as roads, enclosures, field systems, boundary banks and ditches, ponds, parks and woods, wind and water mills, manor houses, moats and churches.\n\nThe oldest remains that have been found of constructed dwellings are remains of huts that were made of mud and branches around 17,000 BC at the Ohalo site (now underwater) near the edge of the Sea of Galilee. The Natufians built houses, also in the Levant, around 10,000 BC. Remains of settlements such as villages become much more common after the invention of agriculture.\n\nLandscape history studies the form (morphology) of settlements – for example whether they are dispersed or nucleated. Urban morphology can thus be considered a special type of cultural-historical landscape studies. Settlements can be ordered by size, centrality or other factors to define a settlement hierarchy.\n\nGeoscience Australia defines a populated place as \"a named settlement with a population of 200 or more persons\".\n\nThe Committee for Geographical Names in Australasia used the term localities for rural areas, while the Australian Bureau of Statistics uses the term \"urban centres/localities\" for urban areas.\n\nThe Agency for Statistics in Bosnia and Herzegovina uses the term \"populated place\" for rural, and \"municipality\" and \"town\" for urban areas.\n\nThe Bulgarian Government publishes a National Register of Populated places (NRPP).\n\nThe Canadian government uses the term \"populated place\" in the \"Atlas of Canada\", but does not define it.\nStatistics Canada uses the term localities for historical named locations.\n\nThe Croatian Bureau of Statistics records population in units called settlements (\"naselja\").\n\nThe Census Commission of India has a special definition of census towns.\n\nThe Central Statistics Office of the Republic of Ireland has a special definition of census towns.\n\nThere are various types of inhabited localities in Russia.\n\nStatistics Sweden uses the term localities (\"tätort\") for various densely populated places. The common English-language translation is \"urban areas\".\n\nThe UK Department for Communities and Local Government uses the term \"urban settlement\" to denote an urban area when analysing census information. The Registrar General for Scotland defines settlements as groups of one or more contiguous localities, which are determined according to population density and postcode areas. The Scottish settlements are used as one of several factors defining urban areas.\n\nThe United States Geological Survey (USGS) has a Geographic Names Information System that defines three classes of human settlement:\n\nPopulated places may be specifically defined in the context of censuses and be different from general-purpose administrative entities, such as \"place\" as defined by the U.S. Census Bureau or census-designated places.\n\nIn the field of geospatial predictive modeling, settlements are \"a city, town, village, or other agglomeration of buildings where people live and work\".\n\nThe Global Human Settlement Layer (GHSL) framework produces global spatial information about the human presence on the planet over time. This in the form of built up maps, population density maps and settlement maps. This information is generated with evidence-based analytics and knowledge using new spatial data mining technologies. The framework uses heterogeneous data including global archives of fine-scale satellite imagery, census data, and volunteered geographic information. The data is processed fully automatically and generates analytics and knowledge reporting objectively and systematically about the presence of population and built-up infrastructures. The GHSL operates in an open and free data and methods access policy (open input, open method, open output).\n\nThe term \"Abandoned populated places\" is a \"Feature Designation Name\" in databases sourced by the National Geospatial-Intelligence Agency and GeoNames.\n\nPopulated places can be abandoned. Sometimes the structures are still easily accessible, such as in a ghost town, and these may become tourist attractions. Some places that have the appearance of a ghost town, however, may still be defined as populated places by government entities.\n\nA town may become a ghost town because the economic activity that supported it has failed, because of a government action, such as the building of a dam that floods the town, or because of natural or human-caused disasters such as floods, uncontrolled lawlessness, or war. The term is sometimes used to refer to cities, towns, and neighborhoods that are still populated, but significantly less so than in years past.\n\n"}
{"id": "2286680", "url": "https://en.wikipedia.org/wiki?curid=2286680", "title": "International Ice Patrol", "text": "International Ice Patrol\n\nThe International Ice Patrol is an organization with the purpose of monitoring the presence of icebergs in the Atlantic and Arctic Oceans and reporting their movements for safety purposes. It is operated by United States Coast Guard but is funded by the 13 nations interested in trans-Atlantic navigation. As of 2011 the governments contributing to the International Ice Patrol include Belgium, Canada, Denmark, Finland, France, Germany, Greece, Italy, Japan, the Netherlands, Norway, Panama, Poland, Spain, Sweden, the United Kingdom, and the United States of America.\n\nThe organization was established in 1914 in response to the sinking of the RMS \"Titanic\". The primary mission of the Ice Patrol is to alert any seacraft traveling the great circle shipping lanes between Europe and the major ports of the United States and Canada of the presence of any icebergs there. \n\nFrom the earliest journeys into the North Atlantic, icebergs have threatened vessels. A review of the history of navigation prior to the turn of the 20th century shows an impressive number of casualties occurred in the vicinity of the Grand Banks of Newfoundland. For example, \"Lady of the Lake\" sank in 1833 with a loss of 215 people. Between 1882 and 1890, 14 vessels were lost and 40 seriously damaged due to ice. This does not include the large number of whaling and fishing vessels lost or damaged by ice. It took one of the greatest marine disasters of all time to arouse public demand for international cooperative action to deal with this marine hazard. This disaster, the sinking of the on 15 April 1912, was the prime impetus for the establishment of the International Ice Patrol.\n\nOn her maiden voyage from Southampton, England bound for New York, \"Titanic\" collided with an iceberg just south of the tail of the Grand Banks and sank in less than three hours. The loss of life was enormous with more than 1,500 of the 2,224 passengers and crew perishing. \"Titanic\", the brand new ship of the White Star Line, was the largest passenger liner of her time displacing 45,000 tons and capable of sustained speed in excess of . Loss of \"Titanic\" gripped the world with a sobering awareness of an iceberg's potential for tragedy. The sheer dimensions of the \"Titanic\" disaster created sufficient public reaction on both sides of the Atlantic to prod reluctant governments into action, producing the first Safety of Life at Sea (SOLAS) convention in 1914. \n\nAfter the \"Titanic\" disaster, the U.S. Navy assigned the cruisers and to patrol the Grand Banks of Newfoundland for the remainder of 1912. In 1913, the Navy could not spare ships for this purpose, so the Revenue Cutter Service (forerunner of the United States Coast Guard) assumed responsibility, assigning the USRC \"Seneca\" and USRC \"Miami\" to conduct the patrol.\n\nAt the first International Conference on the Safety of Life at Sea, which was convened in London on 12 November 1913, the subject of patrolling the ice regions was thoroughly discussed. The convention signed on 30 January 1914, by the representatives of the world's various maritime powers, provided for the inauguration of an international derelict-destruction, ice observation, and ice patrol service, consisting of vessels, which should patrol the ice regions during the season of iceberg danger and attempt to keep the trans-Atlantic lanes clear of derelicts during the remainder of the year. Due primarily to the experience gained in 1912 and 1913, the United States Government was invited to undertake the management of the triple service, the expense to be defrayed by the 13 nations interested in trans-Atlantic navigation.\n\nThe second International Conference on Safety of Life at Sea was convened in London on 16 April 1929. Eighteen nations participated, all of which signed the final act on 31 May 1929. Because of the fear in the United States Senate as a result of ambiguities in Article 54 dealing with control, the 1929 convention was not ratified by the United States until 7 August 1936, and even then the ratification was accompanied by three reservations. At the same time, Congress enacted legislation on 25 June 1936, formally requiring the Commandant of the Coast Guard to administer the International Ice Observation and Ice Patrol Service (Chap. 807, para. 2 49 USC 1922) and describing in general fashion the manner in which this service was to be performed. With only minor changes, this remains today as the basic Coast Guard authority to operate the International Ice Patrol. Since 1929, there have been three SOLAS conventions (1948, 1960 & 1974). None of these have recommended any basic change affecting the Ice Patrol.\n\nEvery year since 1914, the United States Coast Guard and the International Ice Patrol lay a wreath from a ship or an aircraft at the site of the \"Titanic\" disaster on 15 April. The solemn ceremony is attended by the craft's crew and a dedication statement to the \"Titanic\" and her lost passengers is read.\n\nFrom its inception until the beginning of World War II, the Ice Patrol was conducted from two surface patrol cutters alternating surveillance patrols of the southern ice limits. In 1931 and thereafter a third ship was assigned to Ice Patrol to perform oceanographic observations in the vicinity of the Grand Banks. After World War II, aerial surveillance became the primary ice reconnaissance method with surface patrols phased out except during unusually heavy ice years or extended periods of reduced visibility. Use of the oceanographic vessel continued until 1982, when the Coast Guard's sole remaining oceanographic ship, , was converted to a medium endurance cutter. The aircraft has distinct advantages for ice reconnaissance providing much greater coverage in a relatively short period of time.\n\nFrom 1946 until 1966, the Ice Patrol offices, operations center and reconnaissance aircraft were based at the Coast Guard Air Detachment Argentia, Newfoundland during the ice season.\n\nDue to changing operational commitments and financial constraints the Coast Guard Argentia Air Detachment closed in 1966. Ice Patrol headquarters and operations center moved to Governors Island, New York where they remained until October 1983. \n\nToday the International Ice Patrol is located at the Coast Guard Research and Development Center in New London, Connecticut. The ice reconnaissance detachment, usually composed of eleven aircrew and four ice observers flying in a HC-130 aircraft, continues to work out of Newfoundland.\n\nThe Ice Patrol disseminates information on icebergs and the limit of all known sea ice via radio broadcast from the U.S. Coast Guard Communications Command (COMMCOM) located in Chesapeake, Virginia via Inmarsat Safetynet, and radio facsimile chart. Ice Patrol information is also available via http Internet access. 2002 changes to SOLAS requires ships transiting the region guarded by the Ice Patrol to use the services provided during the ice season.\n\n\n"}
{"id": "205135", "url": "https://en.wikipedia.org/wiki?curid=205135", "title": "Landscape", "text": "Landscape\n\nA landscape is the visible features of an area of land, its landforms and how they integrate with natural or man-made features.\n\nA landscape includes the physical elements of geophysically defined landforms such as (ice-capped) mountains, hills, water bodies such as rivers, lakes, ponds and the sea, living elements of land cover including indigenous vegetation, human elements including different forms of land use, buildings and structures, and transitory elements such as lighting and weather conditions.\n\nCombining both their physical origins and the cultural overlay of human presence, often created over millennia, landscapes reflect a living synthesis of people and place that is vital to local and national identity. The character of a landscape helps define the self-image of the people who inhabit it and a sense of place that differentiates one region from other regions. It is the dynamic backdrop to people’s lives. Landscape can be as varied as farmland, a landscape park, or wilderness.\n\nThe Earth has a vast range of landscapes, including the icy landscapes of polar regions, mountainous landscapes, vast arid desert landscapes, islands and coastal landscapes, densely forested or wooded landscapes including past boreal forests and tropical rainforests, and agricultural landscapes of temperate and tropical regions.\n\nThe activity of modifying the visible features of an area of land is referred to as \"landscaping\".\n\nThere are several definitions of what constitutes a landscape, depending on context. In common usage however, a landscape refers either to all the visible features of an area of land (usually rural), often considered in terms of aesthetic appeal, or to a pictorial representation of an area of countryside, specifically within the genre of landscape painting. When people deliberately improve the aesthetic appearance of a piece of land—by changing contours and vegetation, etc.—it is said to have been landscaped, though the result may not constitute a landscape according to some definitions.\n\nThe word \"landscape\" (\"landscipe\" or \"landscaef\") arrived in England—and therefore into the English language—after the fifth century, following the arrival of the Anglo-Saxons; these terms referred to a system of human-made spaces on the land. The term \"landscape\" emerged around the turn of the sixteenth century to denote a painting whose primary subject matter was natural scenery. \"Land\" (a word from Germanic origin) may be taken in its sense of something to which people belong (as in England being the land of the English). The suffix \"‑scape\" is equivalent to the more common English suffix \"‑ship.\" The roots of \"‑ship\" are etymologically akin to Old English \"sceppan\" or \"scyppan\", meaning \"to shape\". The suffix \"‑schaft\" is related to the verb \"schaffen\", so that \"‑ship\" and \"shape\" are also etymologically linked. The modern form of the word, with its connotations of scenery, appeared in the late sixteenth century when the term \"landschap\" was introduced by Dutch painters who used it to refer to paintings of inland natural or rural scenery. The word \"landscape\", first recorded in 1598, was borrowed from a Dutch painters' term. The popular conception of the \"landscape\" that is reflected in dictionaries conveys both a particular and a general meaning, the particular referring to an area of the Earth's surface and the general being that which can be seen by an observer. An example of this second usage can be found as early as 1662 in the Book of Common Prayer:\n\nThere are several words that are frequently associated with the word landscape:\n\nGeomorphology is the scientific study of the origin and evolution of topographic and bathymetric features created by physical or chemical processes operating at or near Earth's surface. Geomorphologists seek to understand why landscapes look the way they do, to understand landform history and dynamics and to predict changes through a combination of field observations, physical experiments and numerical modeling. Geomorphology is practiced within physical geography, geology, geodesy, engineering geology, archaeology and geotechnical engineering. This broad base of interests contributes to many research styles and interests within the field.\n\nThe surface of Earth is modified by a combination of surface processes that sculpt landscapes, and geologic processes that cause tectonic uplift and subsidence, and shape the coastal geography. Surface processes comprise the action of water, wind, ice, fire, and living things on the surface of the Earth, along with chemical reactions that form soils and alter material properties, the stability and rate of change of topography under the force of gravity, and other factors, such as (in the very recent past) human alteration of the landscape. Many of these factors are strongly mediated by climate. Geologic processes include the uplift of mountain ranges, the growth of volcanoes, isostatic changes in land surface elevation (sometimes in response to surface processes), and the formation of deep sedimentary basins where the surface of Earth drops and is filled with material eroded from other parts of the landscape. The Earth surface and its topography therefore are an intersection of climatic, hydrologic, and biologic action with geologic processes.\n\nDesert, Plain, Taiga, Tundra, Wetland, Mountain, Mountain range, Cliff, Coast, Littoral zone, Glacier, Polar regions of Earth, Shrubland, Forest, Rainforest, Woodland, Jungle, Moors.\n\nLandscape ecology is the science of studying and improving relationships between ecological processes in the environment and particular ecosystems. This is done within a variety of landscape scales, development spatial patterns, and organizational levels of research and policy.\n\nLandscape is a central concept in landscape ecology. It is, however, defined in quite different ways. For example: Carl Troll conceives of landscape not as a mental construct but as an objectively given ‘organic entity’, a ‘‘harmonic individuum of space’’. \nErnst Neef defines landscapes as sections within the uninterrupted earth-wide interconnection of geofactors which are defined as such on the basis of their uniformity in terms of a specific land use, and are thus defined in an anthropocentric and relativistic way.\n\nAccording to Richard Forman and Michael Godron, a landscape is a heterogeneous land area composed of a cluster of interacting ecosystems that is repeated in similar form throughout, whereby they list woods, meadows, marshes and villages as examples of a landscape’s ecosystems, and state that a landscape is an area at least a few kilometres wide. \nJohn A. Wiens opposes the traditional view expounded by Carl Troll, Isaak S. Zonneveld, Zev Naveh, Richard T. T. Forman/Michel Godron and others that landscapes are arenas in which humans interact with their environments on a kilometre-wide scale; instead, he defines 'landscape'—regardless of scale—as \"the template on which spatial patterns influence ecological processes\".\nSome define 'landscape' as an area containing two or more ecosystems in close proximity.\n\nIntegrated landscape management is a way of managing a landscape that brings together multiple stakeholders, who collaborate to integrate policy and practice for their different land use objectives, with the purpose of achieving sustainable landscapes. It recognises that, for example, one river basin can supply water for towns and agriculture, timber and food crops for smallholders and industry, and habitat for biodiversity; the way in which each one of these sectors pursues its goals can have impacts on the others. The intention is to minimise conflict between these different land use objectives and ecosystem services. This approach draws on landscape ecology, as well as many related fields that also seek to integrate different land uses and users, such as watershed management.\n\nProponents of integrated landscape management argue that it is well-suited to address complex global challenges, such as those that are the focus of the Sustainable Development Goals. Integrated landscape management is increasingly taken up at the national, local and international level, for example the UN Environment Programme states that \"UNEP champions the landscape approach de facto as it embodies the main elements of integrated ecosystem management\".\n\nLandscape archaeology or landscape history is the study of the way in which humanity has changed the physical appearance of the environment - both present and past. Landscape generally refers to both natural environments and environments constructed by human beings. Natural landscapes are considered to be environments that have not been altered by humans in any shape or form. Cultural landscapes, on the other hand, are environments that have been altered in some manner by people (including temporary structures and places, such as campsites, that are created by human beings). Among archaeologists, the term landscape can refer to the meanings and alterations people mark onto their surroundings. As such, landscape archaeology is often employed to study the human use of land over extensive periods of time.\nLandscape archaeology can be summed up by Nicole Branton's statement: \n\nThe concept of cultural landscapes can be found in the European tradition of landscape painting. From the 16th century onwards, many European artists painted landscapes in favor of people, diminishing the people in their paintings to figures subsumed within broader, regionally specific landscapes.\n\nThe geographer Otto Schlüter is credited with having first formally used \"cultural landscape\" as an academic term in the early 20th century. In 1908, Schlüter argued that by defining geography as a \"Landschaftskunde\" (landscape science) this would give geography a logical subject matter shared by no other discipline. He defined two forms of landscape: the \"Urlandschaft\" (transl. original landscape) or landscape that existed before major human induced changes and the \"Kulturlandschaft\" (transl. 'cultural landscape') a landscape created by human culture. The major task of geography was to trace the changes in these two landscapes.\"\n\nIt was Carl O. Sauer, a human geographer, who was probably the most influential in promoting and developing the idea of cultural landscapes. Sauer was determined to stress the agency of culture as a force in shaping the visible features of the Earth’s surface in delimited areas. Within his definition, the physical environment retains a central significance, as the medium with and through which human cultures act. His classic definition of a 'cultural landscape' reads as follows:\nThe cultural landscape is fashioned from a natural landscape by a cultural group. Culture is the agent, the natural area is the medium, the cultural landscape is the result.\n\nA cultural landscape, as defined by the World Heritage Committee, is the \"cultural properties [that] represent the combined works of nature and of man.\"\n\nThe World Heritage Committee identifies three categories of cultural landscape, ranging from (i) those landscapes most deliberately 'shaped' by people, through (ii) full range of 'combined' works, to (iii) those least evidently 'shaped' by people (yet highly valued). The three categories extracted from the Committee's Operational Guidelines, are as follows:\n\n\nThe Chinese garden is a landscape garden style which has evolved over three thousand years. It includes both the vast gardens of the Chinese emperors and members of the Imperial Family, built for pleasure and to impress, and the more intimate gardens created by scholars, poets, former government officials, soldiers and merchants, made for reflection and escape from the outside world. They create an idealized miniature landscape, which is meant to express the harmony that should exist between man and nature.\nA typical Chinese garden is enclosed by walls and includes one or more ponds, scholar's rocks, trees and flowers, and an assortment of halls and pavilions within the garden, connected by winding paths and zig-zag galleries. By moving from structure to structure, visitors can view a series of carefully composed scenes, unrolling like a scroll of landscape paintings.\n\nThe English landscape garden, also called English landscape park or simply the 'English garden', is a style of parkland garden intended to look as though it might be a natural landscape, although it may be very extensively re-arranged. It emerged in England in the early 18th century, and spread across Europe, replacing the more formal, symmetrical \"jardin à la française\" of the 17th century as the principal style for large parks and gardens in Europe. The English garden (and later French landscape garden) presented an idealized view of nature. It drew inspiration from paintings of landscapes by Claude Lorraine and Nicolas Poussin, and from the classic Chinese gardens of the East, which had recently been described by European travellers and were realized in the Anglo-Chinese garden, and the philosophy of Jean-Jacques Rousseau (1712 – 1778).\n\nThe English garden usually included a lake, sweeps of gently rolling lawns set against groves of trees, and recreations of classical temples, Gothic ruins, bridges, and other picturesque architecture, designed to recreate an idyllic pastoral landscape. The work of Lancelot \"Capability\" Brown and Humphry Repton was particularly influential. By the end of the 18th century the English garden was being imitated by the French landscape garden, and as far away as St. Petersburg, Russia, in Pavlovsk, the gardens of the future Emperor Paul. It also had a major influence on the form of the public parks and gardens which appeared around the world in the 19th century.\n\nLandscape architecture is a multi-disciplinary field, incorporating aspects of botany, horticulture, the fine arts, architecture, industrial design, geology and the earth sciences, environmental psychology, geography, and ecology. The activities of a landscape architect can range from the creation of public parks and parkways to site planning for campuses and corporate office parks, from the design of residential estates to the design of civil infrastructure and the management of large wilderness areas or reclamation of degraded landscapes such as mines or landfills. Landscape architects work on all types of structures and external space – large or small, urban, suburban and rural, and with \"hard\" (built) and \"soft\" (planted) materials, while paying attention to ecological sustainability.\n\nFor the period before 1800, the history of landscape gardening (later called landscape architecture) is largely that of master planning and garden design for manor houses, palaces and royal properties, religious complexes, and centers of government. An example is the extensive work by André Le Nôtre at Vaux-le-Vicomte and at the Palace of Versailles for King Louis XIV of France. The first person to write of making a landscape was Joseph Addison in 1712. The term landscape architecture was invented by Gilbert Laing Meason in 1828 and was first used as a professional title by Frederick Law Olmsted in 1863. During the latter 19th century, the term landscape architect became used by professional people who designed landscapes. Frederick Law Olmsted used the term 'landscape architecture' as a profession for the first time when designing Central Park, New York City, US. Here the combination of traditional landscape gardening and the emerging field of city planning gave landscape architecture its unique focus. This use of the term landscape architect became established after Frederick Law Olmsted, Jr. and others founded the American Society of Landscape Architects (ASLA) in 1899.\n\nPossibly the earliest landscape literature is found in Australian aboriginal myths (also known as Dreamtime or Dreaming stories, songlines, or Aboriginal oral literature), the stories traditionally performed by Aboriginal peoples within each of the language groups across Australia. All such myths variously tell significant truths within each Aboriginal group's local landscape. They effectively layer the whole of the Australian continent's topography with cultural nuance and deeper meaning, and empower selected audiences with the accumulated wisdom and knowledge of Australian Aboriginal ancestors back to time immemorial.\n\nIn the West pastoral poetry represent the earliest form of landscape literature, though this literary genre presents an idealized landscape peopled by shepherds and shepherdesses, and creates \"an image of a peaceful uncorrupted existence; a kind of prelapsarian world\". The pastoral has its origins in the works of the Greek poet Theocritus (c. 316 - c. 260 BC). The Romantic period poet William Wordsworth created a modern, more realistic form of pastoral with \"Michael, A Pastoral Poem\" (1800).\n\nAn early form of landscape poetry, Shanshui poetry, developed in China during the third and fourth centuries A.D.\n\nTopographical poetry is a genre of poetry that describes, and often praises, a landscape or place. John Denham's 1642 poem \"Cooper's Hill\" established the genre, which peaked in popularity in 18th-century England. Examples of topographical verse date, however, to the Late Classical period, and can be found throughout the Medieval era and during the Renaissance. Though the earliest examples come mostly from continental Europe, the topographical poetry in the tradition originating with Denham concerns itself with the classics, and many of the various types of topographical verse, such as river, ruin, or hilltop poems were established by the early 17th century. Alexander Pope's \"Windsor Forest\" (1713) and John Dyer's \"Grongar Hill' (1762) are two other familiar examples. George Crabbe, the Suffolk regional poet, also wrote topographical poems, as did William Wordsworth, of which \"Lines written a few miles above Tintern Abbey\" is an obvious example. More recently, Matthew Arnold's \"The Scholar Gipsy\" (1853) praises the Oxfordshire countryside, and W. H. Auden's \"In Praise of Limestone\" (1948) uses a limestone landscape as an allegory.\n\nSubgenres of topographical poetry include the country house poem, written in 17th-century England to compliment a wealthy patron, and the prospect poem, describing the view from a distance or a temporal view into the future, with the sense of opportunity or expectation. When understood broadly as landscape poetry and when assessed from its establishment to the present, topographical poetry can take on many formal situations and types of places. Kenneth Baker, in his \"Introduction to \"The Faber Book of Landscape Poetry\", identifies 37 varieties and compiles poems from the 16th through the 20th centuries—from Edmund Spenser to Sylvia Plath—correspondent to each type, from \"Walks and Surveys,\" to \"Mountains, Hills, and the View from Above,\" to \"Violation of Nature and the Landscape,\" to \"Spirits and Ghosts.\"\n\nCommon aesthetic registers of which topographical poetry makes use include pastoral imagery, the sublime, and the picturesque, which include images of rivers, ruins, moonlight, birdsong, and clouds, peasants, mountains, caves, and waterscapes.\n\nThough describing a landscape or scenery, topographical poetry often, at least implicitly, addresses a political issue or the meaning of nationality in some way. The description of the landscape therefore becomes a poetic vehicle for a political message. For example, in John Denham's \"Cooper's Hill,\" the speaker discusses the merits of the recently executed Charles I.\n\nOne important aspect of British Romanticism – evident in painting and literature as well as in politics and philosophy – was a change in the way people perceived and valued the landscape. In particular, after William Gilpin's \"Observations on the River Wye\" was published in 1770, the idea of the picturesque began to influence artists and viewers. Gilpin advocated approaching the landscape \"by the rules of picturesque beauty,\" which emphasized contrast and variety. Edmund Burke's \"A Philosophical Enquiry into the Origin of Our Ideas of the Sublime and Beautiful\" (1757) was also an influential text, as was Longinus' \"On the Sublime\" (early A.D., Greece), which was translated into English from the French in 1739. From the 18th century, a taste for the sublime in the natural landscape emerged alongside the idea of the sublime in language; that is elevated rhetoric or speech. A topographical poem that influenced the Romantics, was James Thomson's \"The Seasons\" (1726–30).\nThe changing landscape, brought about by the industrial and agricultural revolutions, with the expansion of the city and depopulation of the countryside, was another influences on the growth of the Romantic movement in Britain. The poor condition of workers, the new class conflicts, and the pollution of the environment all led to a reaction against urbanism and industrialisation and a new emphasis on the beauty and value of nature and landscape. However, it was also a revolt against aristocratic social and political norms of the Age of Enlightenment, as well a reaction against the scientific rationalisation of nature.\n\nThe poet William Wordsworth was a major contributor to the literature of landscape, as was his contemporary poet and novelist Walter Scott. Scott's influence was felt throughout Europe, as well as on major Victorian novelists in Britain, such as Emily Bronte, Mrs Gaskell, George Eliot, and Thomas Hardy, as well as John Cowper Powys in the 20th-century. Margaret Drabble in \"A Writer's Britain\" suggests that Thomas Hardy \"is perhaps the greatest writer of rural life and landscape\" in English.\n\nAmong European writers influenced by Scott were Frenchmen Honoré de Balzac and Alexandre Dumas and Italian Alessandro Manzoni. Manzoni's famous novel \"The Betrothed\" was inspired by Walter Scott's \"Ivanhoe\".\n\nAlso influenced by Romanticism's approach to landscape was the American novelist Fenimore Cooper, who was admired by Victor Hugo and Balzac and characterized as the \"American Scott.\"\n\nLandscape in Chinese poetry has often been closely tied to Chinese landscape painting, which developed much earlier than in the West. Many poems evoke specific paintings, and some are written in more empty areas of the scroll itself. Many painters also wrote poetry, especially in the scholar-official or literati tradition. Landscape images were present in the early \"Shijing\" and the \"Chuci\", but in later poetry the emphasis changed, as in painting]] to the \"Shan shui\" ( lit. \"mountain-water\") style featuring wild mountains, rivers and lakes, rather than landscape as a setting for a human presence. Shanshui poetry developed in China during the third and fourth centuries AD and left most of the varied landscapes of China largely unrepresented. \"Shan shui\" painting and poetry shows imaginary landscapes, though with features typical of some parts of South China; they remain popular to the present day.\n\nFields and Gardens poetry (), in poetry) was a contrasting poetic movement which lasted for centuries, with a focused on the nature found in gardens, in backyards, and in the cultivated countryside. Fields and Gardens poetry is one of many Classical Chinese poetry genres. One of the main practitioners of the Fields and Gardens poetry genre was Tao Yuanming (also known as Tao Qian (365–427), among other names or versions of names). Tao Yuanming has been regarded as the first great poet associated with the Fields and Gardens poetry genre.\n\nMany landscape photographs show little or no human activity and are created in the pursuit of a pure, unsullied depiction of nature devoid of human influence, instead featuring subjects such as strongly defined landforms, weather, and ambient light. As with most forms of art, the definition of a landscape photograph is broad, and may include urban settings, industrial areas, and nature photography. Notable landscape photographers include Ansel Adams, Galen Rowell, Edward Weston, Ben Heine, Mark Gray and Fred Judge.\n\nThe earliest forms of art around the world depict little that could really be called landscape, although ground-lines and sometimes indications of mountains, trees or other natural features are included. The earliest \"pure landscapes\" with no human figures are frescos from Minoan Greece of around 1500 BCE. Hunting scenes, especially those set in the enclosed vista of the reed beds of the Nile Delta from Ancient Egypt, can give a strong sense of place, but the emphasis is on individual plant forms and human and animal figures rather than the overall landscape setting. For a coherent depiction of a whole landscape, some rough system of perspective, or scaling for distance, is needed, and this seems from literary evidence to have first been developed in Ancient Greece in the Hellenistic period, although no large-scale examples survive. More ancient Roman landscapes survive, from the 1st century BCE onwards, especially frescos of landscapes decorating rooms that have been preserved at archaeological sites of Pompeii, Herculaneum and elsewhere, and mosaics.\n\nThe Chinese ink painting tradition of shan shui (\"mountain-water\"), or \"pure\" landscape, in which the only sign of human life is usually a sage, or a glimpse of his hut, uses sophisticated landscape backgrounds to figure subjects, and landscape art of this period retains a classic and much-imitated status within the Chinese tradition.\n\nBoth the Roman and Chinese traditions typically show grand panoramas of imaginary landscapes, generally backed with a range of spectacular mountains – in China often with waterfalls and in Rome often including sea, lakes or rivers. These were frequently used to bridge the gap between a foreground scene with figures and a distant panoramic vista, a persistent problem for landscape artists.\n\nA major contrast between landscape painting in the West and East Asia has been that while in the West until the 19th century it occupied a low position in the accepted hierarchy of genres, in East Asia the classic Chinese mountain-water ink painting was traditionally the most prestigious form of visual art. However, in the West, history painting came to require an extensive landscape background where appropriate, so the theory did not entirely work against the development of landscape painting – for several centuries landscapes were regularly promoted to the status of history painting by the addition of small figures to make a narrative scene, typically religious or mythological.\nDutch Golden Age painting of the 17th century saw the dramatic growth of landscape painting, in which many artists specialized, and the development of extremely subtle realist techniques for depicting light and weather. The popularity of landscapes in the Netherlands was in part a reflection of the virtual disappearance of religious painting in a Calvinist society, and the decline of religious painting in the 18th and 19th centuries all over Europe combined with Romanticism to give landscapes a much greater and more prestigious place in 19th-century art than they had assumed before.\n\nIn England, landscapes had initially been mostly backgrounds to portraits, typically suggesting the parks or estates of a landowner, though mostly painted in London by an artist who had never visited the site. the English tradition was founded by Anthony van Dyck and other, mostly Flemish, artists working in England. By the beginning of the 19th century the English artists with the highest modern reputations were mostly dedicated landscapists, showing the wide range of Romantic interpretations of the English landscape found in the works of John Constable, J.M.W. Turner and Samuel Palmer. However all these had difficulty establishing themselves in the contemporary art market, which still preferred history paintings and portraits. \nIn Europe, as John Ruskin said, and Sir Kenneth Clark confirmed, landscape painting was the \"chief artistic creation of the nineteenth century\", and \"the dominant art\", with the result that in the following period people were \"apt to assume that the appreciation of natural beauty and the painting of landscape is a normal and enduring part of our spiritual activity\"\n\nThe Romantic movement intensified the existing interest in landscape art, and remote and wild landscapes, which had been one recurring element in earlier landscape art, now became more prominent. The German Caspar David Friedrich had a distinctive style, influenced by his Danish training. To this he added a quasi-mystical Romanticism. French painters were slower to develop landscape painting, but from about the 1830s Jean-Baptiste-Camille Corot and other painters in the Barbizon School established a French landscape tradition that would become the most influential in Europe for a century, with the Impressionists and Post-Impressionists for the first time making landscape painting the main source of general stylistic innovation across all types of painting.\n\nIn the United States, the Hudson River School, prominent in the middle to late 19th century, is probably the best-known native development in landscape art. These painters created works of mammoth scale that attempted to capture the epic scope of the landscapes that inspired them. The work of Thomas Cole, the school's generally acknowledged founder, has much in common with the philosophical ideals of European landscape paintings — a kind of secular faith in the spiritual benefits to be gained from the contemplation of natural beauty. Some of the later Hudson River School artists, such as Albert Bierstadt, created less comforting works that placed a greater emphasis (with a great deal of Romantic exaggeration) on the raw, even terrifying power of nature. The best examples of Canadian landscape art can be found in the works of the Group of Seven, prominent in the 1920s. Emily Carr was also closely associated with the Group of Seven, though was never an official member. Although certainly less dominant in the period after World War I, many significant artists still painted landscapes in the wide variety of styles exemplified by Neil Welliver, Alex Katz, Milton Avery, Peter Doig, Andrew Wyeth, David Hockney and Sidney Nolan.\n\nThe term neo-romanticism is applied in British art history, to a loosely affiliated school of landscape painting that emerged around 1930 and continued until the early 1950s. These painters looked back to 19th-century artists such as William Blake and Samuel Palmer, but were also influenced by French cubist and post-cubist artists such as Pablo Picasso, André Masson, and Pavel Tchelitchew (; ). This movement was motivated in part as a response to the threat of invasion during World War II. Artists particularly associated with the initiation of this movement included Paul Nash, John Piper, Henry Moore, Ivon Hitchens, and especially Graham Sutherland. A younger generation included John Minton, Michael Ayrton, John Craxton, Keith Vaughan, Robert Colquhoun, and Robert MacBryde .\n\n"}
{"id": "43170941", "url": "https://en.wikipedia.org/wiki?curid=43170941", "title": "Least squares adjustment", "text": "Least squares adjustment\n\nLeast squares adjustment is a model for the solution of an overdetermined system of equations based on the principle of least squares of observation residuals. It is used extensively in the disciplines of surveying, geodesy, and photogrammetry—the field of geomatics, collectively.\n\nThere are three forms of least squares adjustment: \"parametric\", \"conditional\", and \"combined\". In parametric adjustment, one can find an observation equation \"h(X)=Y\" relating observations \"Y\" explicitly in terms of parameters \"X\" (leading to the A-model below). In conditional adjustment, there exists a condition equation \"g(Y)=0\" involving only observations \"Y\" (leading to the B-model below) — with no parameters \"X\" at all. Finally, in a combined adjustment, both parameters \"X\" and observations \"Y\" are involved implicitly in a mixed-model equation \"f(X,Y)=0\". Clearly, parametric and conditional adjustments correspond to the more general combined case when \"f(X,Y)=h(X)-Y\" and \"f(X,Y)=g(Y)\", respectively. Yet the special cases warrant simpler solutions, as detailed below. Often in the literature, \"Y\" may be denoted \"L\".\n\nThe equalities above only hold for the estimated parameters formula_1 and observations formula_2, thus formula_3. In contrast, measured observations formula_4 and approximate parameters formula_5 produce a nonzero \"misclosure\":\nOne can proceed to Taylor series expansion of the equations, which results in the Jacobians or design matrices: the first one,\nand the second one,\nThe linearized model then reads:\nwhere formula_10 are estimated \"parameter corrections\" to the \"a priori\" values, and formula_11 are post-fit \"observation residuals\".\n\nIn the parametric adjustment, the second design matrix is an identity, \"B=-I\", and the misclosure vector can be interpreted as the pre-fit residuals, formula_12, so the system simplifies to:\nwhich is in the form of ordinary least squares. \nIn the conditional adjustment, the first design matrix is null, \"A=0\".\nFor the more general cases, Lagrange multipliers are introduced to relate the two Jacobian matrices and transform the constrained least squares problem into an unconstrained one (albeit a larger one). In any case, their manipulation leads to the formula_1 and formula_2 vectors as well as the respective parameters and observations \"a posteriori\" covariance matrices.\n\nGiven the matrices and vectors above, their solution is found via standard least-squares methods; e.g., forming the normal matrix and applying Cholesky decomposition, applying the QR factorization directly to the Jacobian matrix, iterative methods for very large systems, etc.\n\n\n\n\nIf rank deficiency is encountered, it can often be rectified by the inclusion of additional equations imposing constraints on the parameters and/or observations, leading to constrained least squares.\n\nLecture notes and Technical reports:\n\nBooks:\n"}
{"id": "21237163", "url": "https://en.wikipedia.org/wiki?curid=21237163", "title": "Line laser", "text": "Line laser\n\nA line laser is a laser modified to project a line rather than a point (e.g. laser pointer). This may be achieved by passing the beam through a cylindrical lens or a Powell lens.\n\nUsing multiple lasers, it is possible to project multiple lines for use with image processing. \n\nDepending on the application, line lasers can generate lines, crosses or other patterns. Civil engineering and interior design projects can use line lasers to measure the levelling of a small building site.\n\n"}
{"id": "739282", "url": "https://en.wikipedia.org/wiki?curid=739282", "title": "List of fells in the Lake District", "text": "List of fells in the Lake District\n\nThis is a list of fells, hills, mountains, groups of mountains and subsidiary summits and tops in the Lake District, England.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThese are the 214 fells selected by Alfred Wainwright for a chapter in his seven \"Pictorial Guides to the Lakeland Fells\". See List of Wainwrights for them sorted by book, and the other Lake District fells he listed in \"The Outlying Fells of Lakeland\".\n\n\nA Marilyn is a hill which has a relative height of at least 150 metres (approximately 500 feet), regardless of its absolute height above sea level. List of Marilyns in England gives a more detailed listing, including the relative height for each fell.\n\n\nThe Hewitts are hills which have a relative height of at least 30 metres (approximately 100 feet), and are over 2000 feet (approximately 610 metres) above sea level.\n\n\n\n"}
{"id": "47357272", "url": "https://en.wikipedia.org/wiki?curid=47357272", "title": "List of geographical tors", "text": "List of geographical tors\n\nThe following list enumerate and expand on notable tors.\n\nDartmoor represents one of the largest areas of exposed granite in the United Kingdom, covering an area of 368 square miles (954 square kilometres). It is part of a chain of granite stretching through Cornwall, as far as the Isles of Scilly.\n\nSome of the more durable granite survived to form the rocky crowns of Dartmoor tors. One of the best known is at Haytor, on the eastern part of the moor, whose granite is of unusually fine quality and was quarried from the hillside below the tor during the 19th and early 20th centuries. Its stone was used to construct the pillars outside the British Museum in London, and to build London Bridge. The last granite to be quarried there was used to build Exeter War Memorial in 1919.\n\nTen Tors is an annual weekend hike on Dartmoor.\n\n\nHills:\n\nThere are many tors in this area, notably in the Dark Peak where the host rock is Millstone Grit:\n\n\nIn addition there are hills which incorporate 'tor' in their name but yet do not feature the geomorphological feature described in this article. Examples include Mam Tor and Shining Tor.\n\n\nThere are numerous tors developed in the Cairngorm granite in the Scottish Highlands:\n\n\nTor Bay, one of the sandy beaches near Oxwich Bay on the Gower Peninsula in south Wales, is so-called because the beach is framed by a huge outcrop of Carboniferous Limestone.\n\n\n\nTors are very commonly found in the Telangana and the Rayalaseema regions of Andhra Pradesh\n\n\n\n"}
{"id": "42055254", "url": "https://en.wikipedia.org/wiki?curid=42055254", "title": "List of international presidential trips made by Abdullah Gül", "text": "List of international presidential trips made by Abdullah Gül\n\nThis is a list of presidential trips made by Abdullah Gül, the 11th President of Republic of Turkey. During his presidency, which began with his inauguration on August 28, 2007, Abdullah Gül has travelled to 63 different states internationally as of February 2014.\n\nThe following international trips were made by Abdullah Gül during 2007:\n\nThe following international trips were made by Abdullah Gül during 2008:\n\nThe following international trips were made by Abdullah Gül during 2009:\n"}
{"id": "31258121", "url": "https://en.wikipedia.org/wiki?curid=31258121", "title": "List of international presidential trips made by Benigno Aquino III", "text": "List of international presidential trips made by Benigno Aquino III\n\nThis is a list of foreign presidential trips made by Benigno Aquino III, the 15th President of the Philippines. During his presidency, which began with his inauguration on June 30, 2010 and ended on June 30, 2016, Benigno Aquino III made 40 international trips to 24 countries internationally, including Vatican City. Aquino said he limited his foreign trips in order to focus on domestic issues. The number of visits per country where he travelled are:\n\nIn 2010, President Aquino made 3 official visits.\n\nPresident Aquino attended the 65th United Nations General Assembly and met with US President Barack Obama and leaders of several business sectors in New York City and San Francisco, California. The President talked at the UNGA regarding the status of the Philippine efforts to achieve the UN Millennium Development Goals (MDGs). He also met with members of the Filipino-American communities in both cities.\n\nPresident Aquino flew to Hanoi for a two-day State Visit following the personal invitation of Vietnamese President Nguyen Minh Triet. The President met with the Vietnamese President for bilateral talks, Prime Minister Nguyen Tan Dung and with General Secretary of the Communist Party Nong Duc Manh. The visit of the President further strengthened the bilateral ties between the two countries which have grown for the past 34 years. President Aquino also met with the Filipino community living and working in Vietnam who are mostly in higher positions such as managerial and supervisory. After his State Visit, the President participated at the 17th ASEAN Summit and Related Meetings where Vietnam was the current chair. On the sidelines of the summit, the President also had several bilateral meetings with neighboring countries such as Japan, Myanmar, South Korea, and Thailand among others.\n\nPresident Aquino participated at the 18th Asia-Pacific Economic Cooperation (APEC) Economic Leaders' Meeting (AELM) in Yokohama, Japan. With the theme \"Change and Action\", this year's APEC Summit focuses on Regional Economic Integration, Growth Strategy, Human Security and Economic and Technical Cooperation. The President hold a bilateral meetings with the other Heads of State attending the summit. President Aquino already met with Prime Minister Naoto Kan during the ASEAN Summit in Hanoi, Vietnam last month, as the government of Japan approved a 21.4 billion peso Official Development Assistance (ODA) to fund major infrastructure projects in the Philippines.\n\nIn 2011, President Aquino made 11 official visits.\n\nPresident Aquino embarks on his first state visit to the Republic of Indonesia. He met with Indonesian President Susilo Bambang Yudhoyono and was accorded ceremonial honors befitting a Head of State, such as an official welcome ceremony at the Istana Merdeka (Presidential Palace) and a state banquet at the Istana Negara (State Palace). The President's visit comes at an opportune time as both the Philippines and Indonesia enjoy strong bilateral relations for more than sixty years, marked by frequent exchange of visits by the Heads of State and high-level officials. President Aquino is on a three-day state visit to Singapore, after coming from Indonesia, to likewise strengthen bilateral and regional ties with fellow Association of Southeast Asian Nations member nations. He called on Singaporean President S.R. Nathan and met Prime Minister Lee Hsien Loong to discuss government's Public-Private Partnership (PPP) initiatives and various issues of bilateral and regional concern. The President also served as keynote speaker in the Singapore Business Forum/International Enterprise Singapore Eminent Leaders Lecture entitled \"Philippines-Partnership for Progress\" and the Ho Rih Hwa Leadership in Asia Public Lecture Series at the Singapore Management University. He also met members of the Filipino community and toured the Changi Water Reclamation Plant. At the Singapore Botanic Gardens, a new orchid breed was named after the visiting President as part of courtesies.\n\nPresident Aquino returned to Indonesia to attend the 18th ASEAN Leaders' Meeting. With the theme \"Towards an ASEAN Community in a Global Community of Nations,\" the agenda focuses on a people-centered ASEAN: A Caring and Sharing Community adopted during the 12th ASEAN summit that was held in the Philippines last 2006. Some of the topics that will be discussed by the ten (10) member countries include the enhancement of sub-regional cooperation and narrowing its development gap, the critical role of Private-Public Partnership (PPP) and the ASEAN single window in which the Philippines will maximize the opportunities provided by the ASEAN economic integration through the free trade areas (FTAs). The meeting will also expedite the expansion of the East Asian Summit and other priority concerns such as maritime security, transnational crime, human rights and democracy.\n\nPresident Aquino undertook his first official visit to the Kingdom of Thailand to meet with Thai Prime Minister Abhisit Vejjajiva. The Chief Executive was accorded with ceremonial honors befitting a head of state like an official welcome ceremony at the Government House in Dusit, Bangkok. The Philippines and Thailand celebrated 62 years of bilateral relations on June 14 and the visit is expected to further strengthen the mutual ties between the two countries. It will also enhance Thai investments in the Philippines as well as boost Filipino companies present in Bangkok. The President was given an \"honoris causa\" degree in Economics by Kasetsart University, the first agricultural university and the third oldest university in Thailand. President Aquino met with the Filipino community in Bangkok.\n\nPresident Aquino conducts a two-day state visit to Brunei Darussalam, following his successful trip to Thailand, to further strengthen bilateral relations with the Sultanate. The President will be received by His Royal Highness The Crown Prince Al-Muhtadee Billah upon his arrival at Bandar Seri Begawan International Airport, and will be given welcoming honors at Istana Nurul Iman, where he will be introduced to the Royal Family and the Grand Chamberlain. The President is also set to have an audience with His Majesty Sultan Haji Hassanal Bolkiah. President Aquino met with some Bruneian businessmen and with the Filipino community here. He will also visit the New Philippine Embassy Chancery, where he will unveil the commemorative marker as part of the inaugural activities.\n\nPresident Aquino held a one-on-one meeting with MILF chairman Al Haj Murad Ibrahim and met other Filipino Muslim rebel groups, discussing peace process in Mindanao.\n\nPresident Aquino embarked on a four-day state visit to the People's Republic of China. The visit was upon the invitation of President Hu Jintao, aimed to strengthen bilateral relations and to promote a people-centered partnership between the Philippines and China. President Aquino first visited Beijing, where he met with President Hu, Chairman Wu Bangguo and Premier Wen Jiabao. He also had a series of meetings with businessmen and witnessed the signing of several Memoranda of Understanding (MOU) in the areas of trade, investments, media, culture, education and tourism. In Shanghai, President Aquino convened with the civic officials led by the Secretary of Communist Party of China (CPC) Shanghai Municipal Committee, Yu Zhengsheng. He spoke before Yangtze River Delta Economic Zone officials and other business enterprise managers in a high-level forum. The President also welcomed possible trade investments during his meeting with various Filipino and Chinese businessmen based in Shanghai. On the last leg of his state visit, President Aquino went to Xiamen, Fujian, where he met with local officials before visiting Hongjian Village, the ancestral seat of the Cojuangco Family. There, he offered incense at the ancestral temple and interacted with some of his distant relatives.\n\nPresident Aquino heads to New York and Washington DC for a Working Visit to the United States of America. In New York, President Aquino participated in the launching of the Open Government Partnership (OGP) upon the invitation of United States President Barack Obama. OGP is a new multilateral initiative that aims to secure concrete commitments from governments to promote transparency, empower citizens, fight corruption and harness new technologies to strengthen governance. The Philippines is one of 2 Asian countries that is part of the 8-country steering committee of the OGP. The President hold several business meetings in New York and lead the ringing of the opening bell at the New York Stock Exchange. In Washington DC, President Aquino delivered a public lecture at the 2011 Annual Meetings of the World Bank Group and the International Monetary Fund, as well as meet with United States Senator Daniel Inouye and the Filipino Community from the District of Columbia (DC), Virginia and Maryland. At a recent press briefing, the President said that \"the drives we have already been achieving in the Philippines are already being highlighted by World Bank.\"\n\nPresident Aquino embarks on his second official visit to Japan to further strengthen diplomatic ties and elevate trade and economic relations, as well as socio-cultural, with one of the country's most cordial and dynamic partners in the region. The President's visit is set to focus on the promotion of the Philippines to investors, discussions on the use of nuclear energy and political-security issues, particularly the territorial disputes in the South China Sea, and other things of interests to both countries. President Aquino gave a keynote speech on the Philippine Economic Forum to inform the Japanese business community of investment opportunities and the renewed business climate under his administration. President Aquino's engagement includes a state call on Emperor Akihito and a bilateral meeting with Prime Minister Yoshihiko Noda. He thanked Japan for its continuing assistance to the Philippines and wants to return the favour when he visits the Ishinomaki City in Miyagi. President Aquino met with top business leaders in Japan, members of the Filipino community, high-level officials of the Japan-Philippines Economic Cooperation Committee (JPECC), International Friendship Exchange Council, and Japan Ship-owners' Association is also included among his official activities.\n\nPresident Aquino participates at the APEC Summit in Honolulu.\n\nPresident Aquino participates at the 19th ASEAN Summit in Bali.\n\nIn 2012, President Aquino made 9 official visits.\n\nPresident Aquino participated at the 20th Association of Southeast Asian Nations (ASEAN) Summit and the Celebration of the 45th Anniversary of ASEAN in Phnom Penh. He joined with other leaders of ASEAN member-countries in the discussions, where North Korea's planned long-range missile launch will most likely to be discussed, as well as other issues of mutual concerns. The President had a coffee meeting with the Philippine media covering the summit on April 3 and met the Filipino community in Cambodia on his third day of visit here.\n\nPresident Aquino had a bilateral meeting with British Prime Minister David Cameron when he visited London. Both leaders discussed Philippines-U.K political and economic cooperation, the U.K's participation in the International Contact Group, regional and international issues, and anti-corruption and good governance practices of both the Philippine and U.K governments. The President also met HRH The Prince Andrew, Duke of York. U.S President Barack Obama welcomed President Aquino to the White House. The Philippines is a long-standing friend and ally of the United States, both President looks forward to discussing the close strategic, economic and people to people ties between the two countries, and cooperation in the Asia-Pacific region. The two leaders will also discuss ways to deepen bilateral cooperation.\n\nPresident Aquino attended the APEC Russia 2012 in Vladivostok.\n\nPresident Aquino attended the wedding of the daughter of Sultan Hassanal Bolkiah, Princess Hajah Hafizah Sururul Bolkiah.\n\nPresident Aquino embarks on a state visit to New Zealand and Australia, the President held a meeting with Prime Minister John Key, Governor-General Quentin Bryce and Prime Minister Julia Gillard.\n\nPresident Aquino attended the 10th ASEAN-Europe Meeting (ASEM) in Vientiane.\n\nPresident Aquino attended the 21st ASEAN Summit in Phnom Penh.\n\nIn 2013, President Aquino made 7 official visits.\n\nPresident Aquino attended the 2013 World Economic Forum in Davos.\n\nPresident Aquino attended the 22nd ASEAN Summit in Bandar Seri Begawan.\n\nPresident Aquino attended the World Economic Forum on East Asia in Naypyidaw.\n\nPresident Aquino attended the APEC Indonesia 2013 in Bali, the 23rd ASEAN Summit and the 8th East Asia Summit in Bandar Seri Begawan.\n\nState visit, the President met with President Park Geun-hye.\n\nPresident Aquino attended the 40th ASEAN-Japan Commemorative Summit in Tokyo.\n\nIn 2014, President Aquino made 13 official visits.\n\nState visit, meeting with Malaysian Prime Minister Najib Razak focusing on the Comprehensive Agreement on the Bangsamoro. He also attended the Business Opportunities Forum.\n\nPresident Aquino attended the 24th ASEAN Summit in Naypyidaw.\n\nOn June 24, 2014, President Aquino undertook a one-day working visit to Japan that cost ₱8.8 million. He first traveled to Tokyo to meet with Prime Minister Shinzō Abe at his official residence for a summit meeting, working lunch, and a joint press conference. During their 45-minute meeting, President Aquino and Prime Minister Abe discussed ways to strengthen their nations' strategic cooperation with the intensifying tensions over the territorial disputes in the South China Sea, where the Prime Minister had agreed to urge the reinterpretation of Article 9 of the Japanese Constitution which would allow the Japan Self-Defense Forces to assist in defending Japan's allies, to which the President expressed support. He later traveled to Hiroshima to address the \"Consolidation for Peace for Mindanao\" conference organized by the Japan International Cooperation Agency and the Research and Education for Peace council from the Universiti Sains Malaysia. The conference expressed Japan's support over the peace process with Bangsamoro. In his address, President Aquino thanked Japan for their support and associated the peace process with the atomic bombings of Hiroshima and Nagasaki that occurred during World War II nearly seventy years prior. After addressing the conference, the President visited the Hiroshima Peace Memorial Park, where he laid a wreath at the Memorial Cenotaph and toured the Hiroshima Peace Memorial Museum, before departing for Manila later that evening.\n\nOn his European trip, President Aquino traveled to Madrid (September 14–15), Brussels (September 15–17), Paris (September 17–19), and Berlin (September 19–20) to enhance bilateral and economic cooperation between the Philippines and the countries of the said cities. After his European trip, President Aquino traveled across the Atlantic Ocean to the United States for a working visit in Boston (September 20–22), New York City (September 22–24), and San Francisco (September 24), where he also attended the United Nations Climate Summit in New York upon the invitation of Secretary-General Ban Ki-moon and U.S. President Barack Obama.\n\nOn Sunday, September 14, President Aquino and his delegation arrived at Torrejón Air Base in Madrid at approximately 7:22 am CEST. He met with former Prime Minister José María Aznar, witnessed the signing of a memorandum of understanding for the Madrid Fusión-Manila gastronomic event to be held in Manila in April 2015, and laid a wreath at a local monument honoring José Rizal, replicating the Rizal Monument in Manila. He also addressed the Filipino community in Spain at the Colegio Nuestra Señora de las Maravillas. After, President Aquino held a series of business meetings with seven Spanish firms, namely Acciona, Abengoa, Indra Sistemas, , Grupo ACS, , and Calidad Pascual. Finally, President Aquino addressed the Networking with the Philippine Business Delegation event, where he urged investment in the Philippines.\nOn Monday, September 15, President Aquino met with Prime Minister Mariano Rajoy at to discuss bilateral economic cooperation with the economic growth of both their countries. During their bilateral meeting, President Aquino informed Prime Minister Rajoy of the situations regarding the territorial disputes in the South China Sea, urging support over the Philippines' proposed Triple Action Plan, and thanked the Prime Minister for Spain's provision of aid to the victims of Super Typhoon Haiyan (Yolanda), the Zamboanga City crisis, and the 2013 Bohol earthquake. The two heads of government also discussed efforts to cease illegal, unreported and unregulated fishing and a bilateral air transport agreement to allow non-stop flights between the two countries. President Aquino then headed to the Palace of Zarzuela to meet with King Felipe VI. At around noon, President Aquino and his delegation headed to Torrejón Air Base to depart Madrid for Brussels, arriving in Brussels at around 2:05 pm CEST. After arriving, President Aquino visited the Berlaymont building, the headquarters of the European Commission, to meet with European Commission President José Manuel Barroso and seek support from the European Union to peacefully resolve the territorial disputes in the South China Sea. The two presidents also discussed the Philippines' cooperation with the European Commission's Directorate-General for Maritime Affairs and Fisheries to \"prevent, deter and eliminate\" illegal, unreported and unregulated fishing. Later that afternoon, President Aquino met with King Philippe at the Royal Palace of Brussels. President Aquino thanked King Philippe for Belgium's support in the rehabilitation of the damage caused by Super Typhoon Haiyan (Yolanda) and their support over the Bangsamoro peace process. In the evening, President Aquino met with around 800 members of the Filipino communities in Belgium and Luxembourg at the Cathedral of St. Michael and St. Gudula.\n\nOn Tuesday, September 16, President Aquino met with European Council President Herman Van Rompuy to discuss the cooperation between the Philippines and the European Union with the signing of the Partnership and Cooperation Agreement, the Bangsamoro peace process, the Maritime Security Strategy, and the European Union's contributions to resolving the territorial disputes in the South China Sea. After their meeting, President Aquino met with Prime Minister Elio Di Rupo at the Prime Minister's official residence in Rue de la Loi, where the two heads of government discussed trade relations. In the afternoon, President Aquino participated at a conference organized by the Philippine Department of Trade and Industry in association with Eurochambres and Friends of Europe, aimed at urging Belgian businesses to invest in the Philippines' public-private partnership programs. He later held a series of business meetings with officials from Royal Dutch Shell, HSBC, and Asia House. In the evening, President Aquino headed to the Château of Val-Duchesse to meet with the Egmont Institute. Upon arriving at the chateau, the President's convoy was greeted by protesters from Migrante Europe and other Filipino human rights organizations, who demand his resignation after \"four years of massive corruption, blatant subservience to US imperialist dictates and brutal leadership,\" according to Migrante Europe chairman Garry Martinez. Upon meeting with the Egmont Institute, the President delivered a speech on addressing local and global issues through international cooperation.\nOn Wednesday, September 17, President Aquino and his delegation departed Brussels and arrived at Paris Orly Airport at around 10:05 am CEST. President Aquino's visit to France, the first of a Philippine President since President Fidel V. Ramos's visit in 1994, was aimed to \"reap economic, political and cultural gains\" to enhance bilateral cooperation between the two countries, according to French Ambassador Gilles Garachon. After arriving, the President attended a wreath laying ceremony with military honors at the Tomb of the Unknown Soldier under the Arc de Triomphe. President Aquino then headed to the Élysée Palace to meet with President François Hollande. During their bilateral meeting, the two presidents discussed ways to enhance bilateral cooperation and efforts to alleviate climate change. President Hollande also expressed his support to resolve the territorial disputes in the South China Sea. The two presidents later witnessed the signing of bilateral agreements on air services, education, and cultural ties, before participating in a working lunch and a joint press conference. After his meeting with President Hollande, President Aquino held business meetings with executives from Airbus, Schneider Electric, and Teleperformance. He later met with Prime Minister Manuel Valls at Hôtel Matignon to discuss the Filipino community in France and their contributions to the French economy. In the evening, the President met with and addressed the Filipino community in France at Chapelle Sainte Bernadette.\n\nOn Thursday, September 18, President Aquino participated in the Philippines–France Business Leaders' Roundtable, where he met with 20 Filipino and French business executives to discuss ways to improve bilateral trade and investment, as well as to promote business opportunities for both countries. After, the President addressed the Philippine Business Opportunities Forum at the InterContinental Paris Le Grand Hotel. In his speech, he urged French businesses to invest in the Philippines, saying that the current state of the Philippine economy has been appreciated as a \"renaissance\" from an economy that was \"kept in the darkness of apathy and hopelessness by an administration motivated only by self-service, as opposed to public service.\" At the hotel, the President also met with officials from the Ayala Corporation, Alstom–Bouygues, and the Egis Group to discuss their expansion plans in the Philippines, having worked on the South Extension of the Manila Light Rail Transit System Line 1. President Aquino later toured the European Headquarters of Dassault Systèmes in Vélizy-Villacoublay. In the evening, President Aquino addressed a forum organized by the Institut français des relations internationales. The President also toured the Louvre later that evening.\nOn Friday, September 19, President Aquino and his delegation departed Paris for Berlin, the last stop of his European trip before heading to the United States. He arrived at Berlin Tegel Airport at around 10:45 am CEST. From there, the President traveled to the German Chancellery to meet with Chancellor Angela Merkel, where he was given military honors. During their meeting, Chancellor Merkel agreed to support the Philippines in resolving the territorial disputes in the South China Sea upon President Aquino's request. They also witnessed the signing of bilateral agreements on social security, skills training, and trade, which was followed by a working lunch and a joint press statement. After, President Aquino headed to the Bellevue Palace to meet with President Joachim Gauck. Later that afternoon, President Aquino met with officials from SAP SE, before addressing a policy forum organized by and the Asia-Pacific Committee of German Business. He later witnessed the signing of a health care agreement between the Ayala Corporation and Siemens and met with officials from Knauf, Investor AB, Saab Group, and Stihl, as well as former Federal Minister of Economic Affairs and Energy Michael Glos. In the evening, the President met with the Filipino community in Germany.\n\nOn Saturday, September 20, President Aquino visited the Philippine embassy in Berlin, where he was awarded a Freedom Medal from the Friedrich Naumann Foundation for \"his successful reforms in the areas of education, anti-corruption and rule of law.\" Before departing Berlin for the United States, the President toured the Berlin Hauptbahnhof and the Berlin Wall. President Aquino and his delegation departed Berlin Tegel Airport at around 6:30 pm CEST, ending his week-long European trip with $2.3 billion worth of investment pledges to the Philippines from 19 European-based companies. He arrived at the Logan International Airport in Boston at approximately 8:33 pm EDT, beginning his four-day working visit to the United States. It marked the President's first visit to Boston since the assassination of his father, former Senator Benigno Aquino, Jr., in 1983 upon returning from exile in Boston.\n\nOn Sunday, September 21, President Aquino first met with family friends for a private lunch. In the afternoon, he visited Boston College where he celebrated Mass at the college's Parish of St. Ignatius of Loyola and attended a convocation with the local Filipino-American community. In his speech, the President updated the community on improvements made in the Philippines regarding the economy, education, and liability of officials, among others. He also recalled moments from his family's three-year exile in Boston, which he calls his \"formative years\".\n\nOn Monday, September 22, President Aquino dined with Representative Joseph P. Kennedy III at a local pizzeria in Newton. The President then visited his former neighborhood in Chestnut Hill, where he visited his former residence, met with its current owner, as well as former neighbors. Later that afternoon, President Aquino was interviewed by radio journalist Jeremy Hobson on his program \"Here and Now\" on WBUR-FM, where he was asked on his response to climate change, ahead of the United Nations Climate Summit, and the threat of the Islamic State of Iraq and the Levant. In the evening, President Aquino delivered a policy speech at the John F. Kennedy School of Government at Harvard University, where he discussed how the school's teachings shaped the skills of many Filipino politicians in his administration, including several members of his Cabinet, to work towards redeveloping the Philippines from the effects of former President Ferdinand Marcos's administration with the declaration of martial law to the administration of his predecessor Gloria Macapagal-Arroyo, saying: \"Like JFK, Ninoy, and Cory, each one has the capacity to dream, to die, to live, to fight, to stand for something, to ask 'why not' when the challenges seem insurmountable. Thus can we transform the world for the better.\" After his speech, President Aquino and his delegation departed Boston for New York City, arriving at the Newark Liberty International Airport at approximately 8:27 pm EDT, where he was greeted by Philippine Ambassador to the United Nations Libran N. Cabactulan.\n\nOn the morning of Tuesday, September 23, President Aquino headed to the United Nations Headquarters to participate in the United Nations Climate Summit. In his four-minute speech, the President urged the international community to assist the Philippines, a major victim to the effects of climate change being frequently visited by typhoons, in combating climate change through funding and the provision of technology, saying: \"We [the Philippines] have never lacked in resolve. What we lack is the access to technology, financing, and investment that would allow us to accelerate our strategy.\" Following the summit, President Aquino participated in a round table discussion with business executives from the U.S. Chamber of Commerce, the US-ASEAN Business Council, and the US-Philippines Society to discuss economic expansion and investment in the Philippines. Later that day, President Aquino participated in the World Leaders Forum at the Low Memorial Library of Columbia University, where he delivered a speech and answered questions from the audience. In his speech, the President spoke on the importance of reforms to address challenges faced constantly by the Philippines. While answering an audience member's question, President Aquino was interrupted by at least three protesters who demanded a response from the President regarding alleged acts of impunity in the Philippines and corruption over Typhoon Haiyan aid. President Aquino refused to respond and Columbia University President Lee Bollinger apologized over the incident.\n\nOn the last day of his trip, Wednesday, September 24, President Aquino and his delegation departed Newark and traveled across the United States for a brief visit to San Francisco, the last stop of his working visit to the United States. He arrived at San Francisco International Airport at approximately 9:38 am PDT. In San Francisco, President Aquino held business meetings with senior officials from Caesars Entertainment Corporation, International Development, and Wells Fargo. Outside the Wells Fargo headquarters on Haight Street, President Aquino was met by protesters from Filipino-American communities in California, the largest of Filipino-American communities in the United States, who were disappointed by the President's decision to decline their invitation and prioritize business meetings, instead of meeting with the community. President Aquino and his delegation departed San Francisco for Manila at around 4:40 pm PDT, ending his 10-day trip to Europe and the United States.\n\nPresident Aquino attended the 7th Bali Democracy Forum in Nusa Dua, Bali. He, along with Indonesian President Susilo Bambang Yudhoyono, co-chaired the forum aimed at reinforcing democracy in the region. On the sidelines of the forum, President Aquino was awarded the Bintang Republik Indonesia Adipurna (\"Star of the Republic of Indonesia\") by President Yudhoyono, the highest award honored by the Government of Indonesia, becoming the first Filipino to receive such award.\n\nPresident Aquino traveled to Beijing to attend the 26th APEC Summit (November 9–11) and Naypyidaw to attend the 25th ASEAN Summit and the Ninth East Asia Summit (November 11–13). The summit meetings were a chance for President Aquino to share the Philippines' plans to contribute to economic integration and regional growth, as well as the country's eagerness to tackle global issues, including human trafficking and pollution. The government spent ₱24 million on the trip.\n\nOn Sunday, November 9, President Aquino arrived at the Beijing Capital International Airport at around 1:20 pm CST. In Beijing, he first headed to the China National Convention Center to attend the APEC CEO Summit, where he addressed business leaders on the economic growth of the Philippines through economic reforms and innovation. He also emphasized the country's transition from being called the \"Sick Man of Asia\" to \"Asia's Rising Tiger\". He then met with Vietnamese President Trương Tấn Sang at the Philippine embassy in Beijing, where the two presidents developed an agenda for a strategic partnership that would improve economic and social ties. In the evening, the President met with Moody's Corporation CEO Raymond W. McDaniel Jr., where they discussed efforts on preventing the Ebola virus epidemic from reaching the Philippines and rehabilitation efforts on Typhoon Haiyan (Yolanda). The President also met with executives from Sanofi and Johnson & Johnson. \n\nOn Monday, November 10, President Aquino returned to the Philippine embassy in Beijing to hold a series of bilateral meetings with Canadian Prime Minister Stephen Harper, Thai Prime Minister Prayut Chan-o-cha, New Zealand Prime Minister John Key, and Papuan Prime Minister Peter O'Neill. With Prime Minister Harper, the two heads of government discussed rehabilitation efforts on Typhoon Haiyan (Yolanda) and the Philippines' status in Canada's Global Markets Action Plan. With Prime Minister Prayut, the two heads of government discussed strengthening economic ties between the Philippines and Thailand, particularly on supporting small and medium-sized enterprises and local farmers. With Prime Minister Key, the two heads of government discussed rehabilitation efforts on Typhoon Haiyan (Yolanda) and the expansion of air routes between New Zealand and the Philippines. The President also thanked the Prime Minister for New Zealand's support for the peace process with Bangsamoro. With Prime Minister O'Neill, the two heads of government discussed the enhancement of cooperation between Papua New Guinea and the Philippines on trade, investment, health services, and agriculture. In the afternoon, President Aquino attended the APEC Business Advisory Council. In the evening, the President joined the other APEC leaders in attending the APEC Economic Leaders' Meeting Welcome Dinner at the Beijing National Aquatics Center, hosted by Chinese President Xi Jinping and First Lady Peng Liyuan. For the occasion, the President and the other APEC leaders wore a modified version of the Mao suit, as part of the APEC tradition of the leaders wearing the host nation's traditional outfit.\n\nOn the morning of Tuesday, November 11, President Aquino and the other APEC leaders participated in the APEC Economic Leaders' Meeting Retreat at the International Conference Center in , where he was given the chance to share the Philippines' views on advancing economic integration to promote economic growth, infrastructure development, and innovation, among others. After, the APEC leaders participated in a tree planting ceremony at the Summer Garden, outside the International Conference Center. After the ceremony, President Aquino met briefly with President Xi for a ten-minute discussion regarding the territorial disputes in the South China Sea, in which both presidents agreed to resolve the disputes in \"constructive ways\". In the afternoon, President Aquino and the other APEC leaders participated in the second session of the meeting, before attending a working lunch. In the evening, President Aquino departed Beijing and arrived at the Naypyidaw International Airport in Myanmar at around 11:05 pm MST.\n\nOn Wednesday, November 12, President Aquino first attended the opening ceremony of the 25th ASEAN Summit, before attending the plenary session at around 10:15 am MST, where the President was given the chance to share his views on political security and sociocultural development in the region. During the session, President Aquino also urged the finalization of a code of conduct to resolve the territorial disputes in the South China Sea. In the afternoon, President Aquino and the other ASEAN leaders participated in a series of summits with the leaders of neighboring nations to further enhance cooperation between ASEAN and the said neighboring nations, beginning with the 12th ASEAN–India Summit with Prime Minister Narendra Modi, followed by the 17th ASEAN–Japan Summit with Prime Minister Shinzō Abe, and concluding with the 40th ASEAN–Australia Commemorative Summit with Prime Minister Tony Abbott. In between, the ASEAN leaders also attended the 6th ASEAN–United Nations Summit with Secretary-General Ban Ki-moon, where the Secretary-General urged ASEAN leaders to renew their commitment to addressing issues regarding peace and security. In the evening, the ASEAN leaders attended a gala dinner hosted by President Thein Sein and First Lady Khin Khin Win. \n\nOn Thursday, November 13, President Aquino attended the Ninth East Asia Summit Plenary Session, where the President was given the chance to share his views on issues regarding peace and stability, climate change, and the spread of pandemic diseases, as well as ways to further enhance Asia-Pacific economic integration. President Aquino and the other ASEAN leaders later participated in the 2nd ASEAN–United States Summit with President Barack Obama, aimed at enhancing cooperation between ASEAN and the United States to maintain regional peace and stability. After, the ASEAN leaders participated in the 17th ASEAN–China Summit with Premier Li Keqiang, where discussions focused on reinforcing ASEAN–China relations despite the ongoing territorial disputes in the South China Sea between China and a number of ASEAN nations. President Aquino then met with Indian Prime Minister Modi, where the two presidents discussed mutual interests on the ASEAN–India Free Trade Agreement and the information technology and business process management sectors, as well as India's support over a peaceful resolution on the South China Sea territorial disputes. Later that afternoon, the ASEAN leaders joined Chinese Premier Li, Japanese Prime Minister Abe, and South Korean President Park Geun-hye at the 17th ASEAN Plus Three Summit to discuss enhancing the cooperation between ASEAN and China, Japan, and South Korea. The ASEAN leaders also attended ASEAN Leaders' Meeting with ASEAN Business Advisory Council, an opportunity for ASEAN nations to be given feedback from the council and guidance to achieve economic integration. In the evening, the ASEAN leaders attended the closing ceremony of the 25th ASEAN Summit. President Aquino then headed to the Naypyidaw International Airport, where he was greeted by Overseas Filipinos in Myanmar before departing for Manila. He departed Naypyidaw at around 8:30 pm MST.\n\nPresident Aquino traveled to Singapore for a two-day working visit that cost ₱11.6 million. He arrived at Changi Airport at 11:28 am SST. After arriving, President Aquino headed to the Istana to meet with Prime Minister Lee Hsien Loong and President Tony Tan Keng Yam, the latter of whom hosted a luncheon for President Aquino. In the evening, President Aquino attended \"The Economist\"'s \"The World in 2015\" Gala Dinner as a keynote speaker. During his interview with executive editor Daniel Franklin regarding his predictions for the following year, the President discussed his domestic and foreign policies, his recent meeting with Chinese President Xi Jinping, the Philippines' interest in joining the Trans-Pacific Partnership, and the Philippine government's efforts in re-establishing damaged areas caused by Super Typhoon Haiyan (Yolanda). The following day, President Aquino met with business executives at a roundtable discussion organized by the Philippine Trade and Investment Center and the Singapore Business Federation, where he urged executives to invest in the Philippines, citing a 6.3 percent growth in GDP from 2010 to 2014 as a form of conviction. He also met with executives from the SIA Engineering Company, Temasek Holdings, Keppel Corporation, and GIC Private Limited. In the afternoon, the President dined at a Jollibee branch at Lucky Plaza, where he was met by a crowd of Filipinos, before departing Singapore for Manila at around 3:10 pm SST.\n\nPresident Aquino traveled to South Korea to attend the two-day 25th ASEAN–Republic of Korea Commemorative Summit in Busan. He initially canceled the trip in order to assist his country from the effects of Typhoon Hagupit (Ruby), but later decided to push through with the trip after being satisfied with the government's efforts and would instead monitor the situation from Busan. President Aquino arrived at Gimhae Air Base at around 1:40 pm KST. On the sidelines of the summit, the President met with President Park Geun-hye. According to Presidential Communications Operations Office Secretary Sonny Coloma, who accompanied him during the trip, President Aquino announced his intention to form a \"comprehensive strategic partnership\" that would further boost Philippines–South Korea relations during their bilateral meeting. The two presidents also discussed issues regarding regional security, education, and the safety of South Koreans in the Philippines. President Aquino also held a bilateral meeting with Malaysian Prime Minister Najib Razak. After, the President joined President Park and the other nine ASEAN leaders in viewing a traditional Korean arts and crafts exhibit at the Busan Exhibition and Convention Center, before attending a dinner and cultural performance hosted by President Park.\n\nThe following day, at around 9:30 am KST, President Aquino attended the first Commemorative Summit session chaired by South Korea, which focused on the multilateral cooperation between the ASEAN countries and South Korea. At around 10:50 am KST, the President attended the second Commemorative Summit session chaired by , which focused on security cooperation, climate change, and emergency management. After the summit, President Aquino and the other ASEAN leaders attended a luncheon hosted by President Park. Before departing for Manila, President Aquino inspected one of the 12 KAI T-50 Golden Eagle aircraft that the Philippines had purchased from the Korea Aerospace Industries at the tarmac of Gimhae Air Base. The President departed Gimhae Air Base at around 5:20 pm KST.\n\nIn 2015, President Aquino made 8 official visits.\n\nPresident Aquino attended the 26th ASEAN Summit in Kuala Lumpur and Langkawi.\n\nIn April 2015, Deputy Presidential Spokeswoman Abigail Valte announced that President Aquino would embark on a three-day state visit to Canada from May 7 to 9, 2015, accepting the invitation from Governor General David Johnston, along with a brief working visit to Chicago in the United States beforehand and a state visit to Japan in June.\n\nOn Wednesday, May 6, President Aquino arrived at the Chicago O'Hare International Airport at approximately 1:14 pm CT to begin his four-day North American trip. He then headed to the JW Marriott Chicago, where he was met by Mayor Rahm Emanuel, who presented him with a Chicago City Council Resolution. After, the President headed to the TransUnion headquarters to attend a round table discussion with representatives from the U.S. Chamber of Commerce, the US-ASEAN Business Council, and the National Center for APEC. During the discussion, several executives of United States firms expressed interest in investing in the Philippines, praising the country's economic growth and development and the \"competence and talent\" of Filipino workers. In the evening, President Aquino met with the Filipino community in Chicago at the JW Marriott Chicago, where he also addressed an economic update on the Philippines, citing a 6.3 percent increase in GDP, a 479 percent increase in foreign investment from 2010 to 2014, and the country's ranking improvements in the World Bank Group's Ease of doing business index and the World Economic Forum's \"Global Competitiveness Report\", among others. \n\nOn Thursday, May 7, President Aquino departed Chicago in the morning and arrived at Macdonald–Cartier International Airport in Ottawa at approximately 12:10 pm EDT, beginning his four-day state visit to Canada. After his arrival, the President arrived at an official welcome ceremony with military honors on a landau driven by the Royal Canadian Mounted Police at Rideau Hall, where he was met by Governor General Johnston and his wife Sharon. After the ceremony, President Aquino paid a courtesy call to Governor General Johnston inside Rideau Hall. During their meeting, Governor General Johnston praised President Aquino for his administration's efforts in contributing to the Philippines' economic growth, to which the President cited good governance, the Pantawid Pamilyang Pilipino Program, and backlog-clearing programs, while the President thanked Governor General Johnston for Canada's efforts in aiding the victims of Typhoon Haiyan (Yolanda) and their advocation for the Bangsamoro peace process. After the meeting, President Aquino participated in a ceremonial planting of a red spruce outside Rideau Hall, which is adjacent to the red maple planted by his mother, former President Corazon Aquino, during her visit in 1989. In the evening, the Johnstons hosted a state dinner for President Aquino. \n\nOn Friday, May 8, President Aquino met with Prime Minister Stephen Harper at the Centre Block of Parliament Hill. At their bilateral meeting, the two heads of government discussed the regional developments on the territorial disputes in the South China Sea, the safety of the Overseas Filipino Workers in Canada, and trade between Canada and the Philippines. President Aquino and Prime Minister Harper witnessed the signing of several bilateral agreements on labor, trade, and development, before attending a joint press conference, followed by a tour of the Library of Parliament. Prime Minister Harper hosted a working luncheon for President Aquino, before the latter headed to Macdonald–Cartier International Airport to depart for Toronto. President Aquino arrived at Toronto Pearson International Airport at 2:28 pm EDT and headed to the Fairmont Royal York to attend a round table business meeting with the Asia Pacific Foundation of Canada, where opportunities for trade and investment between Canadian and Filipino businesses were discussed. Prime Minister Harper, who had traveled to Toronto, hosted a reception at Roy Thomson Hall for President Aquino to meet with over 2,000 members of the Filipino community in Canada. During his remarks, President Aquino addressed to the Filipino community a progress report on the economic growth of the Philippines, stating a 6.3 percent increase in GDP and 1.04 million jobs filled in 2014. With these statistics, he also added that the Philippines had transformed from \"the sick man of Asia\" to \"the darling of Asia.\" In the evening, the President headed back to the Fairmont Royal York to meet with Justin Trudeau, leader of the Liberal Party, and Ontario Premier Kathleen Wynne. He also held a coffee meeting with the Filipino media.\n\nOn Saturday, May 9, President Aquino departed Toronto for Vancouver, the final stop of his three-day state visit to Canada, as well as his four-day visit to North America. The President and his delegation arrived at Vancouver International Airport past noon, where he was welcomed by Minister of National Defence and Multiculturalism and Citizenship Jason Kenney and British Columbia Attorney General Suzanne Anton. After arriving, President Aquino headed to the Pan Pacific Vancouver Hotel to meet with British Columbia Premier Christy Clark, where they also witnessed the signing of a memorandum of understanding between Philippine Labor and Employment Secretary Rosalinda Baldoz and British Columbia International Trade Minister Teresa Wat, aimed at strengthening the employment abilities of Filipinos in British Columbia, as well as their protection. President Aquino also met with executives of the Aquilini Investment Group who had invested in renewable energy in the Philippines, particularly Cebu. During their meeting, the Aquilini Investment Group also expressed interest in investing in the tourism and the agricultural sectors of the Philippines. Finally, the President met with the Filipino community at the Vancouver Convention Centre. In the evening, President Aquino and his delegation departed Vancouver International Airport for Manila.\n\nPresident Aquino traveled to Tokyo for a four-day state visit from June 2 to 5, 2015, aimed at promoting business deals with Japanese investors and seeking support from Japan to resolve the territorial disputes in the South China Sea.\n\nOn Tuesday, June 2, President Aquino arrived at Haneda Airport. After arriving, he headed to the Imperial Hotel to meet with Japanese businessmen, before meeting with the Filipino community at Hotel Okura.\n\nOn Wednesday, June 3, President Aquino was received by Emperor Akihito and Empress Michiko at the Imperial Palace. During their meeting, President Aquino was awarded the Grand Cordon of the Order of the Chrysanthemum by Emperor Akihito, who in return was awarded the Grand Collar (\"Supremo\") of the Order of Lakandula by President Aquino for bolstering the Japan–Philippines relations. President Aquino also attended the 21st International Conference on The Future of Asia organized by Nikkei 225 at Hotel Okura, where he delivered a keynote speech. During his keynote speech, President Aquino urged China to reconsider their land reclamation activities in the West Philippine Sea, as it breaches the conditions of the 2002 ASEAN–China Declaration on the Conduct of Parties, comparing China's actions to Nazi Germany's territorial expansion before World War II. Later that afternoon, President Aquino addressed a joint session of the National Diet, seeking Japan's assistance to resolve the territorial disputes. In the evening, Emperor Akihito and Empress Michiko hosted a state dinner for President Aquino at the Imperial Palace.\n\nOn Thursday, June 4, President Aquino attended the Philippine Investment Forum at the Hotel New Otani, attended by over 1,000 Japanese businessmen, urging them to invest in information technology, infrastructure, and manufacturing in the Philippines. He then headed to the Akasaka Palace to meet with Prime Minister Shinzō Abe for a bilateral meeting, followed by a joint press conference and an official dinner in the evening. The two heads of government discussed the enhancement of the strategic partnership between Japan and the Philippines, as well as developments over the territorial disputes in the South China Sea. President Aquino also thanked Prime Minister Abe for Japan's efforts in aiding the victims of Typhoon Haiyan (Yolanda) and their support towards the Bangsamoro peace process. They then witnessed the signing of the Memorandum of Cooperation for Healthcare, signed by the Philippine Department of Health and the Japanese Ministry of Health, Labour, and Welfare to further enhance universal health care.\n\nOn Friday, June 5, President Aquino held a joint press conference with the Japan National Press Club, where he announced his intentions for a Visiting Forces Agreement with Japan in order for Japanese troops to assist in defense over the territorial disputes in the South China Sea. He was also met by Emperor Akihito and Empress Michiko at the Imperial Hotel, before heading to Haneda Airport to depart Tokyo for Manila with ₱13.5 billion investment pledges from eleven companies and ₱136.9 billion of concessional loans for infrastructure projects.\n\nPresident Aquino attended the 27th ASEAN Summit and the Tenth East Asia Summit in Kuala Lumpur, his last before stepping down from office. During the ASEAN Summit, President Aquino and the other ASEAN leaders announced the creation of the ASEAN Economic Community, an economic integration between ASEAN member states to begin on December 31, 2015. After the summit, the ASEAN leaders signed the ASEAN Convention on Trafficking in Persons (ACTIP) to address the issue of human trafficking, especially within women and children.\n\nDuring an interview at the APEC CEO Summit on November 16, President Aquino announced his participation in the 2015 United Nations Climate Change Conference in Paris, amidst the aftermath of the recent Paris attacks. On November 26, Department of Foreign Affairs Assistant Secretary Maria Cleofe Natividad announced that President Aquino would also undertake a working visit to Rome, where he would meet with Italian President Sergio Mattarella and Italian Prime Minister Matteo Renzi and have an audience with Pope Francis in Vatican City to reciprocate the pope's visit to the Philippines the previous January. At the Climate Change Conference in Paris, President Aquino delivered a three-minute speech \"that highlights Philippine response to the impact of climate change and campaign for the inclusion of human rights, the vulnerability of indigenous peoples and gender issues in the Paris agreement.\"\n\nPresident Aquino arrived at the Paris–Le Bourget Airport on Sunday, November 29, at around 6:15 pm CET.\n\nIn 2016, President Aquino made his last official visit.\n\nPresident Aquino attended the special United States-ASEAN Summit hosted by U.S. President Barack Obama from February 15 to 16 at the Sunnylands estate in Rancho Mirage, California, joining the other leaders of the Association of Southeast Asian Nations (ASEAN). According to a statement released by the White House, the summit aims to strengthen cooperation on \"political, security and economic issues\" between the United States and the ASEAN member states under the United States-ASEAN strategic partnership signed in November 2015. Aquino is also expected to raise the issue on the territorial disputes in the South China Sea which the Philippines is a claimant along with Brunei, Malaysia, and Vietnam. On February 16, after participating in the summit, Aquino visited Los Angeles to address the Los Angeles World Affairs Council, which according to the council is regarding the \"new defense agreement between Manila and Washington, security in East Asia, and the future for economic growth in the Philippines and its neighbors in Southeast Asia,\" at the InterContinental hotel in Century City. On February 17, President Aquino received an honorary Doctor of Humane Letters degree from the Loyola Marymount University \"in recognition of his dedication to his country, his integrity, and his embodiment of a Jesuit education.\" He also met with Los Angeles-based investors and the Filipino-American community in Los Angeles, before departing for Manila.\n\n\n"}
{"id": "57201579", "url": "https://en.wikipedia.org/wiki?curid=57201579", "title": "List of presidential trips made by Sebastián Piñera", "text": "List of presidential trips made by Sebastián Piñera\n\nThis is a list of international trips made by Chilean President Sebastián Piñera in his second mandate.\n\nThe following international trips were made by Chilean President Sebastián Piñera in 2018:\n"}
{"id": "1750673", "url": "https://en.wikipedia.org/wiki?curid=1750673", "title": "List of state visits made by Elizabeth II", "text": "List of state visits made by Elizabeth II\n\nSince ascending the throne in 1952, Queen Elizabeth II has undertaken a number of state and official visits as well as trips throughout the Commonwealth, making her the most widely travelled head of state in history. The Queen does not require a British passport for travelling overseas, as all British passports are issued in her name.\n\nAs the sovereign of more than one independent state, Elizabeth II has represented both Canada and the United Kingdom on state visits, though the former on just two occasions. For the countries where Elizabeth II is sovereign, other than the United Kingdom, the relevant governor-general will usually carry out state visits on the Queen's behalf.\n\n"}
{"id": "11485898", "url": "https://en.wikipedia.org/wiki?curid=11485898", "title": "List of towns and cities with 100,000 or more inhabitants/cityname: D", "text": "List of towns and cities with 100,000 or more inhabitants/cityname: D\n\n\n"}
{"id": "11485988", "url": "https://en.wikipedia.org/wiki?curid=11485988", "title": "List of towns and cities with 100,000 or more inhabitants/cityname: I", "text": "List of towns and cities with 100,000 or more inhabitants/cityname: I\n\n\n"}
{"id": "11486115", "url": "https://en.wikipedia.org/wiki?curid=11486115", "title": "List of towns and cities with 100,000 or more inhabitants/cityname: O", "text": "List of towns and cities with 100,000 or more inhabitants/cityname: O\n\n\n"}
{"id": "48311098", "url": "https://en.wikipedia.org/wiki?curid=48311098", "title": "Loxodromic navigation", "text": "Loxodromic navigation\n\nLoxodromic navigation (from Greek \"λοξóς\", oblique, and \"δρóμος\", path) is a method of navigation by following a rhumb line, a curve on the surface of the Earth that follows the same angle at the intersection with each meridian. This serves to maintain a steady course in sailing.\n\nNavigating on a spherical surface with a fixed course (formula_1 in the figure) results in a spiral path that approaches the North Pole for courses ranging from 270º to 090º and the South Pole for courses from 090º to 270º. On a nautical chart plotted according to the Mercator projection, a loxodromic course appears as a straight line.\n\n\n\n"}
{"id": "10397282", "url": "https://en.wikipedia.org/wiki?curid=10397282", "title": "Metres above sea level", "text": "Metres above sea level\n\nMetres above mean sea level (MAMSL) or simply metres above sea level (MASL or m a.s.l.) is a standard metric measurement in metres of the elevation or altitude of a location in reference to a historic mean sea level. Mean sea levels are affected by climate change and other factors and change over time. For this and other reasons, recorded measurements of elevation above sea level might differ from the actual elevation of a given location over sea level at a given moment.\n\nMetres above sea level is the standard measurement of the elevation or altitude of:\n\nThe elevation or altitude in metres above sea level of a location, object, or point can be determined in a number of ways. The most common include:\n\nAccurate measurement of historical mean sea levels is complex. Land mass subsidence (as occurs naturally in some islands) can give the appearance of rising sea levels. Conversely, markings on land masses that are uplifted due to geological processes can suggest a lowering of mean sea level.\n\nFeet above sea level is the most common analogue for metres above sea level in the US customary measurement system.\n\nMetres above sea level is commonly abbreviated mamsl or MAMSL, based on the abbreviation AMSL for above mean sea level. Other abbreviations are m.a.s.l. and MASL.\n\n"}
{"id": "19344100", "url": "https://en.wikipedia.org/wiki?curid=19344100", "title": "Ordnance Survey", "text": "Ordnance Survey\n\nOrdnance Survey (OS) is a national mapping agency in the United Kingdom which covers the island of Great Britain. Since 1 April 2015 it has operated as Ordnance Survey Ltd, a government-owned company, 100% in public ownership. The Ordnance Survey Board remains accountable to the Secretary of State for Business, Energy and Industrial Strategy. It is also a member of the Public Data Group.\n\nThe agency's name indicates its original military purpose (see ordnance and surveying), which was to map Scotland in the wake of the Jacobite rising of 1745. There was also a more general and nationwide need in light of the potential threat of invasion during the Napoleonic Wars.\n\nOrdnance Survey mapping is usually classified as either \"large-scale\" (in other words, more detailed) or \"small-scale\". The Survey's large-scale mapping comprises 1:2,500 maps for urban areas and 1:10,000 more generally. (The latter superseded the 1:10,560 \"six inches to the mile\" scale in the 1950s.) These large scale maps are typically used in professional land-use contexts and were available as sheets until the 1980s, when they were digitised. Small-scale mapping for leisure use includes the 1:25,000 \"Explorer\" series, the 1:50,000 \"Landranger\" series and the 1:250,000 road maps. These are still available in traditional sheet form.\n\nOrdnance Survey maps remain in copyright for fifty years after their publication. Some of the Copyright Libraries hold complete or near-complete collections of pre-digital OS mapping.\n\nThe origins of the Ordnance Survey lie in the aftermath of the Jacobite rising of 1745 which was finally defeated by forces loyal to the government at the Battle of Culloden in 1746. Prince William, Duke of Cumberland realised that the British Army did not have a good map of the Scottish Highlands to locate Jacobite dissenters such as Simon Fraser, 11th Lord Lovat so that they could be put on trial. In 1747, Lieutenant-Colonel David Watson proposed the compilation of a map of the Highlands to help to subjugate the clans. In response, King George II charged Watson with making a military survey of the Highlands under the command of the Duke of Cumberland. Among Watson's assistants were William Roy, Paul Sandby and John Manson. The survey was produced at a scale of 1 inch to 1000 yards (1:36,000) and included \"the Duke of Cumberland's Map\" (primarily by Watson and Roy), now held in the British Library.\n\nRoy later had an illustrious career in the Royal Engineers (RE), rising to the rank of General, and he was largely responsible for the British share of the work in determining the relative positions of the French and British royal observatories. This work was the starting point of the Principal Triangulation of Great Britain (1783–1853), and led to the creation of the Ordnance Survey itself. Roy's technical skills and leadership set the high standard for which Ordnance Survey became known. Work was begun in earnest in 1790 under Roy's supervision, when the Board of Ordnance (a predecessor of part of the modern Ministry of Defence) began a national military survey starting with the south coast of England. Roy's birthplace near Carluke in South Lanarkshire is today marked by a memorial in the form of a large OS trig point.\n\nBy 1791 the Board received the newer Ramsden theodolite (an improved successor to the one that Roy had used in 1784), and work began on mapping southern Great Britain using a five-mile baseline on Hounslow Heath that Roy himself had previously measured; it crosses the present Heathrow Airport. In 1991 Royal Mail marked the bicentenary by issuing a set of postage stamps featuring maps of the Kentish village of Hamstreet.\n\nIn 1801 the first one-inch-to-the-mile (1:63,360 scale) map was published, detailing the county of Kent, with Essex following shortly afterwards. The Kent map was published privately and stopped at the county border, while the Essex maps were published by Ordnance Survey and ignore the county border, setting the trend for future Ordnance Survey maps.\n\nIn the next 20 years about a third of England and Wales was mapped at the same scale (see Principal Triangulation of Great Britain) under the direction of William Mudge, as other military matters took precedence. It took until 1823 to re-establish a relationship with the French survey made by Roy in 1787. By 1810 one inch to the mile maps of most of the south of England were completed, but they were withdrawn from sale between 1811 and 1816 because of security fears. By 1840 the one-inch survey had covered all of Wales and all but the six northernmost counties of England.\n\nIt was hard work: Major Thomas Colby, the longest-serving Director General of Ordnance Survey, walked in 22 days on a reconnaissance in 1819. In 1824, Colby and most of his staff moved to Ireland to work on a six-inches-to-the-mile (1:10,560) valuation survey. The survey of Ireland, county by county, was completed in 1846. The suspicions and tensions it caused in rural Ireland are the subject of Brian Friel's play \"Translations\".\n\nColby was not only involved in the design of specialist measuring equipment. He also established a systematic collection of place names, and reorganised the map-making process to produce clear, accurate plans. Place names were recorded in \"Name Books\", a system first used in Ireland. The instructions for their use were:\n\nWhilst these procedures generally produced excellent results, mistakes were made: for instance, the Pilgrims Way in the North Downs labelled the wrong route, but the name stuck. Similarly, the spelling of Scafell and Scafell Pike copied an error on an earlier map, and was retained as this was the name of a corner of one of the Principal Triangles, despite \"Scawfell\" being the almost universal form at the time.\n\nColby believed in leading from the front, travelling with his men, helping to build camps and, as each survey session drew to a close, arranging mountain-top parties with enormous plum puddings.\n\nThe British Geological Survey was founded in 1835 as the Ordnance Geological Survey under Henry De la Beche, and remained a branch of the Ordnance Survey until 1965. At the same time the uneven quality of the English and Scottish maps was being improved by engravers under Benjamin Baker. By the time Colby retired in 1846, the production of six-inch maps of Ireland was complete. This had led to a demand for similar treatment in England, and work was proceeding on extending the six-inch map to northern England, but only a three-inch scale for most of Scotland.\n\nWhen Colby retired he recommended William Yolland as his successor, but he was considered too young and the less experienced Lewis Alexander Hall was appointed. After a fire in the Tower of London, the headquarters of the survey was moved to Southampton, and Yolland was put in charge, but Hall sent him off to Ireland so that when Hall left in 1854 Yolland was again passed over in favour of Major Henry James. Hall was enthusiastic about extending the survey of the north of England to a scale of 1:2,500. In 1855, the Board of Ordnance was abolished and the Ordnance Survey was placed under the War Office together with the Topographical Survey and the Depot of Military Knowledge. Eventually in 1870 it was transferred to the Office of Works.\n\nThe primary triangulation of the United Kingdom of Roy, Mudge and Yolland was completed by 1841, but was greatly improved by Alexander Ross Clarke who completed a new survey based on Airy's spheroid in 1858, completing the Principal Triangulation. The following year, he completed an initial levelling of the country.\n\nAfter the Ordnance Survey published its first large-scale maps of Ireland in the mid-1830s, the Tithe Commutation Act 1836 led to calls for a similar six-inch to the mile survey in England and Wales. Official procrastination followed, but the development of the railways added to pressure that resulted in the Ordnance Survey Act 1841. This granted a right to enter property for the purpose of the survey. Following a fire at its headquarters at the Tower of London in 1841 the Ordnance Survey relocated to a site in Southampton and was in disarray for several years, with arguments about which scales to use. Major-General Sir Henry James was by then Director General, and he saw how photography could be used to make maps of various scales cheaply and easily. He developed and exploited photozincography, not only to reduce the costs of map production but also to publish facsimiles of nationally important manuscripts. Between 1861 and 1864, a facsimile of the Domesday Book was issued, county by county; and a facsimile of the Gough Map was issued in 1870.\n\nFrom the 1840s, the Ordnance Survey concentrated on the Great Britain \"County Series\", modelled on the earlier Ireland survey. A start was made on mapping the whole country, county by county, at six inches to the mile (1:10,560). In 1854, \"twenty-five inch\" maps were introduced with a scale of 1:2500 (25.344 inches to the mile) and the six inch maps were then based on these twenty-five inch maps. The first edition of the two scales was completed by the 1890s, with a second edition completed in the 1890s and 1900s. From 1907 till the early 1940s, a third edition (or \"second revision\") was begun but never completed: only areas with significant changes on the ground were revised, many two or three times. Meanwhile, publication of the one-inch to the mile series for Great Britain was completed in 1891.\n\nFrom the late 19th century to the early 1940s, the OS produced many \"restricted\" versions of the County Series maps and other War Department sheets for War Office purposes, in a variety of large scales that included details of military significance such as dockyards, naval installations, fortifications and military camps. Apart from a brief period during the disarmament talks of the 1930s, these areas were left blank or incomplete on standard maps. The War Department 1:2500s, unlike the standard issue, were contoured. The de-classified sheets have now been deposited in some of the Copyright Libraries, helping to complete the map-picture of pre-Second World War Britain.\n\nFrom 1824, the OS began a 6 inch (1:10,560) survey of Ireland for taxation purposes but found this to be inadequate for urban areas and adopted the five-foot scale (1:1056) for Irish cities and towns. From 1840, the six-inch standard was adopted in Great Britain for the un-surveyed northern counties and the 1:1056 scale also began to be adopted for urban surveys. Between 1842 and 1895, some 400 towns were mapped at 1:500 (126 inches), 1:528 (120 inches, \"10 foot scale\") or 1:1056 (60 inches), with the remaining towns mapped at 1:2500 (~25 inches). In 1855, the Treasury authorised funding for 1:2500 for rural areas and 1:500 for urban areas. The 1:500 scale was considered more 'rational' than 1:528 and became known as the \"sanitary scale\" since its primary purpose was to support establishment of mains sewerage and water supply. However, a review of the Ordnance Survey in 1892 found that sales of the 1:500 series maps were very poor and the Treasury declined to fund their continuing maintenance, declaring that any revision or new mapping at this scale must be self-financing. Very few towns and cities saw a second edition of the town plans: by 1909 only fourteen places had paid for updates. The review determined that revision of 1:2500 mapping should proceed apace. \n\nThe most detailed mapping of London was the OS's 1:1056 survey between 1862 and 1872, which took 326 sheets to cover the capital; a second edition (that needed 759 sheets due to urban expansion) was completed and brought out between 1891 and 1895. London was unusual in that land registration on transfer of title was made compulsory there in 1900. The 1:1056 sheets were partially revised to provide a basis for HM Land Registry index maps and the OS mapped the whole London County Council area (at 1:1056) at national expense.\n\nFrom 1911 onwardsand mainly between 1911 and 1913the Ordnance Survey photo-enlarged many 1:2500 sheets covering built-up areas to 1:1250 (50.688 inches to the mile) for Land Valuation and Inland Revenue purposes: the increased scale was to provide space for annotations. About a quarter of these 1:1250s were marked \"Partially revised 1912/13\". In areas where there were no further 1:2500s, these partially revised \"fifty inch\" sheets represent the last large-scale revision (larger than six-inch) of the County Series. The County Series mapping was superseded by the Ordnance Survey National Grid 1:1250s, 1:2500s and 1:10,560s after the Second World War.\n\nDuring World War I, the Ordnance Survey was involved in preparing maps of France and Belgium. During World War II, many more maps were created, including:\n\nAfter the war, Colonel Charles Close, then Director General, developed a strategy using covers designed by Ellis Martin to increase sales in the leisure market. In 1920 O. G. S. Crawford was appointed Archaeology Officer and played a prominent role in developing the use of aerial photography to deepen understanding of archaeology.\n\nIn 1935, the Davidson Committee was established to review the Ordnance Survey's future. The new Director General, Major-General Malcolm MacLeod, started the retriangulation of Great Britain, an immense task involving the erection of concrete triangulation pillars (\"trig points\") on prominent hilltops as infallible positions for theodolites. Each measurement made by theodolite during the retriangulation was repeated no fewer than 32 times.\n\nThe Davidson Committee's final report set the Ordnance Survey on course for the 20th century. The metric national grid reference system was launched and a 1:25000-scale series of maps was introduced. The one-inch maps continued to be produced until the 1970s, when they were superseded by the 1:50000-scale seriesas proposed by William Roy more than two centuries earlier.\n\nOrdnance Survey had outgrown its site in the centre of Southampton (made worse by the bomb damage of the Second World War). The bombing during the Blitz devastated Southampton in November 1940 and destroyed most of Ordnance Survey's city centre offices. Staff were dispersed to other buildings and to temporary accommodation at Chessington and Esher, Surrey, where they produced 1:25000 scale maps of France, Italy, Germany and most of the rest of Europe in preparation for its invasion. Until 1969, Ordnance Survey largely remained at its Southampton city centre HQ and at temporary buildings in the suburb of Maybush nearby, when a new purpose-built headquarters was opened in Maybush adjacent to the wartime temporary buildings there. Some of the remaining buildings of the original Southampton city-centre site are now used as part of the city's court complex.\n\nThe new head office building was designed by the Ministry of Public Buildings and Works for 4000 staff, including many new recruits who were taken on in the late 1960s and early 70s as draughtsmen and surveyors. The buildings originally contained factory-floor space for photographic processes such as heliozincography and map printing, as well as large buildings for storing flat maps. Above the industrial areas are extensive office areas. The complex is notable for its concrete mural by sculptor Keith McCarter and the concrete elliptical paraboloid shell roof over the staff restaurant building.\n\nIn 1995, Ordnance Survey digitised the last of about 230,000 maps, making the United Kingdom the first country in the world to complete a programme of large-scale electronic mapping. In 1999 the agency was designated a Trading Fund, required to cover its costs by charging for its products and to remit a proportion of its profits to the Treasury. Officially, it is now a civilian organisation with executive agency status.\n\nBy the late 1990s technological developments had eliminated the need for vast areas for storing maps and for making printing plates by hand. Although there was a small computer section at Ordnance Survey in the 1960s, the digitising programme had replaced the need for printing large-scale maps, while computer-to-plate technology (in the form of a single machine) had also rendered the photographic platemaking areas obsolete. Part of the latter was converted into a new conference centre in 2000, which was used for internal events and also made available for external organisations to hire.\n\nIn 2010, OS announced that printing and warehouse operations were to be outsourced, ending over 200 years of in-house printing. The Frome-based firm Butler, Tanner and Dennis (BT&D) secured its printing contract. As already stated, large-scale maps had not been printed at Ordnance Survey since the common availability of geographical information systems (GISs), but, until late 2010, the \"OS Explorer\" and \"OS Landranger\" series were printed in Maybush.\n\nIn April 2009 building began of a new head office in Adanac Park on the outskirts of Southampton.\n\nBy 10 February 2011 virtually all staff had relocated to the new \"Explorer House\" building and the old site had been sold off and redeveloped. Prince Philip officially opened the new headquarters building on 4 October 2011.\n\nOn 22 January 2015 plans were announced for the organisation to move from a Trading Fund model to a government-owned limited company, with the move completed in April 2015. The organisation remains fully owned by the UK government and retains many of the features of a public organisation.\n\nOn 6 March 2015 a new CEO was announced to replace Vanessa Lawrence, who had left in 2014. Nigel Clifford, CEO of Procserve Holdings Ltd, was appointed by Business Minister Matthew Hancock.\n\nIn September 2015 the history of the Ordnance Survey was the subject of a BBC Four TV documentary entitled \"A Very British Map: The Ordnance Survey Story\".\n\nOrdnance Survey produces a large range of paper maps and digital mapping products.\n\nOrdnance Survey produces a wide variety of different products aimed at business users, such as utility companies and local authorities. The data is supplied by Ordnance Survey on optical media or increasingly, via the Internet. Products can be downloaded via FTP or accessed 'on demand' via a web browser. Organisations using Ordnance Survey data have to purchase a licence to do so. Some of the main products are:\n\n\nOS's range of leisure maps are published in a variety of scales:\n\n\nUntil 2010, OS also produced the following:\nThese, along with fifteen \"Tour\" maps, were discontinued during January 2010 as part of a drive for cost-efficiency.\n\nThe \"Road\" series was reintroduced in September 2016.\n\nIn 2013, Ordnance Survey released its first official app, OS MapFinder, and has since added three more apps.\n\n\nOrdnance Survey also offers \"OS Custom Made\", a print-on-demand service based on digital raster data that allows a customer to specify the area of the map or maps desired. Two scales are offered1:50,000 (equivalent to 40 km by 40 km) or 1:25,000 (20 km by 20 km)and the maps may be produced either folded or flat for framing or wall mounting. Customers may provide their own titles and cover images for folded maps.\n\nOrdnance Survey also produces more detailed custom mapping to order, at 1:10,000 (\"Landplan\") and at 1:1,250 or 1:500 (\"Siteplan\"), from its large-scale digital data. Custom scales may also be produced from the enlargement or reduction of the existing scales.\n\nOrdnance Survey supplies reproductions of its maps from the early 1970s to the 1990s for educational use. These are widely seen in schools both in Britain and in former British colonies, either as stand-alone geographic aids or as part of geography textbooks or workbooks.\n\nDuring the 2000s, in an attempt to increase schoolchildren's awareness of maps, Ordnance Survey offered a free \"OS Explorer Map\" to every 11-year-old in UK primary education. By the end of 2010, when the scheme closed, over 6 million maps had been given away. The scheme was replaced by free access to the Digimap for Schools service provided by EDINA for eligible schools.\n\nWith the trend away from paper products towards geographical information systems (GISs), Ordnance Survey has been looking into ways of ensuring schoolchildren are made aware of the benefits of GISs and has launched \"MapZone\", an interactive child-orientated website featuring learning resources and map-related games.\n\nOrdnance Survey publishes a quarterly journal, principally for geography teachers, called \"Mapping News\".\n\nOne series of historic maps, published by Cassini Publishing Ltd, is a reprint of the Ordnance Survey first series from the mid-19th century but using the \"OS Landranger\" projection at 1:50,000 and given 1 km gridlines. This means that features from over 150 years ago fit almost exactly over their modern equivalents and modern grid references can be given to old features.\n\nThe digitisation of the data has allowed Ordnance Survey to sell maps electronically. Several companies are now licensed to produce the popular scales (1:50,000 and 1:25,000) and their own derived datasets of the map on CD/DVD or to make them available online for download. The buyer typically has the right to view the maps on a PC, a laptop, and a pocket PC/smartphone, and to print off any number of copies. The accompanying software is GPS-aware, and the maps are ready-calibrated. Thus, the user can quickly transfer the desired area from their PC to their laptop or smartphone, and go for a drive or walk with their position continually pinpointed on the screen. The individual map is more expensive than the equivalent paper version, but the price per square km falls rapidly with the size of coverage bought.\n\nThe Ordnance Survey's original maps were made by triangulation. For the second survey, in 1934, this process was used again and resulted in the building of many triangulation pillars (trig points): short (c. 4 feet/1.2 m high), usually square, concrete or stone pillars at prominent locations such as hill tops. Their precise locations were determined by triangulation, and the details in between were then filled in with less precise methods.\n\nModern Ordnance Survey maps are largely based on aerial photographs, but large numbers of the pillars remain, many of them adopted by private land owners. Ordnance Survey still has a team of surveyors across Great Britain who visit in person and survey areas that cannot be surveyed using photogrammetric methods (such as land obscured by vegetation) and there is an aim of ensuring that any major feature (such as a new motorway or large housing development) is surveyed within six months of being built. While original survey methods were largely manual, the current surveying task is simplified by the use of GPS technology, allowing the most precise surveying standards yet. Ordnance Survey is responsible for a UK-wide network of GPS stations known as \"OS Net\". These are used for surveying and other organisations can purchase the right to utilise the network for their own uses.\n\nOrdnance Survey still maintains a set of master geodetic reference points to tie the Ordnance Survey geographic datum points to modern measurement systems such as GPS. Ordnance Survey maps of Great Britain use the Ordnance Survey National Grid rather than latitude and longitude to indicate position. The Grid is known technically as OSGB36 (Ordnance Survey Great Britain 1936) and was introduced after the 1936–1953 retriangulation.\n\nWhereas cartography is the art and science of mapmaking, cartographic design concerns the map user. It governs the design of a map and it is the cartography that ensures the intended message is delivered both efficiently and aesthetically.\n\nOrdnance Survey's CartoDesign team performs a key role in the organisation, as the authority for cartographic design and development, and engages with internal and external audiences to promote and communicate the value of cartography. They work on a broad range of projects and are responsible for styling all new products and services.\n\nOrdnance Survey's flagship digital product, launched in November 2001, is \"OS MasterMap\", a database that records, in one continuous digital map, every fixed feature of Great Britain larger than a few metres. Every feature is given a unique TOID (TOpographical IDentifier), a simple identifier that includes no semantic information. Typically, each TOID is associated with a polygon that represents the area on the ground that the feature covers, in National Grid coordinates.\n\nOS MasterMap is offered in themed layers, each linked to a number of TOIDs. As of September 2010, the layers are:\n\n\nPricing of licenses to \"OS MasterMap\" data depends on the total area requested, the layers licensed, the number of TOIDs in the layers, and the period in years of the data usage. \"OS MasterMap\" can be used to generate maps for a vast array of purposes and maps can be printed from \"OS MasterMap\" data with detail equivalent to a traditional 1:1250 scale paper map.\n\nOrdnance Survey states that thanks to continuous review, \"OS MasterMap\" data is never more than six months out of date. The scale and detail of this mapping project is unique. By 2009, around 440 million TOIDs had been assigned, and the database stood at 600 gigabytes in size. Currently (March 2011), OS claims 450 million TOIDs. As of 2005, \"OS MasterMap\" was at version 6; 2010's version 8 includes provision for Urban Paths (an extension of the \"integrated transport network\" layer) and pre-build address layer. All these versions have a similar GML schema.\n\nFor several decades Ordnance Survey has had a research department that is active in several areas of geographical information science, including:\n\nOrdnance Survey actively supports the academic research community through its external research and university liaison team. The research department actively supports MSc and PhD students as well as engaging in collaborative research. Most Ordnance Survey products are available to UK universities that have signed up to the Digimap agreement and data is also made available for research purposes that advances Ordnance Survey's own research agenda.\n\nMore information can be found at Ordnance Survey Research.\n\nOrdnance Survey has been subject to criticism. Most centres on the point that Ordnance Survey possesses a virtual government monopoly on geographic data in the UK, but, although a government agency, it has been required to act as a Trading Fund (i.e. a commercial entity) from 1999 to 2015. This meant that it is supposed to be entirely self-funded from the commercial sale of its data and derived products whilst at the same time the public supplier of geographical information. In 1985, the Committee of Enquiry into the Handling of Geographic Information was set up to \"advise the Secretary of State for the Environment within two years on the future handling of geographic information in the UK, taking account of modern developments in information technology and market needs\". The Committee's final report, published in 1987 under the name of its chairman Roger Chorley, stressed the importance of accessible geographic information to the UK and recommended a loosening of policies on distribution and cost recovery.\n\nIn 2007 Ordnance Survey were criticised for contracting the public relations company Mandate Communications to understand the dynamics of the free data movement and discover which politicians and advisers continued to support their current policies.\n\nIn response to the feedback from a consultation, the government announced that a package of Ordnance Survey data sets would be released for free use and re-use. On 1 April 2010 Ordnance Survey released the brand \"OS OpenData\" under an attribution-only license compatible with CC-by. Various groups and individuals had campaigned for this release of data, but some were disappointed when some of the profitable datasets, including the leisure 1:50,000 scale and 1:25,000 scale mapping, as well as the low scale Mastermap were not included. These were withheld with the counter-argument that if licensees do not pay for OS data collection then the government would have to be willing to foot a £30 million per annum bill to obtain the future economic benefit of sharing the mapping.\n\nIn mid-2013 Ordnance Survey described an \"enhanced\" linked-data service with a SPARQL 1.1-compliant endpoint and bulk-download options.\n\nIn June 2018, following the recommendations of the Geospatial Commission it was announced that parts of OS Mastermap would be released under the Open Government Licence would include:\n\nHowever, these would only be free within a usage threshold that was yet to be defined at the release of the announcement.\n\nOrdnance Survey historical works are generally available, as the agency is covered by Crown Copyright: works more than fifty years old, including historic surveys of Britain and Ireland and much of the New Popular Edition, are in the public domain. However, finding suitable originals remains an issue as Ordnance Survey does not provide historical mapping on 'free' terms, instead marketing commercially 'enhanced' reproductions in partnership with companies including GroundSure and Landmark.\n\nThe National Library of Scotland has been developing its archive to make Ordnance Survey maps for all of Great Britain more easily available through their website.\n\nWikimedia has complete sets of scans of the Old/First series one-inch maps of England and Wales; of the Old/First series one-inch maps of Scotland; of the Seventh Series One-inch maps of Great Britain (1952-1967); of the Third Edition quarter-inch maps of England and Wales ; and of the Fifth Series quarter-inch maps of Great Britain. These sets are complete in the sense of including at least one copy of each of the sheets in the series, not in the sense of including all revision levels.\n\nThe UK approach can be contrasted with, for example, that in the Republic of Ireland in more recent times, where Ordnance Survey Ireland claims regular copyright over its mapping (and over digital copies of the public domain historical mapping). All Ordnance Survey Ireland maps (historic and current) are available free to view on their online website.\n\n\n"}
{"id": "6880840", "url": "https://en.wikipedia.org/wiki?curid=6880840", "title": "Possibilism (geography)", "text": "Possibilism (geography)\n\nPossibilism in cultural geography is the theory that the environment sets certain constraints or limitations, but culture is otherwise determined by social conditions.\nIn Cultural ecology Marshall Sahlins used this concept in order to develop alternative approaches to the environmental determinism dominant at that time in ecological studies. Theory by Strabo in 64 BC that humans can make things happen by their own intelligence over time. Strabo cautioned against the assumption that nature and actions of humans were determined by the physical environment they inhabited. He observed that humans were the active elements in a human-environmental partnership.\n\nThe controversy between geographical \"possibilism\" and \"determinism\" might be considered as one of (at least) three dominant epistemologic controversies of contemporary geography. The other two controversies are 1) the \"debate between neopositivists and neokantians about the \"exceptionalism\" or the specificity of geography as a science [and 2)] the contention between Mackinder and Kropotkin about what is—or should be—geography\".\n\n\"Possibilism\" in geography is, thus, considered as a distinct approach to geographical knowledge, directly opposed to geographical \"determinism\".\n\n\n"}
{"id": "3659844", "url": "https://en.wikipedia.org/wiki?curid=3659844", "title": "Rankine's method", "text": "Rankine's method\n\nRankine's method is a technique for laying out circular curves by a combination of chaining and angles at circumference, fully exploiting the theodolite and making a substantial improvement in accuracy and productivity over existing methods. \n\nRankine's method is named for its discoverer William John Macquorn Rankine at an early stage of his career. He had been working on railways in Ireland, on the construction of the Dublin and Drogheda line.\n\n"}
{"id": "1440915", "url": "https://en.wikipedia.org/wiki?curid=1440915", "title": "Retriangulation of Great Britain", "text": "Retriangulation of Great Britain\n\nThe retriangulation of Great Britain was a triangulation project carried out between 1935 and 1962 that sought to improve the accuracy of maps made of Great Britain. Data gathered from the retriangulation replaced data gathered during the Principal Triangulation of Great Britain, which had been performed between 1783 and 1851. The retriangulation involved erecting around 6,500 concrete pillars (known as trig points) on British hilltops, which were used as reference points for the triangulation. Today, use of the trig points and the results of the retriangulation have been replaced by a network of GNSS stations known as OS Net, which is able to achieve an accuracy of over the length of the country compared to achievable by use of the trig points.\n\nThe retriangulation was begun in 1935 by the Director General of the Ordnance Survey, Major-General Malcolm MacLeod. It was directed by the cartographer and mathematician Martin Hotine, head of the Trigonometrical and Levelling Division.\n\nErecting new trig points and making measurements frequently required materials and instruments to be carried on foot, up hills and mountains and to isolated islands, in all kinds of weather. The network of trig points was built and measured between 1936 and 1962, starting with a set of several hundred primary trig points, most of which were placed on high hills so as to be able to link to one another across long distances. In addition, a larger set of roughly six thousand secondary trig points were added to allow the construction of a finer mesh that extended the reference frame of the primary mesh over shorter distances.\n\nThe calculations were constrained; it was hoped to minimise the shifts from the coordinates based on the old triangulation. At eleven primary trig points from Dunnose on the Isle of Wight (456784 m E, 080150 m N) north to Great Whernside in Yorkshire (400202 E, 473904 N) the new lat-lons were adjusted to stay within a metre of the old ones. Once the new Latitude and Longitude of those eleven points were fixed the calculated location of every other point in the triangulation was based on them. By the time the retriangulation was completed, electronic distance measurement devices had come into use which could have greatly reduced the overall error (it now seems Great Britain is 20+ metres shorter than OSGB36 implies) but starting over from scratch was out of the question.\n\n\n\n"}
{"id": "292617", "url": "https://en.wikipedia.org/wiki?curid=292617", "title": "Southern Levant", "text": "Southern Levant\n\nThe Southern Levant is a geographical region encompassing the southern half of the Levant. It corresponds approximately to modern-day Israel, Palestine, and Jordan; some definitions also include southern Lebanon, southern Syria and/or the Sinai Peninsula. As a strictly geographical description, it is sometimes used by archaeologists and historians to avoid the religious and political connotations of other names for the area.\n\nLike much of Southwestern Asia, the Southern Levant is an arid region consisting mostly of desert and dry steppe, with a thin strip of wetter, temperate climate along the Mediterranean coast. Geographically it is dominated by the Jordan Valley, a section of the Great Rift Valley bisecting the region from north to south, and containing the Sea of Galilee, the Jordan River and the Dead Sea – the lowest point on the earth's land surface.\n\nThe Southern Levant has a long history and is one of the areas of the world most intensively investigated by archaeologists. It is considered likely to be the first place that both early hominins and modern humans colonised outside of Africa. Consequently, it has a rich Stone Age archaeology, stretching back as early as 1.5 million years ago.\n\nThe Southern Levant refers to the lower half of the Levant but there is some variance of geographical definition, with the widest definition including Israel, Palestine, Jordan, Lebanon, southern Syria and the Sinai Desert. In the field of archaeology, the southern Levant is \"the region formerly identified as Syria-Palestine and including Canaan.\"\n\nMany scholars studying the region's archaeology have adopted the term Levant (including northern and southern halves) as the \"term of choice\" due to it being a \"wider, yet relevant, cultural corpus\" that does not have the \"political overtones\" of Syria-Palestine. A survey of North American dissertations shows the \"overwhelming emphasis and scope of these works has been the southern Levant, an area formerly identified as Syria-Palestine including Canaan\", but with most modern Ph.D. dissertations using the terms ‘Israel’ and ‘Canaan’.\n\nThe term Southern Levant has also been criticized as imprecise and an awkward name. The term Southern Levant has been described in academic discourse as a \"at least a strictly geographical\" description of the region, avoiding religious and political connotations of names such as \"Canaan\", \"Holy Land\", \"Land of Israel\", or \"Palestine\".\n\nThe Southern Levant lies on the eastern coast of the Mediterranean Sea, in the world region known variously as the Near East, the Middle East or Western or Southwestern Asia. It is bordered to the east, southeast and southwest by the Syrian, Arabian and Sinai deserts, respectively. Some definitions include parts of these deserts in the region. The Litani River is commonly considered the dividing line between the Southern Levant and the Northern Levant (i.e. Syria), or sometimes the Orontes River, also in central Lebanon.\n\nFor the most part, the climate of the Southern Levant is arid or semi-arid, however a narrow strip along the coast experiences a temperate, Mediterranean climate due to its proximity to the sea. Average annual rainfall decreases sharply away from the coast, from over per year in Galilee, to in the Rift Valley, and less than in the eastern deserts and the Negev. Across the region, precipitation is both highly seasonal―most rain falls between October and May, and hardly any in the summer—and subject to large, unpredictable interannual variation. Temperature is also highly variable, with cool winters and hot summers.\n\nThe Jordan River bisects much of the region into the Cisjordan and Transjordan. The Huleh basin feeds into the upper Jordan, which moves southward through a natural basalt barrier into the Sea of Galilee before dropping several hundred metres as it flows through the Jordan Valley. The Jordan River terminates at the Dead Sea, whose banks, at below sea level, are the world's lowest point on dry land.\n\nThe archaeology of the southern Levant is generally conceived as a series of phases or stages in human cultural and evolutionary development based, for the most part, on tool technology for early pre-historic, proto-historic and early historic periods. Later phases are generally associated with historical periods and are named accordingly. While there is no single, accepted sequence that all archaeologists agree upon, the basic conventions indicate a number of Stone Ages, followed by a Copper/Stone age, in turn followed by a Bronze Age. The names given to them, derived from the Greek, are also used widely for other regions. The different ages in turn are often divided up into sequential or sometimes parallel chrono-cultural facies, sometimes called “cultures” or “periods”. Sometimes their names are derived from European prehistory, at other times from local sites, often where they were first discovered.\n\nArchaeologically, it is among the most extensively excavated regions in the world.\n\nThe Southern Levant is amongst the oldest inhabited parts of Eurasia, being on one of three plausible routes by which early hominins could have dispersed out of Africa (along with the Bab al Mandab and the Strait of Gibraltar). \"Homo erectus\" left Africa and became the first hominin species to colonise Europe and Asia approximately two million years ago, probably via the Southern Levant. During this phase of the Pleistocene epoch the region was wetter and greener, allowing \"H. erectus\" to find places with fresh water as it followed other African animals that were dispersing out of Africa at the same time. One such location was 'Ubeidiya, on the southern shore of the Sea of Galilee, where some of the oldest hominin remains in Eurasia have been discovered, dating to between 1.2 million and 1.5 million years ago.\n\nSeveral stone ages, when stone tools prevailed and make up the bulk of artifacts, are followed by periods when other technologies came into use. They lent their names to the different periods. The basic framework for the southern Levant is, as follows: Paleolithic or Old Stone Age is often divided up into phases called, from early-to-late: Lower Paleolithic, Middle Paleolithic and Upper Paleolithic. An Epipaleolithic (latest Paleolithic) period, also known as Mesolithic (transition to Neolithic) follows and is, in turn succeeded by a Neolithic (New Stone Age).\n\nThe following Chalcolithic period includes the first evidence of metallurgy with copper making its appearance. However, as stone technology remains prevalent, the name, Chalcolithic (Copper/Stone) age combines the two.\n\nBronze is used for the following periods, but is actually a misnomer for a good part of that time. An Early Bronze Age is divided into three major phases, Early Bronze I, II and III, but copper and not bronze was the most common metal in use, while stone technology continued to contribute the bulk of tools. Early Bronze III is followed by another period, alternately named Early Bronze IV, Middle Bronze I, Intermediate Bronze or Early Bronze-Middle Bronze. In this period the name is apt; true bronze (a tin alloy of copper) makes its appearance in this time span.\n\nThe next period is generally known as Middle Bronze II and is generally broken down into two sub-periods, Middle Bronze IIa and Middle Bronze IIb. Some scholars acknowledge a Middle Bronze III. The next period is known as Late Bronze and is often sub-divided into Late Bronze I and II.\n\nThe introduction of iron, although relatively rare, especially in the earliest phases, caused the following phase to be named the Iron Age. It is variously sub-divided into Iron I, Iron II and sometimes Iron III, with subdivisions becoming increasingly popular as sequences become better known. Some archaeologists suggest that there in the transition from the Late Bronze Age to the Early Iron Age, the large cultural differences are explained by foreign invasion, that is, the introduction of new ethnicity. More recent evidence indicates that the large culture changes were not the result of a foreign invasion. Rather, the Iron Age people of the southern Levant were related to their Bronze Age predecessors.\n\nThe post Iron Age is generally thought of as historical and accordingly names of periods reflect this. The very latest Iron Age phase is sometimes called “Assyrian” and the following period is universally known as the Persian period.\n\nThe 333 BC conquest of the region is accepted as the beginning of the Hellenistic period. The Deuterocanonical book 2 Maccabees records: \"Apollonius the son of Tharseas, who at that time was governor of Celesyria and Phenicia\", Celesyria being the transliteration of Coele-Syria. It is followed by Early Roman and Late Roman periods. The 4th century is recognized as the beginning of the Byzantine period that lasted until the Arab conquest of the region.\n\nLater periods are alternately known as Early Arab and sub-periods by the names of reigning dynasties. The Crusader conquest of the region is known, appropriately as the Crusader period and it is followed by a Mameluke period after the conquering dynasty. In 1517 the Ottoman empire conquered the region and gave its name to the period that lasted until 1917, when the British conquered it in World War I.\n\n"}
{"id": "30718", "url": "https://en.wikipedia.org/wiki?curid=30718", "title": "Tide", "text": "Tide\n\nTides are the rise and fall of sea levels caused by the combined effects of the gravitational forces exerted by the Moon and the Sun, and the rotation of Earth.\n\nTide tables can be used to find the predicted times and amplitude (or \"tidal range\") of tides at any given locale. The predictions are influenced by many factors including the alignment of the Sun and Moon, the phase and amplitude of the tide (pattern of tides in the deep ocean), the amphidromic systems of the oceans, and the shape of the coastline and near-shore bathymetry (see \"Timing\"). They are however only predictions, the actual time and height of the tide is affected by wind and atmospheric pressure. Some shorelines experience a semi-diurnal tide—two nearly equal high and low tides each day. Other locations experience a diurnal tide—only one high and low tide each day. A \"mixed tide\"—two uneven tides a day, or one high and one low—is also possible.\n\nTides vary on timescales ranging from hours to years due to a number of factors, which determine the lunitidal interval. To make accurate records, tide gauges at fixed stations measure water level over time. Gauges ignore variations caused by waves with periods shorter than minutes. These data are compared to the reference (or datum) level usually called mean sea level.\n\nWhile tides are usually the largest source of short-term sea-level fluctuations, sea levels are also subject to forces such as wind and barometric pressure changes, resulting in storm surges, especially in shallow seas and near coasts.\n\nTidal phenomena are not limited to the oceans, but can occur in other systems whenever a gravitational field that varies in time and space is present. For example, the shape of the solid part of the Earth is affected slightly by Earth tide, though this is not as easily seen as the water tidal movements.\n\nTide changes proceed via the following stages:\n\nOscillating currents produced by tides are known as tidal streams. The moment that the tidal current ceases is called slack water or slack tide. The tide then reverses direction and is said to be turning. Slack water usually occurs near high water and low water. But there are locations where the moments of slack tide differ significantly from those of high and low water.\n\nTides are commonly \"semi-diurnal\" (two high waters and two low waters each day), or \"diurnal\" (one tidal cycle per day). The two high waters on a given day are typically not the same height (the daily inequality); these are the \"higher high water\" and the \"lower high water\" in tide tables. Similarly, the two low waters each day are the \"higher low water\" and the \"lower low water\". The daily inequality is not consistent and is generally small when the Moon is over the Equator.\n\nFrom the highest level to the lowest:\n\nTidal constituents are the net result of multiple influences impacting tidal changes over certain periods of time. Primary constituents include the Earth's rotation, the position of the Moon and Sun relative to the Earth, the Moon's altitude (elevation) above the Earth's Equator, and bathymetry. Variations with periods of less than half a day are called \"harmonic constituents\". Conversely, cycles of days, months, or years are referred to as \"long period\" constituents.\n\nTidal forces affect the entire earth, but the movement of solid Earth occurs by mere centimeters. In contrast, the atmosphere is much more fluid and compressible so its surface moves by kilometers, in the sense of the contour level of a particular low pressure in the outer atmosphere.\nIn most locations, the largest constituent is the \"principal lunar semi-diurnal\", also known as the \"M2\" (or \"M\") tidal constituent. Its period is about 12 hours and 25.2 minutes, exactly half a \"tidal lunar day\", which is the average time separating one lunar zenith from the next, and thus is the time required for the Earth to rotate once relative to the Moon. Simple tide clocks track this constituent. The lunar day is longer than the Earth day because the Moon orbits in the same direction the Earth spins. This is analogous to the minute hand on a watch crossing the hour hand at 12:00 and then again at about 1:05½ (not at 1:00).\n\nThe Moon orbits the Earth in the same direction as the Earth rotates on its axis, so it takes slightly more than a day—about 24 hours and 50 minutes—for the Moon to return to the same location in the sky. During this time, it has passed overhead (culmination) once and underfoot once (at an hour angle of 00:00 and 12:00 respectively), so in many places the period of strongest tidal forcing is the above-mentioned, about 12 hours and 25 minutes. The moment of highest tide is not necessarily when the Moon is nearest to zenith or nadir, but the period of the forcing still determines the time between high tides.\n\nBecause the gravitational field created by the Moon weakens with distance from the Moon, it exerts a slightly stronger than average force on the side of the Earth facing the Moon, and a slightly weaker force on the opposite side. The Moon thus tends to \"stretch\" the Earth slightly along the line connecting the two bodies. The solid Earth deforms a bit, but ocean water, being fluid, is free to move much more in response to the tidal force, particularly horizontally. As the Earth rotates, the magnitude and direction of the tidal force at any particular point on the Earth's surface change constantly; although the ocean never reaches equilibrium—there is never time for the fluid to \"catch up\" to the state it would eventually reach if the tidal force were constant—the changing tidal force nonetheless causes rhythmic changes in sea surface height.\n\nWhen there are two high tides each day with different heights (and two low tides also of different heights), the pattern is called a \"mixed semi-diurnal tide\".\n\nThe semi-diurnal range (the difference in height between high and low waters over about half a day) varies in a two-week cycle. Approximately twice a month, around new moon and full moon when the Sun, Moon, and Earth form a line (a configuration known as a syzygy), the tidal force due to the Sun reinforces that due to the Moon. The tide's range is then at its maximum; this is called the spring tide. It is not named after the season, but, like that word, derives from the meaning \"jump, burst forth, rise\", as in a natural spring.\n\nWhen the Moon is at first quarter or third quarter, the Sun and Moon are separated by 90° when viewed from the Earth, and the solar tidal force partially cancels the Moon's tidal force. At these points in the lunar cycle, the tide's range is at its minimum; this is called the neap tide, or neaps. Neap is an Anglo-Saxon word meaning \"without the power\", as in \"forðganges nip\" (forth-going without-the-power).\n\nSpring tides result in high waters that are higher than average, low waters that are lower than average, 'slack water' time that is shorter than average, and stronger tidal currents than average. Neaps result in less extreme tidal conditions. There is about a seven-day interval between springs and neaps.\n\nThe changing distance separating the Moon and Earth also affects tide heights. When the Moon is closest, at perigee, the range increases, and when it is at apogee, the range shrinks. Every lunations (the full cycles from full moon to new to full), perigee coincides with either a new or full moon causing perigean spring tides with the largest \"tidal range\". Even at its most powerful this force is still weak, causing tidal differences of inches at most.\n\nThese include solar gravitational effects, the obliquity (tilt) of the Earth's Equator and rotational axis, the inclination of the plane of the lunar orbit and the elliptical shape of the Earth's orbit of the Sun.\n\nA compound tide (or overtide) results from the shallow-water interaction of its two parent waves.\n\nBecause the \"M\" tidal constituent dominates in most locations, the stage or \"phase\" of a tide, denoted by the time in hours after high water, is a useful concept. Tidal stage is also measured in degrees, with 360° per tidal cycle. Lines of constant tidal phase are called \"cotidal lines\", which are analogous to contour lines of constant altitude on topographical maps. High water is reached simultaneously along the cotidal lines extending from the coast out into the ocean, and cotidal lines (and hence tidal phases) advance along the coast. Semi-diurnal and long phase constituents are measured from high water, diurnal from maximum flood tide. This and the discussion that follows is precisely true only for a single tidal constituent.\n\nFor an ocean in the shape of a circular basin enclosed by a coastline, the \"cotidal lines\" point radially inward and must eventually meet at a common point, the amphidromic point. The amphidromic point is at once cotidal with high and low waters, which is satisfied by \"zero\" tidal motion. (The rare exception occurs when the tide encircles an island, as it does around New Zealand, Iceland and Madagascar.) Tidal motion generally lessens moving away from continental coasts, so that crossing the cotidal lines are contours of constant \"amplitude\" (half the distance between high and low water) which decrease to zero at the amphidromic point. For a semi-diurnal tide the amphidromic point can be thought of roughly like the center of a clock face, with the hour hand pointing in the direction of the high water cotidal line, which is directly opposite the low water cotidal line. High water rotates about the amphidromic point once every 12 hours in the direction of rising cotidal lines, and away from ebbing cotidal lines. This rotation, caused by the Coriolis effect, is generally clockwise in the southern hemisphere and counterclockwise in the northern hemisphere. The difference of cotidal phase from the phase of a reference tide is the \"epoch\". The reference tide is the hypothetical constituent \"equilibrium tide\" on a landless Earth measured at 0° longitude, the Greenwich meridian.\n\nIn the North Atlantic, because the cotidal lines circulate counterclockwise around the amphidromic point, the high tide passes New York Harbor approximately an hour ahead of Norfolk Harbor. South of Cape Hatteras the tidal forces are more complex, and cannot be predicted reliably based on the North Atlantic cotidal lines.\n\nInvestigation into tidal physics was important in the early development of celestial mechanics, with the existence of two daily tides being explained by the Moon's gravity. Later the daily tides were explained more precisely by the interaction of the Moon's and the Sun's gravity.\n\nSeleucus of Seleucia theorized around 150 B.C. that tides were caused by the Moon. The influence of the Moon on bodies of water was also mentioned in Ptolemy's \"Tetrabiblos\".\n\nIn \"De temporum ratione\" (\"The Reckoning of Time\") of 725 Bede linked semidurnal tides and the phenomenon of varying tidal heights to the Moon and its phases. Bede starts by noting that the tides rise and fall 4/5 of an hour later each day, just as the Moon rises and sets 4/5 of an hour later. He goes on to emphasise that in two lunar months (59 days) the Moon circles the Earth 57 times and there are 114 tides. Bede then observes that the height of a tides varies over the month. Increasing tides are called \"malinae\" and decreasing tides \"ledones\" and that the month is divided into four parts of seven or eight days with alternating \"malinae\" and \"ledones\". In the same passage he also notes the effect of winds to hold back tides.\n\nMedieval understanding of the tides was primarily based on works of Muslim astronomers, which became available through Latin translation starting from the 12th century. Abu Ma'shar (d. circa 886), in his \"Introductorium in astronomiam\", taught that ebb and flood tides were caused by the Moon. Abu Ma'shar discussed the effects of wind and Moon's phases relative to the Sun on the tides. In the 12th century, al-Bitruji (d. circa 1204) contributed the notion that the tides were caused by the general circulation of the heavens.\n\nSimon Stevin in his 1608 \"De spiegheling der Ebbenvloet\", The theory of ebb and flood, dismissed a large number of misconceptions that still existed about ebb and flood. Stevin pleaded for the idea that the attraction of the Moon was responsible for the tides and spoke in clear terms about ebb, flood, spring tide and neap tide, stressing that further research needed to be made.\n\nIn 1609 Johannes Kepler also correctly suggested that the gravitation of the Moon caused the tides, which he based upon ancient observations and correlations.\n\nGalileo Galilei in his 1632 \"Dialogue Concerning the Two Chief World Systems\", whose working title was \"Dialogue on the Tides\", gave an explanation of the tides. The resulting theory, however, was incorrect as he attributed the tides to the sloshing of water caused by the Earth's movement around the Sun. He hoped to provide mechanical proof of the Earth's movement. The value of his tidal theory is disputed. Galileo rejected Kepler's explanation of the tides.\n\nIsaac Newton (1642–1727) was the first person to explain tides as the product of the gravitational attraction of astronomical masses. His explanation of the tides (and many other phenomena) was published in the \"Principia\" (1687) and used his theory of universal gravitation to explain the lunar and solar attractions as the origin of the tide-generating forces.\nNewton and others before Pierre-Simon Laplace worked the problem from the perspective of a static system (equilibrium theory), that provided an approximation that described the tides that would occur in a non-inertial ocean evenly covering the whole Earth. The tide-generating force (or its corresponding potential) is still relevant to tidal theory, but as an intermediate quantity (forcing function) rather than as a final result; theory must also consider the Earth's accumulated dynamic tidal response to the applied forces, which response is influenced by ocean depth, the Earth's rotation, and other factors.\n\nIn 1740, the Académie Royale des Sciences in Paris offered a prize for the best theoretical essay on tides. Daniel Bernoulli, Leonhard Euler, Colin Maclaurin and Antoine Cavalleri shared the prize.\n\nMaclaurin used Newton's theory to show that a smooth sphere covered by a sufficiently deep ocean under the tidal force of a single deforming body is a prolate spheroid (essentially a three-dimensional oval) with major axis directed toward the deforming body. Maclaurin was the first to write about the Earth's rotational effects on motion. Euler realized that the tidal force's \"horizontal\" component (more than the vertical) drives the tide. In 1744 Jean le Rond d'Alembert studied tidal equations for the atmosphere which did not include rotation.\n\nIn 1770 James Cook's barque HMS \"Endeavour\" grounded on the Great Barrier Reef. Attempts were made to refloat her on the following tide which failed, but the tide after that lifted her clear with ease. Whilst she was being repaired in the mouth of the Endeavour River Cook observed the tides over a period of seven weeks. At neap tides both tides in a day were similar, but at springs the tides rose in the morning but in the evening.\n\nPierre-Simon Laplace formulated a system of partial differential equations relating the ocean's horizontal flow to its surface height, the first major dynamic theory for water tides. The Laplace tidal equations are still in use today. William Thomson, 1st Baron Kelvin, rewrote Laplace's equations in terms of vorticity which allowed for solutions describing tidally driven coastally trapped waves, known as Kelvin waves.\n\nOthers including Kelvin and Henri Poincaré further developed Laplace's theory. Based on these developments and the lunar theory of E W Brown describing the motions of the Moon, Arthur Thomas Doodson developed and published in 1921 the first modern development of the tide-generating potential in harmonic form: Doodson distinguished 388 tidal frequencies. Some of his methods remain in use.\n\nThe tidal force produced by a massive object (Moon, hereafter) on a small particle located on or in an extensive body (Earth, hereafter) is the vector difference between the gravitational force exerted by the Moon on the particle, and the gravitational force that would be exerted on the particle if it were located at the Earth's center of mass. \n\nWhereas the gravitational force subjected by a celestial body on Earth varies inversely as the square of its distance to the Earth, the maximal tidal force varies inversely as, approximately, the cube of this distance. If the tidal force caused by each body were instead equal to its full gravitational force (which is not the case due to the free fall of the whole Earth, not only the oceans, towards these bodies) a different pattern of tidal forces would be observed, e.g. with a much stronger influence from the Sun than from the Moon: The solar gravitational force on the Earth is on average 179 times stronger than the lunar, but because the Sun is on average 389 times farther from the Earth, its field gradient is weaker. The solar tidal force is 46% as large as the lunar. More precisely, the lunar tidal acceleration (along the Moon–Earth axis, at the Earth's surface) is about 1.1 × 10 \"g\", while the solar tidal acceleration (along the Sun–Earth axis, at the Earth's surface) is about 0.52 × 10 \"g\", where \"g\" is the gravitational acceleration at the Earth's surface. Venus has the largest effect of the other planets, at 0.000113 times the solar effect. The system of the Earth, the Moon and the Sun is an example of a three-body problem, and there is no exact mathematical closed-form expression of their interdependence.\n\nThe ocean's surface is closely approximated by an equipotential surface, (ignoring ocean currents) commonly referred to as the geoid. Since the gravitational force is equal to the potential's gradient, there are no tangential forces on such a surface, and the ocean surface is thus in gravitational equilibrium. Now consider the effect of massive external bodies such as the Moon and Sun. These bodies have strong gravitational fields that diminish with distance and act to alter the shape of an equipotential surface on the Earth. This deformation has a fixed spatial orientation relative to the influencing body. The Earth's rotation relative to this shape causes the daily tidal cycle. The ocean surface moves because of the changing tidal equipotential, rising when the tidal potential is high, which occurs on the parts of the Earth nearest to and furthest from the Moon. When the tidal equipotential changes, the ocean surface is no longer aligned with it, so the apparent direction of the vertical shifts. The surface then experiences a down slope, in the direction that the equipotential has risen.\n\nOcean depths are much smaller than their horizontal extent. Thus, the response to tidal forcing can be modelled using the Laplace tidal equations which incorporate the following features:\n\n\nThe boundary conditions dictate no flow across the coastline and free slip at the bottom.\n\nThe Coriolis effect (inertial force) steers flows moving towards the Equator to the west and flows moving away from the Equator toward the east, allowing coastally trapped waves. Finally, a dissipation term can be added which is an analog to viscosity.\n\nThe theoretical amplitude of oceanic tides caused by the Moon is about at the highest point, which corresponds to the amplitude that would be reached if the ocean possessed a uniform depth, there were no landmasses, and the Earth were rotating in step with the Moon's orbit. The Sun similarly causes tides, of which the theoretical amplitude is about (46% of that of the Moon) with a cycle time of 12 hours. At spring tide the two effects add to each other to a theoretical level of , while at neap tide the theoretical level is reduced to . Since the orbits of the Earth about the Sun, and the Moon about the Earth, are elliptical, tidal amplitudes change somewhat as a result of the varying Earth–Sun and Earth–Moon distances. This causes a variation in the tidal force and theoretical amplitude of about ±18% for the Moon and ±5% for the Sun. If both the Sun and Moon were at their closest positions and aligned at new moon, the theoretical amplitude would reach .\n\nReal amplitudes differ considerably, not only because of depth variations and continental obstacles, but also because wave propagation across the ocean has a natural period of the same order of magnitude as the rotation period: if there were no land masses, it would take about 30 hours for a long wavelength surface wave to propagate along the Equator halfway around the Earth (by comparison, the Earth's lithosphere has a natural period of about 57 minutes). Earth tides, which raise and lower the bottom of the ocean, and the tide's own gravitational self attraction are both significant and further complicate the ocean's response to tidal forces.\n\nEarth's tidal oscillations introduce dissipation at an average rate of about 3.75 terawatts.\nAbout 98% of this dissipation is by marine tidal movement.\nDissipation arises as basin-scale tidal flows drive smaller-scale flows which experience turbulent dissipation. This tidal drag creates torque on the moon that gradually transfers angular momentum to its orbit, and a gradual increase in Earth–moon separation. The equal and opposite torque on the Earth correspondingly decreases its rotational velocity. Thus, over geologic time, the moon recedes from the Earth, at about /year, lengthening the terrestrial day.\nDay length has increased by about 2 hours in the last 600 million years. Assuming (as a crude approximation) that the deceleration rate has been constant, this would imply that 70 million years ago, day length was on the order of 1% shorter with about 4 more days per year.\n\nThe shape of the shoreline and the ocean floor changes the way that tides propagate, so there is no simple, general rule that predicts the time of high water from the Moon's position in the sky. Coastal characteristics such as underwater bathymetry and coastline shape mean that individual location characteristics affect tide forecasting; actual high water time and height may differ from model predictions due to the coastal morphology's effects on tidal flow. However, for a given location the relationship between lunar altitude and the time of high or low tide (the lunitidal interval) is relatively constant and predictable, as is the time of high or low tide relative to other points on the same coast. For example, the high tide at Norfolk, Virginia, U.S., predictably occurs approximately two and a half hours before the Moon passes directly overhead.\n\nLand masses and ocean basins act as barriers against water moving freely around the globe, and their varied shapes and sizes affect the size of tidal frequencies. As a result, tidal patterns vary. For example, in the U.S., the East coast has predominantly semi-diurnal tides, as do Europe's Atlantic coasts, while the West coast predominantly has mixed tides.\n\nFrom ancient times, tidal observation and discussion has increased in sophistication, first marking the daily recurrence, then tides' relationship to the Sun and moon. Pytheas travelled to the British Isles about 325 BC and seems to be the first to have related spring tides to the phase of the moon.\n\nIn the 2nd century BC, the Babylonian astronomer, Seleucus of Seleucia, correctly described the phenomenon of tides in order to support his heliocentric theory. He correctly theorized that tides were caused by the moon, although he believed that the interaction was mediated by the pneuma. He noted that tides varied in time and strength in different parts of the world. According to Strabo (1.1.9), Seleucus was the first to link tides to the lunar attraction, and that the height of the tides depends on the moon's position relative to the Sun.\n\nThe \"Naturalis Historia\" of Pliny the Elder collates many tidal observations, e.g., the spring tides are a few days after (or before) new and full moon and are highest around the equinoxes, though Pliny noted many relationships now regarded as fanciful. In his \"Geography\", Strabo described tides in the Persian Gulf having their greatest range when the moon was furthest from the plane of the Equator. All this despite the relatively small amplitude of Mediterranean basin tides. (The strong currents through the Euripus Strait and the Strait of Messina puzzled Aristotle.) Philostratus discussed tides in Book Five of \"The Life of Apollonius of Tyana\". Philostratus mentions the moon, but attributes tides to \"spirits\". In Europe around 730 AD, the Venerable Bede described how the rising tide on one coast of the British Isles coincided with the fall on the other and described the time progression of high water along the Northumbrian coast.\n\nThe first tide table in China was recorded in 1056 AD primarily for visitors wishing to see the famous tidal bore in the Qiantang River. The first known British tide table is thought to be that of John Wallingford, who died Abbot of St. Albans in 1213, based on high water occurring 48 minutes later each day, and three hours earlier at the Thames mouth than upriver at London.\n\nWilliam Thomson (Lord Kelvin) led the first systematic harmonic analysis of tidal records starting in 1867. The main result was the building of a tide-predicting machine using a system of pulleys to add together six harmonic time functions. It was \"programmed\" by resetting gears and chains to adjust phasing and amplitudes. Similar machines were used until the 1960s.\n\nThe first known sea-level record of an entire spring–neap cycle was made in 1831 on the Navy Dock in the Thames Estuary. Many large ports had automatic tide gauge stations by 1850.\n\nWilliam Whewell first mapped co-tidal lines ending with a nearly global chart in 1836. In order to make these maps consistent, he hypothesized the existence of amphidromes where co-tidal lines meet in the mid-ocean. These points of no tide were confirmed by measurement in 1840 by Captain Hewett, RN, from careful soundings in the North Sea.\n\nThe tidal forces due to the Moon and Sun generate very long waves which travel all around the ocean following the paths shown in co-tidal charts. The time when the crest of the wave reaches a port then gives the time of high water at the port. The time taken for the wave to travel around the ocean also means that there is a delay between the phases of the Moon and their effect on the tide. Springs and neaps in the North Sea, for example, are two days behind the new/full moon and first/third quarter moon. This is called the tide's \"age\".\n\nThe ocean bathymetry greatly influences the tide's exact time and height at a particular coastal point. There are some extreme cases; the Bay of Fundy, on the east coast of Canada, is often stated to have the world's highest tides because of its shape, bathymetry, and its distance from the continental shelf edge. Measurements made in November 1998 at Burntcoat Head in the Bay of Fundy recorded a maximum range of and a highest predicted extreme of .\nSimilar measurements made in March 2002 at Leaf Basin, Ungava Bay in northern Quebec gave similar values (allowing for measurement errors), a maximum range of and a highest predicted extreme of . Ungava Bay and the Bay of Fundy lie similar distances from the continental shelf edge, but Ungava Bay is free of pack ice for about four months every year while the Bay of Fundy rarely freezes.\n\nSouthampton in the United Kingdom has a double high water caused by the interaction between the \"M\" and \"M\" tidal constituents. Portland has double low waters for the same reason. The \"M\" tide is found all along the south coast of the United Kingdom, but its effect is most noticeable between the Isle of Wight and Portland because the \"M\" tide is lowest in this region.\n\nBecause the oscillation modes of the Mediterranean Sea and the Baltic Sea do not coincide with any significant astronomical forcing period, the largest tides are close to their narrow connections with the Atlantic Ocean. Extremely small tides also occur for the same reason in the Gulf of Mexico and Sea of Japan. Elsewhere, as along the southern coast of Australia, low tides can be due to the presence of a nearby amphidrome.\n\nIsaac Newton's theory of gravitation first enabled an explanation of why there were generally two tides a day, not one, and offered hope for a detailed understanding of tidal forces and behavior. Although it may seem that tides could be predicted via a sufficiently detailed knowledge of instantaneous astronomical forcings, the actual tide at a given location is determined by astronomical forces accumulated by the body of water over many days. In addition, accurate results would require detailed knowledge of the shape of all the ocean basins—their bathymetry, and coastline shape.\n\nCurrent procedure for analysing tides follows the method of harmonic analysis introduced in the 1860s by William Thomson. It is based on the principle that the astronomical theories of the motions of Sun and Moon determine a large number of component frequencies, and at each frequency there is a component of force tending to produce tidal motion, but that at each place of interest on the Earth, the tides respond at each frequency with an amplitude and phase peculiar to that locality. At each place of interest, the tide heights are therefore measured for a period of time sufficiently long (usually more than a year in the case of a new port not previously studied) to enable the response at each significant tide-generating frequency to be distinguished by analysis, and to extract the tidal constants for a sufficient number of the strongest known components of the astronomical tidal forces to enable practical tide prediction. The tide heights are expected to follow the tidal force, with a constant amplitude and phase delay for each component. Because astronomical frequencies and phases can be calculated with certainty, the tide height at other times can then be predicted once the response to the harmonic components of the astronomical tide-generating forces has been found.\n\nThe main patterns in the tides are\nThe \"Highest Astronomical Tide\" is the perigean spring tide when both the Sun and Moon are closest to the Earth.\n\nWhen confronted by a periodically varying function, the standard approach is to employ Fourier series, a form of analysis that uses sinusoidal functions as a \"basis\" set, having frequencies that are zero, one, two, three, etc. times the frequency of a particular fundamental cycle. These multiples are called \"harmonics\" of the fundamental frequency, and the process is termed harmonic analysis. If the basis set of sinusoidal functions suit the behaviour being modelled, relatively few harmonic terms need to be added. Orbital paths are very nearly circular, so sinusoidal variations are suitable for tides.\n\nFor the analysis of tide heights, the Fourier series approach has in practice to be made more elaborate than the use of a single frequency and its harmonics. The tidal patterns are decomposed into many sinusoids having many fundamental frequencies, corresponding (as in the lunar theory) to many different combinations of the motions of the Earth, the Moon, and the angles that define the shape and location of their orbits.\n\nFor tides, then, \"harmonic analysis\" is not limited to harmonics of a single frequency. In other words, the harmonies are multiples of many fundamental frequencies, not just of the fundamental frequency of the simpler Fourier series approach. Their representation as a Fourier series having only one fundamental frequency and its (integer) multiples would require many terms, and would be severely limited in the time-range for which it would be valid.\n\nThe study of tide height by harmonic analysis was begun by Laplace, William Thomson (Lord Kelvin), and George Darwin. A.T. Doodson extended their work, introducing the \"Doodson Number\" notation to organise the hundreds of resulting terms. This approach has been the international standard ever since, and the complications arise as follows: the tide-raising force is notionally given by sums of several terms. Each term is of the form\nwhere is the amplitude, is the angular frequency usually given in degrees per hour corresponding to measured in hours, and is the phase offset with regard to the astronomical state at time \"t\" = 0 . There is one term for the Moon and a second term for the Sun. The phase of the first harmonic for the Moon term is called the lunitidal interval or high water interval. The next step is to accommodate the harmonic terms due to the elliptical shape of the orbits. Accordingly, the value of is not a constant but also varying with time, slightly, about some average figure. Replace it then by where A is another sinusoid, similar to the cycles and epicycles of Ptolemaic theory. Accordingly,\nwhich is to say an average value with a sinusoidal variation about it of magnitude , with frequency and phase . Thus the simple term is now the product of two cosine factors:\n\nGiven that for any and \nit is clear that a compound term involving the product of two cosine terms each with their own frequency is the same as \"three\" simple cosine terms that are to be added at the original frequency and also at frequencies which are the sum and difference of the two frequencies of the product term. (Three, not two terms, since the whole expression is formula_5.) Consider further that the tidal force on a location depends also on whether the Moon (or the Sun) is above or below the plane of the Equator, and that these attributes have their own periods also incommensurable with a day and a month, and it is clear that many combinations result. With a careful choice of the basic astronomical frequencies, the Doodson Number annotates the particular additions and differences to form the frequency of each simple cosine term.\n\nRemember that astronomical tides do \"not\" include weather effects. Also, changes to local conditions (sandbank movement, dredging harbour mouths, etc.) away from those prevailing at the measurement time affect the tide's actual timing and magnitude. Organisations quoting a \"highest astronomical tide\" for some location may exaggerate the figure as a safety factor against analytical uncertainties, distance from the nearest measurement point, changes since the last observation time, ground subsidence, etc., to avert liability should an engineering work be overtopped. Special care is needed when assessing the size of a \"weather surge\" by subtracting the astronomical tide from the observed tide.\n\nCareful Fourier data analysis over a nineteen-year period (the \"National Tidal Datum Epoch\" in the U.S.) uses frequencies called the \"tidal harmonic constituents\". Nineteen years is preferred because the Earth, Moon and Sun's relative positions repeat almost exactly in the Metonic cycle of 19 years, which is long enough to include the 18.613 year lunar nodal tidal constituent. This analysis can be done using only the knowledge of the forcing \"period\", but without detailed understanding of the mathematical derivation, which means that useful tidal tables have been constructed for centuries. The resulting amplitudes and phases can then be used to predict the expected tides. These are usually dominated by the constituents near 12 hours (the \"semi-diurnal\" constituents), but there are major constituents near 24 hours (\"diurnal\") as well. Longer term constituents are 14 day or \"fortnightly\", monthly, and semiannual. Semi-diurnal tides dominated coastline, but some areas such as the South China Sea and the Gulf of Mexico are primarily diurnal. In the semi-diurnal areas, the primary constituents \"M\" (lunar) and \"S\" (solar) periods differ slightly, so that the relative phases, and thus the amplitude of the combined tide, change fortnightly (14 day period).\n\nIn the \"M\" plot above, each cotidal line differs by one hour from its neighbors, and the thicker lines show tides in phase with equilibrium at Greenwich. The lines rotate around the amphidromic points counterclockwise in the northern hemisphere so that from Baja California Peninsula to Alaska and from France to Ireland the \"M\" tide propagates northward. In the southern hemisphere this direction is clockwise. On the other hand, \"M\" tide propagates counterclockwise around New Zealand, but this is because the islands act as a dam and permit the tides to have different heights on the islands' opposite sides. (The tides do propagate northward on the east side and southward on the west coast, as predicted by theory.)\n\nThe exception is at Cook Strait where the tidal currents periodically link high to low water. This is because cotidal lines 180° around the amphidromes are in opposite phase, for example high water across from low water at each end of Cook Strait. Each tidal constituent has a different pattern of amplitudes, phases, and amphidromic points, so the \"M\" patterns cannot be used for other tide components.\n\nBecause the Moon is moving in its orbit around the Earth and in the same sense as the Earth's rotation, a point on the Earth must rotate slightly further to catch up so that the time between semidiurnal tides is not twelve but 12.4206 hours—a bit over twenty-five minutes extra. The two peaks are not equal. The two high tides a day alternate in maximum heights: lower high (just under three feet), higher high (just over three feet), and again lower high. Likewise for the low tides.\n\nWhen the Earth, Moon, and Sun are in line (Sun–Earth–Moon, or Sun–Moon–Earth) the two main influences combine to produce spring tides; when the two forces are opposing each other as when the angle Moon–Earth–Sun is close to ninety degrees, neap tides result. As the Moon moves around its orbit it changes from north of the Equator to south of the Equator. The alternation in high tide heights becomes smaller, until they are the same (at the lunar equinox, the Moon is above the Equator), then redevelop but with the other polarity, waxing to a maximum difference and then waning again.\n\nThe tides' influence on current flow is much more difficult to analyse, and data is much more difficult to collect. A tidal height is a simple number which applies to a wide region simultaneously. A flow has both a magnitude and a direction, both of which can vary substantially with depth and over short distances due to local bathymetry. Also, although a water channel's center is the most useful measuring site, mariners object when current-measuring equipment obstructs waterways. A flow proceeding up a curved channel is the same flow, even though its direction varies continuously along the channel. Surprisingly, flood and ebb flows are often not in opposite directions. Flow direction is determined by the upstream channel's shape, not the downstream channel's shape. Likewise, eddies may form in only one flow direction.\n\nNevertheless, current analysis is similar to tidal analysis: in the simple case, at a given location the flood flow is in mostly one direction, and the ebb flow in another direction. Flood velocities are given positive sign, and ebb velocities negative sign. Analysis proceeds as though these are tide heights.\n\nIn more complex situations, the main ebb and flood flows do not dominate. Instead, the flow direction and magnitude trace an ellipse over a tidal cycle (on a polar plot) instead of along the ebb and flood lines. In this case, analysis might proceed along pairs of directions, with the primary and secondary directions at right angles. An alternative is to treat the tidal flows as complex numbers, as each value has both a magnitude and a direction.\n\nTide flow information is most commonly seen on nautical charts, presented as a table of flow speeds and bearings at hourly intervals, with separate tables for spring and neap tides. The timing is relative to high water at some harbour where the tidal behaviour is similar in pattern, though it may be far away.\n\nAs with tide height predictions, tide flow predictions based only on astronomical factors do not incorporate weather conditions, which can \"completely\" change the outcome.\n\nThe tidal flow through Cook Strait between the two main islands of New Zealand is particularly interesting, as the tides on each side of the strait are almost exactly out of phase, so that one side's high water is simultaneous with the other's low water. Strong currents result, with almost zero tidal height change in the strait's center. Yet, although the tidal surge normally flows in one direction for six hours and in the reverse direction for six hours, a particular surge might last eight or ten hours with the reverse surge enfeebled. In especially boisterous weather conditions, the reverse surge might be entirely overcome so that the flow continues in the same direction through three or more surge periods.\n\nA further complication for Cook Strait's flow pattern is that the tide at the north side (e.g. at Nelson) follows the common bi-weekly spring–neap tide cycle (as found along the west side of the country), but the south side's tidal pattern has only \"one\" cycle per month, as on the east side: Wellington, and Napier.\n\nThe graph of Cook Strait's tides shows separately the high water and low water height and time, through November 2007; these are \"not\" measured values but instead are calculated from tidal parameters derived from years-old measurements. Cook Strait's nautical chart offers tidal current information. For instance the January 1979 edition for 41°13·9’S 174°29·6’E (north west of Cape Terawhiti) refers timings to Westport while the January 2004 issue refers to Wellington. Near Cape Terawhiti in the middle of Cook Strait the tidal height variation is almost nil while the tidal current reaches its maximum, especially near the notorious Karori Rip. Aside from weather effects, the actual currents through Cook Strait are influenced by the tidal height differences between the two ends of the strait and as can be seen, only one of the two spring tides at the north end (Nelson) has a counterpart spring tide at the south end (Wellington), so the resulting behaviour follows neither reference harbour.\n\nTidal energy can be extracted by two means: inserting a water turbine into a tidal current, or building ponds that release/admit water through a turbine. In the first case, the energy amount is entirely determined by the timing and tidal current magnitude. However, the best currents may be unavailable because the turbines would obstruct ships. In the second, the impoundment dams are expensive to construct, natural water cycles are completely disrupted, ship navigation is disrupted. However, with multiple ponds, power can be generated at chosen times. So far, there are few installed systems for tidal power generation (most famously, La Rance at Saint Malo, France) which face many difficulties. Aside from environmental issues, simply withstanding corrosion and biological fouling pose engineering challenges.\n\nTidal power proponents point out that, unlike wind power systems, generation levels can be reliably predicted, save for weather effects. While some generation is possible for most of the tidal cycle, in practice turbines lose efficiency at lower operating rates. Since the power available from a flow is proportional to the cube of the flow speed, the times during which high power generation is possible are brief.\n\nTidal flows are important for navigation, and significant errors in position occur if they are not accommodated. Tidal heights are also important; for example many rivers and harbours have a shallow \"bar\" at the entrance which prevents boats with significant draft from entering at low tide.\n\nUntil the advent of automated navigation, competence in calculating tidal effects was important to naval officers. The certificate of examination for lieutenants in the Royal Navy once declared that the prospective officer was able to \"shift his tides\".\n\nTidal flow timings and velocities appear in \"tide charts\" or a tidal stream atlas. Tide charts come in sets. Each chart covers a single hour between one high water and another (they ignore the leftover 24 minutes) and show the average tidal flow for that hour. An arrow on the tidal chart indicates the direction and the average flow speed (usually in knots) for spring and neap tides. If a tide chart is not available, most nautical charts have \"tidal diamonds\" which relate specific points on the chart to a table giving tidal flow direction and speed.\n\nThe standard procedure to counteract tidal effects on navigation is to (1) calculate a \"dead reckoning\" position (or DR) from travel distance and direction, (2) mark the chart (with a vertical cross like a plus sign) and (3) draw a line from the DR in the tide's direction. The distance the tide moves the boat along this line is computed by the tidal speed, and this gives an \"estimated position\" or EP (traditionally marked with a dot in a triangle).\n\nNautical charts display the water's \"charted depth\" at specific locations with \"soundings\" and the use of bathymetric contour lines to depict the submerged surface's shape. These depths are relative to a \"chart datum\", which is typically the water level at the lowest possible astronomical tide (although other datums are commonly used, especially historically, and tides may be lower or higher for meteorological reasons) and are therefore the minimum possible water depth during the tidal cycle. \"Drying heights\" may also be shown on the chart, which are the heights of the exposed seabed at the lowest astronomical tide.\n\nTide tables list each day's high and low water heights and times. To calculate the actual water depth, add the charted depth to the published tide height. Depth for other times can be derived from tidal curves published for major ports. The rule of twelfths can suffice if an accurate curve is not available. This approximation presumes that the increase in depth in the six hours between low and high water is: first hour — 1/12, second — 2/12, third — 3/12, fourth — 3/12, fifth — 2/12, sixth — 1/12.\n\nIntertidal ecology is the study of ecosystems between the low- and high-water lines along a shore. At low water, the intertidal zone is exposed (or \"emersed\"), whereas at high water, it is underwater (or \"immersed\"). Intertidal ecologists therefore study the interactions between intertidal organisms and their environment, as well as among the different species. The most important interactions may vary according to the type of intertidal community. The broadest classifications are based on substrates — rocky shore or soft bottom.\n\nIntertidal organisms experience a highly variable and often hostile environment, and have adapted to cope with and even exploit these conditions. One easily visible feature is vertical zonation, in which the community divides into distinct horizontal bands of specific species at each elevation above low water. A species' ability to cope with desiccation determines its upper limit, while competition with other species sets its lower limit.\n\nHumans use intertidal regions for food and recreation. Overexploitation can damage intertidals directly. Other anthropogenic actions such as introducing invasive species and climate change have large negative effects. Marine Protected Areas are one option communities can apply to protect these areas and aid scientific research.\n\nThe approximately fortnightly tidal cycle has large effects on intertidal and marine organisms. Hence their biological rhythms tend to occur in rough multiples of this period. Many other animals such as the vertebrates, display similar rhythms. Examples include gestation and egg hatching. In humans, the menstrual cycle lasts roughly a lunar month, an even multiple of the tidal period. Such parallels at least hint at the common descent of all animals from a marine ancestor.\n\nWhen oscillating tidal currents in the stratified ocean flow over uneven bottom topography, they generate internal waves with tidal frequencies. Such waves are called \"internal tides\".\n\nShallow areas in otherwise open water can experience rotary tidal currents, flowing in directions that continually change and thus the flow direction (not the flow) completes a full rotation in hours (for example, the Nantucket Shoals).\n\nIn addition to oceanic tides, large lakes can experience small tides and even planets can experience \"atmospheric tides\" and \"Earth tides\". These are continuum mechanical phenomena. The first two take place in fluids. The third affects the Earth's thin solid crust surrounding its semi-liquid interior (with various modifications).\n\nLarge lakes such as Superior and Erie can experience tides of , but these can be masked by meteorologically induced phenomena such as seiche. The tide in Lake Michigan is described as or  inches.\nThis is so small that other larger effects completely mask any tide, and as such these lakes are considered non-tidal.\n\nAtmospheric tides are negligible at ground level and aviation altitudes, masked by weather's much more important effects. Atmospheric tides are both gravitational and thermal in origin and are the dominant dynamics from about , above which the molecular density becomes too low to support fluid behavior.\n\nEarth tides or terrestrial tides affect the entire Earth's mass, which acts similarly to a liquid gyroscope with a very thin crust. The Earth's crust shifts (in/out, east/west, north/south) in response to lunar and solar gravitation, ocean tides, and atmospheric loading. While negligible for most human activities, terrestrial tides' semi-diurnal amplitude can reach about at the Equator— due to the Sun—which is important in GPS calibration and VLBI measurements. Precise astronomical angular measurements require knowledge of the Earth's rotation rate and polar motion, both of which are influenced by Earth tides. The semi-diurnal \"M\" Earth tides are nearly in phase with the Moon with a lag of about two hours.\n\n\"Galactic tides\" are the tidal forces exerted by galaxies on stars within them and satellite galaxies orbiting them. The galactic tide's effects on the Solar System's Oort cloud are believed to cause 90 percent of long-period comets.\n\nTsunamis, the large waves that occur after earthquakes, are sometimes called \"tidal waves\", but this name is given by their \"resemblance\" to the tide, rather than any actual link to the tide. Other phenomena unrelated to tides but using the word \"tide\" are rip tide, storm tide, hurricane tide, and black or red tides. Many of these usages are historic and refer to the earlier meaning of tide as \"a portion of time, a season\".\n\n\n"}
{"id": "2857072", "url": "https://en.wikipedia.org/wiki?curid=2857072", "title": "Triangulated irregular network", "text": "Triangulated irregular network\n\nA triangulated irregular network (TIN) is a representation of a continuous surface consisting entirely of triangular facets, used mainly as Discrete Global Grid in primary elevation modeling. \n\nThe vertices of these triangles are created from field recorded spot elevations through a variety of means including surveying through conventional, Global Positioning System Real-Time Kinematic (GPS RTK), photogrammetry, or some other means. Associated with three-dimensional data (\"x\", \"y\", and \"z\") and topography, TINs are useful for the description and analysis of general horizontal (\"x\" and \"y\") distributions and relationships.\n\nDigital TIN data structures are used in a variety of applications, including geographic information systems (GIS), and computer aided drafting (CAD) for the visual representation of a topographical surface. A TIN is an vector-based representation of the physical land surface or sea bottom, made up of irregularly distributed nodes and lines with three-dimensional coordinates (\"x\", \"y\", and \"z\") that are arranged in a network of non-overlapping triangles.\n\nA TIN comprises a triangular network of vertices, known as mass points, with associated coordinates in three dimensions connected by edges to form a triangular tessellation. Three-dimensional visualizations are readily created by rendering of the triangular facets. In regions where there is little variation in surface height, the points may be widely spaced whereas in areas of more intense variation in height the point density is increased.\n\nA TIN used to represent terrain is often called a digital elevation model (DEM), which can be further used to produce digital surface models (DSM) or digital terrain models (DTM). An advantage of using a TIN over a rasterized digital elevation model (DEM) in mapping and analysis is that the points of a TIN are distributed variably based on an algorithm that determines which points are most necessary to create an accurate representation of the terrain. Data input is therefore flexible and fewer points need to be stored than in a raster DEM, with regularly distributed points. While a TIN may be considered less suited than a raster DEM for certain kinds of GIS applications, such as analysis of a surface's slope and aspect, it is often used in CAD to create contour lines. A DTM and DSM can be formed from a DEM. A DEM can be interpolated from a TIN.\n\nTIN are based on a Delaunay triangulation or constrained Delaunay. Delaunay conforming triangulations are recommended over constrained triangulations. This is because the resulting TINs are likely to contain fewer long, skinny triangles, which are undesirable for surface analysis. Additionally, natural neighbor interpolation and Thiessen (Voronoi) polygon generation can only be performed on Delaunay conforming triangulations. A constrained Delaunay triangulation can be considered when you need to explicitly define certain edges that are guaranteed not to be modified (that is, split into multiple edges) by the triangulator. Constrained Delaunay triangulations are also useful for minimizing the size of a TIN, since they have fewer nodes and triangles where breaklines are not densified.\n\nThe TIN model was developed in the early 1970s as a simple way to build a surface from a set of irregularly spaced points. The first triangulated irregular network program for GIS was written by W. Randolph Franklin, under the direction of David Douglas and Thomas Peucker (Poiker), at Simon Fraser University in 1973.\n\n"}
{"id": "34330145", "url": "https://en.wikipedia.org/wiki?curid=34330145", "title": "United States Geological Survey Library", "text": "United States Geological Survey Library\n\nThe United States Geological Survey Library (USGS Library) is a program within the United States Geological Survey, a scientific bureau within the Department of Interior of the United States government. The USGS operates as a fact-finding research organization with no regulatory responsibility.\n\nThe USGS Library has major branches in Lakewood, Colorado (Denver Federal Center), and Menlo Park, California and smaller, focused research libraries in Flagstaff, Arizona and Lafayette, Louisiana.\n\nToday the United States Geological Survey Library's users have access to over 3 million items: over 1.7 million books and journals, 700,000 maps, 370,000 microforms, 270,000 pamphlets, 260,000 black-and-white photographs, 60,000 color transparencies, 15,000 field record notebooks, and 250 videocassettes. Materials include USGS publications as well as those produced by state and foreign geological surveys, scientific societies, museums, academic institutions, and government scientific agencies. The libraries in Reston and Menlo Park are designated as official depositories for selected U.S. Government publications.\nThe libraries in Reston and Menlo Park have been designated as official Federal Government Depositories providing public access to selected U.S. Government publications.\n\nThe newly revised classification system presented in this report is designed for use in the U.S.\nGeological Survey (USGS) Library and other earth science libraries. Prior to the administration of Fred Boughton Weeks, 1903-1908, the library lacked a classification scheme. The Dewey Decimal system for geologic material was not sufficiently developed to accommodate the range of specialized material collected at the USGS Library, and The Library of Congress Classification System had not yet been published. The library staff and patrons were concerned about continued development of the collection without an acceptable classification scheme.\nMr. Weeks and bibliographer John M. Nickles of the library staff, with the assistance of three\nconsultants from the New York Public Library, developed the USGS classification system designed specifically for an earth science library.\nThe U.S. Geological Survey Library classification system has been designed for earth science\nlibraries. It is a tool for assigning call numbers to earth science and allied pure science materials in order to collect these materials into related subject groups on the library shelves and arrange them alphabetically by author and title. The classification can be used as a retrieval system to access materials through the subject and geographic numbers.\nThe classification scheme has been developed over the years since 1904 to meet the ever-changing needs of increased specialization and the development of new areas of research in the earth sciences.\n\nThe Field Records Collection is an archive of unpublished field notes, correspondence, manuscripts, maps, analysis reports and other data created or collected by USGS geologists during field studies and other project work. The majority of the collection dates from 1879 and relates to work done in the contiguous United States. Materials in the collection represent almost 130 years of scientific investigations by the USGS, from the earliest days of the agency to recently completed projects. Records contributed by approximately 1,200 USGS scientists are presently archived. Located in the Central Region Library in Denver, Colorado, the collection is available for on-premises examination during normal library hours.\nField records and project archives on Alaska are kept in the Alaska Technical Data Unit Field Records Archive.\n\nThe Rare Book Collection of the USGS Library comprises unusual publications, rare books, and maps collected since 1879. Included are historical maps and publications of the Survey, as well as early publications of many federal, state and other geological surveys. Records of select geological societies are also maintained in the collection, such as the Geological Society of Washington, which was founded by John Wesley Powell and other noted scientists after the Civil War. Of special note are many 19th century maps with topics such as American political boundaries, transportation, geology, and mining.\n\nAt an auction in Paris, France, pieces of M. Jules Desnoyers's (1800–1887) library were purchased in 1885 by the USGS Library to start the foreign country collection. M. Desnoyers was a founder and later Secretary of the Société Géologique de France, and in 1834 he was appointed librarian of the Muséum National d'Histoire Naturelle in Paris.\n\nWilliam R. Halliday, M.D. (b. 1926), joined the National Speleological Society in 1947. By the late 1950s he was director of the Western Speleological Survey. His works include Adventure Is Underground (1959), Caves of California (1962), Caves of Washington (1963), Depths of the Earth (1966), Caves and Cavers of the United States (1966), American Caves and Caving (1974), Discovery and Exploration of the Oregon Caves: Oregon Caves National Monument (with Frank K. Walsh; 1976) and, Floyd Collins of Sand Cave: A Photographic Memorial (1998). He donated his private collection of rare and out-of-print books and pamphlets on caves, caving and speleology to the USGS Library in 2000.\n\nDr. Halliday has also donated several collections of private papers, correspondence and research to the University of Washington Library and to the J. Willard Marriott Library of the University of Utah.\n\nIn 1933, the Library acquired the George F. Kunz collection for $1.00 from the estate of the former USGS employee and Vice-President of Tiffany & Co. The George F. Kunz Collection is a significant special collection on gems and minerals including rare books on gemology, the folklore of gemstones through history, lapidary arts and archival gem trade records important to the provenance of named stones such as the \"Hope Diamond.\" Kunz was a former USGS employee, a vice-president of Tiffany & Co., and one of the world's preeminent gem experts. The collection was acquired through the genroisty of Dr. Kunz's heirs, Mrs. Opal Kunz and Mrs. Hans Zinsser. Mr. Walter E. Reid, mining consultant and strong friend of the library, was largely instrumental in securing the Kunz collection.\n\n\"The George F. Kunz Collection is a significant special collection of many rare books, pamphlets, and other unique materials on the acquisition, collecting and lore of jewels and precious stones. Acquired by the US Geological Survey Library in 1933 after the death of George F. Kunz, a noted mineralogist and vice-president of the Tiffany & Co. of New York, the Kunz Collection today is fairly unknown outside of a small circle of gemologists, historians, and art collectors. In this paper, a short biography of George F. Kunz is given, as well as a description of the contents and scope of his collection held in the USGS Library. Some examples of the unique materials held in the collection are shown. How the Kunz Collection is used by library patrons and museums is also discussed. Appended to the paper is a bibliography of the works by and about Dr. Kunz.\"\n\nThe library's map collections have provided invaluable aid to authorities and scientists in times of crisis (the California Northridge earthquake in 1994 and major fires in the nation's forests). Topographic maps have also been used for genealogy research to pinpoint where ancestors lived, locate forgotten cemeteries, provide information on boundary changes, and research natural and man-made changes to areas over time. Planners have used the foreign map collections to study foreign terrain, geologic conditions and natural resources. During WWII, The New York Times (June 11, 1944) reported \"A 'Commando' raid by a group of civilian scientists, a search through obscure seventeenth century French manuscripts, months of study of geological reports, experiments with model beaches – all these were part of the Allied preparations for the invasion of Normandy … The dramatic story of the preparations, which began in … libraries, shifted to laboratories and ended on the shell-swept beaches …\". The collections were consulted for the military interventions in Afghanistan and Iraq. Library maps have provided aid in international disaster areas such as the aftermath of Hurricane Mitch and volcanoes worldwide. A brief mention of a diamond found in the 1906 annual report of the USGS began a trail of research and investigation that led one geologist to prospect for diamonds in Canada.\n\nResponsibility for the Topographic Map Archive was formally transferred to the USGS Library in Reston, Virginia, in March 2003. The Archive includes each U.S. state and territory, in all scales, editions and various printings. With coverage dating from the 1880s when the USGS began publishing standard topographic quadrangles; the Archive is the most complete collection of USGS topographic maps.\n\nThe Heringen Collection, is a group of military texts and maps, looted by the Nazis from European libraries, universities, geological societies, private businesses, homes and offices. Hidden in a potash mine in Heringen, Hesse, Germany, they were transported by the U.S. military at the end of WWII as captured war materials. Some 23,000 reports, books and maps were accepted by the USGS Library and integrated into the main collection. The materials are consulted for research ranging from European road development, water resources use or mining and construction. In 1946, the Heringen Collection was transferred from the U.S. Geological Survey's Military Geology Unit to the Library.\n\nIn an article published in journal, Earth Sciences History, the author says that the results of the German theft of Russian maps influenced the way they made maps for the next two generations. \"The Heringen Collection at the US Geological Survey is a special collection of maps, books and reports stolen by units of the German Wehrmacht (armed forces) as they invaded and occupied countries during World War II. The materials in the Collection came from private, society and public library collections, and were used by military geologists in each German army to help protect its soldiers, to advance their invasion, and to consolidate their occupation. They used the maps of the occupied countries against their peoples. For a generation after the invasion of the Soviet Union, this influenced the way Russian maps were drawn and printed.\"\n\nThe U.S. Antarctic Resource Center (USARC) in Reston, Virginia, is our Nation's depository for Antarctic maps, charts, geodetic ground control, satellite images, aerial photographs, publications, slides, and video tapes. These resources are produced by Antarctic Treaty nations in support of their activities in Antarctica and provided to the USARC in compliance with a standing resolution of the treaty providing for exchange of information. The USGS maintains these materials through an interagency cooperative agreement with the National Science Foundation (NSF), which also supports the USGS Antarctic Mapping Program.\n\nThe Photographic Library is an archive of still photographs and original sketches dating from the 1870s and taken by USGS scientists as part of their field studies. Topics include USGS personnel, earthquakes, volcanoes, geologic hazards and other phenomena, historical mining operations, and earth science photographs. The works of pioneer photographers such as William Henry Jackson, Timothy H. O'Sullivan, Carleton Watkins, John Karl Hillers, Thomas Moran, Andrew J. Russell, E. O. Beaman and William Bell (photographer) are represented in the collection. Some photographs have been used to illustrate publications, but most have never been published.\n\nCongress authorized a Library for the United States Geological Survey (USGS) in 1879. The library was formally established in 1882, with the naming of the first librarian, Charles C. Darwin, and began with a staff of 3 and a collection of 1,400 books. The Act of Congress establishing the USGS authorized the creation of a program for exchanging copies of USGS reports for publications of state, national, and international organizations. The exchange program was modeled after a program used by Dr. Ferdinand V. Hayden when he was head of the Interior Department's U.S. Geological and Geographical Survey of the Territories (1867–1879). The U.S. Geological Survey Library inherited 1,000 volumes of serials from Dr. Hayden's former exchange program, which he had based on the program begun by the Smithsonian Institution in 1846.\nAfter Dr. Hayden died in 1887, his widow donated his personal collection to the U.S. Geological Survey Library. Other early gifts were made by Major John Wesley Powell, second Director of the US Geological Survey, who donated his collection of State Geological Survey reports and the family of Dr. Isaac Lea (Philadelphia publisher and gem collector whose family donated nearly 600 items of his personal library). Dr. William Halliday, a world-renowned speleologist began donating his cave collection in 2003.\n\nIn a review of the USGS Library operations in 1937, William Heers, the Chief Librarian, noted that the library had more than 200,000 books and reports, about 60,000 pamphlets, and also about 60,000 maps, most of these obtained by gift and exchange. Fully half of those researchers who used the library were outside of the US Geological Survey. In service to those outside the government, between 8-10,000 books were loaned out each year through interlibrary loans, both within the continental US and overseas.\n\nIn a review of the USGS Library during its centennial, it was noted that in 1978 the library had acquired nearly 116,000 new items. About 75% of these were journals, of which 10,000 serial, magazine, and other periodical titles were received. In 1978, the library also circulated 105,000 items, made 17,700 interlibrary loans and answered some 27,000 requests for information.\n\nIn March 2012, the USGS Library joined the Biodiversity Heritage Library with the goal of contributing important historical works related to taxonomy as well as relevant USGS publications.\n\nThe U.S. Geological Survey Library system has become the largest earth science library in the world. Materials within the library system include books and maps dating back to the 16th and 17th centuries. Other materials include a nearly complete set of the various State Geological Survey publications and a virtually complete set of USGS topographic maps.\nThe original collection was based on exchange partnerships with domestic and international scientific organizations.\n\n\n"}
{"id": "39474341", "url": "https://en.wikipedia.org/wiki?curid=39474341", "title": "Water remote sensing", "text": "Water remote sensing\n\nWater Remote Sensing studies the color of water through the observation of the spectrum of water leaving radiation. From the study of this spectrum, the concentration of optically active components of the upper layer of the water body can be concluded via specific algorithms.\nWater quality monitoring by remote sensing and close-range instruments has obtained considerable attention since the founding of EU Water Framework Directive.\n\nIf water remote sensing is defined as the observation of the water from a distance in order to describe its color, without taking water samples, the gradual development of understanding of the transparency of natural waters and of the reason of their clarity variability and coloration has been sketched from the times of Henry Hudson (1600) to those of Chandrasekhara Raman (1930). However, the development of water remote sensing techniques (by the use of satellite imaging, aircraft or close range optical devices) didn't start until the early 1970s. These first techniques measured the spectral and thermal differences in the emitted energy from water surfaces. In general, empirical relationships were settled between the spectral properties and the water quality parameters of the water body. In 1974, Ritchie et al. (1974) developed an empirical approach to determine suspended sediments. This kind of empirical models are only able to use to determine water quality parameters of water bodies with similar conditions. In 1992 an analytical approach was used by Schiebe et al. (1992). This approach was based on the optical characteristics of water and water quality parameters to elaborate a physically based model of the relationship between the spectral and physical properties of the surface water studied. This physically based model was successfully applied in order to estimate suspended sediment concentrations.\n\nWater Remote sensing instruments allow to record the color of a water body, which provides information on the presence and abundance of optically active natural water components. The water color spectrum is defined as an apparent optical property (AOP) of the water. This means that the color of the water is influenced by the angular distribution of the light field and by the nature and quantity of the substances in the medium, in this case, water. Thus, the value of this parameter will change with changes in the optical properties and concentrations of the optically active substances in the water, the inherent optical properties or IOPS. The IOPS are independent from the angular distribution of light but they are dependent from the type and substances present in the medium as well. For instance, the diffuse attenuation coefficient of downwelling irradiance, Kd (it is often used as an index of water clarity or ocean turbidity) is defined as an AOP, while the absorption coefficient and the scattering coefficient of the medium are defined as IOPS.\nThere are two different approaches to determine the concentration of optically active water components by the study of the spectra. The first approach consist of empirical algorithms based on statistical relationships and the second approach consists of analytical algorithms based on the inversion of calibrated bio-optical models. Accurate calibration of the relationships/models used is an important condition for successful inversion on water remote sensing techniques and the determination of concentration of water quality parameters from observed spectral remote sensing data.\nThus, these techniques depend on their ability to record these changes in the spectral signature of light backscattered from water surface and relate these recorded changes to water quality parameters via empirical or analytical approaches. Depending of the water constituents of interest and the sensor used, different parts of the spectrum will be analysed.\n\nBy the use of Optical close range devices (e.g. spectrometers, radiometers), airplanes or helicopters (airborne remote sensing) and satellites (space born remote sensing), the light reflected from the water bodies is measured. For instance, algorithms are used to retrieve parameters such as chlorophyll-a(Chl-a) and Suspended Particulate Matter (SPM) concentration, the absorption by colored dissolved organic matter at 440 nm (aCDOM) and secchi depth. The measurement of these values will give an idea about the water quality of the water body being studied. A very high concentration of green pigments like chlorophyll might indicate the presence of an algal bloom, for example, due to eutrophication processes. Thus, the chlorophyll concentration could be used as a proxy or indicator for the trophic condition of a water body. In the same manner, other optical quality parameters such as suspended particles or Suspended Particulate matter (SPM), Colored Dissolved Organic Matter (CDOM), Transparency (Kd), and chlorophyll-a (Chl-a) can be used to monitor water quality.\n\n"}
