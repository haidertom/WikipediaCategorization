{"id": "16701731", "url": "https://en.wikipedia.org/wiki?curid=16701731", "title": "Accrediting Bureau of Health Education Schools", "text": "Accrediting Bureau of Health Education Schools\n\nThe Accrediting Bureau of Health Education Schools (ABHES) is a recognized higher education accreditation organization in the United States specializing in the institutional accreditation of private, postsecondary institutions that offer allied health education programs, and the programmatic accreditation of programs leading to associate degrees or certificates in the medical assistant, medical laboratory technician and surgical technology fields. The ABHES is the only healthcare education accrediting agency that is recognized by the U.S. Department of Education. In addition to recognition by the U.S. Department of Education, the ABHES is also recognized by the American Association of Medical Assistants (AAMA), the American Medical Technologists (AMT) and the Liaison Council for Certification of Surgical Technologists (LLC-ST).\n\nThe organization is based in Falls Church, Virginia.\n\n\n"}
{"id": "55092696", "url": "https://en.wikipedia.org/wiki?curid=55092696", "title": "Anthropomaximology", "text": "Anthropomaximology\n\nAccording to the International Federation of Kinesiology, anthropomaximology is the study of the anatomy, physiology, and mechanics of body movement, especially in humans, and its application to the evaluation and treatment of muscular imbalance or derangement. The concept was developed in the USSR during the 1970s–1980s as a result of numerous Olympic victories. The Soviets utilized anthropomaximology in their athletic training, combining rigorous physical exercise with mental training techniques which allowed the competitors to tap into \"hidden reserves\" and surpass other athletes' endurance.\n"}
{"id": "18208725", "url": "https://en.wikipedia.org/wiki?curid=18208725", "title": "Biorisk", "text": "Biorisk\n\nBiorisk generally refers to the risk associated with biological materials and/or infectious agents. The term has been used frequently for various purposes since the early 1990s. The term is used by regulators, laboratory personnel and industry alike and is used by WHO. WHO/Europe also provides tools and training courses in biosafety and biosecurity.\n\nAn international Laboratory Biorisk Management Standard developed under the auspices of the European Committee for Standardization, defines biorisk as the combination of the probability of occurrence of harm and the severity of that harm where the source of harm is a biological agent or toxin. The source of harm may be an unintentional exposure, accidental release or loss, theft, misuse, diversion, unauthorized access or intentional unauthorized release.\n\nIn Norway, \"Biorisk\" is trademarked by the Norwegian accredited registrar DNV.\n\n"}
{"id": "28077130", "url": "https://en.wikipedia.org/wiki?curid=28077130", "title": "CAB Direct (database)", "text": "CAB Direct (database)\n\nCAB Direct is a source of references for the \"applied life sciences\" It incorporates two bibliographic databases: CAB Abstracts and Global Health. CAB Direct is an access point for multiple bibliographic databases produced by \"CABI\". This database contains 8.8 million bibliographic records, which includes 85,000 full text articles. It also includes noteworthy literature reviews. News articles and reports are also part of this combined database.\n\nIn the U.K., in 1947, the \"Imperial Agricultural Bureaux\" became the \"Commonwealth Agricultural Bureaux\" or \"CAB\". In 1986 the \"Commonwealth Agricultural Bureaux\" became \"CAB International\" or \"CABI\" \n\nCAB Abstracts is an applied life sciences bibliographic database emphasising agricultural literature, which is international in scope. It contains 8 million records, with coverage from 1973 to present day, adding 360,000 abstracts per year. Subject coverage includes agriculture, environment, veterinary sciences, applied economics, food science and nutrition. Database covers international issues in agriculture, forestry, and allied disciplines in the life sciences. Indexed publications are from 120 countries in 50 languages, including English abstracts for most articles. Literature coverage includes journals, proceedings, books, and a large collection of agricultural serials. Other non-journal formats are also indexed. \nCAB Abstracts Archive is a searchable database produced by \"CABI\". It is created from 600 volumes of printed abstracts, which are the collected and published scientific research from 1910 to 1972, and then digitized to form the archive. This archive database contains more than 1.8 million records which covers agriculture, veterinary science, nutrition and the environment. Subject coverage also includes biodiversity, pest control, environmental pollution, animal disease (including zoonotic diseases), nutrition, and food production. Natural resource management includes plant and animal breeding. CAB Abstracts Archive is also indexed in other databases, which also serve as access points. These other databases are \"CAB Direct\", Web of Knowledge, EBSCOhost, OvidSP, and Dialog.\n\nThe following print journals (digitized) comprise CAB Abstracts Archive:\n\nWeed Abstracts, derived from CAB Abstracts, is an abstracts database focused on published research regarding weeds and herbicides. This includes weed biology, encompassing research areas from genetics to ecology, including parasitic, poisonous, allergenic and aquatic weeds. Further coverage includes all topics related to weed control, in both crop and non-crop situations. Research on herbicides, includes formulations, herbicide resistance and the effects of herbicide residues in the environment. 10,000 records are add to this database per year. \n\nWeed Abstracts is updated weekly with summaries from notable English and foreign language journal articles, reports, conferences and books about weeds and herbicides. With the back-file, coverage is from 1990 to present day bringing the total of available research summaries to 130,000 records.\n\nGlobal Health is a bibliographic database which focuses on research literature in public health and medical health science sectors (including practice). Information (see infobox above) in indexed in more than 5000 academic journals, and indexed from other sources such as reports, books and conferences. Global Health contains over 1.2 million scientific records from 1973 to the present, with an addition of 90,000 indexed and abstracted records per year. Sources are abstracted from publications in 158 countries written in 50 languages. Any relevant non-English-language papers are translated into English. Proceedings, patents, thesis papers, electronic publications and relevant but difficult-to-find literature sources are also part of this database. \n\nGlobal Health Archive is a searchable database produced by CABI. It is created from 800,000 records, from six printed abstract journals, which are collected published scientific research from 1910 to 1972, digitized to form the archive. Global Health Archive is also indexed in other databases, which also serve as access points. These other databases are \"CAB Direct\", Web of Knowledge, EBSCOhost, OvidSP, and Dialog.\n\nWhen combined with the \"Global Health\" database indexing coverage can be from 1910 to present day. Hence, coverage is made up of past epidemics, from rates and patterns of disease transmission, duration of pandemics, timing of epidemiological peaks, geographic distribution of diseases, and government preparedness and quarantine provisions. The following can also be taken into account: effects on different age and social groups, severity in developing vs. developed countries, symptoms, causes of mortality - such as secondary problems like pneumonia - and mortality rates. \n\nRecords for this database are derived from the following journals throughout certain years:\n\nSubject coverage includes Public health, Tropical and Communicable diseases, Nutrition, Parasitology, Entomology, and Mycology.\n\nTropical Diseases Bulletin is a bibliographic and abstracts database which focuses on research published regarding infectious diseases and public health in developing countries and the tropics and subtropics. This includes research areas from epidemiology to diagnosis, therapy to disease prevention, tropical medicine, and related aspects of travel medicine. Published research coverage on patients and populations encompasses the health of marginalized populations: immigrants, refugees, and indigenous peoples.\n\nBack-file coverage is from 1990 to present day, with an accessible base of 195,000 abstracts and the addition of 11,000 records per year. As a monthly journal Tropical Diseases Bulletin is also available in print. This print journal has author, subject and serials cited indexes. Coverage of the print back-file is to 1912. A searchable, electronic database version of this journal is part of the \"Global Health Archive\" (see above).\n\nThis indexing database focuses on scientific literature pertaining to all topics in organic farming, in both the temperate and tropical zones. This includes sustainability issues and soil fertility. Coverage is global; literature is obtained from 125 countries. The temporal coverage spans 30 years, 180,000 organic research abstracts, along with the addition of 8000 records per year. Linking to full text articles, guided searches, broad subject categorization along with subject refinement are also provided. The editorial advisory board of this database also commission reviews pertaining to organic farming.\n\nCABI full text repository is integrated into all \"CABI databases\" including CAB Abstracts, and Global Health. Both of these are online and print journals. Coverage includes 70,000 full text articles, through agreements with third party publishers. Eighty percent of the content is exclusive to CABI. \n\nThe full text repository is made up of fifty percent journal articles, and equal percentage of conference (proceeding) papers, and other accessible literature is also included. Eighty percent of the articles are in English and coverage includes 56 countries. Also included in this database are relevant but hard to find materials which crosses disciplines consisting of agriculture, health and the life sciences. Mainstream literature and hard to find materials of equal relevance are given equal access.\n\n\"CABI full text repository\" is indexed in other databases, which also serve as access points, consisting of \"Web of Knowledge (Thomson Reuters)\", \"CAB Direct\", \"OvidSP, Dialog, Dimdi, and EBSCOhost\".\n\n"}
{"id": "3141410", "url": "https://en.wikipedia.org/wiki?curid=3141410", "title": "Child mortality", "text": "Child mortality\n\nChild mortality, also known as child death, refers to the death of children under the age of 14 and encompasses neonatal mortality, under-5 mortality, and mortality of children aged 5–14. Many child deaths go unreported for a variety of reasons, including lack of death registration and lack of data on child migrants. Without accurate data on child deaths, we cannot fully discover and combat the greatest risks to a child's life.\n\nReduction of child mortality is reflected in several of the United Nations' Sustainable Development Goals. Rapid progress has resulted in a significant decline in preventable child deaths since 1990, with the global under-5 mortality rate declining by over half between 1990 and 2016. While in 1990, 12.6 million children under age five died, in 2016 that number fell to 5.6 million children. However, despite advances, there are still 15,000 under-five deaths per day from largely preventable causes. About 80 per cent of these occur in sub-Saharan Africa and South Asia, and just 6 countries account for half of all under-five deaths: India, Nigeria, Pakistan, the Democratic Republic of the Congo, Ethiopia and China. 45% of these children died during the first 28 days of life.\n\nChild mortality refers to number of child deaths under the age of 5 per 1000 live births. However, the child mortality could be simplified into more specific terms such as prenatal, perinatal, Neonatal, infancy and under 5. Prenatal: child death before the birth, Perinatal: child death before one week of birth, Neonatal: child death before 28 days of birth, Infancy: child death before 1st birthday, and child mortality under 5 refer to any deaths from birth to the 5th birthday.\n\nPerinatal mortality rate: Number of child deaths within first week of birth/ total number of birth\n\nNeonatal mortality rate: number of child deaths within first 28 days of life/ total number of birth\n\nInfancy mortality rate: number of child deaths within first 12 months of life/ total number of birth\n\nUnder 5 mortality rates: number of child deaths within 5th birthday/ total number of birth\n\nThe leading causes of death of children under five include:\n\n\nThere is variation of child mortality around the world; countries that are in the second or third stage of the Demographic Transition Mode (DTM) have higher rates of child mortality than countries in the fourth or fifth state of the DTM. Chad infant mortality is about 96 per 1,000 live births. And developed country such as Japan infant mortality is about 2.2 per 1,000 live births. In 2010, there were estimated to 7.6 million child deaths around the world and most of it occurred in less developed countries and 4.7 million died from infection and disorder. Child mortality isn’t only caused by infection and disorder, it is also caused by premature birth, birth defect, new born infection, birth complication, and disease like malaria, sepsis, and diarrhea. In less developed countries, malnutrition is the main source of child mortality. Pneumonia, diarrhea and malaria together are the cause of 1 out of every 3 child deaths before the age of 5 and nearly half of under-five deaths globally are attributable to under nutrition.\n\nChild survival is a field of public health concerned with reducing child mortality. Child survival \ninterventions are designed to address the most common causes of child deaths that occur, which include diarrhea, pneumonia, malaria, and neonatal conditions. Of the portion of children under the age of 5 alone, an estimated 5.6 million children die each year mostly from such preventable causes.\n\nThe child survival strategies and interventions are in line with the fourth Millennium Development Goals (MDGs) which focused on reducing child mortality by 2/3 of children under five before the year 2015. In 2015, the MDGs were replaced with the Sustainable Development Goals (SDGs), which aim to end these deaths by 2030. In order to achieve SDG targets, progress must be accelerated in more than 1/4 of all countries (most of which are in sub-Saharan Africa) in order to achieve targets for under-5 mortality, and in 60 countries (many in sub-Saharan Africa and South Asia) to achieve targets for neonatal mortality. Without accelerated progress, 60 million children under age 5 will die between 2017 and 2030, about half of which would be newborns.\n\nTwo-thirds of child deaths are preventable. Most of the children who die each year could be saved by low-tech, evidence-based, cost-effective measures such as vaccines, antibiotics, micronutrient supplementation, insecticide-treated bed nets, improved family care and breastfeeding practices, and oral rehydration therapy. Empowering women, removing financial and social barriers to accessing basic services, developing innovations that make the supply of critical services more available to the poor and increasing local accountability of health systems are policy interventions that have allowed health systems to improve equity and reduce mortality.\n\nIn developing countries, child mortality rates related to respiratory and diarrheal diseases can be reduced by introducing simple behavioral changes, such as handwashing with soap. This simple action can reduce the rate of mortality from these diseases by almost 50 per cent.\n\nProven, cost-effective interventions can save the lives of millions of children per year. The UN Vaccine division as of 2014 supported 36% of the world's children in order to best improve their survival chances, yet still, low-cost immunization interventions do not reach 30 million children despite success in reducing polio, tetanus, and measles. Measles and tetanus still kill more than 1 million children under 5 each year. Vitamin A supplementation costs only $0.02 cents for each capsule and given 2-3 times a year will prevent blindness and death. Although vitamin A supplementation has been shown to reduce all-cause mortality by 12 to 24 per cent, only 70 per cent of targeted children were reached in 2015. Between 250,000 and 500,000 children become blind every year, with 70 percent of them dying within 12 months. Oral rehydration therapy (ORT) is an effective treatment for lost liquids through diarrhea; yet only 4 in 10 (44 per cent) of children ill with diarrhea are treated with ORT.\n\nEssential newborn care - including immunizing mothers against tetanus, ensuring clean delivery practices in a hygienic birthing environment, drying and wrapping the baby immediately after birth, providing necessary warmth, and promoting immediate and continued breastfeeding, immunization, and treatment of infections with antibiotics - could save the lives of 3 million newborns annually. Improved sanitation and access to clean drinking water can reduce childhood infections and diarrhea. Over 30% of the world's population does not have access to basic sanitation, and 844 million people use unsafe sources of drinking water.\n\nAgencies promoting and implementing child survival activities worldwide include UNICEF and non-governmental organizations; major child survival donors worldwide include the World Bank, the British Government's Department for International Development, the Canadian International Development Agency and the United States Agency for International Development. In the United States, most non-governmental child survival agencies belong to the CORE Group, a coalition working, through collaborative action, to save the lives of young children in the world's poorest countries.\n\nChild mortality has been dropping as each country reaches a high stage of DTM. From 2000 to 2010, child mortality has dropped from 9.6 million to 7.6 million. In order to reduce child mortality rates, there needs to be better education, higher standards of healthcare and more caution in childbearing. Child mortality could be reduced by attendance of professionals at birth and by breastfeeding and through access to clean water, sanitation, and immunization. In 2016, the world average was 41 (4.1%), down from 93 (9.3%) in 1990. This is equivalent to 5.6 million children less than five years old dying in 2016.\n\nHuge disparities in under-5 mortality rates exist. Globally, the risk of a child dying in the country with the highest under-5 mortality rate is about 60 times higher than in the country with the lowest under-5 mortality rate. Sub-Saharan Africa remains the region with the highest under-5 mortality rates in the world: All six countries with rates above 100 deaths per 1,000 live births are in sub-Saharan Africa.\n\nFurthermore, approximately 80% of under-5 deaths occur in only two regions: sub-Saharan Africa and South Asia. 6 countries account for half of the global under-5 deaths, namely, India, Nigeria, Pakistan, the Democratic Republic of the Congo, Ethiopia and China. India and Nigeria alone account for almost a third (32 per cent) of the global under-five deaths.\n\nLikewise, there are disparities between wealthy and poor households in developing countries. According to a Save the Children paper, children from the poorest households in India are three times more likely to die before their fifth birthday than those from the richest households.\n\nThe child survival rate of nations varies with factors such as fertility rate and income distribution; the change in distribution shows a strong correlation between child survival and income distribution as well as fertility rate, where increasing child survival allows the average income to increase as well as the average fertility rate to decrease.\n\n\n"}
{"id": "2300688", "url": "https://en.wikipedia.org/wiki?curid=2300688", "title": "Complications of pregnancy", "text": "Complications of pregnancy\n\nComplications of pregnancy are health problems that are caused by pregnancy. Complications that occur primarily during childbirth are termed obstetric labor complications, and problems that occur primarily after childbirth are termed puerperal disorders. Severe complications of pregnancy, childbirth, and the puerperium are present in 1.6% of mothers in the US and in 1.5% of mothers in Canada. In the immediate postpartum period (puerperium), 87% to 94% of women report at least one health problem. Long-term health problems (persisting after six months postpartum) are reported by 31% of women.\n\nIn 2016, complications of pregnancy, childbirth, and the puerperium resulted globally in 230,600 deaths, down from 377,000 deaths in 1990. The most common causes of maternal mortality are maternal bleeding, maternal sepsis and other infections, hypertensive diseases of pregnancy, obstructed labor, and , which includes miscarriage, ectopic pregnancy, and elective abortion.\n\nThere is no clear distinction between complications of pregnancy and symptoms and discomforts of pregnancy. However, the latter do not significantly interfere with activities of daily living or pose any significant threat to the health of the mother or baby. Still, in some cases the same basic feature can manifest as either a discomfort or a complication depending on the severity. For example, mild nausea may merely be a discomfort (morning sickness), but if severe and with vomiting causing water-electrolyte imbalance it can be classified as a pregnancy complication (hyperemesis gravidarum).\n\nThe following problems originate mainly in the mother.\n\nGestational diabetes is when a woman without diabetes develops high blood sugar levels during pregnancy.\n\nHyperemesis gravidarum is the presence of severe and persistent vomiting, causing dehydration and weight loss. It is more severe than the more common morning sickness and is estimated to affect 0.5–2.0% of pregnant women.\n\n\nPotential severe hypertensive states of pregnancy are mainly:\n\nDeep vein thrombosis (DVT) has an incidence of 0.5 to 7 per 1,000 pregnancies, and is the second most common cause of maternal death in developed countries after bleeding.\n\nLevels of hemoglobin are lower in the third trimesters. According to the United Nations (UN) estimates, approximately half of pregnant women suffer from anemia worldwide. Anemia prevalences during pregnancy differed from 18% in developed countries to 75% in South Asia.\n\nTreatment varies due to the severity of the anaemia, and can be used by increasing iron containing foods, oral iron tablets or by the use of parenteral iron.\n\nA pregnant woman is more susceptible to certain infections. This increased risk is caused by an increased immune tolerance in pregnancy to prevent an immune reaction against the fetus, as well as secondary to maternal physiological changes including a decrease in respiratory volumes and urinary stasis due to an enlarging uterus. Pregnant women are more severely affected by, for example, influenza, hepatitis E, herpes simplex and malaria. The evidence is more limited for coccidioidomycosis, measles, smallpox, and varicella. Mastitis, or inflammation of the breast occurs in 20% of lactating women.\n\nSome infections are vertically transmissible, meaning that they can affect the child as well.\n\nPeripartum cardiomyopathy is decrease in heart function which occurs in the last month of pregnancy, or up to six months post-pregnancy. It increases the risk of congestive heart failure, heart arrhythmias, thromboembolism, and cardiac arrest.\n\nHypothyroidism (also called Hashimoto's disease) is an autoimmune disease that affects the thyroid in women. This condition can have a profound effect during pregnancy and on the child. The infant may be seriously affected and have a variety of birth defects. Many women with Hashimoto's disease develop an underactive thyroid. The clinician will do an exam and order one or more tests.\n\nThe following problems occur in the fetus or placenta, but may have serious consequences on the mother as well.\n\nEctopic pregnancy is implantation of the embryo outside the uterus\n\nMiscarriage is the loss of a pregnancy prior to 20 weeks. In the UK, miscarriage is defined as the loss of a pregnancy during the first 23 weeks.\n\nPlacental abruption is the separation of the placenta from the uterus.\n\n\nPlacenta praevia is when the placenta fully or partially covers the cervix.\n\nPlacenta accreta is an abnormal adherence of the placenta to the uterine wall.\n\nMultiples may become monochorionic, sharing the same chorion, with resultant risk of twin-to-twin transfusion syndrome. Monochorionic multiples may even become monoamniotic, sharing the same amniotic sac, resulting in risk of umbilical cord compression and entanglement. In very rare cases, there may be conjoined twins, possibly impairing function of internal organs.\n\nThe embryo and fetus have little or no immune function. They depend on the immune function of their mother. Several pathogens can cross the placenta and cause (perinatal) infection. Often microorganisms that produce minor illness in the mother are very dangerous for the developing embryo or fetus. This can result in spontaneous abortion or major developmental disorders. For many infections, the baby is more at risk at particular stages of pregnancy. Problems related to perinatal infection are not always directly noticeable.\n\nThe term TORCH complex refers to a set of several different infections that may be caused by transplacental infection.\n\nBabies can also become infected by their mother during birth. During birth, babies are exposed to maternal blood and body fluids without the placental barrier intervening and to the maternal genital tract. Because of this, blood-borne microorganisms (hepatitis B, HIV), organisms associated with sexually transmitted disease (e.g., gonorrhoea and chlamydia), and normal fauna of the genito-urinary tract (e.g., Candida) are among those commonly seen in infection of newborns.\n\nThere have been rare but known cases of intrauterine bleeding caused by injury inflicted by the fetus with its fingernails or toenails.\n\nFactors increasing the risk (to either the woman, the fetus/es, or both) of pregnancy complications beyond the normal level of risk may be present in a woman's medical profile either before she becomes pregnant or during the pregnancy. These pre-existing factors may relate to physical or mental health, or to social issues, or a combination of those.\n\nSome common risk factors include:\n\nSome disorders and conditions can mean that pregnancy is considered high-risk (about 6-8% of pregnancies in the USA) and in extreme cases may be contraindicated. High-risk pregnancies are the main focus of doctors specialising in maternal-fetal medicine.\n\nSerious pre-existing disorders which can reduce a woman's physical ability to survive pregnancy include a range of congenital defects (that is, conditions with which the woman herself was born, for example, those of the heart or , some of which are listed above) and diseases acquired at any time during the woman's life.\n\nA Dutch 2010 research paper showed that \"low-risk\" pregnancy in the Netherlands may actually carry a higher risk of perinatal death than a \"high-risk\" pregnancy.\n\n"}
{"id": "2021968", "url": "https://en.wikipedia.org/wiki?curid=2021968", "title": "Computerized physician order entry", "text": "Computerized physician order entry\n\nComputerized physician order entry (CPOE), sometimes referred to as computerized provider order entry or computerized provider order management (CPOM), is a process of electronic entry of medical practitioner instructions for the treatment of patients (particularly hospitalized patients) under his or her care.\n\nThe entered orders are communicated over a computer network to the medical staff or to the departments (pharmacy, laboratory, or radiology) responsible for fulfilling the order. CPOE reduces the time it takes to distribute and complete orders, while increasing efficiency by reducing transcription errors including preventing duplicate order entry, while simplifying inventory management and billing. \n\nCPOE is a form of patient management software.\n\nIn a graphical representation of an order sequence, specific data should be presented to CPOE system staff in cleartext, including: \n\n\nSome textual data can be reduced to simple graphics.\n\nCPOE systems use terminology familiar to medical and nursing staff, but there are different terms used to classify and concatenate orders. The following items are examples of additional terminology that a CPOE system programmer might need to know:\n\nThe application responding to, \"i.e.\", performing, a request for services (orders) or producing an observation. The filler can also originate requests for services (new orders), add additional services to existing orders, replace existing orders, put an order on hold, discontinue an order, release a held order, or cancel existing orders.\n\nA request for a service from one application to a second application. In some cases an application is allowed to place orders with itself.\n\nOne of several segments that can carry order information. Future ancillary specific segments may be defined in subsequent releases of the Standard if they become necessary.\n\nThe application or individual originating a request for services (order).\n\nA list of associated orders coming from a single location regarding a single patient.\n\nA grouping of orders used to standardize and expedite the ordering process for a common clinical scenario. (Typically, these orders are started, modified, and stopped by a licensed physician.)\n\nA grouping of orders used to standardize and automate a clinical process on behalf of a physician. (Typically, these orders are started, modified, and stopped by a nurse, pharmacist, or other licensed health professional.)\n\nFeatures of the ideal computerized physician order entry system (CPOE) include:\n\nIn the past, physicians have traditionally hand-written or verbally communicated orders for patient care, which are then transcribed by various individuals (such as unit clerks, nurses, and ancillary staff) before being carried out. Handwritten reports or notes, manual order entry, non-standard abbreviations and poor legibility lead to errors and injuries to patients, . A follow up IOM report in 2001 advised use of electronic medication ordering, with computer- and internet-based information systems to support clinical decisions. Prescribing errors are the largest identified source of preventable hospital medical error. A 2006 report by the Institute of Medicine estimated that a hospitalized patient is exposed to a medication error each day of his or her stay. While further studies have estimated that CPOE implementation at all nonrural hospitals in the United States could prevent over 500,000 serious medication errors each year. Studies of computerized physician order entry (CPOE) has yielded evidence that suggests the medication error rate can be reduced by 80%, and errors that have potential for serious harm or death for patients can be reduced by 55%, and other studies have also suggested benefits. Further, in 2005, CMS and CDC released a report that showed only 41 percent of prophylactic antibacterials were correctly stopped within 24 hours of completed surgery. The researchers conducted an analysis over an eight-month period, implementing a CPOE system designed to stop the administration of prophylactic antibacterials. Results showed CPOE significantly improved timely discontinuation of antibacterials from 38.8 percent of surgeries to 55.7 percent in the intervention hospital. CPOE/e-Prescribing systems can provide automatic dosing alerts (for example, letting the user know that the dose is too high and thus dangerous) and interaction checking (for example, telling the user that 2 medicines ordered taken together can cause health problems). In this way, specialists in pharmacy informatics work with the medical and nursing staffs at hospitals to improve the safety and effectiveness of medication use by utilizing CPOE systems.\n\nGenerally, CPOE is advantageous, as it leaves the trails of just better formatting retrospective information, similarly to traditional hospital information systems designs. The key advantage of providing information from the physician in charge of treatment for a single patient to the different roles involved in processing he treatise itself is widely innovative. This makes CPOE the primary tool for information transfer to the performing staff and lesser the tool for collecting action items for the accounting staff. However, the needs of proper accounting get served automatically upon feedback on completion of orders.\n\nCPOE is generally not suitable without reasonable training and tutoring respectively. As with other technical means, the system based communicating of information may be inaccessible or inoperable due to failures. That is not different to making use of an ordinary telephone or with conventional hospital information systems. Beyond, the information conveyed may be faulty or erratic. A concatenated validating of orders must be well organized. Errors lead to liability cases as with all professional treatment of patients.\n\nPrescriber and staff inexperience may cause slower entry of orders at first, use more staff time, and is slower than person-to-person communication in an emergency situation. Physician to nurse communication can worsen if each group works alone at their workstations.\n\nBut, in general, the options to reuse order sets anew with new patients lays the basic for substantial enhancement of the processing of services to the patients in the complex distribution of work amongst the roles involved. The basic concepts are defined with the clinical pathway approach. However, success does not occur by itself. The preparatory work has to be budgeted from the very beginning and has to be maintained all the time. Patterns of proper management from other service industry and from production industry may apply. However, the medical methodologies and nursing procedures do not get affected by the management approaches.\n\nCPOE presents several possible dangers by introducing new types of errors. Automation causes a false sense of security, a misconception that when technology suggests a course of action, errors are avoided. These factors contributed to an \"increased\" mortality rate in the Children's Hospital of Pittsburgh's Pediatric ICU when a CPOE systems was introduced. In other settings, shortcut or default selections can override non-standard medication regimens for elderly or underweight patients, resulting in toxic doses. Frequent alerts and warnings can interrupt work flow, causing these messages to be ignored or overridden due to alert fatigue. CPOE and automated drug dispensing was identified as a cause of error by 84% of over 500 health care facilities participating in a surveillance system by the United States Pharmacopoeia. Introducing CPOE to a complex medical environment requires ongoing changes in design to cope with unique patients and care settings, close supervision of overrides caused by automatic systems, and training, testing and re-training all users.\n\nCPOE systems can take years to install and configure. Despite ample evidence of the potential to reduce medication errors, adoption of this technology by doctors and hospitals in the United States has been slowed by resistance to changes in physician's practice patterns, costs and training time involved, and concern with interoperability and compliance with future national standards. According to a study by RAND Health, the US healthcare system could save more than 81 billion dollars annually, reduce adverse medical events and improve the quality of care if it were to widely adopt CPOE and other health information technology. As more hospitals become aware of the financial benefits of CPOE, and more physicians with a familiarity with computers enter practice, increased use of CPOE is predicted. Several high-profile failures of CPOE implementation have occurred, so a major effort must be focused on change management, including restructuring workflows, dealing with physicians' resistance to change, and creating a collaborative environment.\n\nAn early success with CPOE by the United States Department of Veterans Affairs (VA) is the Veterans Health Information Systems and Technology Architecture or VistA. A graphical user interface known as the Computerized Patient Record System (CPRS) allows health care providers to review and update a patient's record at any computer in the VA's over 1,000 healthcare facilities. CPRS includes the ability to place orders by CPOE, including medications, special procedures, x-rays, patient care nursing orders, diets and laboratory tests.\n\nThe world's first successful implementation of a CPOE system was at El Camino Hospital in Mountain View, California in the early 1970s. The Medical Information System (MIS) was originally developed by a software and hardware team at Lockheed in Sunnyvale, California, which became the TMIS group at Technicon Instruments Corporation. The MIS system used a light pen to allow physicians and nurses to quickly point and click items to be ordered.\n\n, one of the largest projects for a national EHR is by the National Health Service (NHS) in the United Kingdom. The goal of the NHS is to have 60,000,000 patients with a centralized electronic health record by 2010. The plan involves a gradual roll-out commencing May 2006, providing general practices in England access to the National Programme for IT (NPfIT). The NHS component, known as the \"Connecting for Health Programme\", includes office-based CPOE for medication prescribing and test ordering and retrieval, although some concerns have been raised about patient safety features.\n\nIn 2008, the Massachusetts Technology Collaborative and the New England Healthcare Institute (NEHI) published research showing that 1 in 10 patients admitted to a Massachusetts community hospital suffered a preventable medication error. The study argued that Massachusetts hospitals could prevent 55,000 adverse drug events per year and save $170 million annually if they fully implemented CPOE. The findings prompted the Commonwealth of Massachusetts to enact legislation requiring all hospitals to implement CPOE by 2012 as a condition of licensure.\n\nIn addition, the study also concludes that it would cost approximately $2.1 million to implement a CPOE system, and a cost of $435,000 to maintain it in the state of Massachusetts while it saves annually about $2.7 million per hospital. The hospitals will still see payback within 26 months through reducing hospitalizations generated by error. Despite the advantages and cost savings, the CPOE is still not well adapted by many hospitals in the US.\n\nThe Leapfrog’s 2008 Survey showed that most hospitals are still not complying with having a fully implemented, effective CPOE system. The CPOE requirement became more challenging to meet in 2008 because the Leapfrog introduced a new requirement: Hospitals must test their CPOE systems with Leapfrog’s CPOE Evaluation Tool. So the number of hospitals in the survey considered to be fully meeting the standard dropped to 7% in 2008 from 11% the previous year. Though the adoption rate seems very low in 2008, it is still an improvement from 2002 when only 2% of hospitals met this Leapfrog standard.\n\n\n"}
{"id": "1864519", "url": "https://en.wikipedia.org/wiki?curid=1864519", "title": "Condom fatigue", "text": "Condom fatigue\n\nCondom fatigue is a term used by medical professionals and safer sex educators to refer to the phenomenon of decreased condom use. It can also be used to describe a general weariness of and decreased effectiveness of safer sex messages. This is sometimes called \"prevention fatigue\".\n\nThe term has particularly been used to describe men who have sex with men, though the term applies to people of all genders and sexual orientations. Condom fatigue has been partially blamed for an increase in HIV infection rates, though this has not been substantiated in any study.\n\nCondom fatigue is not a universal phenomenon. In Germany, condom use between new sexual partners has increased between 1994 and 2010 from 65% to 87%.\n\nHIV infection is increasing at a rate of 12% annually among 13–24-year-old American men who have sex with men. Experts attribute this to \"AIDS fatigue\" among younger people who have no memory of the worst phase of the epidemic in the 1980s and early 1990s, as well as \"condom fatigue\" among those who have grown tired of and disillusioned with the unrelenting safer sex message. The increase may also be because of new treatments.\n\n"}
{"id": "8313008", "url": "https://en.wikipedia.org/wiki?curid=8313008", "title": "Condoms, needles, and negotiation", "text": "Condoms, needles, and negotiation\n\nCondoms, needles, and negotiation, also known as the CNN approach, is a harm reduction approach to reducing the rate of transmission of sexually transmitted infections such as HIV/AIDS by:\n\nIn contrast with the abstinence, be faithful, use a condom, or \"ABC\" approach to this problem, the \"CNN\" approach aims primarily at reducing the rate of transmission among high-risk groups such as women in areas where women have low levels of social power, prostitutes and their clients, and intravenous drug users.\n\nPope Benedict XVI has strongly criticized reduction policies with regards to HIV/AIDS, saying that \"it is a tragedy that cannot be overcome by money alone, that cannot be overcome through the distribution of condoms, which even aggravates the problems\". This position has been widely criticised for misrepresenting and oversimplifying the role of condoms in preventing infections. Other experts, including the Director of Harvard University's AIDS Prevention Research Project, have supported the Pope's position.\n\n\n"}
{"id": "16872890", "url": "https://en.wikipedia.org/wiki?curid=16872890", "title": "Demographic and Health Surveys", "text": "Demographic and Health Surveys\n\nThe Demographic and Health Surveys (DHS) Program is responsible for collecting and disseminating accurate, nationally representative data on health and population in developing countries. The project is implemented by ICF International and is funded by the United States Agency for International Development (USAID) with contributions from other donors such as UNICEF, UNFPA, WHO, and UNAIDS.\n\nThe DHS is highly comparable to the Multiple Indicator Cluster Surveys and the technical teams developing and supporting the surveys are in close collaboration. \n\nSince September 2013, ICF International has been partnering with seven internationally experienced organizations to expand access to and use of the DHS data: Johns Hopkins Bloomberg School of Public Health Center for Communication Programs; Program for Appropriate Technology in Health (PATH); Avenir Health; Vysnova; Blue Raster; Kimetrica; and EnCompass.\n\nSince 1984, The Demographic and Health Surveys (DHS) Program has provided technical assistance to more than 300 demographic and health surveys in over 90 countries. DHS surveys collect information on fertility and total fertility rate (TFR), reproductive health, maternal health, child health, immunization and survival, HIV/AIDS; maternal mortality, child mortality, malaria, and nutrition among women and children stunted. The strategic objective of The DHS Program is to improve and institutionalize the collection and use of data by host countries for program monitoring and evaluation and for policy development decisions.\n\nThe DHS Program supports the following data collection options:\n\nThe DHS Program works to provide survey data for program managers, health care providers, policymakers, country leaders, researchers, members of the media, and others who can act to improve public health. The DHS Program distributes unrestricted survey data files for legitimate academic research at no cost.\n\nOnline databases include: STATcompiler, STATmapper, HIV/AIDS Survey Indicators Database, HIV Spatial Data Repository, HIVmapper, and Country QuickStats.\n\nThe DHS Program produces publications that provide country specific and comparative data on population, health, and nutrition in developing countries. Most publications are available online for download, but if an electronic version of the publication is not available, a hard copy may be available.\n\nThe DHS Program has been active in over 90 countries in Africa, Asia, Central Asia; West Asia; and Southeast Asia, Latin America and the Caribbean. A list of the publications for each country is available online at The DHS Program web site.\n\nSince 2001, The DHS Program has worked in over 15 countries in Africa, Asia and Latin America and Caribbean conducting population-based HIV testing. By collecting blood for HIV testing from representative samples of the population of men and women in a country, the DHS Program provides nationally representative estimates of HIV rates. The testing protocol provides for anonymous, informed, and voluntary testing of women and men.\n\nThe program also collects data on internationally recognized AIDS indicators. Currently, the main sources of HIV/AIDS indicators in the database are the Demographic and Health Surveys (DHS), the Multiple Indicator Cluster Surveys (MICS), the Reproductive Health Surveys (RHS), the Sexual Behavior Surveys (SBS), and Behavioral Surveillance Surveys (BSS). Eventually it will cover all countries for which indicators are available. The project also collects data on the capacity of health care facilities to deliver HIV prevention and treatment services.\n\nSince 2000, DHS (and some AIS) surveys have collected data on ownership and use of mosquito nets, treatment of fever in children, and intermittent preventive treatment of pregnant women. In recent years, additional questions on indoor residual spraying, and biomarker testing for anemia and malaria have been conducted.This has however not changed the trend in malaria infections thereby calling for more interventions by researchers and scientists.\n\nThe DHS Program researches and trains for integrating gender into population, health and nutrition programs and HIV/AIDS-related activities in the developing world.\n\nQuestions on gender roles and empowerment are integrated into most DHS questionnaires. For countries interested in more in-depth data on gender, modules of questions are available on specific topics such as status of women, domestic violence, and female genital mutilation.\n\nThe DHS Program has interviewed thousands of young people and gathered information about their education, employment, media exposure, nutrition, sexual activity, fertility, unions, and general reproductive health, including HIV prevalence. \nThe Youth Corner on the DHS website presents findings about youth and features profiles of young adults ages 15–24 from more than 30 countries worldwide. The Youth Corner is part of the broader effort by the Interagency Youth Working Group (IYWG) to help program managers, donors, national and local governments, teachers, religious leaders, and nongovernmental organizations (NGOs) plan and implement programs to improve the reproductive health of young adults.\n\nThe DHS Program now analyzes the impact of geographic location using DHS data and geographic information systems (GIS). The DHS Program routinely collects geographic information in all surveyed countries. Using GIS, researchers can link DHS data with routine health data, health facility locations, local infrastructure such as roads and rivers, and environmental conditions.\n\nUsing field-friendly technologies, the DHS Program is able to collect biomarker data relating to conditions and infections. DHS surveys have tested for anemia (by measuring hemoglobin), HIV infection, sexually transmitted diseases such as syphilis and the herpes simplex virus, serum retinol (Vitamin A), lead exposure, high blood pressure, and immunity from vaccine-preventable diseases like measles and tetanus. Traditionally, much of the data gathered in DHS surveys is self-reported. Biomarkers complement this information by providing an objective profile of a specific disease or health condition in a population. Biomarker data contributes to the understanding of behavioral risk factors and determinants of different illnesses.\n\n\n"}
{"id": "53151687", "url": "https://en.wikipedia.org/wiki?curid=53151687", "title": "Early childhood trauma", "text": "Early childhood trauma\n\nEarly childhood trauma refers to adversity experienced in early childhood. Early childhood is defined as conception to age five, the most critical developmental period in human life. Adversity that causes toxic stress and/or trauma experienced in early childhood can lead to a variety of problems in later life, in a critical developmental period in a child’s life spanning from conception to the age of five. Childhood experiences, both positive and negative, have a tremendous impact on future violence victimization and perpetration, and lifelong health and opportunity. As such, early experiences are an important public health issue. Much of the foundational research in this area has been referred to as Adverse Childhood Experiences (ACEs).\n\nNew research shows that even witnessing traumatic events can impact the physical development of a child’s brain — potentially leading to lifelong health and social issues.\n\nDevelopment of psychological resilience is believed to significantly reduce the effects of a childhood trauma on a child’s development. Early childhood adversity alters the peripheral and central immune system and increases the sensitivity of the body's immune response to cocaine in adulthood.\n"}
{"id": "4639874", "url": "https://en.wikipedia.org/wiki?curid=4639874", "title": "Epidemiological transition", "text": "Epidemiological transition\n\nIn demography and medical geography, epidemiological transition is a phase of development witnessed by a sudden and stark increase in population growth rates brought by improved food security and innovations in public health and medicine, followed by a re-leveling of population growth due to subsequent declines in fertility rates. This accounts for the replacement of infectious diseases by chronic diseases over time due to increased life span as a result of improved health care and disease prevention. This theory was originally posited by Abdel Omran in 1971.\n\nOmran divided the epidemiological transition of mortality into three phases, in the last of which chronic diseases replace infection as the primary cause of death. These phases are:\n\nIn 1998 Barrett et al proposed two additional phases in which cardiovascular diseases diminish as a cause of mortality due to changes in culture, lifestyle and diet, and diseases associated with aging increase in prevalence. In the final phase, disease is largely controlled for those with access to education and health care, but inequalities persist.\n\n\nThe epidemiological transition occurs when a country undergoes the process of transitioning from developing nation to developed nation status. The developments of modern healthcare and medicine, such as antibiotics, drastically reduce infant mortality rates and extend average life expectancy which, coupled with subsequent declines in fertility rates, reflects a transition to chronic and degenerative diseases as more important causes of death.\n\nThe theory of epidemiological transition uses patterns of health and disease as well as their forms of demographic, economical and sociological determinants and outcomes.\n\nIn general human history, Omran's first phase occurs when human population sustains cyclic, low-growth, and mostly linear, up-and-down patterns associated with wars, famine, epidemic outbreaks, as well as small golden ages, and localized periods of \"prosperity\". In early pre-agricultural history, infant mortality rates were high and average life expectancy low. Today, life expectancy in developing countries remains relatively low, as in many Sub-Saharan African nations where it typically doesn't exceed 60 years of age.\n\nThe second phase involves improved nutrition as a result of stable food production along with advances in medicine and the development of health care systems. Mortality in Western Europe and North America was halved during the 19th century due to closed sewage systems and clean water provided by public utilities, with a particular benefit for children of both sexes and to females in the adolescent and reproductive age periods, probably because the susceptibility of these groups to infectious and deficiency diseases is relatively high. An overall reduction in malnutrition enabled populations to better resist infectious disease. Treatment breakthroughs of importance included the initiation of vaccination during the early nineteenth century, and the discovery of penicillin in the mid 20th century, which led respectively to a widespread and dramatic decline in death rates from previously serious diseases such as smallpox and sepsis. Population growth rates surged in the 1950s, 1960's and 1970's to 1.8% per year and higher, with the world gaining 2 billion people between 1950 and the 1980s. A decline in mortality without a corresponding decline in fertility leads to a population pyramid assuming the shape of a bullet or a barrel, as young and middle-age groups comprise equivalent percentages of the population.\n\nOmran's third phase occurs when human birth rates drastically decline from highly positive replacement rates to stable replacement numbers. In several European nations replacement rates have even become negative. This transition generally represents the net effect of individual choices on family size and the ability to implement those choices. Omran gives three possible factors tending to encourage reduced fertility rates:\n\nImprovements in female and childhood survival that occur with the shift in health and disease patterns discussed above have distinct and seemingly contradictory effects on fertility. While better health and greater longevity enjoyed by females of reproductive age tend to enhance fertility, the reduced risks to infants and young children that occurs in the later stages of the transition tends to have the opposite effect: prolonged breastfeeding associated with reduced mortality among infants and toddlers, together with parental recognition of improved childhood survival, tend to lengthen birth intervals and depress overall reproductive rates.\n\nThe transition may also be associated with demographic movements to urban areas, and a shift from agriculture and labor-based production output to technological and service-sector-based economies. This shift in demographic and disease profiles is currently under way in most developing nations, however every country is unique and transition speed is based on numerous geographical and sociopolitical factors. Whether the transition is due to socioeconomic improvements (as in developed countries) or by modern public health programs (as has been the case in many developing countries), the lowering of mortality and of infectious disease tends to increase economic productivity through better functioning of adult members of the labor force and through an increase in the proportion of children who survive and mature into productive members of society.\n\nOmran developed three models to explain the epidemiological transition.\n\n\n\n McMichael, Preston, and Murray offer a more nuanced view of the epidemiological transition, highlighting macro trends and emphasizing that there is a change from infectious to non-communicable disease, but arguing that it happens differently in different contexts.\n\nOne of the first to refine the idea of the epidemiological transition was Preston, who in 1976 proposed the first comprehensive statistical model relating mortality and cause-specific mortality. Preston used life tables from 43 national populations, including both developed countries such as United States and England and developing countries such as Chile, Colombia, Costa Rica, Guatemal, México, Panama, Taiwan, Trinidad and Tobago, and Venezuela. He used multiple linear regression to analyze the cause-specific-age-standardized death rates by sex. The estimated slopes represented the proportional contribution of each cause to a unit change in the total mortality rate. With the exception of neoplasms in both sexes and cardiovascular disease in males, all of the estimated slopes were positive and statistically significant. This demonstrated that the mortality rates from each specific cause were expected to decline as total mortality declined. The major causes accounting for the decline were all infectious and parasitic diseases.\n\nMcMichael et al. argue (2004) that the epidemiological transition has not taken place homogeneously in all countries. Countries have varied in the speed with which they go through the transition as well as what stage of the transition they are in. The global burden of disease website provides visual comparisons of the disease burdens of countries and the changes over time. The epidemiological transition correlates with changes in life expectancy. Worldwide, mortality rates have decreased as both technological and medical advancements have led to a tremendous decrease in infectious diseases. With fewer people dying from infectious diseases, there is a rising prevalence of chronic and/or degenerative diseases in the older surviving population.\n\nMcMichael et al. describe life expectancy trends as grouped into three categories, as suggested by Casselli et al.:\n\n\nMurray and Lopez (1996) offered one of the most important cause-of-death models as part of the 1990 Global Burden of Disease Study. Their \"cause of death\" patterns sought to describe the fraction of deaths attributed to a set of mutually exclusive and collectively exhaustive causes. They divided diseases into three cause groups and made several important observations:\n\n\nThe regression approach underlying the Global Burden of Disease received some critique in light of real-world violations of the model's \"mutually exclusive and collectively exhaustive\" cause attribution.\n\nBuilding on the existing body of evidence, Salomon and Murray (2002), further add nuances to the traditional theory of epidemiological transition by disintegrating it based on disease categories and different age-sex groups, positing that the epidemiological transition entails a real transition in the cause composition of age-specific mortality, as opposed to just a transition in the age structure. Using Global Burden of Disease data from 1990, they disintegrate the transition across three cause groups: communicable diseases, non-communicable diseases and injuries, seeking to explain the variation in all-cause mortality as a function of cause-specific mortality in 58 countries from 1950 to 1998. This analysis validates the underlying premise of the classic epidemiological transition theory: as total mortality declines and income rises, communicable diseases cause less and less mortality compared to non-communicable diseases and injuries. Decomposing this overall impact by age-sex groups, they find that for males, when overall mortality decreases, the importance of non-communicable diseases (NCDs) increases relative to the other causes with an age-specific impact on the role of injuries, whereas for women, both NCDs and injuries gain a more significant share with mortality decreases. For children over one year, they find that there is a gradual transition from communicable to non-communicable diseases, with injuries remaining significant in males. For young adults, the epidemiological transition is particularly different: for males, there is a shift from injuries to NCDs in lower income settings, and the opposite in higher-income settings; for females, rising income also signifies a shift from NCDs to injuries, but the role of injuries becomes more significant over time compared to males. Finally, for both males and females over 50, there is no epidemiological transition impact on the cause composition of mortality.\n\nThe majority of the literature on the epidemiological transition that was published since these seminal papers confirms the context-specific nature of the epidemiological transition: while there is an overall all-cause mortality decline, the nature of cause-specific mortality declines differs across contexts. Increasing obesity rates in high-income countries are further confirming the epidemiological transition theory as the epidemic leads to an increase in NCDs. The picture is more nuanced in low- and middle-income countries, where there are signs of a protracted transition with the double burden of communicable and noncommunicable disease. A recent review of cause-specific mortality rates from 12 low- and middle-income countries in Asia and sub-Saharan Africa by Santosa and Byass (2016) shows that broadly, low- and middle-income countries are rapidly transitioning to lower total mortality and lower infectious disease mortality. A more macro-level analysis from the Global Burden of Disease data conducted by Murray and others (2015) finds that while there is a global trend towards decreasing mortality and increasing NCD prevalence, this global trend is being driven by country-specific effects as opposed to a broader transition; further, there are varying patterns within and between countries, which makes it difficult to have a single unified theory of epidemiological transition. \n\nA theory of epidemiological transition aimed at explaining not just describing changes in population disease and mortality profiles would need to encompass the role in different morbid conditions of infectious diseases contracted over the life course. The concept of linear transition from infectious diseases to other conditions referred to as degenerative or non-communicable, was based on a false dichotomy as common microorganisms have now been confirmed as causal agents in several conditions recorded as the underlying cause of many deaths. A revised transition model might focus more on disease aetiology and the determinants of cause-specific mortality change, while encompassing the possibility that infectious causation may be established for other morbid conditions through the vast amount of ongoing research into associations with infectious diseases.\n\n\n"}
{"id": "50504513", "url": "https://en.wikipedia.org/wiki?curid=50504513", "title": "Ergonomic hazard", "text": "Ergonomic hazard\n\nErgonomic hazards are physical conditions that may pose risk of injury to the musculoskeletal system, such as the muscles or ligaments of the lower back, tendons or nerves of the hands/wrists, or bones surrounding the knees. Ergonomic hazards include things such as awkward or extreme postures, whole-body or hand/arm vibration, poorly designed tools, equipment, or workstations, repetitive motion, and poor lighting. Ergonomic hazards occur in both occupational and non-occupational settings such as in workshops, building sites, offices, home, school, or public spaces and facilities.\n"}
{"id": "2370329", "url": "https://en.wikipedia.org/wiki?curid=2370329", "title": "Euthenics", "text": "Euthenics\n\nEuthenics is the study of the improvement of human functioning and well-being by improvement of living conditions. Affecting the \"improvement\" through altering external factors such as education and the controllable environment, including the prevention and removal of contagious disease and parasites, environmentalism, education regarding employment, home economics, sanitation, and housing.\n\nRose Field notes of the definition in a May 23, 1926 \"New York Times\" article, \"the simplest being efficient living\". A right to environment.\n\nThe Flynn effect has been often cited as an example of euthenics. Another example is the steady increase in body size in industrialized countries since the beginning of the 20th century.\n\nEuthenics is not normally interpreted to have anything to do with changing the composition of the human gene pool by definition, although everything that affects society has some effect on who reproduces and who does not.\n\nThe term was derived in the late 19th century from the Greek verb \"eutheneo\", εὐθηνέω (\"eu\", well; the, root of τίθημι \"tithemi\", to cause).\n\nAlso from the Greek Euthenia, Εὐθηνία. Good state of the body: prosperity, good fortune, abundance.—\"Herodotus\".\n\nThe opposite of Euthenia is Penia, Πενία (\"deficiency\" or \"poverty\") the personification of poverty and need.\n\nEllen H. Swallow Richards (1842–1911; Vassar Class of '70) was one of the first writers to use the term, in \"The Cost of Shelter\" (1905), with the meaning \"the science of better living\". It is unclear if (and probably unlikely that) any of the study programs of euthenics ever completely embraced Richards' multidisciplinary concept, though several nuances remain today, especially that of interdisciplinarity.\n\nAfter Richards' death in 1911, Julia Lathrop (1858–1932; VC '80)—one of Vassar's most distinguished alumnae—continued to promote the development of an interdisciplinary program in euthenics at the college. Lathrop soon teamed with alumna Minnie Cumnock Blodgett (1862–1931; VC '84), who with her husband, John Wood Blodgett, offered financial support to create a program of euthenics at Vassar College. Curriculum planning, suggested by Vassar president Henry Noble MacCracken in 1922, began in earnest by 1923, under the direction of Professor Annie Louise Macleod (Chemistry; First woman PhD, McGill University, 1910).\n\nAccording to Vassar's chronology entry for March 17, 1924, \"the faculty recognized euthenics as a satisfactory field for sequential study (major). A Division of Euthenics was authorized to offer a multidisciplinary program [radical at the time] focusing the techniques and disciplines of the arts, sciences and social sciences on the life experiences and relationships of women. Students in euthenics could take courses in horticulture, food chemistry, sociology and statistics, education, child study, economics, economic geography, physiology, hygiene, public health, psychology and domestic architecture and furniture. With the new division came the first major in child study at an American liberal arts college.\"\n\nFor example, a typical major in child study in euthenics includes introductory psychology, laboratory psychology, applied psychology, child study and social psychology in the Department of Psychology; the three courses offered in the Department of Child Study; beginning economics, programs of social reorganization and the family in Economics; and in the Department of Physiology, human physiology, child hygiene, principles of public health.\n\nThe Vassar Summer Institute of Euthenics accepted its first students in June 1926. Created to supplement the controversial euthenics major which began February 21, 1925, it was also located in the new Minnie Cumnock Blodgett Hall of Euthenics (York & Sawyer, architects; ground broke October 25, 1925). Some Vassar faculty members (perhaps emotionally upset with being displaced on campus to make way, or otherwise politically motivated) contentiously \"believed the entire concept of euthenics was vague and counter-productive to women's progress.\"\n\nHaving overcome a lukewarm reception, Vassar College officially opened its Minnie Cumnock Blodgett Hall of Euthenics in 1929. Dr. Ruth Wheeler (Physiology and Nutrition – VC '99) took over as director of euthenics studies in 1924. Wheeler remained director until Mary Shattuck Fisher Langmuir (VC '20) succeeded her in 1944, until 1951.\n\nThe college continued for the 1934–35 academic year its successful cooperative housing experiment in three residence halls. Intended to help students meet their college costs by working in their residences. For example, in Main, students earned $40 a year by doing relatively light work such as cleaning their rooms.\n\nIn 1951, Katharine Blodgett Hadley (VC '20) donated $400,000, through the Rubicon Foundation, to Vassar to help fund operating deficits in the current and succeeding years and to improve faculty salaries.\n\n\"Discontinued for financial reasons, the Vassar Summer Institute for Family and Community Living, founded in 1926 as the Vassar Summer Institute of Euthenics, held its last session, July 2, 1958. This was the first and last session for the institute's new director, Dr. Mervin Freedman.\"\n\nElmira College is noted as the oldest college still in existence which (as a college for women) granted degrees to women which were the equivalent of those given to men (the first to do so was the now-defunct Mary Sharp College). Elmira College became coeducational in all of its programs in 1969.\n\nA special article was written in the December 12, 1937 \"New York Times\", quoting recent graduates of Elmira College, urging for courses in colleges for men on the care of children. Reporting that \"preparation for the greatest of all professions, that of motherhood and child-training, is being given the students at Elmira College in the Nursery School which is Conducted as part of the Department of Euthenics.\"\n\nElmira College was one of the first of the liberal arts colleges to recognize the fact that women should have some special training, integrated with the so-called liberal studies, which would prepare them to carry on, with less effort and fewer mistakes, a successful family life. Courses in nutrition, household economics, clothing selection, principles of foods and meal planning, child psychology, and education in family relations are a part of the curriculum.\n\nThe Elmira College nursery school for fifteen children between the ages of two and five years was opened primarily as a laboratory for college students, but it had become so popular with parents in the community that there was always a long waiting list.\n\nThe \"New York Times\" article notes how the nursery had become one of the essential laboratories of the college, where recent mothers testified to the value of the training they received while in college. \"Today,\" one graduate said, \"when it is often necessary for young women to continue professional work outside the home after marriage, it is important that young fathers, who must share in the actual care and training of the children, should have some knowledge of correct methods.\"\n\nMany factors led to the movement never getting the funding it needed to remain relevant, including: vigorous debate about the exact meaning of euthenics, a strong antifeminism movement paralleling even stronger women's rights movements, confusion with the term eugenics, the economic impact of the Great Depression and two world wars. These factors also prevented the discipline from gaining the attention it needed to put together a lasting, vastly multidisciplinary curriculum. Therefore, it split off into separate disciplines. Child Study is one such curriculum.\n\nMartin Heggestad of the Mann Library notes that \"Starting around 1920, however, home economists tended to move into other fields, such as nutrition and textiles, that offered more career opportunities, while health issues were dealt with more in the hard sciences and in the professions of nursing and public health. Also, improvements in public sanitation (for example, the wider availability of sewage systems and of food inspection) led to a decline in infectious diseases and thus a decreasing need for the largely household-based measures taught by home economists.\" Thus, the end of euthenics as originally defined by Ellen Swallow Richards ensued.\n\nAccording to Ellen Richards, in her book \"Euthenics: the science of controllable environment\" (1910):\n\nDebate over misconceptions about the movement started almost from the beginning. In his comparison \"Eugenics, Euthenics, And Eudemics\", (American Journal of Sociology, Vol. 18, No. 6, May 1913), Lester F. Ward of Brown University opens the second section regarding euthenics lamenting: \nWard later noted about the organic environment that:\nVassar historians note that \"critics faulted the new program as a weakening of science and a slide into vocationalism. The influential educator and historian of education, Abraham Flexner—one of the founders of the Princeton Institute for Advanced Study—attacked the program, along with other “ad hoc” innovations like intercollegiate athletics and student governments, in Universities, American, English, German (1930).\"\n\nIn the summer of 1926, Margaret Sanger created a stir when she gave a radio address, called \"Racial Betterment\", in the first Euthenics Institute, where she praised attempts to \"close our gates to the so-called 'undesirables'\" and proposed efforts to \"discourage or cut down on the rapid multiplication of the unfit and undesirable at home\", by government-subsidized voluntary sterilization. (from \"The Selected Papers of Margaret Sanger\", vol. 1 (2003), Esther Katz, ed.)\n\nEugenicist, Charles Benedict Davenport, noted in his article \"Euthenics and Eugenics,\" found reprinted in the \"Popular Science Monthly\" of January 1911, page 18, 20:\n\nIn a New York Times op-ed dated October 24, 1926, entitled \"Eugenics and euthenics\", in response to an op-ed entitled \"Bright Children Who Fail\" which appeared the previous October 15, student of child psychology, Joseph A. Krisses observes:\n\n\n\n"}
{"id": "54932601", "url": "https://en.wikipedia.org/wiki?curid=54932601", "title": "Femalia", "text": "Femalia\n\nFemalia is a book of 32 full-color photographs of human vulvas, edited by Joani Blank and first published by Down There Press in 1993. A reprint edition was published by Last Gasp in 2011. The photographs were taken by Tee Corinne, Michael Perry, Jill Posener, and Michael A. Rosen. The photographs are presented without commentary, except for Blank's brief introduction to the volume as a whole.\n\nThe word used as the book's title, \"\", was taken from the novel \"Vox\" by Nicholson Baker. The photographs by Corinne and Perry had been taken years before the book's original publication in 1993; those by Posener and Rosen were taken specifically for inclusion in the first edition of \"Femalia\".\n\n\"Femalia\" grew out of Blank's long-term work as a feminist sex educator. She felt that medical and pornographic images of the female genitals were inadequate to her purposes. In her introduction to the first edition, Blank lamented the absence of readily available photographic representations of the vulva other than heavily edited images in male-oriented pornography, and the resulting feeling on the part of a majority of women that \"in one way or another, their genitals are not quite ‘normal’\".\n\nFeminist authors have sharply contrasted the portrayals of vulvas in \"Femalia\" with those in typical male-oriented pornography and in biomedical sources. \"Femalia\"'s portrayals are characterized as accurate, honest, open, and truthful, as exhibiting \"stark reality\"; as promoting a positive view of the vulva; as emphasizing the diversity of the vulva in different women, as well as the diversity of opinions and perspectives about the vulva on the part of both men and women; and as emphasizing female autonomy. By contrast, portrayals of the vulva in pornography and in biomedical science are characterized as stylized and uniform, excluding women whose genitalia do not match their models. Pornographic portrayals are further characterized as commodified, and medical portrayals as sterile. Feminist sex educators have advocated perusal of the images in \"Femalia\" as an exercise to help women to regard their genitals in a more positive light.\n\nLibrarian Sanford Berman has cited \"Femalia\" as an example to illustrate his thesis that libraries engage in inappropriate self-censorship, often motivated by concerns about controversial sexual content, in deciding which books to stock. Berman comments, \"A detailed, artistic picture of a seashell adorns the cover. Were the contents strictly shell photos, the book might make it into at least some libraries. Shells, yes. Vulvas, no.\"\n\nIn a study of systematic differences in the depiction of female genitals in online pornography, anatomy textbooks, and feminist publications, \"Femalia\" was used as one of three sources of sample depictions in the feminist-publications category. This study found a statistically significant difference between online pornography and feminist publications in depicted protuberance of the labia minora, with greater mean protuberance shown in the feminist publications. It also found greater variation in measured genital proportions shown in the feminist publications than in the other two categories of sources.\n\n\"Femalia\" was used as one of two sources of sample depictions of female genitals (the other was \"Penthouse\") in a psychological study of the relationship between women's aesthetic perceptions of female genitals and their attitudes toward gynecological examinations. More specifically, the examinations in question were Pap smears, and the relevant attitudes were anxiety, embarrassment, and likelihood of making or keeping an appointment for a Pap smear.\n\nThe Royal Australian College of General Practitioners (RACGP) has published a guideline document, authored by Dr. Magdalena Simonis under authority of the RACGP, intended to inform healthcare professionals about female genital cosmetic surgery (FGCS), such as labiaplasty, and to advise them about management of patient requests for FGCS. In this document, Dr. Simonis identifies lack of appreciation of female genital diversity, not only on the part of the public but also on the part of healthcare professionals, as a contributing factor to the demand for FGCS. She advocates the use of \"Femalia\" as a tool for patient education about genital diversity, in part because it depicts female genitals without digital enhancement. Dr. Simonis has further referenced this educational use of \"Femalia\" in slide and poster presentations intended to promote better management of the demand for FGCS on the part of healthcare professionals.\n\nMedical anthropologist Eric Plemons has stated that:\nPlemons documents the use of \"Femalia\" as a resource to demonstrate the existence of female genital diversity, and to educate both clinicians and patients as to the range of normal vulval appearance. He attributes its widespread use by healthcare professionals to their belief that \"it is one of very few photographic collections of ‘normal’ vulvas that exists\".\n\n\"Femalia\" has been used as a way of assessing preferences for perineal and genital cosmetic appearance, to improve cosmesis in male-to-female transsexuals (transwomen) undergoing genital sex reassignment surgery (GSRS). Beginning in the year 2000, surgeon Neal Wilson began showing photographs from \"Femalia\" to his prospective GSRS patients and asking them to indicate which vulvas they found most aesthetically pleasing, as well as which ones they would choose for themselves. Dr. Wilson attempted to approximate through surgery the appearance of the photographs from \"Femalia\" selected by his prospective patients, even though he held that they set \"impossible standards\" because of the limitations of early 21st-century surgical technique. Dr. Wilson has republished, in an online journal article, the three photographs most often selected by his patients. He has also provided summary statistics concerning his patients′ choices of vulval photographs from \"Femalia\", as well as a short narrative summary of the specific anatomical features that he believed to be characteristic of the most popular photographs.\n\n"}
{"id": "2953473", "url": "https://en.wikipedia.org/wiki?curid=2953473", "title": "Food group", "text": "Food group\n\nA food group is a collection of foods that share similar nutritional properties or biological classifications. Nutrition guides typically divide foods into food groups and recommend daily servings of each group for a healthy diet. In the United States for instance, USDA has described food as being in from 4 to 11 different groups.\n\n\nThe number of \"common\" food groups varies depending on who is defining them. Canada's Food Guide, which has been in continual publication since 1942 and is the second most requested government document (after the income tax form) in Canada, recognizes only four official food groups, listing the remainder of foods as \"another\". Some of these \"others\" include:\n\n"}
{"id": "58391294", "url": "https://en.wikipedia.org/wiki?curid=58391294", "title": "Food labelling and advertising law (Chile)", "text": "Food labelling and advertising law (Chile)\n\nChile's food labelling and advertising law, formally titled \"Ley 20.606, sobre la composición de los alimentos y su publicidad\" (“Law 20.606, on the nutritional composition of foods and their advertising”) establishes a regulatory framework on food security and healthy food with the intention of guiding consumers towards behaviour patterns that promote public health. After the 2012 law was enacted, its accompanying regulations came into full force on June 27, 2016. Andrew Jacobs, writing for \"The New York Times\", has characterized this measure as \"the world’s most ambitious attempt to remake a country’s food culture\" and suggests it \"could be a model for how to turn the tide on a global obesity epidemic that researchers say contributes to four million premature deaths a year.\"\n\nIn Chile, the law — often referred to by less cumbersome names such as \"ley de etiquetado de alimentos\" (“food labelling law”), \"ley del Súper Ocho\" (“Super Eight law”), or simply \"ley de alimentos\" (“food law”) — specifically regulates the delivery of nutritional information on foods high in sodium, saturated fats, sugars or calories. The standard also prohibits the sale of such foods in educational institutions, and limits the advertising of these products to children under fourteen.\n\nAccording to a 2010 national health survey, more than 60 percent of Chile’s population suffers from excessive weight. The problem begins early in childhood, with more than 10 percent of children under six, more than 15 percent of preschoolers and more than 25 percent of first-grade children presenting with obesity. When the overweight and the obese children are considered as a group, more than 50 percent of them, according to the Chilean Ministry of Health, are found to suffer from malnutrition, which is considered the main public health problem in the country.\n\nThe law has eleven articles; its stipulations establish: \n\n\n\n\n\n\n\n\n\nHealth ministry decree No. 13 (April 16, 2015), amended the government's processed foods regulation to adapt it to the provisions of Law 20.606 and specifying maximum calories, sodium, sugars and saturated fats in food; the values were set to diminish by progressive stages after the regulation's entry into force. The limits stipulated by law are:\n\nThe regulation also detailed the foods that are exempted from the labelling obligation, which includes foods without added sugars, honey or syrups; without added sodium and without saturated fats; those sold in bulk or portioned out, divided and prepared at the request of the public (even if they are packaged at the time of sale); infant formula; commercially prepared minced baby food, unless they contain added sugar; food prepared for medical use; food for weight control regimens; dietary supplements and certain foods for athletes; and table-top sugar substitutes.\n\nSeveral countries have expressed interest in the Chilean standards and have considered their content in developing their own countries' labelling regulations, including Argentina, Australia, Brazil, Canada, Ecuador, Guatemala, Honduras, Israel, Mexico, New Zealand, Nicaragua, Panama, Peru, El Salvador and Uruguay.\n\nIn addition, international organizations — including the Caribbean Community (CARICOM), the Pan American Health Organization, the UN's Food and Agriculture Organization and World Health Organization, the Union of South American Nations and the OECD — have expressed support for the Chilean food labelling and advertising law and regulations and have facilitated bilateral cooperation, memoranda of understanding and the establishment of international networks. Codex Alimentarius has urged member countries to revise regulations on labelling, while the World Trade Organization has established international discussion panels on food labelling, at which Chile has been a prominent speaker.\n\nIn addition, during North American Free Trade Agreement negotiations, the governments of Mexico and Canada have advocated for nutritional warnings on foods, inspired by the Chilean experience, but the current United States government has supported efforts of the commercial food and beverage industry to prevent the adoption of laws similar to Chile's by demanding NAFTA clauses forbidding the enactment of such consumer safety laws in Canada, Mexico and the United States.” Lora Verheecke, a researcher at the Corporate Europe Observatory, a non-profit group tracking corporate lobbying, has declared that once such pro-industry and anti-consumer rules are enshrined into international trade agreements, it becomes extremely difficult to overturn them in the laws of trade-pact member states: “It kind of kills a law before it can be written, and once you put it into one trade agreement, it can become the precedent for all future deals with future countries.”\n"}
{"id": "25249846", "url": "https://en.wikipedia.org/wiki?curid=25249846", "title": "Functional beverage", "text": "Functional beverage\n\nA functional beverage is a drink typically intended to convey a health benefit. Some include ingredients like herbs, vitamins, minerals, nootropics, amino acids, or additional raw fruit or vegetables.\n\nExamples of functional beverages include sports and performance drinks, energy drinks, ready to drink (RTD) teas, smart drinks (shine+), enhanced fruit drinks, soy beverages, and enhanced water.\n\nFunctional beverages have become popular among people who want specific health benefits from their foods and beverages. Both convenience and health have been identified as important factors in consumers' decision-making about food and beverage purchases. Functional drinks are advertised as having various health benefits. For example, some claim to improve heart health, immunity, digestion, and joint health, while others promote themselves as satiating and energy-boosting.\n\nThe functional beverage industry is a subsector of the functional food and non-alcoholic beverage industry. It is the fastest-growing sector of the industry, partially due to the maturity of the carbonated soft drink sector and heavy investments by major food and beverage companies. Another reason for the industry's growth may be the consumer-oriented market scheme whereby innovative ideas come from consumers. By 2008, in the U.S., the market share of functional beverages accounted for 48.9% of the non-alcoholic industry, which is worth $118.3 billion.\n\nIn 2006, functional beverage consumption per capita rose to 66.4 gallons, while the carbonated soft drink sector saw a decline in per-capita consumption to 50.4 gallons (decreased from an average per-capita consumption of 192.5 gallons in 2006).\n\nFunctional beverage industry players are generally categorized into four types: \n\nThe functional beverage industry encompasses a wide range of varieties targeting different health-related concerns. One trend has been toward hybrid drinks, which are marketed as having benefits like thirst-quenching ability, with daily dosages of vitamins or other nutrients. Another trend is the rise of probiotics, exemplified by Activia yogurt, marketed for intestinal and immune health. Other beverages, like , a carambola punch energy drink in the Function Drinks line, advertise improved memory and mental sharpness. Functional drinks marketed to children have also been developed, and received attention with Nestlé's Boost.\n\nA 2005 trend toward single-serve functional beverages was fueled by consumers' demands for convenience. According to Campbell's director of single-serve beverages, \"People know they will be seen when they are drinking single-serving beverages, so the package is critical.\" Drinks marketed toward weight loss, health, and beauty (like Nova the Essential Drink) account for a considerable market share. Lastly, \"energy-boosting\" functional beverage products, such as Red Bull and 5-Hour Energy, have been rated fastest in growth in the functional beverage market.\n\nThe functional beverage industry generally competes using four primary strategies:\n\nMarket segments of the functional beverage industry are divided mainly into four parts. Those include hydration; energy/rejuvenation; health and wellness; and weight management. Each segment has its own target market and consumers. Overlapping of target consumers does occur—not because of undefined market needs, but due to consumer acceptance of functional beverages.\n\nRecently, there has been an increase in the promotion of hydration drinks. Fowhich it marketed as an exclusive hydration drink, sold only in Neiman Marcus stores. Among the drink's ingredient list were antioxidant vitamins and fruit extracts, which the company claims \"hydrate the inner and outer layer of the skin\" and protect drinkers from free radicals.\n\nGatorade has also created several drinks marketed as hydration beverages with various health benefits. Its \"Thirst Quencher\" drinks, according to advertisements, each contain an \"excellent source\" of various vitamins:\n\nIn tandem with these adjustments, a low-calorie version called G2 was also reformulated. According to Gatorade, G2 now also provides:\n\nGatorade's new products are a good example of the first major strategy of competition, listed in the \"Market\" section above. By reformulating its products, Gatorade's goals were to promote their own new products as healthier, and to emphasize the healthy ingredients in the drinks.\n\nHighly caffeinated, often highly sweetened \"energy drinks\" have become popular on the beverage market in the United States, as well as globally, in the past decade. Consumer demand has helped generate a new generation of \"energy drink\" brands containing similar amounts of caffeine, calories, and sugar.\n\nVarious stimulants found in energy drinks include taurine, glucoronolactone, caffeine, B vitamins, guarana, ginseng, ginkgo biloba, L-carnitine, sugars, antioxidants, yerba maté, creatine, and milk thistle. Although these ingredients have been approved by the FDA, health experts still recommend that consumers read their energy drinks' labels, as these ingredients may not improve health.\n\n\"Health-conscious\" individuals are among the target consumers of many functional beverage companies. To target these individuals, many companies have introduced functional beverages which contain less sugar, and therefore less calories. For example, VitaminWater 10 contains only 10 calories per serving (25 calories for a 351mL bottle, with 7.5 grams of sugar). An entire bottle also contains 250% of the RDI of vitamin C, and 25% of the RDI of vitamins B, B, B, and B. VitaminWater 10 lowered its calorie content by using an all-natural sweetener (stevia) extracted from the \"Stevia rebaudiana\" plant. This also makes it possible for the company to advertise VitaminWater 10 as \"natural\".\n\nWith increased worries about obesity and its implications on health, combined with consumer demand for convenience goods, consumer demand has increased for easy weight loss methods that can be easily integrated into daily lifestyles. Functional beverages are striving to market themselves as such, by adding ingredients that are claimed to promote weight loss.\n\nFor example:\n\nSome investigators report slimming actions induced by chlorogenic acids from green coffee, but further investigations need to be performed.\n\nAs of 2008, based on dollar sales, the most popular functional beverages, in order, were:\n\nAccording to a 2006 article, the functional beverage market's consumer group is characterized as well-educated females aged 35–55, belonging to the upper middle, middle, and lower middle classes. This is thought to result from this group's perceptions that functional drinks produce positive health beliefs, as well as their relatively high disposable income. A 2002 article stated that within the energy and stimulant drink sector, young adults aged 18 to 34 are considered to be the main target market, as evidenced by high consumption rates. However, due to constant changes in attitudes about different types of functional beverages, these target markets could change.\n\nHealth experts are concerned about the increased consumption and popularity of functional beverages. Although these beverages may serve to hydrate the individual, they may not mitigate or even address today's major health issues, such as obesity, heart disease, and cancer. Most functional beverages are sweetened, and consumption of sweetened beverages is associated with higher levels of obesity and heart disease. Most of these drinks contain significant amounts of sugars and hence calories, which would add to discretionary and total caloric intake. As such, these ingredients pose health risks because of what they contain (sugar and caffeine) or what they replace in the diet (vitamin and mineral-rich foods).\n\nAnother set of concerns is that some functional beverages contain ingredients that have not been sufficiently studied for health benefits, safety, and dosage. At the same time, many functional beverages have higher levels of a certain ingredient, like caffeine—which, when consumed in large amounts, is associated with heart disease and cancer. \n\nMany functional drinks have high levels of sugar, even if they have other \"healthy\" ingredients. For example, a 20oz bottle of Glacéau's VitaminWater has been reported to contain approximately 33 g of sugar, which is similar to the sugar content of a can of Coca-Cola. This prompted The Coca-Cola Company to be sued for claiming that VitaminWater was a healthy beverage.\n\nGiven their sugar content, many functional beverages may not be as healthy an alternative as other commonly consumed beverages. In addition, the sugar content of such beverages promotes dental cavities amongst frequent users.\n\nIn some functional beverages, particularly energy drinks, the caffeine content can be up to 141 milligrams per serving, more than an average 8-ounce cup of coffee containing 133 mg of caffeine. There have been reports to Health Canada of adverse reactions involving energy drinks.\n\n\n"}
{"id": "47951977", "url": "https://en.wikipedia.org/wiki?curid=47951977", "title": "Guardian24", "text": "Guardian24\n\nGuardian24 Ltd are a UK based solution provider for the safety of lone workers throughout the UK and Ireland. The company was founded in Belfast, Northern Ireland in 1998.\n\nIn 2000, Guardian24 developed the UK’s first lone worker support solution with a sole focus on protecting those who work alone from injury or attack.\n\nHaving begun trading in Ireland in 1998, the company was acquired by the Send for Help Group in 2014.\n\nIn December 2017, Send For Help was announced as one of Britain’s fastest growing companies for a second consecutive year. The Fast Track 100 list, which is published annually in The Sunday Times, ranks Britain’s top 100 private companies with the fastest growing sales over their latest three years. The company ranks at no. 47 in 2016 and no. 80 in the 2017 league table.\n\nGuardian24’s lone worker safety service consists of a physical safety alarm, known as the MicroGuard device as well as smartphone, tablet and mobile phone applications.\n\nGuardian24 has a 24/7 Alarm Receiving Centre (ARC) where trained controllers deal with emergency calls on a daily basis.\n\nIn 2016, Guardian24 were awarded the National Security Inspectorate (NSI) Guarding Gold. This certifies that the company have met the requirements of BS 8484:2016, along with ISO 9001, recognising British Standards for Lone Worker Security.\n\nGuardian24 were awarded 'Secured by Design' status for the MicroGuard personal safety device. 'Secured by Design' is the official UK Police initiative that supports 'designing out crime' through the use of high quality products and processes.\n\nGuardian24 have also been awarded for their efforts in research and development and innovation within the lone worker industry. Some of the awards include:\n\nSecurity & Fire Excellence Awards, 2015 – Guardian24 won this award for best deployment of Lone Worker technology with client Macmillan Cancer Support \n\nLone Worker Solutions, 2014 – An independent award recognising Guardian24’s commitment to research and development \n\nIFSEC and FIREX Awards, 2013 – Guardian24 received Lone Worker Protection Service of the Year \n\nUlster Bank Business Achiever Awards, 2011 – Guardian24 were awarded the Service Business Award to celebrate excellence and innovation in entrepreneurial companies \n\nUTV Business Eye Awards, 2011 – Guardian24 won this award for innovative research and development projects \n"}
{"id": "12739077", "url": "https://en.wikipedia.org/wiki?curid=12739077", "title": "Healing of periapical lesions", "text": "Healing of periapical lesions\n\nApical periodontitis is typically the body’s defense response to the threat of microbial invasion from the root canal. Primary among the members of the host defense mechanism is the polymorphonuclear leukocyte, otherwise known as the neutrophil. The task of the neutrophil is to locate and destroy microbes that intrude into the body – anywhere in the body – and they represent the hallmark of acute inflammation.\n\nIn response to tissue injury, neutrophils leave the circulatory system in great numbers and gather at the site of tissue injury. They are drawn to the site by chemotaxis, following a concentration gradient of chemotactic molecules until they reach the site of greatest concentration: the site of injury and microbial presence. Once there, the antimicrobial action of superoxide and hydrogen peroxide, derived from the metabolic processes of the neutrophils, act to combat the microbial invasion. While primarily mobilized to kill the invading microorganisms, the neutrophils actually cause a significant amount of host tissue damage as well. Although the neutrophils themselves rarely remain alive for more than a few days, the excessive accumulation of dead neutrophils and the enzymes they released is a major cause of tissue breakdown in the acute phases of apical periodontitis.\n\nSoon after inflammation has been initiated, macrophages enter the scene and, if not controlled by the initial ambush of neutrophils and their tactics, the microbial invasion is faced with a second strike consisting of these leukocytes, along with lymphocytes. Together, the cells of this second strike compose the bulk of the apical periodontitis lesion and serve an important role in the subsequent chronic phase of inflammation of apical periodontitis, as they can live for many months. Some researchers posit that it must not be macrophages that are involved, as they could not appropriately discriminate between the varied array of opsonized entities as necessary, and that, in reality, the properties ascribed to the macrophage in the initiation phase of the inflammatory response actually belong to the lymphatic dendritic cell. It is unclear, however, if the latter is a distinct population of cells or if it is merely a particularly specialized strain of macrophage.\n\nWhen infections such as these occur elsewhere in the body, the host defense system, able to travel the body via the circulatory system, is, more often than not, capable of appropriately gaining access to the site of infection in order to mount a proper and successful retaliation. Dental pulp, which is a richly vascularized and innervated tissue, is enclosed by tissues, such as dentin, which are incapable of expanding. It has terminal blood flow and possesses only small-gauge circulatory access at the apical foramen. All of these characteristics severely constrain the defensive capacity of the pulp tissue when faced with the different aggressions to which it may be subjected. As a result, necrotic tissue located within the pulp chamber and canals provide nutrients for pathogenic bacteria to grow and form a periapical lesion; the infected tooth serves as a biochemically and physiologically ideal location for bacterial growth and maturation, and, in essence, acts as a refuge from which bacterial reinforcements can mobilize to the periapical lesion. It is this concept that serves as the basis for conventional endodontic therapy; both chemical and mechanical debridement procedures are essential in effectively disrupting and removing the microbial ecosystem that is associated with the disease process. Thus, whenever a pulp is removed and the canal treated and filled in a manner that is compatible with or favorable to a physiologic reaction, we may expect a satisfactory percentage of endodontic success.\n\nIn 1890, W.D. Miller, considered the father of oral microbiology, was the first to associate pulpal disease with the presence of bacteria. This was confirmed by Kakehashi, who, in 1965, proved that bacteria were the cause of pulpal and periradicular disease in studies using animal models; pulpal exposures were initiated in both normal and germ-free rats, and while no pathologic changes were exhibited in the mouths of the germ-free rats, introduction of the normal oral microbial flora produced pulpal necrosis and led to periradicular lesion formation in the normal rats. The germ-free rats healed regardless of the severity of pulpal exposure, demonstrating that the presence or absence of bacteria was the determinant for pulpal and periapical disease.\n\nMoreover, it has since been discovered that endodontic infections are polymicrobial. In fact, the bacteria present within endodontic infections are thoroughly similar to the bacteria that are involved in periodontal disease. It has also been shown that certain enzymes produced by bacteria are detrimental to the host, and can work in concert with the destructive capability of the enzymes released by dying neutrophils. Recent studies have revealed that the gene for collagenases could be detected in stains of \"Porphyromonas gingivalis\", one of the many endodontic infective agents that are also involved in periodontal disease.\n\nAdditionally, it has been proven that a positive correlation exists between the number of bacteria in an infected root canal and the size of the resultant periradicular radiolucency.\n\nIn attempting to resolve a periapical lesion of endodontic origin, it is essential to be conscious of these principles in order to effectively combat the infection. Without proper consideration for the causes, the pulpal and periapical infection cannot be suitably treated, for effective patient management requires the correct diagnosis and removal of the cause of the infection of endodontic origin to correct the associated periapical lesion. Because periapical disease is almost inevitably preceded by pulp disease, proper chemomechanical debridement of the infected root canals, together with incision and drainage of associated periradicular swellings, will usually allow for rapid improvement in patient signs and symptoms. The same end can be accomplished by extracting the involved tooth.\n\nAlthough periapical changes will be in response to pulpal changes the majority of the time, it is still important to determine the disease process sequence. When the disease process is of pulpal origin, the pulpal infection and necrosis may drain not only through the apical foramen, but also through an accessory canal, which may present radiographically as a periradicular or furcation radiolucency. This may further lead to furcal involvement through loss of clinical attachment and alveolar bone. A cursory clinical examination and radiographic analysis can easily lead the clinician off the right course and pulpal involvement might be overlooked when the tooth is asymptomatic. Similarly, a periodontal abscess may very well appear to be pulpal in origin, when in fact it is not. Notwithstanding the tissue of origin, though, when it is determined that there is a pulpal involvement to the periodontal lesion, the endodontic infection should be controlled prior to beginning definitive management of the periodontal lesion, especially when regenerative or bone grafting techniques are planned.\n\nTo achieve healing of the periapical lesion, one must obtain and maintain a decontaminated root canal system. \"System\" is to be emphasized, because the root canal system does not merely consist of tapering cone-shaped canals from orifice to apex, but rather, can and often is an intricate labyrinth of canals that diverge and weave to form an elaborate web of anastomosing passages. It is precisely because of this reality that “it is important to appreciate that files produce shape, but it is essential to understand that irrigants clean [the] root canal system. Copious amounts of sodium hypochlorite are necessary to utterly dissolve all remnants of pulp tissue as well as completely destroy all microorganisms. The tooth stability does not undergo major changes after surgery comparated with the initial value which was determined before establishing any kind of treatment.\n\nMany authoritative clinicians and researchers advise completing endodontic therapy as soon as possible, especially in situations necessitating incision and drainage, in order to remove the cause of infection without delay. Recent studies have shown, however, that intracanal application of certain medicaments prior to the completion of endodontic therapy may produce highly favorable results when followed by conventional therapy, even when the periapical area is very large. The use of chlorhexidine gluconate and calcium hydroxide for infection control was shown to lead to substantial healing of a large periapical lesion.\n\nThe traditional thought that it is necessary to complete endodontic therapy as quickly as possible may be related only to the initial steps of therapy, namely, a thorough instrumentation, thus ensuring a proper biomechanical preparation. While completion of the procedure with immediate obturation might secure the decontaminated root canal system, delaying this step in order to allow for application of medicaments has been shown to be beneficial. Periodic application and renewal of calcium hydroxide over a year’s time (four applications over a 12-month period), has been shown to represent a nonsurgical approach to resolving even extensive inflammatory periapical lesions.\n\nThe use of adjunctive antibiotics is usually uncalled for when proper debridement procedures can be executed in a conventional periapical lesion of endodontic origin; however, they can be centrally important to the treatment of a progressive or persistent infection. It has been proposed, however, that disinfection of the root canal by means of an antibacterial agent, such as propolis or otosporin, can lead to improved healing by reducing and controlling pulpal and periapical inflammatory reactions. This would, in turn, promote the healing process as well as provide for better control, prevention and reduction of post-treatment pain and discomfort.\n\nThere are a number of active biologic mediators that have been implicated in promoting apical resorption. Matrix metalloproteinases (MMPs), which are endogenous zinc-dependent catabolic enzymes, are primarily responsible for the degradation of much of the tissue matrices built on such architecturally important substances as collagen and proteoglycan core proteins. Their biologic activities have been extensively researched and reviewed, and their importance in the pathogenesis of apical periodontitis is obvious. Furthermore, concentrations of IgG antibodies have been found to be nearly five times higher in lesions of apical periodontitis than in uninflamed oral mucosa.\n\nProstaglandins, specifically PGE2 and PGI2, are important in inflammation and have been implicated in promoting apical resorption. This is because neutrophils, which are rich sources of PGE2, are present when the majority of rapid bone loss occurs during the initial stages of apical periodontitis. It has been illustrated clinically that parenteral administration of indomethacin, an inhibitor of cyclooxygenase, can act to suppress resorption of apical hard tissue.\n\nThe predominant mechanism of bone resorption in a periapical lesion, as in the rest of the body, is the performed by osteoclasts. In the periapical lesion, mediators that are normally produced primarily only by osteoblasts are released by many other cells as well, overstimulating proosteoclasts. As a result, these begin to proliferate and several cells fuse to form multinucleated giant cells capable of spreading over the infected, injured site and cause resorption of the periapical alveolar bone.\n\nIt is possible that after conventional endodontic therapy has been completed, little to no resolution of the periapical lesion occurs over a considerable amount of time; there is a great deal of current research that discusses the possible reasons for this outcome and suggests possible treatment options. For example, it has been demonstrated that there is an association between nonresolving apical periodontitis lesions and the presence of cholesterol clefts within the periapical lesion; in fact, an incidence of up to 44% has been reported! It was shown that macrophages joined to form multinucleated giant cells and then produced a well-circumscribed area of tissue reaction, not unlike the granulomatous tissue reactions of a typical foreign body reaction, and persisted for up to 8 months. Similarly, endodontic materials as well as food debris may also be the cause of persistent periapical lesions. It was once shown that contaminated gutta percha resulted in a persistent periapical lesion for more than a decade!\n\nFor retreatment of a non-healing lesion, there is really no magical method that can be employed; the course of action is merely to achieve what was supposed to have been achieved the first time. Keeping in mind the notion that endodontic retreatment is a problem-solving exploit will substantially increase its success.\n\nAfter endodontic therapy has been executed, or re-executed, successfully, and the canals can no longer provide a nutrient-rich habitat for microbes, the issue of bone healing comes into focus. Ostensibly, then, for regeneration to occur, the root canal system must have been decontaminated and further access to microbial invasion must be prohibited. Regeneration of the bone has been demonstrated to occur, on average, at a rate of 3.2 mm² per month, and studies suggest that 71% of lesions have achieved complete resolution one year post-operatively.\n\nSituations in which a surgical form of retreatment had been selected and in which apical resolution has still not occurred may still benefit from additional surgical intervention. A comparison of the outcome of periradicular surgery in teeth that had previously undergone surgical treatment versus teeth that were undergoing a surgical procedure for the first time showed that, after 5 years, 86% of surgically treated teeth healed with complete bone filling of the surgical cavity while only 59% of resurgically treated teeth healed with complete bone filling. It has thus been demonstrated that surgical retreatment of teeth previously treated with surgery is a valid alternative to extraction.\n\nHowever, a combination of three antibiotics (metronidazole, ciprofloxacin, and minocycline) in a paste has been used successfully to treat these lesions non-surgically.\n"}
{"id": "2176031", "url": "https://en.wikipedia.org/wiki?curid=2176031", "title": "Healthcare Effectiveness Data and Information Set", "text": "Healthcare Effectiveness Data and Information Set\n\nThe Healthcare Effectiveness Data and Information Set (HEDIS) is a widely used set of performance measures in the managed care industry, developed and maintained by the National Committee for Quality Assurance (NCQA).\n\nHEDIS was designed to allow consumers to compare health plan performance to other plans and to national or regional benchmarks. Although not originally intended for trending, HEDIS results are increasingly used to track year-to-year performance. HEDIS is one component of NCQA's accreditation process, although some plans submit HEDIS data without seeking accreditation. An incentive for many health plans to collect HEDIS data is a Centers for Medicare and Medicaid Services (CMS) requirement that health maintenance organizations (HMOs) submit Medicare HEDIS data in order to provide HMO services for Medicare enrollees under a program called .\n\nHEDIS was originally titled the \"HMO Employer Data and Information Set\" as of version 1.0 of 1991. In 1993, Version 2.0 of HEDIS was known as the \"Health Plan Employer Data and Information Set\". Version 3.0 of HEDIS was released in 1997. In July 2007, NCQA announced that the meaning of \"HEDIS\" would be changed to \"Healthcare Effectiveness Data and Information Set.\"\n\nIn current usage, the \"reporting year\" after the term \"HEDIS\" is one year following the year reflected in the data; for example, the \"HEDIS 2009\" reports, available in June 2009, contain analyses of data collected from \"measurement year\" January–December 2008.\n\nThe 83 HEDIS measures are divided into five \"domains of care\": \n\nMeasures are added, deleted, and revised annually. For example, a measure for the length of stay after giving birth was deleted after legislation mandating minimum length of stay rendered this measure nearly useless. Increased attention to medical care for seniors prompted the addition of measures related to glaucoma screening and osteoporosis treatment for older adults. Other health care concerns covered by HEDIS are immunizations, cancer screenings, treatment after heart attacks, diabetes, asthma, flu shots, access to services, dental care, alcohol and drug dependence treatment, timeliness of handling phone calls, prenatal and postpartum care, mental health care, well-care or preventive visits, inpatient utilization, drug utilization, and distribution of members by age, sex, and product lines.\n\nNew measures in HEDIS 2013 are “Asthma Medication Ratio,” “Diabetes Screening for People With Schizophrenia and Bipolar Disorder Who Are Using Antipsychotic Medications,” “Diabetes Monitoring for People With Diabetes and Schizophrenia,” “Cardiovascular Monitoring for People With Cardiovascular Disease and Schizophrenia,” and “Adherence to Antipsychotic Medications for Individuals With Schizophrenia.”\n\nHEDIS data are collected through surveys, medical charts and insurance claims for hospitalizations, medical office visits and procedures. Survey measures must be conducted by an NCQA-approved external survey organization. Clinical measures use the administrative or hybrid data collection methodology, as specified by NCQA. Administrative data are electronic records of services, including insurance claims and registration systems from hospitals, clinics, medical offices, pharmacies and labs. For example, a measure titled Childhood Immunization Status requires health plans to identify 2 year old children who have been enrolled for at least a year. The plans report the percentage of children who received specified immunizations. Plans may collect data for this measure by reviewing insurance claims or automated immunization records, but this method will not include immunizations received at community clinics that do not submit insurance claims. For this measure, plans are allowed to select a random sample of the population and supplement claims data with data from medical records. By doing so, plans may identify additional immunizations and report more favorable and accurate rates. However, the hybrid method is more costly, time-consuming and requires nurses or medical record reviewers who are authorized to review confidential medical records.\n\nHEDIS results must be audited by an NCQA-approved auditing firm for public reporting. NCQA has an on-line reporting tool called Quality Compass that is available for a fee of several thousand dollars. It provides detailed data on all measures and is intended for employers, consultants and insurance brokers who purchase health insurance for groups. NCQA's web site includes a summary of HEDIS results by health plan. NCQA also collaborates annually with U.S. News & World Report to rank HMOs using an index that combines many HEDIS measures and accreditation status. The \"Best Health Plans\" list is published in the magazine in October and is available on the magazine's web site. Other local business organizations, governmental agencies and media report HEDIS results, usually when they are released in the fall.\n\nProponents cite the following advantages of HEDIS measures:\n\n\nHEDIS was described in 1995 as \"very controversial\". Criticisms of HEDIS measures have included:\n\n\nhttp://www.ncqa.org/Portals/0/HEDISQM/HEDIS2013/HEDIS_2013_October_Update_Final_10.1.12.pdf\n\n"}
{"id": "2820462", "url": "https://en.wikipedia.org/wiki?curid=2820462", "title": "Hegar's sign", "text": "Hegar's sign\n\nHegar sign is a non-sensitive indication of pregnancy in women — its absence does not exclude pregnancy. It pertains to the features of the cervix and the uterine isthmus. It is demonstrated as a softening in the consistency of the uterus, and the uterus and cervix seem to be two separate regions.\n\nThe sign is usually present from 4–6 weeks until the 12th week of pregnancy. Hegar's sign is more difficult to recognize in multiparous women.\nInterpretation : On bimanual examination, (two fingers in the anterior fornix and two fingers below the uterus per abdomen) the abdominal and vaginal fingers seem to oppose below the body of uterus (examination must be gentle to avoid abortion).\n\nThis sign was repeatedly demonstrated and described by Ernst Ludwig Alfred Hegar, a German gynecologist, in 1895. Hegar credited Reinl, one of his assistants, who originally described this sign in 1884.\n\n\n"}
{"id": "47392188", "url": "https://en.wikipedia.org/wiki?curid=47392188", "title": "Identification of medicinal products", "text": "Identification of medicinal products\n\nIdentification of Medicinal Products (IDMP) is a set of five ISO norms which has been developed in response to a worldwide demand for internationally harmonized specifications for medicinal products. IDMP provides the basis for the unique identification of medicinal products, it facilitates the activities of medicines regulatory agencies worldwide by jurisdiction for a variety of regulatory activities (development, registration and life cycle management of medicinal products; pharmacovigilance and risk management). IDMP is the base for the Marketing authorization of medicinal products in Europe. It requires the five ISO Norms being implemented in the Marketing Authorization Application process.\n\nMessaging specifications are included as an integral part of the IDMP standards. They describe and protect the integrity of the interactions for the submission of regulated medicinal product information in the context of the unique product identification; they include acknowledgement of receipt including the validation of transmitted information. Health level Seven (HL7) Message Exchange are normative within the IDMP Standards.\n\nIDMP Standards are designed to allow unambiguous identification of products across regions to improve the robustness of pharmacovigilance and regulatory activities. They can also be applied to Investigational Medicinal Products.\n\nIDMP Standards are completed with Implementation Guides which are currently in development (2017).\n\nThe standards can be found from ISO TC 215´s deliveries\n\nRegulated information on substances\n\nDefines substances and specified substances by their main general characteristics, and their roles in medicinal products (e.g. active, adjuvant). In addition specified substances are listed more granular with specific descriptions (e.g. including manufacturing information, grade of purity etc.).\n\nRegulated Information on pharmaceutical dose forms, units of presentation, routes of administration and packaging\n\nIdentifies and defines concepts for each of the above. For example, in dose forms: “injection solution”, “injection suspension” (or a less granular regional term linked to these)\n\nRegulated medicinal product information\n\nDefines, characterises and uniquely identifies regulated medicinal products during their entire life cycle (development, authorisation, post-Marketing and renewal or withdrawal from the market) by describing the detailed data elements and their structural relationships\n\nRegulated pharmaceutical product information\n\nPharmaceutical Product Identification (PhPID) uniquely identifies a generic (pharmaceutical) representation of a medicinal product at Levels Substance(s)/Strength(s) – Strength Units /Reference Strengths per Administrable Dose Form\n\nUnits of measurement\n\nSpecifies rules for the usage of units of measurement for IDMP;\ndefines requirements for traceability to metrological standards; establishes reference code system for units; provides structure and rules for mapping between different unit vocabularies and language translations.\n\n\nEuropean Medicines Agency (EMA) IDMP Landingpage\n"}
{"id": "50740518", "url": "https://en.wikipedia.org/wiki?curid=50740518", "title": "International Decision Support Initiative", "text": "International Decision Support Initiative\n\nThe International Decision Support Initiative (iDSI) is a partnership between governments, universities, and thinktanks that helps health policy makers make better decisions. iDSI targets low- and middle-income countries (LMICs), helping them prioritize health interventions as a means toward universal health coverage. iDSI launched in November 2013 as the result of a 2012 Center for Global Development working group.\n\nThe following organizations are iDSI's core partners:\n\n\nOther partners include Centre for Health Economics (at the University of York), Imperial College London, Itad, Johns Hopkins Berman Institute of Bioethics, the London School of Hygiene and Tropical Medicine, Meteos, Office of Health Economics, the University of Glasgow, and the University of Strathclyde.\n\niDSI receives funding from the Bill & Melinda Gates Foundation, the UK Department for International Development, and the Rockefeller Foundation.\n\nIn December 2015, iDSI received $12.8 million in funding from the Bill & Melinda Gates Foundation for phase 2 of its operations.\n\niDSI has operated in China, India, Indonesia, Myanmar, the Philippines, South Africa, and Vietnam as \"focus countries\", but has also operated in additional countries.\n\nMost of iDSI's work has focused on noncommunicable diseases, maternal and child death, and more general priority-setting.\n\nAs part of their focus on universal health care, iDSI has also worked on priority setting for mental health.\n\niDSI is one of the collaborators for DCP3.\n\n"}
{"id": "24223801", "url": "https://en.wikipedia.org/wiki?curid=24223801", "title": "Kazutaka Kogi", "text": "Kazutaka Kogi\n\nKazutaka Kogi (born 1933) is a Japanese academic known for his contributions to simple, low-cost interventions in small manufacturing enterprises that improve the working conditions for the employees and at the same time also improve the overall productivity of the workforce. The interventions are based on simple and low-cost modifications, on local solutions to highly specific local problems and specifically on the collaboration between the shopfloor and the managerial level. This collaborative or participatory approach is possible because the intervention is presented as a win-win situation for both parties. Kazutaka Kogi and his colleague Kageyo Noro are considered to have founded the concept of participatory ergonomics in Singapore in 1983\n\nHe has worked extensively for the International Labour Organization and held the Vice-Presidency for ICOH in 2006-2009.\n\n\n"}
{"id": "31320936", "url": "https://en.wikipedia.org/wiki?curid=31320936", "title": "List of cholesterol in foods", "text": "List of cholesterol in foods\n\nThis list consists of common foods with their cholesterol content recorded in milligrams per 100 grams (3.5 ounces) of food.\n\nCholesterol is a sterol, a steroid-like lipid made by animals, including humans. The human body makes one-eighth to one-fourth teaspoons of pure cholesterol daily. A cholesterol level of 5.5 millimoles per litre or below is recommended for an adult. The rise of cholesterol in the body can give a condition in which excessive cholesterol is deposited in artery walls called atherosclerosis. This condition blocks the blood flow to vital organs which can result in high blood pressure or stroke. \nCholesterol is not always bad. It's a vital part of the cell wall and a precursor to substances such as brain matter and some sex hormones. There are some types of cholesterol which are beneficial to the heart and blood vessels. High-density lipoprotein is commonly called \"good\" cholesterol. These lipoproteins help in the removal of cholesterol from the cells, which is then transported back to the liver where it is disintegrated and excreted as waste or broken down into parts.\n\n\n"}
{"id": "13139134", "url": "https://en.wikipedia.org/wiki?curid=13139134", "title": "List of counseling topics", "text": "List of counseling topics\n\nCounseling is the activity of the counselor, or a professional who counsels people, especially on personal problems and difficulties.\n\nThis is a list of counseling topics.\n\n"}
{"id": "23281432", "url": "https://en.wikipedia.org/wiki?curid=23281432", "title": "List of current youth hearing conservation programs", "text": "List of current youth hearing conservation programs\n\n\n"}
{"id": "35200902", "url": "https://en.wikipedia.org/wiki?curid=35200902", "title": "Low-threshold treatment programs", "text": "Low-threshold treatment programs\n\nLow-threshold treatment programs are harm reduction-based health care centers targeted towards drug users. \"Low-threshold\" programs are programs that make minimal demands on the patient, offering services without attempting to control their intake of drugs, and providing counselling only if requested. Low-threshold programs may be contrasted with \"high-threshold\" programs, which require the user to accept a certain level of control and which demand that the patient accept counselling.\n\nLow-threshold treatment programs are not to be confused with simple needle exchange programs, and may include comprehensive healthcare and counseling services. The International Journal of Drug Policy in its volume 24 published an Editorial which endeavoured to define a service known to be \"low-threshold\", based on some popular and known criteria. According to that Editorial, low-threshold services for drug users can be defined as those which offer services to drug users; do not impose abstinence from drug use as a condition of service access; and endeavour to reduce other documented barriers to service access.\n\nInjection drug users (IDUs) are at risk of a wide range of health problems arising from non-sterile injecting practices, complications of the drug itself or of the lifestyle associated with drug use and dependence. Furthermore, unrelated health problems, such as diabetes, may be neglected because of drug dependence. However, despite their increased health care needs, IDUs do not have the required access to care or may be reluctant to use conventional services. Consequently, their health may deteriorate to a point at which emergency treatment is required, with considerable costs to both the IDUs and the health system. Accordingly, harm reduction based health care centers, also known as \"targeted health care outlet\" or \"low-threshold health care outlet\" for IDUs have been established across a range of settings utilising a variety of models. These targeted outlets provide integrated, low-threshold services within a harm-reduction framework targeting IDUs, and sometimes include social and/or other services. Where a particular service is not provided, referral and assistance with access is available. In 2007, for example, 33% of all US needle-syringe programs (NSPs) provided on-site medical care, and 7% provided buprenorphine treatment. Similarly, in many European countries NSP outlets serve as low-threshold primary health care centers targeting primarily IDUs.\n\nThese targeted outlets vary widely and may be either \"distributive\", providing basic harm reduction services and simple healthcare with facilitated referrals to specialist services, or \"one-stop-shops\" where a range of services including specialist services are provided onsite. The services being offered by these outlets range from simple needle and syringe provision, to expanded services including basic and preventive primary healthcare, hepatitis B and A vaccinations, hepatitis C testing, counselling, tuberculosis screening and sometimes opioid maintenance therapy. Some centers offer hepatitis, HIV treatment and dental care. The goal of these outlets is to provide: (1) opportunistic health care, (2) increased temporal and spatial availability of health care, (3) trustworthy services of health care, (4) cost-effective mode of health care, (5) targeted and tailored services.\n\nIn the United States as of 2011, 211 NSPs were known to be operating in 32 states, the District of Columbia, Puerto Rico and the Indian Nations. The bulk of funding has come from state and local governments, since for most of the last several decades, federal funding for needle exchange programs has been specifically banned.\n\nGlobally, as of 2008, at least 77 countries and territories offer NSPs with varying structures, aims and goals. Some countries use needle exchange services as part of integrated programs to contain drug use, while others aim simply to contain HIV infection as their top priority, considering reduction in incidence of drug use as a much lower priority. Acceptance of NSPs vary widely from country to country. On the one hand, in Australia and New Zealand, electronic dispensing machines are available at selected locations such as the Auckland needle exchange and the Christchurch needle exchange, allowing needle exchange service 24 hours to registered users. On the other hand, over half of the countries in Asia, the Middle East, and North Africa retain the death penalty for drug offenses, although some have not carried out executions in recent years.\n\nLow-threshold programs offering needle exchange have faced much opposition on political and moral grounds. Concerns are often expressed that NSPs may encourage drug use, or may actually increase the number of dirty needles in the community. Another fear is that NSPs may draw drug activity into the communities in which they operate. It has also been argued that in fighting disease, needle exchanges take attention away from bigger drug problems, and that, contrary to saving lives, they actually contribute to drug-related deaths. Even in Australia, which is considered a leading country in harm reduction, a survey showed that a third of the public believed that NSPs encouraged drug use, and 20% believed that NSPs dispensed drugs. In the United States, the ambivalent public attitude towards NSPs is often reflected in police interference, with 43% of NSP program managers reporting frequent (at least monthly) client harassment, 31% reporting frequent confiscation of clients' syringes, 12% reporting frequent client arrest, and 26% reporting uninvited police appearances at program sites. A single 1997 study which showed a correlation between frequent program use and elevated rates of HIV infection among IDUs in Vancouver, Canada, has become widely cited by opponents of NSPs as demonstrating their counter-productiveness.\n\nAuthors from the 1997 Vancouver study have, in multiple publications, issued disclaimers against the misuse of their work by opponents of NSPs. They point out that frequent attendees of the program tended to be young and often indulged in extreme high-risk behaviors. The 1997 results were hence of a statistically biased sampling. They have emphasized that the correct message to be derived from their 1997 study can be read in the title of their work: \"Needle exchange is not enough\". This is the same message presented by many other articles since.\n\nComprehensive, systematic surveys of the costs and effectiveness of low-threshold primary healthcare programs are not available due to the heterogeneity of these programs and the study designs. Narrower focus studies dealing solely with the needle exchange issue are abundant, however, and generally support the thesis that NSPs reduce the risk of prevalence of HIV, hepatitis and other blood-bourne diseases. These studies suggest that such outlets improve the overall health status of IDUs and save on the health budget by reducing episodes in emergency departments and tertiary hospitals. In Australia, monitoring of drug users participating in NSPs showed the incidence of HIV among NSP clients to be essentially identical to that of the general population. Fears that NSPs may draw drug activity into the communities in which they operate are contradicted by a study that showed that by far the greatest number of clients of an NSP in Chicago came to the area to exchange needles (60%) rather than to buy drugs (3.8%).\n\nInternationally, support for the effectiveness of low-threshold programs including needle exchange have come from studies conducted in Afghanistan, China, Spain, Taiwan, Estonia, Canada, Iran, and many other countries. However, in many countries, there is strong opposition to such programs.\n\nDespite the lack of definitive scientific evidence on the effectiveness of IDU-targeted low-threshold services, the available evidence, revealing barriers to service access and the late presentation of seriously ill IDUs to hospital, suggests the ongoing need for targeted and low-threshold services. Because of this, organizations ranging from the National Institutes of Health, the Centers for Disease Control, the American Bar Association, the American Medical Association, the American Psychological Association, the World Health Organization, and many others have endorsed low-threshold programs including needle exchange.\n"}
{"id": "44848510", "url": "https://en.wikipedia.org/wiki?curid=44848510", "title": "Nigel Edwards (health)", "text": "Nigel Edwards (health)\n\nNigel Edwards is a health policy researcher, appointed Chief Executive at the Nuffield Trust in April 2014.\n\nHe was formerly an expert advisor with KPMG’s Global Centre of Excellence for Health and Life Sciences, a Senior Fellow at The King’s Fund. He was Policy Director of the NHS Confederation for 11 years.\n\nHe has commented on government announcements about the English NHS, such as George Osborne's promise to find extra cash for the NHS, and the reconfiguration of cancer services in Staffordshire. In 2014 he is reported as saying \" that \"there's nothing intrinsically bad about private or public sector provision\", and that the Better Care Fund might live up to the advertised savings if it concentrated entirely on moving people out of hospital into residential care.\n\nHe was reckoned by the Health Service Journal to be the 42nd most influential person in the English NHS in 2015.\n\nAs of autumn 2017 Edwards is concerned about the condition and funding of the NHS. Edwards stated, “It is indisputable that the NHS is facing a yet another difficult winter. But whether or not it experiences a full-blown crisis will depend largely on unpredictable events, like a sudden outbreak of flu or norovirus. What is clear is that, seven years into austerity, the pressure on the system is immense, making the health service much less resilient to these kinds of events than is comfortable.”\n"}
{"id": "150389", "url": "https://en.wikipedia.org/wiki?curid=150389", "title": "Nipple", "text": "Nipple\n\nThe nipple is a raised region of tissue on the surface of the breast from which, in females, milk leaves the breast through the lactiferous ducts to feed an infant. The milk can flow through the nipple passively or it can be ejected by smooth muscle contractions that occur along the ductal system. The nipple is surrounded by the areola which is often a darker color than the surrounding skin. It is often called a teat when referring to non-humans. Teat can also be used to describe the flexible mouthpiece of a baby bottle. In humans, nipples of both males and females can be stimulated as part of sexual arousal. In many cultures, human female nipples are sexualized, or \"...regarded as sex objects and evaluated in terms of their physical characteristics and sexiness.\"\n\nIn mammals, a nipple (also called mammary papilla or teat) is a small projection of skin containing the outlets for 15–20 lactiferous ducts arranged cylindrically around the tip. Marsupials and eutherian mammals typically have an even number of nipples arranged bilaterally, from as few as two to as many as 19.\n\nThe skin of the nipple is rich in a supply of special nerves that are sensitive to certain stimuli: these are slowly-adapting and rapidly-adapting cutaneous mechanoreceptors. Mechanoreceptors are identified respectively by Type I slowly-adapting with multiple Merkel corpuscle end-organs and Type II slowly-adapting with single Ruffini corpuscle end-organs, as well as Type I rapidly-adapting with multiple Meissner corpuscle end-organs and Type II rapidly-adapting with single Pacinian corpuscle end-organs. The dominant nerve supply to the nipple comes from the lateral cutaneous branches of fourth intercostal nerve. The nipple is also used as an anatomical landmark. It marks the T4 (fourth thoracic vertebra) dermatome and rests over the approximate level of the diaphram.\n\nThe arterial supply to the nipple and breast originates from the anterior intercostal branches of the internal thoracic (mammary) arteries; lateral thoracic artery; and thoracodorsal arteries. The venous vessels parallel the arteries. The lymphatic ducts that drain the nipple are the same for the breast. The axillary nodes are the apical axillary nodes, the lateral group and the anterior group. 75% of the lymph is drained through the axillary lymph nodes located near the armpit. The rest of the drainage leaves the nipple and breast through infroclavicular, pectoral, or parasternal nodes.\n\nSince nipples change throughout the life span in men and women, the anatomy of the nipple can change and this change may be expected and considered normal.\n\nAlmost all mammals have nipples. Why males have nipples has been the subject of scientific research. Differences among the sexes (called sexual dimorphism) within a given species are considered by evolutionary biologists to be mostly the result of sexual selection, directly or indirectly. For traits where there is no difference among the sexes, evolutionary biologists assume that there has been no advantage to one of the sexes losing the trait.\n\nThe physiological purpose of nipples is to deliver milk to the infant, produced in the female mammary glands during lactation. During breastfeeding, nipple stimulation by an infant will simulate the release of oxytocin from the hypothalamus. Oxytocin is a hormone that increases during pregnancy and acts on the breast to help produce the milk-ejection reflex. Oxytocin release from the nipple stimulation of the infant causes the uterus to contract even after childbirth. The strong uterine contractions that are caused by the stimulation of the mother's nipples help the uterus contract to clamp down the uterine arteries. These contractions are necessary to prevent post-partum hemorrhage.\n\nWhen the baby suckles or stimulates the nipple, oxytocin levels rise and small muscles in the breast contract and move the milk through the milk ducts. The result of nipple stimulation by the newborn helps to move breast milk out through the ducts and to the nipple. This contraction of milk is called the “let-down reflex.” Latching on refers to the baby fastening onto the nipple to breastfeeding. A good attachment is when the bottom of the areola (the area around the nipple) is in the baby's mouth and the nipple is drawn back inside his or her mouth. A poor latch results in insufficient nipple stimulation to create the let down reflex. The nipple is poorly stimulated when the baby latches on too close to the tip of the nipple. This poor attachment can cause sore and cracked nipples and a reluctance of the mother to continue to breastfeed. After the birth of the infant, the milk supply increases based upon the continuous and increasing stimulation of the nipple by the infant. If the baby increases nursing time at the nipple, the mammary glands respond to this stimulation by increasing milk production.\n\nNipple pain can be a disincentive for breastfeeding. Sore nipples that progress to cracked nipples is of concern since many woman cease breastfeeding due to the pain. In some instances an ulcer will form on the nipple. One reason for the development of cracked and sore nipples is the incorrect latching-on of the infant to the nipple. If a nipple appears to be wedge-shaped, white and flattened, this may indicates that the attachment of the infant is not good and there is a potential of developing cracked nipples. Herpes infection of the nipple is painful. Nipple pain can also be caused by excessive friction of clothing against the nipple that causes a fissure.\n\nNipple discharge refers to any fluid that seeps out of the nipple of the breast. Discharge from the nipple does not occur in lactating women. And discharge in non-pregnant women or women who are not breasfeeding may not cause concern. Men that have discharge from their nipples are not typical. Discharge from the nipples of men or boys may indicate a problem. Discharge from the nipples can appear without squeezing or may only be noticeable if the nipples are squeezed. One nipple can have discharge while the other does not. The discharge can be clear, green, bloody, brown or straw-colored. The consistency ct can be thick, thin, sticky or watery.\n\nSome cases of nipple discharge will clear on their own without treatment. Nipple discharge is most often not cancer (benign), but rarely, it can be a sign of breast cancer. It is important to find out what is causing it and to get treatment. Here are some reasons for nipple discharge:\n\n\nSometimes, babies can have nipple discharge. This is caused by hormones from the mother before birth. It usually goes away in 2 weeks. Cancers such as Paget disease (a rare type of cancer involving the skin of the nipple) can also cause nipple discharge.\n\nNipple discharge that is not normal is bloody, comes from only one nipple, or comes out on its own without squeezing or touching the nipple. Nipple discharge is more likely to be normal if it comes out of both nipples or happens when the nipple is squeezed your nipples. Squeezing the nipple to check for discharge can make it worse. Leaving the nipple alone may make the discharge stop.\n\nAny nipple discharge in a male usually is of more concern. Most of the time a mammogram and an examination of the fluid is done. Oftentimes a biopsy is performed A fine needle aspiration (FNA) biopsy can be fast and least painful. A very thin, hollow needle and slight suction will be used to remove a small sample from under the nipple. Using a local anesthetic to numb the skin may not be necessary since a thin needle is used for the biopsy. Receiving an injection to prevent pain from the biopsy may be more painful than the biopsy itself.\n\nSome genetically-males develop a condition known as gynecomastia, in which the breast tissue under the nipple develops and grows. Discharge from the nipple can occur. The nipple may swell in some genetically-males possibly due to increased levels of estrogen.\n\nChanges in appearance may be normal or related to disease.\nThe average projection and size of human female nipples is slightly more than .\n\nSymptoms of breast cancer can often be seen first by changes of the nipple and areola, although not all women have the same symptoms, and some people do not have any signs or symptoms at all. A person may find out they have breast cancer after a routine mammogram.\nWarning signs can be:\n\n\nChanges in the nipple are not necessarily symptoms or signs of breast cancer. Other conditions of the nipple can mimic the signs and symptoms of breast cancer.\n\nSome infections are transmitted through the nipple, especially if irritation or injury to the nipple has occurred. In these circumstances, the nipple itself can become infected with Candida that is present in the mouth of the breastfeeding infant. The infant will transmit the infection to the mother. Most of the time, this infection is localized to the area of the nipple. In some cases the infection can can progress to become a full-blown case of mastitis or breast infection. In some cases, if the mother has an infection with no nipple cracks or ulcerations, it is still safe to breastfeed the infant.\n\nHerpes infection of the nipple can go unnoticed because the lesions are small but usually are quite painful. Herpes in the newborn is a serious and sometimes fatal infection. Transmission of Hepatitis C and B to the infant can occur if the nipples are cracked.\n\nOther infections can be transmitted through a break of the skin of the nipple and can infect the infant.\n\nA nipple-sparing/subcutaneous mastectomy is a surgical procedure where breast tissue is removed, but the nipple and areola is preserved. This procedure was historically done only prophylactically or with mastectomy for benign disease over fear of increased cancer development in retained areolar ductal tissue. Recent series suggest that it may be an oncologically sound procedure for tumors not in the subareolar position.\n\nThe culture tendency to hide the female nipple under clothing has existed in Western culture since the 1800s. As female nipples are often perceived an intimate part, covering them might originate as a Victorian taboo just as was riding side saddle. Exposing the entire breast and nipple is a form of protest for some and a crime for others. The exposure of nipples is usually considered immodest and in some instances is viewed as lewd or indecent behavior.\n\nA case in Erie, Pennsylvania concerning the exposure of breasts and nipple proceeded to the Supreme Court in the US. The Erie ordinance was regulating the nipple in public as an act that is committed when a person \"'... knowingly or intentionally, ... appears in a state of nudity commits Public Indecency.'\" Later in the statute, nudity is further described as an uncovered female nipple. But nipple exposure of a man was not regulated. A commentator expressed this opinion on the statute by noting: \"Ponder the significance of that. A man walks around bare-chested and the worst that happens is he won't get served in restaurants. But a woman who goes topless is legally in the same boat as if she'd had sex in public. That may seem crazy, but in the U.S. it's a permissible law. — Cecil Adams\"\nThe legality around the exposure of nipples are inconsistently regulated throughout the US. Some states do not allow the visualization of any part of the breast. Other jurisdictions prohibit any female chest anatomy by banning anatomical structures that lie below the top of the areola or nipple. Such is the case in West Virginia and Massachusetts. West Virginia's regulation is very specific and is not likely to be misinterpreted and states: \"[The] display of 'any portion of the cleavage of the human female breast exhibited by a dress, blouse, skirt, leotard, bathing suit, or other wearing apparel provided the areola is not exposed, in whole or in part.'\"\n\nInstagram has a 'no nipples' policy with exceptions: material that is not allowed includes \"...some photos of female nipples, but photos of post-mastectomy scarring and women actively breastfeeding are allowed. Nudity in photos of paintings and sculptures is OK, too\". Previously, Instagram had removed images of nursing mothers. Instagram removed images of Rihanna and had her account cancelled when she posted selfies with nipples. This was incentive for the Twitter campaign #FreeTheNipple. Another recent development is the Instagram page that invites users to post images of nipples from both sexes. The account called @genderless_nipples displays close ups of both the nipples of men and women for the purpose of spotlighting what may be inconsistency. Some contributors have found 'a way around' this policy. Facebook has also been struggling to define its nipple policy.\n\nFilmmaker Lina Esco made a film entitled \"Free The Nipple\", which is about \"...laws against female toplessness or restrictions on images of female, but not male, nipples\", which Esco states is an example of sexism in society.\n\nNipples can be sensitive to touch, and nipple stimulation can incite sexual arousal. Few women report experiencing orgasm from nipple stimulation. Before Komisaruk et al.'s functional magnetic resonance (fMRI) research on nipple stimulation in 2011, reports of women achieving orgasm from nipple stimulation relied solely on anecdotal evidence. Komisaruk's study was the first to map the female genitals onto the sensory portion of the brain; it indicates that sensation from the nipples travels to the same part of the brain as sensations from the vagina, clitoris and cervix, and that these reported orgasms are genital orgasms caused by nipple stimulation, and may be directly linked to the genital sensory cortex (\"the genital area of the brain\").\n\nSome companies and non-profit organisations have used the word \"nipple\" or images of nipples to draw attention to their product or cause.\n\nThe word \"nipple\" most likely originates as a diminutive of \"neb\", an Old English word meaning \"beak\", \"nose\", or \"face\", and which is of Germanic origin. The words \"teat\" and \"tit\" share a Germanic ancestor. The second of the two, tit, was inherited directly from Proto-Germanic, while the first entered English via Old French.\n\n"}
{"id": "55752601", "url": "https://en.wikipedia.org/wiki?curid=55752601", "title": "PEROSH", "text": "PEROSH\n\nThe consortium was established in Rome on 7 November 2003 to foster research on important fields in OSH.\n\nIn Dublin on 7 November 2008 the articles of association were revised and broadened to facilitate the collaboration within the institutes. The most important regulations imply that each partner institute bears the costs of its activities and that the partnership employs its own Manager International Affairs. He has been representing PEROSH since 2009.\n\nThe partnership was renewed and extended in Paris in May 2013.\n\n\nThe PEROSH partners aim to improve the quality and effectiveness of European research and the EU-wide dissemination of results in the field of occupational safety and health. Therefore, PEROSH partners are committed to maintain a proactive dialogue with the EU and other national and international OSH-partners.\n\nJoint interdisciplinary research projects within PEROSH aim to create a close cooperation within the network. This saves resources, creates synergies and fosters the mutual exchange of scientific personnel.\n\nAt the same time, the members of PEROSH intend to accomplish EU-research projects, also in smaller consortiums, and to pool their interest in OSH research towards European institutions.\n\nUsually there are up to ten joint research projects with more than 80 researchers involved. These research projects address prevailing OSH topics, e. g.:\n\n\nThe list of ongoing and completed projects can be found on the website of PEROSH.\n\nPEROSH identifies upcoming trends and risks in the working world to precociously adjust its research activities.\n\nExchanges of experts between the member institutes and technical seminars promote the transfer of knowledge and harmonisation.\n\nPEROSH also carries on research in the field of standardisation, especially the determination of workplace-related safety factors for protective equipment.\n\nIn June 2018 the general directors of the member institutes met in Bonn (Germany) on the occasion of the 15th anniversary of PEROSH. They signed the new PEROSH agreement for the period 2018-2022 and elected two new chairpersons as of January 2019. \n\nTwo boards structure the work of PEROSH: the Steering Committee (SC) and the Scientific Steering Group (SSG).\n\nThe Steering Committee consists of the general directors of the member institutes and is responsible for the strategic management of PEROSH. The SC discusses the inclusion of new members, the appointment of the chairperson and the vice-chairperson of the SC, the establishment and mandate of the SSG and working groups. They agree on the annual budget and approve the annual account of revenue and expenditures.\n\nThe Scientific Steering Group consists of the research/scientific directors of the member institutes of PEROSH. The SSG meets twice a year to coordinate ongoing research projects and to determine new research topics and collaboration options.\n\nThe Manager International Affairs represents PEROSH towards the bodies of the European Union (EU). He promotes European activities in OSH, prepares joint statements to EU queries, reacts to EU requests for tender, and organises workshops and conferences. He is responsible for the homepage and publishes a newsletter on relevant OSH aspects three times a year.\n\n\n"}
{"id": "6989424", "url": "https://en.wikipedia.org/wiki?curid=6989424", "title": "Pharmacoeconomics", "text": "Pharmacoeconomics\n\nPharmacoeconomics refers to the scientific discipline that compares the value of one pharmaceutical drug or drug therapy to another. It is a sub-discipline of health economics. A pharmacoeconomic study evaluates the cost (expressed in monetary terms) and effects (expressed in terms of monetary value, efficacy or enhanced quality of life) of a pharmaceutical product. Pharmacoeconomic studies serve to guide optimal healthcare resource allocation, in a standardized and scientifically grounded manner.\n\nPharmacoeconomics centers on the economic evaluation of pharmaceuticals, and can use cost-minimization analysis, cost-benefit analysis, cost-effectiveness analysis or cost-utility analysis. Quality-adjusted life years have become the dominant outcome of interest in pharmacoeconomic evaluations, and many studies employ a cost-per-QALY analysis. Economic evaluations are carried out alongside randomized controlled trials and using methods of decision-analytic modeling. Pharmacoeconomics is a useful method of economic evaluation of various treatment options. As more expensive drugs are being developed and licensed it has become imperative especially in context of developing countries where resources are scarce to apply the principles of pharmacoeconomics for various drugs and treatment options so that maximum improvement in quality of life can be achieved in minimum cost.\n\nIn 1993, Australia became the first nation to use pharmacoeconomic analysis as part of the process for deciding whether new drugs should be subsidized by the Federal Government. The Pharmaceutical Benefits Advisory Committee (PBAC) advises Federal Government ministers on whether new drugs should be placed on a list for of drugs that consumers can then purchase from pharmacies at a subsidized price. Since 1993, this approach to evaluating costs and benefits is used in Canada, Finland, New Zealand, Norway, Sweden, and the UK.\n\n\n"}
{"id": "29146741", "url": "https://en.wikipedia.org/wiki?curid=29146741", "title": "Population Impact Measures", "text": "Population Impact Measures\n\nPopulation Impact Measures (PIMs) are biostatistical measures of risk and benefit used in epidemiological and public health research. They are used to describe the impact of health risks and benefits in a population, to inform health policy.\n\nFrequently used measures of risk and benefit identified by Jerkel, Katz and Elmore, describe measures of risk difference (attributable risk), rate difference (often expressed as the odds ratio or relative risk), Population Attributable Risk (PAR), and the relative risk reduction, which can be recalculated into a measure of \"absolute benefit\", called the Number needed to treat. Population Impact Measures are an extension of these statistics, as they are measures of absolute risk at the population level, which are calculations of number of people in the population who are at risk to be harmed, or who will benefit from Public Health interventions. \n\nThey are measures of absolute risk and benefit, producing numbers of people who will benefit from an intervention or be at risk from a risk factor within a particular local or national population. They provide local context to previous measures, allowing policy-makers to identify and prioritise the potential benefits of interventions on their own population. They are simple to compute, and contain the elements to which policy-makers would have to pay attention in the commissioning or improvement of services. They may have special relevance for local policy-making. They depend on the ability to obtain and use local data, and by being explicit about the data required may have the added benefit of encouraging the collection of such data.\n\nTo describe the impact of preventive and treatment interventions, the Number of Events Prevented in a Population (NEPP) is defined as \"the number of events prevented by the intervention in your population over a defined time period\". NEPP extends the well-known measure Number needed to treat (NNT) beyond the individual patient to the population. To describe the impact of a risk factor on causing ill health and disease the Population Impact Number of Eliminating a Risk factor (PIN-ER-t) is defined as \"the potential number of disease events prevented in a population over the next t years by eliminating a risk factor\". The PIN-ER-t extends the well-known Population Attributable Risk (PAR) to a particular population and relates it to disease incidence, converting the PAR from a measure of relative to absolute risk.\n\nThe components for the calculations are as follows: Population denominator (size of the population); Proportion of the population with the disease; Proportion of the population exposed to the risk factor or the incremental proportion of the diseased population eligible for the proposed intervention (the latter requires the actual or estimated proportion who are currently receiving the interventions ‘subtracted’ from best practice goal from guidelines or targets, adjusted for likely compliance with the intervention); Baseline risk – the probability of the outcome of interest in this or similar populations; and Relative Risk of outcome given exposure to a risk factor or Relative Risk Reduction associated with the intervention.\n\nThe formula is: NEPP=N*Pd*Pe*ru*RRR where: N = population size, Pd = prevalence of the disease, Pe = proportion eligible for treatment, ru = risk of the event of interest in the untreated group or baseline risk over appropriate time period (can be multiplied by life expectancy to produce life-years), RRR = relative risk reduction associated with treatment.\n\nIn order to reflect the incremental effect of changing from current to ‘best’ practice, and to adjust for levels of compliance, the proportion eligible for treatment, Pe, is (Pb-Pt)*Pc, where Pt is the proportion currently treated, Pb is the proportion that would be treated if best practice was adopted, and Pc is the proportion of the population who are compliant with the intervention.\n\nYou can calculate the NEPP and its confidence intervals at this web site from the Population Health Decision Support & Simulation site.\n\n[Note: Number Needed to Treat (NNT): 1/(Baseline risk x Relative Risk Reduction)]\n\nThe formula is: PIN-ER-t = N*Ip*PAR Where: N is the number of people in the population; Ip the baseline risk of the outcome of interest in the population as a whole; t is the time period over which the outcome is measured.\n\nThe PAR/F, Population Attributable Risk (or Fraction), is calculated for two or multiple strata. The basic formula to compute the PAR for dichotomous variables is PAR = Pe*(RR-1)/1+ Pe*(RR-1). Where: Pe is the prevalence of the population within each income stratum as the exposure, and RR is the prevalence of risk factors in each stratum relative to the highest income fifth. This is modified where there are multiple strata to: PAR = [Pe1(RR1-1)+Pe2(RR2-1)+Pe3(RR3-1)…]/[1+Pe1(RR1-1)+Pe2(RR2-1)+ Pe3(RR3-1)...].\nYou can calculate the PIN-ER-t and its confidence intervals at this web site from the Population Health Decision Support & Simulation site.\n"}
{"id": "48676301", "url": "https://en.wikipedia.org/wiki?curid=48676301", "title": "Population informatics", "text": "Population informatics\n\nThe field of population informatics is the systematic study of populations via secondary analysis of massive data collections (termed \"big data\") about people. Scientists in the field refer to this massive data collection as the social genome, denoting the collective digital footprint of our society. Population informatics applies data science to social genome data to answer fundamental questions about human society and population health much like bioinformatics applies data science to human genome data to answer questions about individual health. It is an emerging research area at the intersection of SBEH (Social, Behavioral, Economic, & Health) sciences, computer science, and statistics in which quantitative methods and computational tools are used to answer fundamental questions about our society.\n\nThe term was first used in August 2012 when the Population Informatics Research Group was founded at the University of North Carolina at Chapel Hill. The term was first defined in a peer reviewed article in 2013 and further elaborated on in another article in 2014. The first Workshop on Population Informatics for Big Data was held at the ACM SIGKDD conference in Sydney, Australia, in August 2015.\n\nTo study social, behavioral, economic, and health sciences using the massive data collections, aka social genome data, about people. The primary goal of population informatics is to increase the understanding of social processes by developing and applying computationally intensive techniques to the social genome data.\n\nSome of the important sub-disciplines are :\n\nRecord Linkage, the task of finding records in a dataset that refer to the same entity across different data sources, is a major activity in the population informatics field because most of the digital traces about people are fragmented in many heterogeneous databases that need to be linked before analysis can be done.\n\nOnce relevant datasets are linked, the next task is usually to develop valid meaningful measures to answer the research question. Often developing measures involves iterating between inductive and deductive approaches with the data and research question until usable measures are developed because the data were collected for other purposes with no intended use to answer the question at hand. Developing meaningful and useful measures from existing data is a major challenge in many research projects. In computation fields, these measures are often called features.\n\nFinally, with the datasets linked and required measures developed, the analytic dataset is ready for analysis. Common analysis methods include traditional hypothesis driven research as well more inductive approaches such as data science and predictive analytics.\n\nComputational social science refers to the academic sub-disciplines concerned with computational approaches to the social sciences. This means that computers are used to model, simulate, and analyze social phenomena. Fields include computational economics and computational sociology. The seminal article on computational social science is by Lazer et al. 2009 which was a summary of a workshop held at Harvard with the same title. However, the article does not define the term computational social science precisely.\n\nIn general, computational social science is a broader field and encompasses population informatics. Besides population informatics, it also includes complex simulations of social phenomena. Often complex simulation models use results from population informatics to configure with real world parameters.\n\nData Science for Social Good (DSSG) is another similar field coming about. But again, DSSG is a bigger field applying data science to any social problem that includes study of human populations but also many problems that do not use any data about people.\n\nPopulation reconstruction is the multi-disciplinary field to reconstruct specific (historical) populations by linking data from diverse sources, leading to rich novel resources for study by social scientists.\n\nThe first Workshop on Population Informatics for Big Data was held at the ACM SIGKDD conference in Sydney, Australia, in 2015. The workshop brought together computer science researchers, as well as public health practitioners and researchers. This Wikipedia page started at the workshop.\n\nThe International Population Data Linkage Network (IPDLN) facilitates communication between centres that specialize in data linkage and users of the linked data. The producers and users alike are committed to the systematic application of data linkage to produce community benefit in the population and health-related domains.\n\nThree major challenges specific to population informatics are: \n\n\n"}
{"id": "357147", "url": "https://en.wikipedia.org/wiki?curid=357147", "title": "Portable hyperbaric bag", "text": "Portable hyperbaric bag\n\nA portable hyperbaric bag, of which one brand is the Gamow bag (pronounced Gam-Off) is an inflatable pressure bag large enough to accommodate a person inside. A person can be placed inside the bag which is sealed and inflated with a foot pump. Within minutes, the effective altitude can be decreased by 1000 to as much as 3000 meters (3281 to 9743 feet) depending on the elevation. The bag is pressurised to 105-220 mmHg, pressure gradient is regulated by pop-off valves set to the target pressure. It is primarily used for treating severe cases of altitude sickness, high-altitude cerebral edema, and high-altitude pulmonary edema. Like office-based hyperbaric medicine, the Gamow bag uses increased partial pressure of oxygen for therapy of hypobaric injury, but it has the advantage of being portable for field use. Patients typically are treated in 1-hour increments and then are reevaluated.\n\nThe Gamow bag was named after its inventor, Dr. Igor Gamow, son of George Gamow. Dr. Gamow originally designed a predecessor to the gamow bag called \"The Bubble\" to study the effect of high altitude on stamina and performance in athletes. Dr. Gamow later re-designed 'The Bubble' into a bag that could be used in the high-altitude wilderness.\n\n"}
{"id": "31615916", "url": "https://en.wikipedia.org/wiki?curid=31615916", "title": "Positive psychology in the workplace", "text": "Positive psychology in the workplace\n\nImplementing positive psychology in the workplace means creating an environment that is relatively enjoyable and productive. This also means creating a work schedule that does not lead to emotional and physical distress.\n\nPositive psychology in the workplace is about shifting attention away from negative aspects such as work violence, stress, burnout, and job insecurity. Through the employment of positive psychology, a working environment with a goal of promoting positive affect in its employees can be created.\n\nFun should not be looked at as something that cannot be achieved during work but rather as a motivation factor for the staff. Along this line, it is important to examine the role of: helping behaviors, team building exercises, job resources, job security and work support.\n\nThe emerging field of positive psychology also helps to creatively manage organizational behaviors and to increase productivity in the workplace through applying positive organizational forces. Recent researches on job satisfaction and employee retention have created a great need to focus on implementing positive psychology in the workplace.\n\nAccording to the United States Department of Labor, “In 2009 employed persons worked an average of 7.5 hours on the days they worked, which were mostly weekdays. [In addition to that], 84 percent of employed persons did some or all of their work at their workplace.[1]” This indicates that majority of the population spend their waking hours at work, outside their homes. Therefore, employers must do their best to create a low stress and inspiring work environment to yield greater productivity.\n\nMichelle T. Iaffaldano and Paul M. Muchinsky were among the first people to ignite interest in the connection between job satisfaction and job performance. The meta-analytic research of these individuals impacted the way in which later research on the topic was conducted, especially regarding sample sizes.\n\nMartin E.P. Seligman and Mihaly Csikszentmihalyi are noted frontrunners in the area of positive psychology as a field of study. They state that “psychology has become a science largely about healing. Therefore its concentration on healing largely neglects the fulfilled individual and thriving community”. Seligman and Csikszentmihalyi further stress that, “the aim of positive psychology is to begin to catalyze a change in the focus of psychology from preoccupation only with repairing the worst things in life to also building positive qualities.”\n\nAbraham Maslow and Carl Rogers developed Humanistic Psychology that focuses on the positive potential of people and on helping people reach their full potential.\n\nPeter Warr is noted for his early work on work well being. “Proponents of the well-being perspective argue that the presence of positive emotional states and positive appraisals of the worker and his or her relationships within the workplace accentuate worker performance and quality of life”. A common idea in work environment theories is that demands match or slightly exceed the resources. With regards to research concerning positive outcomes within the employment setting, several models have been established like \"Demand Control\", \"Job Demands-Resources\", and \"Job Characteristics\".\n\nRobert A. Karasek is credited with this particular work design model. In Karasek’s model, workplace stress is in indicator of how taxing a worker's job is and how much control, authority, discretion, and decision latitude the worker has over his/her tasks and duties. This creates four kinds of jobs—passive, active, low strain and high strain The Demand Control Model (DCM) has been used by researchers to design jobs that enhance the psychological and physical well-being. This model promotes a work design that proposes high demand and high control, fostering an environment that encourages learning and simultaneously offers autonomy.\n\nThis model is based on the assumption that “workers with active jobs are more likely to seek challenging situations that promote mastery, thereby encouraging skill and knowledge acquisition”. It also points out the role of social support, referring to the quality interactions between colleagues and managers. However, there is some controversy over this model because some researchers believe it lacks evidence for the interaction between demand and control.\n\nThe DCM is commonly criticized for its inability to consistently replicate findings to support its basic assumption. The DCM has been criticized for “its simplicity, inability to capture the complexity of work environments.However, there is evidence supporting the idea that “high amounts of job control is associated with increases in job satisfaction and decreased depression, however, high demands with out adequate control may lead to increase anxiety”.\n\nThe job demands-resources model (JD-R) is an expansion of the DCM and is founded on the same principle that high job demands and high job resources produce employees with more positive work attitudes. The difference between the JD-R and DCM is that the JD-R expounds upon the differentiation between demand and resources, as well as encompasses a broader view of resources. This model refers to demands as “ those physical, psychological, social, or organizational aspects of the job that require sustained physical and/or psychological effort. This may refer to jobs that require contact with customers. Resources are regarded as “those physical, psychological, social, or organizational aspects of the job that are either/or: (1) functional in achieving work goals; (2) reduce job demands and the associated physiological and psychological costs; and (3) stimulate personal growth, learning, and development”. Another difference between these two theories is that the JD-R postulates that resources can be predictors of motivation and learning related outcomes. The findings by Bakker and colleagues supports their hypothesis that many resources may be linked to job well-being. They also found that “task enjoyment and organizational commitment are the result of combinations of many different job demands and job resources. Enjoyment and commitment were high when employees were confronted with challenging and stimulating tasks, and simultaneously had sufficient resources at their disposal”.\n\nThe job characteristics model (JCM) is “an influential theory of work design developed by Hackman and Oldham. It is based upon five characteristics - skill variety, task identity, task significance, task autonomy, and task feedback - which are used to identify the general content and structure of jobs”. This model argues that employees with a personal need for growth and development, as well as knowledge and skill, will display more positive work outcomes. These include things such as: job satisfaction, lower absenteeism, and better work turnover. This model is based upon an idea that high task control and feedback are two essential elements for maximizing work potential. Stronger experiences of these five traits is said to lead to greater job satisfaction and better performance.\n\nIn order to protect the physical and mental health of workers, the demands of the job must be balanced by easily accessible job resources in order to prevent burnout in employees yet encourage employee engagement. The interaction between the demand and resources within a job determines employee engagement or burnout. Engagement signifies a positive employee who is committed to the safety within the workplace for self and others. In contrast, burnout represents a negative employee possessing elements of anxiety, depression, and work-related stress. Engagement increases as job resources like knowledge of safety are present. On the other hand, burnout increases when more job demands are present without the buffering effects of job resources.\n\nHazards in the workplace can be seen as a combination of the physical demands of the work and the complexity of the work. Job resources provide a buffering effect that protects the employees from job demands like high work pressure, an unfavorable physical environment, and emotionally demanding interactions. Employees are better equipped to handle changes in their work environment when resources are readily available. The resources a job can provide include autonomy, support, and knowledge of safety. Autonomy allows employees the freedom to decide how to execute their work. Support can originate directly from a supervisor or from other workers in the environment. And lastly, employees must have knowledge about safety procedures and policies. When the employee is able to work in a safe environment, workers are more satisfied with their jobs. A safe environment provides support and resources that promote healthy employees.\n\nEmotional intelligence is the ability to recognize, and interpret emotions that can be used to regulate emotions and assist cognitive processes which promote emotional and intellectual growth. Emotional intelligence has been researched by Carmelli (2003) in order to see its effect on employees work performance. Due to the social nature of the interactions of the employees, emotional intelligence is essential in order to work well with co-workers. When employees work well together their task performance improves and as a result the business benefits. With emotional intelligence, employees are better able to perceive others needing help and are more willing to help for intrinsic benefits.\n\nIsen & Reeve (2005) proposed that positive affect led to positive intrinsic motivation for completing a task. As a result of the intrinsic motivation, the employees enjoyed the task more and were more optimistic when having to complete more uninteresting task. The combination of having the freedom to choose tasks and maintaining positive affect results in better task performance. Positive affect promotes self-control to remain focused on any task and forward-looking thinking that motivates workers to look-forward to more enjoyable tasks.\n\nConcepts of positive psychology like hope and altruism provide a positive work environment that influences the moods and attitudes of workers. Youssef & Luthans (2007) examined the effects hope, optimism, and resilience had in the workplace on employees’ job performance, job satisfaction, work happiness, and organizational commitment. Hope and resilience had a more direct effect on organizational commitment whereas hope had a greater impact on performance. Hope allows employees to be better at creating more realistic plans for completing task so as not to focus on the failure that accompanies an incomplete task. Optimism strengthens the employee’s resilience to break through barriers and causes the employee to build social support and other strengths to overcome obstacle he or she may encounter.\n\nPositive psychology also encourages maintaining positive mood in the work environment to encourage productivity on an individual level and organizational level. Organizational citizenship behaviors (OCB) refer to behaviors like altruism and compliance that are not formal tasks in that the behaviors are not a mandatory of the workers job description. They are considered extra-role behaviors that help in gauging the workers commitment to the job and to the rules of the job in the absence of monitoring these behaviors. OCB have proven to improve the moods of employees and the moods in the workplace. A helping behavior improves mood because the individual is no longer focused of negative moods; helping others acts as a distracter for the employee. Altruism is effective because it has more impact in a social setting like the workplace and is more extrinsically rewarding. OCB encourage positive interactions among workers and lead to better psychological health for employees.\n\nAccording to Froman (2010), having a more hopeful perspective about life leads one to being more optimistic about responding to opportunities. Workers are more resilient to adversity and are able to bounce back more quickly. When organizations encourage positive attitudes in their employees, they grow and flourish. As a result, the organization profits and grows from the human capital of productive employees and the monetary capital resulting from productive workers.\n\nChan (2010) studied fun activities in the workplace that created a positive work environment that could retain and attract employees and encourage employee well-being. Activities must be enjoyable and pleasurable. The activities also encourage employees to be more responsible and a team player. These qualities empower employees to more engaged with their work, take on more leadership roles, and experience less stress. Making work fun promotes positive, happy moods in employees that in turn increase job satisfaction and organizational commitment. According to Chan’s framework, workplace fun must be staff-oriented, supervisor-oriented, social-oriented, or strategy oriented. While staff-oriented activities focus on creating fun work for employees, supervisor-oriented activities create a better relationship between the employees and supervisors. Social-oriented activities create social events that are organizational-based (i.e. company barbecue or Christmas office party). Strategy-oriented activities allow more autonomy with employees in different aspects of their work in hopes of cultivating strengths within the organization’s employees. The framework proposes that a fun work environment promotes employee well-being in addition to fostering creativity, enthusiasm, satisfaction and communication among the organization’s employees. The research found in this study hopes to encourage implementing other work fun activities in other various industries in order to engage and retain positive employees.\n\nThere are several examples of popular, real-world uses of infusing Positive Psychology in the workplace. In such contexts such as a workplace, researchers often hope to examine and measure variable levels of such factors such as productivity and organization. One such popular model is the aforementioned Job Characteristics Model (JCM), which applies influential theories of work as it correlates to the five central characteristics of skill variety, task identity, task significance, task autonomy, and task feedback. However, such practices such as business teams within a workplace often present the varying dynamics of positivity and negativity in business behaviors. There are often a plethora of special research teams that go into looking at certain workplaces in order to help report to employers the status of their employees. Furthermore, the three psychological states often measured and examined are: meaningfulness of performed work, responsibility of outcomes, and results knowledge. In mixing together these aspects, a score is generated in order to observe a range reflecting a job quality. In addition, each score details the differing degrees of autonomy and necessary feedback as it relates to ensuring high quality work. Most research points to the fact that typical teams of high performance are those that function high on positivity in their workplace behaviors.\n\nAdequate research regarding whether the practice of measuring factors, such as positive behaviors is lacking. More specifically, in attempting to measure some form of a variable in order to later ensure a positive environment context in the workplace, there is debate to an extent regarding which proper components to value and measure. Additionally, the act and process of specifically looking into certain factors of productivity in the workplace can also go on to influence workers negatively due to pressure.\n\nThe multitudes of research and new, developing information detailing the possibility of positive psychology at work often deals with reporting workplace safety, the engagement of the employees, productivity, and overall happiness. Moreover, understanding the significance of a healthy work environment can directly provide and contribute to work mastery and work ethic. Motivation, researchers have learned, helps to keep a reinforced sense of both discipline and a higher perception which then yields to higher levels of efficiency for both employees and employers.\n\n\n"}
{"id": "3232045", "url": "https://en.wikipedia.org/wiki?curid=3232045", "title": "Proximate", "text": "Proximate\n\nProximates are used in the analysis of biological materials as a decomposition of a human-consumable good into its major constituents. They are a good approximation of the contents of packaged comestible goods and serve as a cost-effective and easy verification of nutritional panels. This means that testing can be used to verify lots, but cannot be used to validate a food processor or food processing facility; instead, a nutritional assay must be conducted on the product to qualify said producers. Nutritional panels in the United States are regulated by the FDA and must undergo rigorous testing to ensure the exact and precise content of nutrients. This should prevent food processors from making unfounded claims to the public.\n\nIn industry, the standard proximates are:\nAnalytically, four of the five constituents are obtained via chemical reactions and experiments. The fifth constituent, carbohydrates, are calculated based on the determination of the four others. Proximates should nearly always account for 100% of a food product; any deviation from 100% displays the resolution of the chemical test, as small variations in the way each test is performed accumulate or overlap the compositional make-up.\n\nThere are additional ingredients that may fall under the category of one of the five constituents. Carbohydrates, for example, include but are not limited to:\nWhereas ash includes but is not limited to:\nAlthough proximates do not give the entire nutritional assay, they are an inexpensive way to track deviations in the quality of foods.\n"}
{"id": "41336070", "url": "https://en.wikipedia.org/wiki?curid=41336070", "title": "Quality of well-being scale", "text": "Quality of well-being scale\n\nThe Quality of Well-Being Scale (QWB) is a general health quality of life questionnaire which measures overall status and well-being over the previous three days in four areas: physical activities, social activities, mobility, and symptom/problem complexes.\n\nIt consists of 71 items and takes 20 minutes to complete. There are two different versions of the QWB; the original was designed to be administered by an interviewer, and the second development (the QWB-SA) was designed to be self-administered.\n\nThe four domain scores of the questionnaire are combined into a total score that ranges from 0 to 1.0, with 1.0 representing optimum function and 0 representing death.\n\nThe QWB was originally called the Health Status Index, then the Index of Well-Being, and then eventually became the Quality of Well-Being Scale. It has undergone several modifications since its development.\n\nThe process of administering the QWB can be described in three stages. They are the assessment of functional status, scaling the responses and indicating prognosis.\n\nAssessment of functional status involves a structured interview which records the symptoms and problems experienced over the last eight days. It is used to classify the patient’s level of functioning. The interview takes about seven minutes or longer, according to the patient’s level of health. Questions in the interview covered three criteria of functioning: physical activity, social activity and mobility and confinement. The interview also records the presence of symptoms or problem complexes, which are problems that were experienced on the previous day, but were not being experienced at the present time.\n\nThe responses from the interview were then scaled. Preference weights were given for each function level by 867 raters. The preference weights indicated the social judgement of the importance of each function level. A score is generated, which is known as W. W can then be adjusted to reflect the prognosis of a given medical condition.\n\nSince the development of the Quality of Well-Being Scale and the consequent Quality of Well-Being Scale-Self Administered, the questionnaire has been utilized in numerous studies worldwide. Due to the general nature of the questionnaire, it has proven useful in a variety of different formats and contexts.\n\nOne way in which the QWB and the QWB-SA has been utilized is that it has been a comparator used to validate other measures, or a starting point for creating subscales of the questionnaire. An example of this is a subscale developed for use with the QWB-SA that assesses mental health, a comparator study seeking to investigate the Health and Activity Limitation Index and a study seeking to validate a new questionnaire called the Assessment of Quality of Life (AQoL)-8D.\n\nThe QWB and the QWB-SA have also been validated or assessed for suitability in various cultures and countries. The QWB has been assessed for use in Trinidad and Tobago and the QWB-SA has been validated for German patients with prostate disease, as well as Chinese patients with epilepsy.\n\nSelf-perceived quality-of-life scale\n"}
{"id": "1301665", "url": "https://en.wikipedia.org/wiki?curid=1301665", "title": "Registration, Evaluation, Authorisation and Restriction of Chemicals", "text": "Registration, Evaluation, Authorisation and Restriction of Chemicals\n\nRegistration, Evaluation, Authorisation and Restriction of Chemicals (REACH) is a European Union regulation dating from 18 December 2006. REACH addresses the production and use of chemical substances, and their potential impacts on both human health and the environment. Its 849 pages took seven years to pass, and it has been described as the most complex legislation in the Union's history and the most important in 20 years. It is the strictest law to date regulating chemical substances and will affect industries throughout the world. REACH entered into force on 1 June 2007, with a phased implementation over the next decade. The regulation also established the European Chemicals Agency, which manages the technical, scientific and administrative aspects of REACH.\n\nWhen REACH is fully in force, it will require all companies manufacturing or importing chemical substances into the European Union in quantities of one tonne or more per year to register these substances with a new European Chemicals Agency (ECHA) in , Finland. Since REACH applies to some substances that are contained in objects (\"articles\" in REACH terminology), any company importing goods into Europe could be affected.\n\nThe European Chemicals Agency has set three major deadlines for registration of chemicals. In general these are determined by tonnage manufactured or imported, with 1000 tonnes/a. being required to be registered by 1 December 2010, 100 tonnes/a. by 1 June 2013 and 1 tonne/a. by 1 June 2018. In addition, chemicals of higher concern or toxicity also have to meet the 2010 deadline.\n\nAbout 143,000 chemical substances marketed in the European Union were pre-registered by the 1 December 2008 deadline. Although pre-registering was not mandatory, it allows potential registrants much more time before they have to fully register. Supply of substances to the European market which have not been pre-registered or registered is illegal (known in REACH as \"no data, no market\").\n\nREACH also addresses the continued use of chemical \"substances of very high concern\" (SVHC) because of their potential negative impacts on human health or the environment. From 1 June 2011, the European Chemicals Agency must be notified of the presence of SVHCs in articles if the total quantity used is more than one tonne per year and the SVHC is present at more than 0.1% of the mass of the object. Some uses of SVHCs may be subject to prior authorisation from the European Chemicals Agency, and applicants for authorisation will have to include plans to replace the use of the SVHC with a safer alternative (or, if no safer alternative exists, the applicant must work to find one) - known as \"substitution\". , there are 168 SVHCs on the candidate list for authorization.\n\nREACH applies to all chemicals imported or produced in the EU. The European Chemicals Agency will manage the technical, scientific and administrative aspects of the REACH system.\n\nTo somewhat simplify the registration of the 143,000 substances and to limit vertebrate animal testing as far as possible, substance information exchange forums (SIEFs) are formed amongst legal entities (such as manufacturers, importers, and data holders) who are dealing with the same substance. This allows them to join forces and finances to create 1 registration dossier. However, this creates a series of new problems as a SIEF is the cooperation between sometimes a thousand legal entities that did not know each other at all before but suddenly must:\nin order to complete a several thousand end points dossier in a limited time.\n\nThe European Commission supports businesses affected by REACH by handing out – free of charge – a software application (IUCLID) that simplifies capturing, managing, and submitting data on chemical properties and effects. Such submission is a mandatory part of the registration process. Under certain circumstances the performance of a chemical safety assessment (CSA) is mandatory and a chemical safety report (CSR) assuring the safe use of the substance has to be submitted with the dossier. Dossier submission is done using the web-based software REACH-IT.\n\nThe aim of REACH is to improve the protection of human health and the environment by identification of the intrinsic properties of chemical substances. At the same time, innovative capability and competitiveness of the EU chemicals industry should be enhanced.\n\nThe European Commission’s (EC) White Paper of 2001 on a ‘future chemical strategy’ proposed a system that requires chemicals manufactured in quantities of greater than 1 tonne to be ‘registered’, those manufactured in quantities greater than 100 tonnes to be ‘evaluated’, and certain substances of high concern (for example carcinogenic, mutagenic and toxic to reproduction - CMR’s) to be ‘authorised’.\n\nThe EC adopted its proposal for a new scheme to manage the manufacture, importation and supply of chemicals in Europe on in October 2003. This proposal eventually became law once the European Parliament officially approved its final text of REACH. It came into force on 1 June 2007.\n\nOne of the major elements of the REACH regulation is the requirement to communicate information on chemicals up and down the supply chain. This ensures that manufacturers, importers, and also their customers are aware of information relating to health and safety of the products supplied. For many retailers the obligation to provide information about substances in their products within 45 days of receipt of a request from a consumer is particularly challenging. Having detailed information on the substances present in their products will allow retailers to work with the manufacturing base to substitute or remove potentially harmful substances from products. The list of harmful substances is continuously growing and requires organizations to constantly monitor any announcements and additions to the REACH scope. This can be done on the European Chemicals Agency's website.\n\nA requirement is to collect, collate and submit data to the European Chemicals Agency (ECHA) on the hazardous properties of all substances (except Polymers and non-isolated intermediates) manufactured or imported into the EU in quantities above 1 tonne per year. Certain substances of high concern, such as carcinogenic, mutagenic and reproductive toxic substances (CMRs) will have to be authorised.\n\nChemicals will be registered in three phases according to the tonnage of the substance evaluation:\n\nMore than 1000 tonnes a year, or substances of highest concern, must be registered in the first 3 years;\n\n100-1000 tonnes a year must be registered in the first 6 years;\n\n1-100 tonnes a year must be registered in the first 11 years.\n\nIn addition, industry should prepare risk assessments and provide controls measures for using the substance safely to downstream users.\n\nEvaluation provides a means for the authorities to require registrants, and in very limited cases downstream users, to provide further information.\n\nThere are two types of evaluation: dossier evaluation and substance :\n\nDossier evaluation is conducted by authorities to examine proposals for testing to ensure that unnecessary animal tests and costs are avoided, and to check the compliance of registration dossier with the registration requirements.\n\nThe relevant authorities perform substance evaluation when there is a reason to suspect that a substance presents a risk to human health or the environment (e.g. because of its structural similarity to another substance). Therefore, all registration dossiers submitted for a substance are examined together and any other available information is taken into account.\n\nThe REACH proposal sets up a system under which the use of substances with properties of very high concern and their placing on the market can be made subject to an authorisation requirement.\n\nThis authorisation requirement ensures that risks from the use of such substances are either adequately controlled or justified by socio-economic grounds, having taken into account the available information on alternative substances or processes.\n\nThe Regulation enables restrictions of use to be introduced across the European Community where this is shown to be necessary. Member States or the Commission may prepare such proposals.\n\nManufactures and/or importers should develop risk reduction measures for all known uses of the chemical including downstream uses. Downstream users such as plastic pipe producers should provide detail of their uses to their suppliers. In cases where downstream users decide not to disclose this information, they need to have their own CSR.\nREACH is the product of a wide-ranging overhaul of EU chemical policy. It passed the first reading in the European Parliament on 17 November 2005, and the Council of Ministers reached a political agreement for a common position on 13 December 2005. The European Parliament approved REACH on 13 December 2006 and the Council of Ministers formally adopted it on 18 December 2006. Weighing up expenditure versus profit has always been a significant issue, with the estimated cost of compliance being around €5 billion over 11 years, and the assumed health benefits of saved billions of euro in healthcare costs. However, there have been different studies on the estimated cost which vary considerably in the outcome. It came into force on 20 January 2009, and will be fully implemented by 2015.\n\nA separate regulation – the CLP Regulation (for \"Classification, Labelling, Packaging\") – implements the United Nations Globally Harmonized System of Classification and Labelling of Chemicals (GHS) and will steadily replace the previous Dangerous Substances Directive and Dangerous Preparations Directive.\n\nThe REACH regulation was amended in April 2018 to include specific information requirements for nanomaterials.\n\nThe legislation was proposed under dual reasoning: protection of human health and protection of the environment.\n\nUsing potentially toxic substances (such as phthalates or brominated flame retardants) is deemed undesirable and REACH will force the use of certain substances to be phased out. Using potentially toxic substances in products other than those ingested by humans (such as electronic devices) may seem to be safe, but there are several ways in which chemicals can enter the human body and the environment. Substances can leave particles during consumer use, for example into the air where they can be inhaled or ingested. Even where they might not do direct harm to humans, they can contaminate the air or water, and can enter the food chain through plants, fish or other animals. According to the European Commission, little safety information exists for 99 percent of the tens of thousands of chemicals placed on the market before 1981. There were 100,106 chemicals in use in the EU in 1981, when the last survey was performed. Of these only 3,000 have been tested and over 800 are known to be carcinogenic, mutagenic or toxic to reproduction. These are listed in the Annex 1 of the Dangerous Substances Directive (now Annex VI of the CLP Regulation).\n\nContinued use of many toxic chemicals is sometimes justified because \"at very low levels they are not a concern to health\". However, many of these substances may bioaccumulate in the human body, thus reaching dangerous concentrations. They may also chemically react with one another, producing new substances with new risks.\n\nA number of countries outside of the European Union have started to implement REACH-regulations or are in the process of adopting such a regulatory framework to approach a more globalized system of chemicals registration under the Globally Harmonized System of Classification and Labelling of Chemicals (GHS).\nBalkan countries such as Croatia and Serbia are in the process of adopting the EU REACH system under the auspices of the EU IPA programme. Switzerland has moved towards implementation of REACH through partial revision of the Swiss Chemical Ordinance on February 1, 2009. The new Chemicals Management Regulation in Turkey is paving the way for the planned adoption of REACH in 2013. China has moved towards a more efficient and coherent system for the control of chemicals in compliance with GHS.\n\nApart from the potential costs to industry and the complexity of the new law, REACH has also attracted concern because of animal testing. Animal tests on vertebrates are now required but allowed only once per each new substance and if suitable alternatives cannot be used. If a company pays for such tests, it must sell the rights of the results for a \"reasonable\" price, which is not defined. There are additional concerns that access to the necessary information may prove very costly for potential registrants needing to purchase it.\n\nAn opinion in \"Nature\" in 2009 by Thomas Hartung and Constanza Rovida estimated that 54 million vertebrate animals would be used under REACH and that the costs would amount to €9.5 billion. Hartung is the former head of European Centre for the Validation of Alternative Methods (ECVAM). In a news release, ECHA criticised assumptions made by Hartung and Rovida; ECHA's alternative assumptions reduced sixfold the number of animals.\n\nOn 8 June 2006, the REACH proposal was criticized by non-EU countries, including the United States, India and Brazil, which stated that the bill would hamper global trade.\n\nNon-EU consultancies offer \"only representative\" services, though according to REACH it is not possible to register a substance if your \"only representative\" consultancy company is not based in the EU, unless it is subcontracted to an EU-based registrant.\n\nOnly representatives are EU based entities that must comply with REACH (Article 8) and should operate standard, transparent working practices. The Only Representative assumes responsibility and liability for fulfilling obligiations of importers in accordance with REACH for substances being brought into the EU by a non-EU manufacturer.\n\nThe SIEFs will bring new challenges. An article in the business news service Chemical Watch described how some \"pre-registrants\" may simply be consultants hoping for work (\"gold diggers\") while others may be aiming to charge exorbitant rates for the data they have to offer (\"jackals\").\n\nSource:\n\nThe European Chemical Agency (ECHA) has published the REACH Authorisation List, in an effort to tighten the use of Substances of Very High Concern (SVHCs). The list is an official recommendation from the ECHA to the European Commission. The list is also regularly updated and expanded. Currently the Candidate List for Authorisation comprises a total of 173 SVHCs, some of which are already active on the Authorization List.\n\nTo sell or use these substances, manufacturers, importers, and retailers in the European Union (EU) must apply for authorization from the ECHA. The applicant is to submit a chemical safety report on the risks entailed by the substance, as well as an analysis of possible alternative substances or technologies including present and future research and development processed.\n\n\n"}
{"id": "52975690", "url": "https://en.wikipedia.org/wiki?curid=52975690", "title": "Robert Kezaala", "text": "Robert Kezaala\n\nDr. Robert Kezaala is a medical doctor, epidemiologist, scholar and public health leader in the field of immunization and health emergencies. Currently he is serving as a Senior Health Advisor and team lead for Accelerated Immunization Initiatives: measles, rubella, epidemic meningitis and yellow fever control and Immunization in Emergencies at the United Nations Children’s Fund.\n\nDr. Kezaala received his medical degree from Makerere University in Kampala, Uganda. He also holds an MPH from the Royal Tropical Institute (KIT) in Amsterdam, Netherlands majoring in epidemiology and health planning.\n\nDr. Kezaala has over 30 years of professional experience in public health including 24 years at international level. In the late 1980s, Dr. Kezaala practiced as Medical Officer in Karamoja province in the northeast of Uganda with recognized work in immunization and Tuberculosis control. From 1992 to 1993, Dr Kezaala worked with UNDP in multi-sectoral HIV/AIDS control where he managed the collaborative program that supported Uganda government efforts to address the AIDS epidemic. Thereafter, until 1998, he worked with the International Federation of Red Cross and Red Crescent Societies (IFRC) as Regional Health Delegate for Eastern and Southern Africa, managing a variety of health interventions including HIV/AIDS control, community water and sanitation and refugee health and emergency response when he led IFRC's initial health response in Goma during the 1994 Rwanda crisis. Subsequently, he joined the World Health Organization (WHO), where he worked for 14 years, first as epidemiologist and Team Lead for WHO-EPI in Ethiopia. From 2001 to 2005, Dr. Kezaala headed Measles Control for the Africa Region of WHO, when the Africa region registered a reduction in measles mortality by 70%. He spent the next seven years serving as a medical officer with the Polio Eradication Initiative at the WHO headquarters in Geneva, Switzerland. While here, he worked in country support across the globe, including Chad, Pakistan, the Horn of Africa and served as the outbreak response manager for the 2010 Polio outbreak that affected Tajikistan, Kazakhstan and Russia. During the stint in GPEI, Dr Kezaala developed the Short Interval Additional Dose (SIAD) tactical approach that has since become a standard for Polio outbreak response. In 2012, Dr Kezaala served as WHO liaison officer to the US Centers for Disease Control (CDC) in setting up the Emergency Operations Centre (EOC) for CDC's global Polio Eradication Initiative. Since June 2012, Dr Kezaala has served as Senior Health Advisor at the UNICEF headquarters in New York in charge of the Accelerated Immunization Initiatives - responsible for Measles and Rubella control, Yellow Fever, epidemic Meningitis and immunization in emergency settings. In 2016, he was instrumental as liaison officer to WHO in the response to the central Africa Yellow Fever outbreak that affected Angola and the Democratic Republic of Congo. \n\nNumerous news outlets and reports such as U.S. News, CNN, TV2Africa, allAfrica have quoted Dr. Kezaala. He is also a thought leader in topics related to public health, vaccines, health diplomacy and on Uganda.\n"}
{"id": "25314864", "url": "https://en.wikipedia.org/wiki?curid=25314864", "title": "Self-injury Awareness Day", "text": "Self-injury Awareness Day\n\nSelf-injury Awareness Day (SIAD) (also known as Self-Harm Awareness Day) is a grassroots annual global awareness event / campaign on March 1, where on this day, and in the weeks leading up to it and after, some people choose to be more open about their own self-harm, and awareness organizations make special efforts to raise awareness about self-harm and self-injury. Some people wear an orange awareness ribbon, write \"LOVE\" on their arms, draw a butterfly on their wrists in awareness of \"the Butterfly Project\" wristband or beaded bracelet to encourage awareness of self-harm. The goal of the people who observe SIAD is to break down the common stereotypes surrounding self-harm and to educate medical professionals about the condition.\n\nDepression and self-harm often go hand-in-hand, though there are many other reasons people self-harm. As many as two million Americans currently engage in self-harm, with methods like cutting, scratching, bruising, and hitting themselves, along with other more harmful methods. It’s said that these behaviors promote feelings of control and help relieve tension, while helping the person express their emotions and escape the numbness that accompanies depression.\n\nSIAD was created to spread awareness and understanding of self-injury, which is often misrepresented and misunderstood in the mainstream. Those who self-harm are often left feeling alone and afraid to reach out for help because they fear they'll be seen as \"crazy.\"\n\nMany organizations are now getting involved in SIAD. Some of them include:\n\n"}
{"id": "55862581", "url": "https://en.wikipedia.org/wiki?curid=55862581", "title": "Senior dog diet", "text": "Senior dog diet\n\nSenior dog food diets are pet foods that are catered toward the senior or mature pet population. The senior dog population consists of dogs that are over the age of seven for most dog breeds, though in general large and giant breed dogs tend to reach this life stage earlier when compared to smaller breed dogs who are considered senior at a much later age. Senior dog foods contain nutrients and characteristics that are used to improve the health of the aging dog. Aging in dogs causes many changes to occur physiologically that will require a change in nutrient composition of their diet. A major change that occurs is the decrease in energy requirements which is addressed by lowered caloric content of senior pet foods. Although energy requirements decrease, protein requirements increase as the dog ages. Senior dog foods include a higher protein content as well as highly digestible protein sources to deal with this. Nutrients included for joint and bone health include glucosamine, chondroitin, omega-3 fatty acids as well as two main minerals; calcium and phosphorus. Sources of fiber included in senior dog foods include beet pulp and flax seed as well as fructooligosaccharides (FOS) and mannanoligosaccharides (MOS). These act to increase gastrointestinal health. Brain and cognitive health decline as the dog ages which leads to the inclusion of vitamin E and L-carnitine in senior dog diets to combat this decline. Skin and coat health can also decline in older dogs due to various reasons. The inclusion of linoleic acid as well as vitamin A into senior dog diets helps to improve or maintain the skin and coat of senior dogs. Immune system health is important to maintain in older dogs to prevent the development of various diseases. By including omega-3 and omega-6 fatty acids, vitamin E, β-carotene as well as pre- and pro-biotics, the immune system can be boosted and maintained to help improve overall health. \nThe maintenance energy requirement (MER), or the energy that is required to maintain normal activity, decreases significantly as a result of lean body mass loss in aging dogs. The MER can decrease by up to 25% as dogs age due to this loss. Basal metabolic rate is maintained by lean mass energy expenditure, which accounts for 96% of the function of lean mass. The metabolizable energy, or the amount of available energy which is left after the losses in urine, feces and combustible gas is subtracted, can be found on the food bag or calculated using the modified Atwater equation:\n\nME (kcal/kg) = 10[(3.5 x Crude Protein) + (8.5 x Crude Fiber) + (3.5 x Nitrogen Free Extract)]\n\nThis equation takes into consideration the amount of energy availability from crude protein, crude fiber, and the nitrogen free extract from pet foods in order to calculate the amount of energy the animal is receiving from the food.\n\nIt is important to consider the metabolizable energy content of senior or mature pet foods using this equation, as energy requirements will vary with age.\n\nA dog's requirements for protein increases as a result of a reduced ability to synthesize proteins as it ages. As a result, it is extremely important to not restrict protein consumption to a senior dog as it can be as just as harmful as protein deficiency in young dogs. To ensure good health, it is important to provide dogs with the 22 amino acids which they require. Of these 22 amino acids, 12 can be synthesized. The rest must be provided by good sources of dietary protein in adequate quantities. Good sources of protein include eggs and fish, which have a high biological value. This value describes the percentage of usable amino acids within the protein. It has been recommended that a minimum of 2.55 grams of protein per kilogram of body weight should be fed daily to ensure that protein requirements are met. It is important to understand that protein requirements based on weight are variable and that many factors influence the protein requirements of each senior dog.\n\nJoint deterioration occurs as dogs age. As their joints become less lubricated there is increased friction between the bone and the cartilage. With this increased friction, the cartilage deteriorates and wears away. The reduction of this cushion in the joints causes bone-on-bone contact to occur, causing the animal great discomfort. This can cause various related issues such as altered gaits and changes in activity levels resulting in a greater possibility of obesity and other conditions related to mobility and activity levels.\n\nThere has been research done in human medicine that indicates the positive effect that a combination of chondroitin sulphate and glucosamine can have on moderate-to-severe knee pain. This effect is likely very similar to the effect these two ingredients have on the joints of aging dogs. It is important to note the effects of these supplements is not instant and the aforementioned studies showed approximately a 3-month period between the beginning of supplementation and the reduction of symptoms.\n\nGlucosamine is a building block for the synthesis of cartilage tissue. It is found naturally in the body, mainly in the fluid which surrounds the joints. This can help aging joints by maintaining the cartilage, thus reducing the pain caused by bone-on-bone contact within the joint (this is the primary source of joint pain in aging animals). This will increase the mobility of the dog which is vital for the maintenance of a healthy weight and general body function. There have also been some studies which have showed anti-inflammatory properties of glucosamine which would also help joint function in aging dogs. Glucosamine is usually provided in supplements in the form of glucosamine sulfate, or by the inclusion of chicken meal in the diet, as it contains glucosamine as well as chondroitin.\n\nChondroitin is a major component in the composition of cartilage. It helps the cartilage retain moisture, lubricating the joint and allowing ease of movement of the bone across the cartilage. This reduces the damage to the cartilage over time. Chondroitin is produced naturally in the body but older dogs can often benefit from a supplemental dose of chondroitin. Chondroitin is commonly supplied as a supplement in the form of chondroitin sulfate.\n\nOmega-3 fatty acids include docosahexaenoic acid (DHA) and eicosapentaenoic acid (EPA). These two fatty acids have been shown to improve gait score and lameness in dogs with osteoarthritis. Omega-3 fatty acids have also been shown to have noticeable anti-inflammatory properties. It is for this reason, among other benefits, that they are routinely included at supplemental levels in senior dog diets. A good source of omega-3 fatty acids in dog foods include fish oils and other fish sources (especially salmon and herring) as well as flaxseed.\n\nOne of the most basic requirements of the aging dog’s body is the requirement for maintenance of their bones. In order for the bones to be able to heal from any injury or erosion, as well as maintain their strength to avoid these problem, they need a ready supply of calcium and phosphorus. Both of these are essential nutrients according to AAFCO guidelines, and should be included in a senior dog diet. Calcium and Phosphorus are also very valuable in the maintenance tooth health of dogs. In order for calcium to be properly absorbed into the body dogs will require another nutrient, vitamin D. adequate vitamin D is needed to form enough calcitriol, known as the active form of vitamin D. If enough is not present the body will begin to draw from stores of vitamin D within the body like the bones and teeth for its needs. This can lead to bone weakening and the inability to repair bone damage.\n\nBeet pulp is a common ingredient in dog diets as it is a very versatile and useful fiber source. Beet pulp provides fiber to the diet which acts as a stool hardener and aids in lower tract “cleansing”. The composition of beet pulp is such that it is an insoluble and moderately fermentable fiber. This means it can add bulk to the diet as well as moisture to the stool while also supplying the animal’s cells lining the intestine with energy due to the moderate fermentation that occurs.\n\nFlax seed is the whole seed of the flax plant which contains both soluble and insoluble fiber. The insoluble fraction includes cellulose, hemicellulose, and lignin. These components have a very good water binding capacity which aids in adding bulk into the diet of the dog. This has varying benefits for dogs depending on their lifestyle. In some dogs, it aids in digestion by preventing constipation, in others it acts to improve satiety and encourage weight loss. Flaxseed is also a good source of omega-3 and omega-6 fatty acids which have multiple health benefits for the animal such as improving coat quality. Flax seed is also one of the richest sources of alpha linoleic acid (ALA). ALA can be converted by the dog to DHA and EPA to carry out various functions in the body.\n\nFructooligosaccharides, commonly known as FOS, consist of many different types of indigestible oligosaccharides. FOS is shown to be beneficial in providing a source of energy for the good gut bacteria in dogs. Mannanoligosaccharides are also known as MOS which also have an effect on the overall gut health in dogs. These compounds both contain oligosaccharides however; they work in different manners. Constipation prevention and treatment can be carried out by the supplementation of FOS by its subsequent effect on gut bacteria. MOS works in a different manner by effecting the attachment of bad bacteria in the gut of the dog. These bad bacteria attach to the epithelial lining of the gastrointestinal tract and can cause the beginnings of pathogenic diseases. MOS works to counteract these by preventing the binding of these deleterious bacteria.\n\nA study carried out in dogs determined that these two compounds when supplemented together can help with overall immune function. This is due to the decrease in overall bad bacteria and an increase in good bacteria in the gastrointestinal tract. These two compounds also were not found to have any detrimental effects on food consumption, stool quality or stool output.\n\nA dogs brain undergoes many pathological changes during the aging process. Some of these changes can include damage to the DNA (deoxyribonucleic acid), a decrease in the amount of myelin overlay on nerve cells as well as a buildup of protein in the brain which can potentially have toxic effects. Due to these physiological changes senior and aging dog can have possible impairment of proper cognition. This impairment can include complex learning tasks as well as memory issues.\n\nThe addition of Vitamin E as an antioxidant in senior dog food can have a positive effect on brain and cognitive health. Vitamin E is a fat soluble vitamin which works to prevent oxidative damage from occurring. Reactive oxygen species can develop in the brain and can have a harmful effect by causing oxidative stress on the tissues if they are not subdued by antioxidants. Mitochondrial aerobic metabolism is thought to be the largest source of reactive oxidative species. As the mitochondria age their function declines which causes an increase in the production of oxidative species.\n\nStudies carried out in aging dogs looking at the effects of antioxidant supplemented diets have shown that older dogs supplemented with antioxidants including Vitamin E were able to correctly perform tasks more often than senior dogs whose diets were not supplemented. It has also been shown that in senior dogs consuming these antioxidant enriched diets there was an increase in positive behavioural actions during the feeding period compared to senior dogs consuming diets that were not supplemented.\n\nL-carnitine is an amino acid and precursor of acetyl-L-carnitine which is a mitochondrial cofactor. It acts to help with overall mitochondrial function as well as lipid metabolism which is an important function of mitochondria. This is important as an increase in mitochondrial function will help to reduce the rates of oxidative reactions in the brain which overall decrease damage to DNA and stimulates better cognitive function.\n\nSeveral physiological changes in the senior pet can lead to a decline in skin and coat health. Some of these changes include a loss of elasticity in the skin which leads to wrinkling, hair follicle atrophy which can cause hair loss, a decrease in oil secretion which can lead to dry and flaky skin as well as a loss of melanocytes which causes the loss of pigmentation of the hair follicles. Skin and coat health is one of most noticeable aging changes due to the fact that it results in a change in appearance of the senior dog. Skin and coat health are important to upkeep as dogs age and there are many components in senior dog foods that can benefit this important area of health.\n\nLinoleic acid is a polyunsaturated fatty acid that is classified as an omega 6-fatty acid. Linoleic acid plays an important role in the maintenance of the water barrier of skin. This helps prevent the dryness and scaly skin that occurs during the aging process. Omega 6-fatty acids can also have a slight anti-imflammatory role. Good sources of linoleic acid to look for in senior dog foods include corn oil, soybean oil and poultry fat.\n\nVitamin A is a fat soluble vitamin that aids in the keratinization process of hair. This process is important in maintaining a healthy coat in the aging dog and preventing the deterioration of epithelial tissues. Dogs do not directly need a source of Vitamin A as they can convert beta-carotene (a precursor to Vitamin A) into Vitamin A. However, Vitamin A supplementation in senior dog diets can assist senior dogs in maintaining their coats as their sebaceous activity and skin elasticity decrease. Vitamin A supplements can be included in senior dogs diets however there are also other good sources of Vitamin A. These include milk, egg yolk, and liver. The inactive form of Vitamin A, beta-carotene can be found in high amounts in carrots.\n\n Vitamin E is a key component found in dog foods for the skin to maintain elasticity and to replace old skin cells. Due to the anti-oxidant mechanisms of vitamin E it can prevent the formation of free radicals and in turn may prevent cancer cells from proliferating in senior dogs. Vitamin E is found in both plant and animal products such as vegetable oil, dark red vegetables and liver.\n\nZinc is among one of many trace minerals recommended for dogs of all ages. Dogs experience loss of elasticity and dryness of the skin as they age. The addition of zinc in the diet aids in the development of collagen and wound healing, and also will prevent the skin from becoming dry and flaky. Senior dogs can obtain zinc in their diet through the addition of various ingredients, including; red meats, whole grains, poultry by-product meals, and fish meals.\n\nLoss of hair pigmentation is a common concern for senior dogs. Copper has been shown to improve coat conditions by reducing dry skin and improving the overall pigmentation of the coat. Therefore, copper may able to delay the natural aging process of the whitening of a dog's coat.\n\nSenior dogs require a larger amount of riboflavin for maintenance compared to adult dogs. Vitamin B2, also known as riboflavin, plays an important role as a cofactor for the metabolism of carbohydrates. Riboflavin is required in the diet to prevent cracking and dry skin, as well as a darkening of the pigmentation of skin. Riboflavin is also important for the vision of the senior dog as deficiencies can cause alterations in blood supply to the cornea which may lead to impaired vision and potential blindness. A source of riboflavin in senior dog diets is important to help prevent changes that aging can cause on skin.\n\nImmune functions start to decline due to compromised ability to efficiently produce various proteins and cells that are important for the body's defense system as dogs age. Free radicals can cause oxidative stress, killing the cells or impairing the functional capability of the cells, which leads to weakening of the immune system. Therefore, providing dietary antioxidants can be an effective method to prevent the oxidative stress and support the immune system.\n\nOmega-6 and omega-3 fatty acids are very important for a strong healthy immune system and for preventing chronic disease in dogs. It is crucial in pet diets that the ratio of omega-6 to omega-3 fatty acids is properly balanced in order to achieve optimal health.\n\nIt is recommended to have a ratio of 5:1 to 10:1, with there being more omega-6 fatty acids than omega-3's. AAFCO has a maximum ratio listed of 30:1. For ideal health and decreased risk of low-grade chronic inflammation, it is more beneficial to have a lower ratio versus a higher one. Omega-3 fatty acids have anti-inflammatory properties and therefore need to be supplemented in a closer ratio to omega-6's which are more inflammatory. Out of all of the omega-3 fatty acids that could be used, the most potent are found in fish oil in the forms of EPA and DHA, these have the highest immunomodulatory activities. Omega-3 fatty acids tend to increase antioxidant requirements because they oxidize so rapidly, therefore when they are in a closer ratio to omega-6 fatty acids, as recommended, antioxidants must also be supplemented in the diet.\n\nVitamin E is an antioxidant that can be supplemented in the diet in order to strengthen the effect of fatty acid supplementations. This vitamin works to decrease the production of pro-inflammatory markers that are found in synovial fluid of the joints. With the help of this antioxidant, chronic inflammation can be avoided which aids senior dogs in maintaining a healthier immune system as well as helping to ease the symptoms of osteoarthritis. Also, formation of , which is a reactive oxygen species that suppress lymphocyte proliferation, can be decreased by vitamin E.\n\nBeta-carotene can be found in certain vegetables and it is a highly potent antioxidants. The number of T-cells is naturally decreased with age, leading to compromised immune function. However, in old dogs supplemented with dietary beta-carotene had no statistical difference in the amount of CD4+ T cells when compared to younger dogs. It can also enhance cell-mediated immune responses and help prevent cancer. Dogs supplemented with high dose of dietary beta-carotene may show red discolouration of feces and staining of hair. However, toxicity level of beta-carotene in dogs is not clearly understood as dogs can also cleave beta-carotene into vitamin A in their intestines.\n\nSince the gastrointestinal tract is exposed to foreign materials from ingested food, a healthy microbiota in gut is very important component of the immune system. Prebiotic and probiotic supplements can help maintain healthy gut flora. Examples of common prebiotic ingredients in dog foods are Fructooligosaccharides(FOS), Mannanoligosaccharides (MOS), and beta-glucan. Examples of common probiotic ingredients in dog foods are \"Lactobacillus acidophilus\" and \"Enterococcus faecium\".\n"}
{"id": "3442553", "url": "https://en.wikipedia.org/wiki?curid=3442553", "title": "Spermatorrhea", "text": "Spermatorrhea\n\nSpermatorrhea is a condition of excessive, involuntary ejaculation. It is a recognized disorder in traditional Chinese medicine, in which certain patterns of involuntary ejaculation reflect problems with kidney qi.\n\nIn Ayurvedic Medicine, Ashwagandha and Bala are used to treat this vata ailment. Indian TKDL also has medicinal prescription using the herb.\n\nIn the 18th and 19th centuries, if a patient had ejaculations outside of marital intercourse, or released more semen than is typical, then he was diagnosed with a disease called \"spermatorrhea\" or \"seminal weakness\".Indian Ayurveda has a cure for this disease which can be Developed with the help of cannabis infused medicines. A variety of drugs and other treatments, including circumcision and castration, were advised as treatment. Some alternative practitioners, especially herb healers, continue to diagnose and advise treatments for cases of spermatorrhea.\n\nIn Western medicine during the nineteenth century, spermatorrhea was regarded as a medical disorder with corrupting and devastating effects on the mind and body. The cure for spermatorrhea was regarded as enforced chastity and avoidance of masturbation, with circumcision sometimes being used as a treatment.\n\nAccording to modern Western medicine, ejaculation is a normal process, and some even see it as a normal part of daily life, and incapable of causing ill effects, other than temporary tiredness and reduction of sexual desire in the individual concerned. In contrast, Traditional Chinese Medicine counts the production of semen as one of the biggest strains on jing (kidney essence).\n\n"}
{"id": "55514377", "url": "https://en.wikipedia.org/wiki?curid=55514377", "title": "The Rockefeller Foundation Economic Council on Planetary Health", "text": "The Rockefeller Foundation Economic Council on Planetary Health\n\nThe Rockefeller Foundation Economic Council on Planetary Health at the Oxford Martin School was established on 1 June 2017 to further define the new discipline of planetary health. Its mandate is to explore the economic link between human health and the earth’s natural systems on which health depends. By the end of 2019, it must recommend actionable public policy on this link.\n\nThe Council, made up of world leaders from government, international organizations, civil society, business, finance and academia, will meet several times throughout the 18 months of its mandate to develop specific recommendations and a decision-making framework that balances economic development with ecosystem protection, while promoting human health and well-being.\n\nThe Council is hosted at the Oxford Martin School at the University of Oxford.\n\nThe Rockefeller Foundation is a private foundation, with a stated mission of \"promoting the well-being of humanity throughout the world.\" The Oxford Martin School is a research and policy unit based in the Social Sciences Division of the University of Oxford. Together, they have joined forces to build the new and emerging field of planetary health. Planetary health examines \"the relationship between human health and the natural systems on which it depends.\"\n\nThe scientific case for a planetary health approach was established in a July 2015 report in The Lancet, “Safeguarding human health in the Anthropocene epoch,” wherein the Rockefeller Foundation-Lancet Commission on planetary health detailed the ways in which the degradation of natural systems harms the health of individuals, families and communities around the world. The report made several recommendations for how to do this, including having integrated social, economic and environmental policies, and better governance.\n\nThe role of the Economic Council on Planetary Health will be to provide advice and recommendations for how to reach these goals. The Council will meet several times a year to explore the economic link between human health and environmental change; increase existing scientific planetary health evidence by providing leaders and policy-makers with economic data for protecting human health through the preservation of the earth’s natural systems; and recommend the necessary economic policy reforms.\n\nBy the end of 2019, the Council is expected to produce a report that will recommend actionable public policy for governments and institutions on advancing planetary health.\n\nThe Rockefeller Foundation will provide $15 million toward establishing the pillars of a new planetary health discipline. Other organizations are also contributing to the emerging field, including the Planetary Health Alliance (PHA).\n\nThe Chair of The Rockefeller Foundation Economic Council on Planetary Health is Ernesto Zedillo, former president of Mexico and current Director of the Yale Center for the Study of Globalization.\n\nOther members include:\nThe Council Members are supported by an international Secretariat consisting of:\n\n"}
{"id": "56809094", "url": "https://en.wikipedia.org/wiki?curid=56809094", "title": "Vaginal stenosis", "text": "Vaginal stenosis\n\nVaginal stenosis is an abnormal condition in which the vagina becomes narrower and shorter due to the formation of fibrous tissue. Vaginal stenosis can have a negative impact on sexual dysfunction, dyspareunia and make pelvic exams difficult and painful. The lining of the vagina may also be thinner and drier and contain scar tissue. This condition can result in pain during sexual intercourse or a pelvic exam. Vaginal stenosis is often caused by an episiotomy, radiation therapy to the pelvis or some types of surgery. Chemotherapy can also increase the likelihood of developing vaginal stenosis. Vaginal stenosis can be a defect caused by congenital adrenal hyperplasia. Having an episiotomy is associated with stenosis.\n\nUterine, vaginal, rectal and cervical cancers are often treated with pelvic radiation therapy (RT). Radiation-induced vaginal stenosis can be a side effect of treatment. Causes are external beam radiation therapy (EBRT), or brachytherapy. It is one of the most prevalent side effects of pelvic radiation, affecting about one third of women. Radiation-induced stenosis can be a late reaction to treatment. Damage to the vaginal epithelium causes abnormal collagen production that leads to atrophy, loss of muscle, decreased blood flow, hypoxia, and fibrosis. Pallor, adhesions, and fragility can be observed along with loss of elasticity.\n\nThe inadequate prenatal suppression of adrenal androgens leads to congenital adrenal hyperplasia. This condition can result in the vagia being affected by stenosis as a result.\n\nStenosis of the vagina is treated with vaginal dilator therapy, but the evidence is lacking for its efficacy.\n\n"}
{"id": "275206", "url": "https://en.wikipedia.org/wiki?curid=275206", "title": "Vaginismus", "text": "Vaginismus\n\nVaginismus is a condition in which involuntary muscle spams prevents vaginal penetration. This often results in pain with attempts at sex. Often it begins when sexual intercourse is first attempted.\nThe underlying cause is generally a fear that penetration will hurt. Risk factors include a history of sexual assault, endometriosis, vaginitis, or a prior episiotomy. Diagnosis is based on the symptoms and examination. It requires there to be no anatomical or physical problems and a desire for penetration on the part of the women.\nTreatment may include behavior therapy such as graduated exposure therapy and gradual vaginal dilatation. Surgery is not generally indicated. Botulinum toxin is being studied. About 0.5% of women are affected. Outcomes are generally good with treatment.\n\nSeverity as well as the pain during penetration varies between women.\n\nA woman is said to have primary vaginismus when she is unable to have penetrative sex or experience vaginal penetration without pain. It is commonly discovered in teenage girls and women in their early twenties, as this is when many girls and young women first attempt to use tampons, have penetrative sex, or undergo a Pap smear. Women with vaginismus may be unaware of the condition until they attempt vaginal penetration. A woman may be unaware of the reasons for their condition.\n\nA few of the main factors that may contribute to primary vaginismus include:\n\n\nPrimary vaginismus is often idiopathic.\n\nVaginismus has been classified by Lamont according to the severity of the condition. Lamont describes four degrees of vaginismus: In first degree vaginismus, the patient has spasm of the pelvic floor that can be relieved with reassurance. In second degree, the spasm is present but maintained throughout the pelvis even with reassurance. In third degree, the patient elevates the buttocks to avoid being examined. In fourth degree vaginismus (also known as grade 4 vaginismus), the most severe form of vaginismus, the patient elevates the buttocks, retreats and tightly closes the thighs to avoid examination. Pacik expanded the Lamont classification to include a fifth degree in which the patient experiences a visceral reaction such as sweating, hyperventilation, palpitations, trembling, shaking, nausea, vomiting, losing consciousness, wanting to jump off the table, or attacking the doctor. The Lamont classification continues to be used to the present and allows for a common language among researchers and therapists.\n\nAlthough the pubococcygeus muscle is commonly thought to be the primary muscle involved in vaginismus, Pacik identified two additionally-involved spastic muscles in treated patients under sedation. These include the entry muscle (bulbocavernosum) and the mid-vaginal muscle (puborectalis). Spasm of the entry muscle accounts for the common complaint that patients often report when trying to have intercourse: \"It's like hitting a brick wall\".\n\nSecondary vaginismus occurs when a person who has previously been able to achieve penetration develops vaginismus. This may be due to physical causes such as a yeast infection or trauma during childbirth, while in some cases it may be due to psychological causes, or to a combination of causes. The treatment for secondary vaginismus is the same as for primary vaginismus, although, in these cases, previous experience with successful penetration can assist in a more rapid resolution of the condition. Peri-menopausal and menopausal vaginismus, often due to a drying of the vulvar and vaginal tissues as a result of reduced estrogen, may occur as a result of \"micro-tears\" first causing sexual pain then leading to vaginismus.\n\nFurther factors that may contribute to either secondary or primary vaginismus include:\n\nWhich muscles are involved is unclear but may include the pubococcygeus muscle, levator ani, bulbocavernosus, circumvaginal, and perivaginal muscles.\n\nA Cochrane review found little high quality evidence regarding the treatment of vaginismus in 2012. Specifically it is unclear if systematic desensitisation is better than other measures including nothing.\n\nAccording to Ward and Ogden's qualitative study on the experience of vaginismus (1994), the three most common contributing factors to vaginismus are fear of painful sex; the belief that sex is wrong or shameful (often the case with patients who had a strict religious upbringing); and traumatic early childhood experiences (not necessarily sexual in nature).\n\nPeople with vaginismus are twice as likely to have a history of childhood sexual interference and held less positive attitudes about their sexuality, whereas no correlation was noted for lack of sexual knowledge or (non-sexual) physical abuse.\n\nOften, when faced with a person experiencing painful intercourse, a gynecologist will recommend Kegel exercises and provide some additional lubricants. Strengthening the muscles that unconsciously tighten during vaginismus may be extremely counter-intuitive for some people. Although vaginismus has not been shown to affect a person's ability to produce lubrication, providing additional lubricant can be helpful in achieving successful penetration. This is due to the fact that women may not produce natural lubrication if anxious or in pain. Treatment of vaginismus may involve the use Hegar dilators, (sometimes called vaginal trainers) progressively increasing the size of the dilator inserted into the vagina.\n\nBotulinum toxin A (Botox) has been considered as a treatment option, under the idea of temporarily reducing the hypertonicity of the pelvic floor muscles. Although no random controlled trials have been done with this treatment, experimental studies with small samples have shown it to be effective, with sustained positive results through 10 months. Similar in its mechanism of treatment, lidocaine has also been tried as an experimental option.\n\nAnxiolytics and antidepressants are other pharmacotherapies that have been offered to people in conjunction with other psychotherapy modalities, or if these patients experience high levels of anxiety from their condition. Results from these medications have not been consistent.\n\nTrue epidemiological studies of vaginismus have not been done, as diagnosis would require painful examinations that such women would most likely avoid. Data available is primarily reported statistics from clinical settings.\n\nA study of vaginismus in people in Morocco and Sweden found a prevalence of 6%. 18-20% of people in British and Australian studies were found to have manifest dyspareunia, while the rate among elderly British people was as low as 2%.\n\nA 1990 study of people presenting to sex therapy clinics found reported vaginismus rates of between 12% and 17%, while a random sampling and structured interview survey conducted in 1994 by National Health and Sexual Life Survey documented 10%-15% of people reported that in the past six months they had experienced pain during intercourse.\n\nThe most recent study-based estimates of vaginismus incidence range from 5% to 47% of people presenting for sex therapy or complaining of sexual problems, with significant differences across cultures. It seems likely that a society's expectations of person's sexuality may particularly impact on the people with the condition.\n\n"}
{"id": "1219218", "url": "https://en.wikipedia.org/wiki?curid=1219218", "title": "Water birth", "text": "Water birth\n\nWater birth is childbirth that occurs in water. Proponents believe water birth results in a more relaxed, less painful experience that promotes a midwife-led model of care. Critics argue that the safety of water birth has not been scientifically proven and that a wide range of adverse neonatal outcomes have been documented, including increased mother or child infections and the possibility of infant drowning. A 2018 Cochrane Review of water immersion in the first stages of labor found evidence of fewer epidurals and few adverse effects but insufficient information regarding giving birth in water. Parent, child, and birthing organizations have produced statements both supporting and criticizing water birthing.\n\nA moderate to weak level of evidence indicates that water immersion during the first stage of childbirth reduces the pain of labor. A 2018 Cochrane Review found that immersion during the first stage of childbirth reduces the use of epidurals, however there is no clear evidence on the benefits of water immersion for the second stage of labor or full water birth. There is no evidence of increased adverse effects for immersion during the first or second stages of labor. There is not strong evidence that a water birth reduces tearing or perineal trauma. \n\nWater birth may offer perineal support for a birthing mother, and some theorize that this may decrease the risk of tearing and reduce the use of episiotomy.\n\nA 2014 review reported that it has been found that water immersion during the first stage of labor can reduce the length of the first stage, reduce labor pain, and the use of epidural/spinal analgesia. It is also associated with a lower rate of cesarean delivery and stress urinary incontinence symptoms 42 days after delivery. The review reported that immersion during labor did not appear to increase the rate of infections for the mother or the baby, and APGAR scores for the baby were similar to that of conventional births.\n\nThe British Royal College of Obstetricians and Gynaecologists and the Royal College of Midwives issued a joint statement supporting water birth for healthy women with uncomplicated pregnancies but does not recommend it in cases of complications.\n\nIn a 2005 commentary, the Committee on Fetus and Newborn of the American Academy of Pediatrics (AAP) released an analysis of the scientific literature regarding underwater births. The Committee noted several positive studies for underwater birth but went on to criticize them for lacking proper scientific controls, a significant number of infant deaths and diseases, and the general lack of information to support the use of water births. The paper concluded:\n\nThe safety and efficacy of underwater birth for the newborn has not been established. There is no convincing evidence of benefit to the neonate but some concern for serious harm. Therefore, underwater birth should be considered an experimental procedure that should not be performed except within the context of an appropriately designed RCT after informed parental consent.\n\nThe AAP received numerous letters in response to the statement, many claiming passionately that water birth had strong benefits and minimal risks for both parents and children and criticizing the AAP for failing to publish positive studies about the practice. In response, an author of the statement noted that the claims made were unsubstantiated and based purely on anecdotal evidence, with no randomized controlled trials (RCTs) that would allow an evidence-based assessment of the safety and benefits of water births. The author concluded by urging for proponents to support such a trial so that the question could be answered. The editor of the journal \"Pediatrics\", where the commentary was published, noted that no such trials had ever been submitted to the journal, which had a policy against publishing articles that are not based on scientific evidence. The reply concluded that \"I have not received any science-based commentaries from the groups that you cite in your letter. We cannot publish every letter, based on opinions only, that we receive.\"\n\nA birth pool is a specially designed vessel containing water for women to immerse themselves in for pain relief during labour. Birth pools work on the same principle as a bathtub, but are distinct from them due to buoyancy and freedom of movement, factors deemed to be important in labour. A birth pool can either be permanently installed or portable. Getting into a pool of water for labour is often called \"water birth\" because some women choose to remain in the water for birth as well.\n\nHealth policy in England stipulates women should be given the opportunity to labour in water through the publication of Intrapartum care guidelines issued in 2007 by the National Institute for Health and Care Excellence (NICE). The Royal College of Obstetricians and Gynaecologists and the Royal College of Midwives have jointly supported labour and birthing in water, and encourage hospitals to ensure birth pools are available to all women.\n\nImmersing in water in a birth pool is one of the methods available to manage pain during labour, in addition to TENS machine, Gas and air, Pethidine injection, deep breathing, massage and epidural.\n\nBefore birth pools became readily available there are many stories of women labouring and birthing in re-purposed tub-like products including animal watering troughs.\n\nOrdinary bathtubs found in American and British homes are not adequate to provide enough room for women to comfortably move and try different positions in labour, such as squatting or kneeling, and are not deep enough to create buoyancy. In order to create the feeling of weightlessness through buoyancy the water needs to almost cover the women's breasts while she is sitting and should cover her belly while she is squatting, leaning over the side of the pool or kneeling upright in the pool sitting back on her heels.\n\nThe original circular birth pool Dr Michel Odent used at Pithiviers hospital (France) in the early 1980s was two meters in diameter and .6 meters deep, large enough to accommodate two people and make it difficult for interference during the birthing process. Modern birth pools are somewhat smaller with a diameter between 110-150 centimeters and at least twenty, preferably twenty-two, inches of water.\n\nFactors to consider when choosing a birth pool are:\n\nBirth pools are generally categorised between two broad types: permanently installed or portable. Many hospitals in the United Kingdom now have a birth pool plumbed in, and portable birth pools can be purchased or hired for use at home or in hospital.\n\n"}
{"id": "12135807", "url": "https://en.wikipedia.org/wiki?curid=12135807", "title": "Welfare, Choice and Solidarity in Transition", "text": "Welfare, Choice and Solidarity in Transition\n\nWelfare, Choice and Solidarity in Transition: reforming the health sector in Eastern Europe was written by János Kornai and Karen Eggleston, published in 2001.\n\nThis book focused on ten post-socialist Eastern European countries, including Albania, Bulgaria, Croatia, Czech Republic, Hungary, Republic of Macedonia, Poland, Romania, Slovakia, and Slovenia.\n\nIn 2007, (according to the definition of the World Bank) in these ten countries, Albania is a lower-middle-income economy; the Czech Republic and Slovenia are high-income economies; and others belong to upper-middle-income economies.\n\n"}
{"id": "7941353", "url": "https://en.wikipedia.org/wiki?curid=7941353", "title": "Women who have sex with women", "text": "Women who have sex with women\n\nWomen who have sex with women (WSW) are women who engage in sexual activities with other women, whether or not they identify themselves as lesbian, bisexual, pansexual, heterosexual, or dispense with sexual identification altogether. The term \"WSW\" is often used in medical literature to describe such women as a group for clinical study, without needing to consider sexual self-identity.\n\nIn terms of medical issues with regard to lesbian sexual practices, the sexual identification of women who consult a medical professional is usually not sought nor volunteered, due to the misconceptions and assumptions about sexuality and the hesitancy of some women in disclosing their accurate sexual histories even to a physician. Many women who do not participate in heterosexual activity do not go to see a physician because they do not require birth control, which is the initiating factor for most women to seek consultation with a gynecologist when they become sexually active. As a result, these women are not screened regularly with pap smears because they have a lower perceived risk of acquiring a sexually transmitted infection or types of cancer. A factor which leads to lesbians neglecting to seek medical screening in the United States is a lack of health insurance offered by employers for same-sex domestic partners.\n\nWhen women do seek medical attention, medical professionals often fail to take a complete medical history. In a recent study of 2,345 lesbian and bisexual women, only 9.3% had claimed they had ever been asked their sexual orientation by a physician. A third of the respondents believed disclosing their sexual history would result in a negative reaction, and 30% had received a negative reaction from a medical professional after identifying themselves as lesbian or bisexual.\n\nA patient's complete history helps medical professionals identify higher risk areas and corrects assumptions about the personal histories of women. In a similar survey of 6,935 lesbians, 77% had had sexual contact with one or more male partners, and 6% had that contact within the previous year.\n\nHeart disease is listed by the U.S. Department of Health and Human Services as the number one cause of death for all women. Factors that add to risk of heart disease include obesity and smoking, both of which are more prevalent in lesbians. Studies show that lesbians have a higher body mass and are generally less concerned about weight issues than heterosexual women, although they are more likely to engage in exercise regularly.\n\nLack of differentiation between lesbians and heterosexual women in medical studies that concentrate on health issues for women skews results for lesbians and non-lesbian women. Reports are inconclusive about occurrence of breast cancer in lesbians. It has been determined, however, that the lower rate of lesbians tested by regular pap smears makes it more difficult to detect cervical cancer at early stages in lesbians. The risk factors for developing ovarian cancer rates are higher in lesbians than in heterosexual women, perhaps because many lesbians lack protective factors of pregnancy, abortion, contraceptives, breast feeding, and miscarriages.\n\nSince medical literature began to describe homosexuality, it has often been approached from a view that sought to find an inherent psychopathology as the root cause. Much literature on mental health and lesbians centered on their depression, substance abuse, and suicide. Although these issues exist among lesbians, discussion about their causes shifted after homosexuality was removed from the Diagnostic and Statistical Manual in 1973. Instead, social ostracism, legal discrimination, internalization of negative stereotypes, and limited support structures indicate factors homosexuals face in Western societies that often adversely affect their mental health. Women who identify as lesbian report feeling significantly different and isolated during adolescence; these emotions have been cited as appearing on average at 15 years old in lesbians and 18 years old in women who identify as bisexual. On the whole, women tend to work through developing a self-concept internally, or with other women with whom they are intimate. Women (heterosexual or otherwise) also limit who they divulge their sexual identities to and more often see being lesbian as a choice, as opposed to gay men, who work more externally and see being gay as outside their control.\n\nAnxiety disorders and depression are the most common mental health issues for women. Depression is reported among lesbians at a rate similar to heterosexual women. It is a more significant problem among women who feel they must hide their sexual orientation from friends and family, experience compounded ethnic or religious discrimination, or experience relationship difficulties with no support system. More than half the respondents to a 1994 survey of health issues in lesbians reported they had suicidal thoughts, and 18% had attempted suicide.\n\nA population-based study completed by the National Alcohol Research Center found that women who identify as lesbian or bisexual are less likely to abstain from alcohol. Lesbians and bisexual women have a higher likelihood of reporting problems with alcohol, as well as not being satisfied with treatment for substance abuse programs. Many lesbian communities are centered in bars, and drinking is an activity that correlates to community participation for lesbians and bisexual women.\n\nSome STIs are communicable between women, including human papillomavirus (HPV), trichomoniasis, syphilis, human immunodeficiency virus (HIV), bacterial vaginosis (BV), and herpes simplex virus (HSV). Transmission of specific sexually transmitted diseases among women who have sex with women depends on the sexual practices women engage in. Any object that comes in contact with cervical secretions, vaginal mucosa, or menstrual blood, including fingers or penetrative objects may transmit sexually transmitted diseases. Oral-genital contact may indicate a higher risk of acquiring HSV, even among women who have had no prior sex with men. Bacterial vaginosis occurs more often in lesbians, but it is unclear if BV is transmitted by sexual contact; it occurs in celibate as well as sexually active women. BV often occurs in both partners in a lesbian relationship; a recent study of women with BV found that 81% had partners with BV. Lesbians are not included in a category of frequency of HIV transmission, although transmission is possible through vaginal and cervical secretions; the highest rate of transmission of HIV to women is among those who have sexual intercourse with men or participate in intravenous drug use.\n\n\n"}
