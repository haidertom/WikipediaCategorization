<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>A History of Vector Analysis</title>
    <ns>0</ns>
    <id>16289784</id>
    <revision>
      <id>836652692</id>
      <parentid>833357849</parentid>
      <timestamp>2018-04-16T01:38:36Z</timestamp>
      <contributor>
        <username>Rgdboer</username>
        <id>92899</id>
      </contributor>
      <minor/>
      <comment>/* Summary of book */ lk Equipollence, G. Bellavitis, Dot product, Cross product</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8043">{{Infobox book| &lt;!-- See Wikipedia:WikiProject_Novels or Wikipedia:WikiProject_Books --&gt;
| name          = A History of Vector Analysis
| image         = A History of Vector Analysis.jpg
| caption       =
| author        = Michael J. Crowe
| cover_artist  =
| country       = United states
| language      = English
| genre         = [[Non-fiction books|Non-fiction]]
| subject       = Geometry
| publisher     = [[University of Notre Dame Press]]
| pub_date      = 1967
| media_type    = Print 
| pages         =
| isbn          = 
| oclc          = 
}}

'''''A History of Vector Analysis''''' (1967) is a book on the history of [[vector analysis]] by Michael J. Crowe, originally published by the [[University of Notre Dame Press]].
As a scholarly treatment of a reformation in [[technical communication]], the text is a contribution to the [[history of science]]. In 2002, Crowe gave a talk&lt;ref&gt;[http://www.math.ucdavis.edu/~temple/MAT21D/SUPPLEMENTARY-ARTICLES/Crowe_History-of-Vectors.pdf Michael J. Crowe, A History of Vector Analysis (talk at University of Louisville, 2002)]&lt;/ref&gt; summarizing the book, including an entertaining introduction in which he covered its publication history and related the award of a Jean Scott prize of $4000.  Crowe had entered the book in a competition for "a study on the history of complex and hypercomplex numbers" twenty-five years after his book was first published.

==Summary of book==
The book has eight chapters: the first on the origins of vector analysis including Ancient Greek and 16th and 17th century influences; the second on the 19th century [[William Rowan Hamilton]] and [[quaternions]]; the third on other 19th and 18th century vectorial systems including [[equipollence (geometry)|equipollence]] of [[Giusto Bellavitis]] and the [[exterior algebra]] of [[Hermann Grassmann]].

Chapter four is on the general interest in the 19th century on vectorial systems including analysis of journal publications as well as sections on major figures and their views (e.g., [[Peter Guthrie Tait]] as an advocate of Quaternions and [[James Clerk Maxwell]] as a critic of Quaternions); the fifth chapter describes the development of the modern system of vector analysis by [[Josiah Willard Gibbs]] and [[Oliver Heaviside]].

In chapter six, "Struggle for existence",
Michael J. Crowe delves into the [[zeitgeist]] that pruned down quaternion theory into vector analysis on [[three-dimensional space]]. He makes clear the ambition of this effort by considering five major texts as well as a couple dozen articles authored by participants in "The Great Vector Debate". These are the books:
:''Elementary Treatise on Quaternions'' (1890) [[Peter Guthrie Tait]]
:''Elements of Vector Analysis'' (1881,1884) [[Josiah Willard Gibbs]]
:''Electromagnetic Theory'' (1893,1899,1912) [[Oliver Heaviside]]
:''Utility of Quaternions in Physics'' (1893) [[Alexander MacAulay]]
:''Vector Analysis and Quaternions'' (1906) [[Alexander Macfarlane]]

Twenty of the ancillary articles appeared in [[Nature (journal)|Nature]]; others were in [[Philosophical Magazine]], London or Edinburgh Proceedings of the [[Royal Society]], [[Physical Review]], and Proceedings of the [[American Association for the Advancement of Science]]. The authors included [[Cargill Gilston Knott]] and a half-dozen other hands.

The "struggle for existence" is a phrase from [[Charles Darwin]]’s [[Origin of Species]] and Crowe quotes Darwin:  "…young and rising naturalists,…will be able to view both sides of the question with impartiality." After 1901 with the Gibbs/Wilson/Yale publication [[Vector Analysis]], the question was decided in favour of the vectorialists with separate [[dot product|dot]] and [[cross product]]s. The pragmatic temper of the times set aside the four-dimensional source of vector algebra.

Crowe's chapter seven is a survey of "Twelve major publications in Vector Analysis from 1894 to 1910". Of these twelve, seven are in German, two in Italian, one in Russian, and two in English. Whereas the previous chapter examined a debate in English, the final chapter notes the influence of [[Heinrich Hertz]]' results with radio and the rush of German research using vectors. Joseph George Coffin of MIT and [[Clark University]] published his ''Vector Analysis'' in 1909; it too leaned heavily into applications. Thus Crowe provides a context for Gibbs and Wilson’s famous textbook of 1901.

The eighth chapter is the author's summary and conclusions.&lt;ref&gt;Quote from page ix, "Concerning bibliography. No formal bibliographical section has been included in this book. The reader will find however that the sections of notes at the end of each chapter will serve rather well as a bibliography for that chapter. Moreover the need for a bibliography is greatly diminished by the existence of a book that lists nearly all relevant primary documents published to about 1912."&lt;/ref&gt; The book relies on references in chapter endnotes instead of a bibliography section.  Crowe also states that the ''Bibliography'' of the [[Quaternion Society]], and its supplements to 1912, already listed all the primary literature for the study.

==Summary of reviews==
There were significant reviews given near the time of original publication. Stanley Goldberg&lt;ref&gt;Stanley Goldberg (1969) [[American Mathematical Monthly]] 76(9):1086–8&lt;/ref&gt; wrote "The polemics on both sides make very rich reading, especially when they are spiced with the sarcastic wit of a Heaviside, and the fervent, almost religious railing of a Tait." [[Morris Kline]] begins his 1969 review&lt;ref&gt;[[Morris Kline]] (1969) [http://www.ams.org/mathscinet/pdf/0229496.pdf Review of ''A History of Vector Analysis''] [[Mathematical Reviews]] 37 #5070&lt;/ref&gt; with "Since historical publications on modern developments are rare, this book is welcome." and ends with "the subtitle [,The Evolution of the Idea of a Vectorial System,] is a better description of the contents than the title proper."  Then [[William C. Waterhouse]]—picking up where Kline's review left off—writes in 1972 "Crowe's book on vector analysis seems a little anemic in comparison, perhaps because its title is misleading. ... [Crowe] does succeed in his goal of tracing the genealogy of the 3-space system, concluding that it was developed out of quaternions by physicists."&lt;ref&gt;[[William C. Waterhouse]] (1972) Review, [[Bulletin of the American Mathematical Society]] 78(3):385–391&lt;/ref&gt;

In 2003 Sandro Caparrini challenged Crowe’s conclusions by noting that "geometrical representations of forces and velocities by means of directed line segments...was already fairly well known by the middle of the eighteenth century" in his essay "Early Theories of Vectors".&lt;ref&gt;{{cite book |author = Becchi, Antonio |author2 = Massimo Corradi |author3 = Federico Foce |author4 = Orietta Pedemonte |title=Essays on the History of Mechanics: In Memory of Clifford Ambrose Truesdell and Edoardo Benvenuto |publisher=Birkhäuser Verlag |location=Basel |year=2003 |pages=175–198|isbn=3-7643-1476-1 |oclc= |doi= |accessdate=}}&lt;/ref&gt; Caparrini cites several sources, in particular [[Gaetano Giorgini]] (1795 — 1874) and his appreciation in an 1830 article&lt;ref&gt;[[Michel Chasles]] (1830) "Mémoire de géométrie pure, sur les systèmes de forces, et les systèmes d'aires planes; et sur les polygones, polyèdres, et les centres de moyennes distances", ''Correspondence Mathématique et Physique'' 6:92–120&lt;/ref&gt; by [[Michel Chasles]]. Caparrini goes on to indicate that [[torque|moments of forces]] and [[angular velocity|angular velocities]] were recognized as vectorial entities in the second half of the eighteenth century.

==See also==
* [[History of quaternions]]
* [[Hypercomplex number]]
* [[Vector space]]

==Notes and references==
{{reflist|2}}

{{DEFAULTSORT:History Of Vector Analysis, A}}
[[Category:1967 books]]
[[Category:Mathematics books]]
[[Category:History of mathematics]]
[[Category:Books about the history of science]]
[[Category:Historical treatment of quaternions]]</text>
      <sha1>mczm3tihvxnt3un31ez5cvn6l1m5mq2</sha1>
    </revision>
  </page>
  <page>
    <title>Ackermann's formula</title>
    <ns>0</ns>
    <id>54426651</id>
    <revision>
      <id>867746236</id>
      <parentid>867746169</parentid>
      <timestamp>2018-11-07T19:07:33Z</timestamp>
      <contributor>
        <ip>196.216.165.227</ip>
      </contributor>
      <comment>/* Example */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9055">{{not to be confused with|Ackermann function}}
{{Technical|date=July 2017}}

'''Ackermann's formula''' is a [[control system]] design method for solving the [[Full state feedback|pole allocation]] problem. One of the primary problems in control system design is the creation of controllers that will alter the dynamics of a system and alter the poles to a more suitable, and sometimes more stable, state. Such a problem can be tackled by many different methods; one such solution is the addition of a feedback loop in such a way that a gain is added to the input with which one can change the poles of the original system. If the system is [[ Controllability|controllable]], an efficient method for pole placement is Ackermann's formula, which allows one to choose arbitrary poles within the system. &lt;ref&gt; Modern Control System Theory and Design, 2nd Edition by Stanley M. Shinners &lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.uta.edu/utari/acs/ee4314/lectures/Lecture%2022.pdf |format=PDF |title=State variable feedback  |website=Uta.edu |accessdate=2017-07-06}}&lt;/ref&gt;

==State feedback system==
Consider a linear time invariant system&lt;ref&gt;{{cite web|url=https://en.wikibooks.org/wiki/Control_Systems/State_Feedback#Ackerman.27s_formula|title=Control Systems/State Feedback - Wikibooks, open books for an open world|website=en.wikibooks.org|accessdate=6 July 2017}}&lt;/ref&gt; with a [[state-space representation]]

: &lt;math&gt; \dot{x}(t)=Ax(t)+Bu(t) &lt;/math&gt;

: &lt;math&gt; y(t)=Cx(t) &lt;/math&gt;

where &lt;math&gt; x(t) &lt;/math&gt; is the state vector, &lt;math&gt; u(t) &lt;/math&gt; is the input vector, and &lt;math&gt; A,B,C &lt;/math&gt; are matrices of compatible dimensions that represent the dynamics of our system, and, for simplicity's sake, assume  &lt;math&gt; D=0 &lt;/math&gt;. An input-output description of this system is given by the [[transfer function]]

: &lt;math&gt; C(sI-A)^{-1}B=C\ \frac{\operatorname{Adj}(sI-A)}{\det(sI-A)}\ B.&lt;/math&gt;

Since  &lt;math&gt;(sI-A)^{-1}=\frac{\operatorname{Adj}(sI-A)}{\det(sI-A)} &lt;/math&gt;,  the denominator of the system is given by the [[characteristic polynomial]] of  &lt;math&gt; A &lt;/math&gt;. Thus, the poles of the system are the [[eigenvalue]]s of &lt;math&gt;A&lt;/math&gt;.

If the system is [[Exponential stability|unstable]], or has a slow response or any other characteristic that does not specify the design criteria, it could be advantageous to make changes to it. The realization given by &lt;math&gt;\{A,B,C\}&lt;/math&gt;, however, represents the dynamics of the system, and sometimes cannot be altered. Thus, one approach to this problem might be to create a feedback loop with a gain &lt;math&gt;K&lt;/math&gt; that will feed the state variable into the input.

If the system is [[Controllability|controllable]], there is always an input &lt;math&gt;u(t)&lt;/math&gt; such that any state &lt;math&gt;x_{0}&lt;/math&gt; can be transferred to any other state &lt;math&gt;x(t)&lt;/math&gt;. With that in mind, a feedback loop can be added to the system with the control input &lt;math&gt;u(t)=r(t)-Kx(t)&lt;/math&gt;, such that the new dynamics of the system will be 

: &lt;math&gt;\dot{x}(t)=Ax(t)+B[r(t)+Kx(t)]= [A+BK] x(t)+Br(t)&lt;/math&gt;

: &lt;math&gt;y(t)=Cx(t).&lt;/math&gt;

In this new realization, the poles will be dependent on the characteristic polynomial &lt;math&gt;\Delta_{new}&lt;/math&gt; of &lt;math&gt;A-BK&lt;/math&gt;, that is 

: &lt;math&gt;\Delta_\text{new}(s)=\det(sI-(A-BK)).&lt;/math&gt;

==Ackermann's formula==

Computing the characteristic polynomial and choosing a suitable feedback matrix can be a challenging task, especially in larger systems. One way to make computations easier is through Ackermann's formula. For simplicity's sake, consider a single input vector with no reference parameter &lt;math&gt;r&lt;/math&gt;, such as 

: &lt;math&gt;u(t)=-k^T x(t)&lt;/math&gt;

: &lt;math&gt;\dot x(t)=Ax(t)-Bk^T x(t),&lt;/math&gt;

where &lt;math&gt;k^T&lt;/math&gt; is a feedback vector of compatible dimensions. Given that the system is still controllable, Ackermann's method states that the design process can be simplified by the following equation: 

: &lt;math&gt;k^T =\left[0\ 0\ \cdots \ 0\ 1\right]\mathcal{C}^{-1}\Delta_\text{new}(A),
&lt;/math&gt;

in which &lt;math&gt;\Delta_\text{new}(A)&lt;/math&gt; is the desired characteristic polynomial evaluated at matrix &lt;math&gt;A&lt;/math&gt;. 

=== Proof===
&lt;ref&gt;{{cite web|url=http://www.eolss.net/sample-chapters/c18/e6-43-13-11.pdf |title=Pole Placement Control |format=PDF |website=Eolss.net |date= |accessdate=2017-07-06}}&lt;/ref&gt;
Assume that the system is [[Controllability|controllable]]. Defining &lt;math&gt;A_{CL}:=(A-Bk^{T})&lt;/math&gt; gives

: &lt;math&gt;\Delta(A_{CL})=(A_{CL})^n + \sum_{k=0}^{n-1} \alpha_k A_{CL}^{k-1}&lt;/math&gt;

Calculating the powers of &lt;math&gt;A_{CL}&lt;/math&gt; results in 

: &lt;math&gt;(A_{CL})^0=(A-Bk^T)^0=I&lt;/math&gt;

: &lt;math&gt;(A_{CL})^1 = (A-Bk^T)^1=A-Bk^T&lt;/math&gt;

: &lt;math&gt;(A_{CL})^2=(A-Bk^T)^2=A^2-ABk^T-Bk^T A+(Bk^T)^2=A^2-ABk^T-(Bk^T)[A-Bk^T]=A^2-ABk^T-Bk^T A_{CL}&lt;/math&gt;

: &lt;math&gt;(A_{CL})^n = (A-Bk^T)^n=A^n-A^{n-1} Bk^T-A^{n-2} Bk^T A_{CL}- \cdots -Bk^T A_{CL}^{n-1}&lt;/math&gt;

Replacing the previous equations into &lt;math&gt;\Delta(A_{CL})&lt;/math&gt; yields 

: &lt;math&gt;\Delta(A_{CL})=(A^n-A^{n-1} Bk^T-A^{n-2} Bk^T A_{CL}-\cdots-Bk^T A_{CL}^{n-1})+\cdots+\alpha_2(A^2-ABk^T-Bk^T A_{CL}) + \alpha_1 (A-Bk^T)+\alpha_0I&lt;/math&gt;

: &lt;math&gt;\Delta(A_{CL}) =(A^n+\alpha_{n-1}A^{n-1}+\cdots + \alpha_2 A^2+\alpha_1 A+\alpha_0 I)-(A^{n-1}Bk^{T}+A^{n-2}Bk^T A_{CL}+\cdots+Bk^TA_{CL}^{n-1}) + \cdots +\alpha_2 (ABk^T+Bk^T A_{CL})+\alpha_1(Bk^T)&lt;/math&gt;

Noting that &lt;math&gt;(A^n+\alpha_{n-1}A^{n-1} + \cdots + \alpha_2 A^2 + \alpha_1 A+\alpha_0 I)=\Delta(A)&lt;/math&gt;.

: &lt;math&gt;\Delta(A_{CL})=\Delta(A)-(A^{n-1}Bk^T+A^{n-2} Bk^T A_{CL} + \cdots + Bk^T A_{CL}^{n-1}) + \cdots + \alpha_2 (ABk^T + Bk^T A_{CL}) +\alpha_1 (A+Bk^T)&lt;/math&gt;

Rewriting the above equation as a matrix product and omitting the terms that  &lt;math&gt;k^T&lt;/math&gt; does not appear isolated gives

: &lt;math&gt;\Delta(A_{CL})=\Delta(A)-\left[B\ \ AB\ \ \cdots \ \ A^{n-1} B\right]\left[\begin{array}{c}
\vdots\\
k^T
\end{array}\right]&lt;/math&gt;

From the [[Cayley–Hamilton theorem]],  &lt;math&gt;\Delta\left(A_{CL}\right)=0&lt;/math&gt;, thus

&lt;math&gt;\left[B\ \ AB\ \ \cdots \ \ A^{n-1}B\right]\left[\begin{array}{c}
\vdots\\
k^T
\end{array}\right]=\Delta(A)&lt;/math&gt;

Note that  &lt;math&gt;\mathcal{C}=\left[B\ \ AB\ \ \cdots \ \ A^{n-1}B\right] &lt;/math&gt; is the [[Controllability#Continuous linear time-invariant (LTI) systems|controllability matrix]] of the system. Since the system is controllable,  &lt;math&gt;\mathcal{C}&lt;/math&gt; is invertible. Thus, 

: &lt;math&gt;\left[\begin{array}{c}
\vdots\\
k^{T}
\end{array}\right]=\mathcal{C}^{-1}\Delta(A)&lt;/math&gt;

To find &lt;math&gt;k^{T}&lt;/math&gt;, both sides can be multiplied by the vector &lt;math&gt;\left[\begin{array}{ccccc}
0 &amp; 0 &amp; 0 &amp; \cdots &amp; 1\end{array}\right]&lt;/math&gt;. This yields 

: &lt;math&gt;\left[\begin{array}{ccccc}
0 &amp; 0 &amp; 0 &amp; \cdots &amp; 1\end{array}\right]\left[\begin{array}{c}
\vdots\\
k^{T}
\end{array}\right]=\left[\begin{array}{ccccc}
0 &amp; 0 &amp; 0 &amp; \cdots &amp; 1\end{array}\right]\mathcal{C}^{-1}\Delta(A)&lt;/math&gt;

Thus,

: &lt;math&gt;k^{T}=\left[\begin{array}{ccccc}
0 &amp; 0 &amp; 0 &amp; \cdots &amp; 1\end{array}\right]\mathcal{C}^{-1}\Delta(A)&lt;/math&gt;

==Example==

Consider&lt;ref&gt;{{cite web|url=http://web.mit.edu/16.31/www/Fall06/1631_topic13.pdf |format=PDF |title=Topic #13 : 16.31 Feedback Control|website=Web.mit.edu |accessdate=2017-07-06}}&lt;/ref&gt;

&lt;math&gt;\dot{x}=\left[\begin{array}{cc}
1 &amp; 1\\
1 &amp; 2
\end{array}\right]x+\left[\begin{array}{c}
1\\
0
\end{array}\right]u&lt;/math&gt;

We know from the characteristic polynomial of &lt;math&gt;A&lt;/math&gt; that the system is unstable since &lt;math&gt;det(sI-A)=(s-1)(s-2)-1=(s-1)^2&lt;/math&gt;, the matrix &lt;math&gt;A&lt;/math&gt; will only have positive eigenvalues. Thus, to stabilize the system we shall put a feedback gain &lt;math&gt;K=\left[\begin{array}{cc}
k_1 &amp; k_2\end{array}\right]. &lt;/math&gt;

From Ackermann's formula, we can find a matrix &lt;math&gt;k&lt;/math&gt;  that will change the system so that its characteristic equation will be equal to a desired polynomial. Suppose we want &lt;math&gt;\Delta_\text{desired}(s)=s^2+11s+30&lt;/math&gt;.

Thus, &lt;math&gt;\Delta_\text{desired}(A)=A^2+11A+30I&lt;/math&gt; and computing the controllability matrix yields

: &lt;math&gt;\mathcal{C}=\left[\begin{array}{cc}
B &amp; AB\end{array}\right]=\left[\begin{array}{cc}
1 &amp; 1\\
0 &amp; 1
\end{array}\right]&lt;/math&gt; and

: &lt;math&gt;\mathcal{C}^{-1}=\left[\begin{array}{cc}
1 &amp; -1\\
0 &amp; 1
\end{array}\right].&lt;/math&gt;

Also, we have that &lt;math&gt;A^2=\left[\begin{array}{cc}
2 &amp; 3\\
3 &amp; 5
\end{array}\right].&lt;/math&gt;

Finally, from Ackermann's formula

: &lt;math&gt;k^{T}=\left[\begin{array}{cc}
0 &amp; 1\end{array}\right]\left[\begin{array}{cc}
1 &amp; -1\\
0 &amp; 1
\end{array}\right]\left[\left[\begin{array}{cc}
2 &amp; 3\\
3 &amp; 5
\end{array}\right]+11\left[\begin{array}{cc}
1 &amp; 1\\
1 &amp; 2
\end{array}\right]+30I\right]&lt;/math&gt;

: &lt;math&gt;k^T=\left[\begin{array}{cc}
0 &amp; 1\end{array}\right]\left[\begin{array}{cc}
1 &amp; -1\\
0 &amp; 1
\end{array}\right]\left[\begin{array}{cc}
43 &amp; 14\\
14 &amp; 57
\end{array}\right]=\left[\begin{array}{cc}
0 &amp; 1\end{array}\right]\left[\begin{array}{cc}
29 &amp; -43\\
14 &amp; 57
\end{array}\right]&lt;/math&gt;

: &lt;math&gt;k^T=\left[\begin{array}{cc}
14 &amp; 57\end{array}\right]&lt;/math&gt;

==References==
{{Reflist}}

[[Category:Mathematical concepts]]
[[Category:Engineering concepts]]
[[Category:Control engineering]]</text>
      <sha1>d84v10azgnmaog0lykhvu9dl1t63kxk</sha1>
    </revision>
  </page>
  <page>
    <title>Almost surely</title>
    <ns>0</ns>
    <id>351908</id>
    <revision>
      <id>867101044</id>
      <parentid>866987344</parentid>
      <timestamp>2018-11-03T17:27:21Z</timestamp>
      <contributor>
        <ip>2600:100C:B201:C7F4:9D39:1BA8:9F4D:DE97</ip>
      </contributor>
      <comment>/* Tossing a coin repeatedly */Fixed typo</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8672">{{Redirect|Probability 1|Rudolf Carnap's notion of "probability&lt;sub&gt;1&lt;/sub&gt;" |Probability interpretations}}
&lt;!---the above disambiguation link does make sense when this article is reached via the REDIRECT from "probability 1"---&gt;
In [[probability theory]], one says that an [[event (probability theory)|event]] happens '''almost surely''' (sometimes abbreviated as '''a.s.''') if it happens with probability one. In other words, the set of possible exceptions may be non-empty, but it has probability zero. The concept is precisely the same as the concept of "[[almost everywhere]]" in [[measure theory]].

In probability experiments on a finite [[sample space]], there is often no difference between ''almost surely'' and ''surely''. However, the distinction becomes important when the [[sample space]] is an [[infinite set]], because an infinite set can have non-empty subsets of probability zero.

Some examples of the use of this concept include the strong and uniform versions of the [[law of large numbers]], and the continuity of the paths of [[Brownian motion]].

The terms '''almost certainly''' (a.c.) and '''almost always''' (a.a.) are also used. '''Almost never''' describes the opposite of ''almost surely'': an event that happens with probability zero happens ''almost never''.&lt;ref name=Gradel&gt;{{cite book |last1=Grädel |first1=Erich |last2=Kolaitis |first2=Phokion G. |last3=Libkin |first3=Leonid | author3-link=Leonid Libkin |last4=Marx |first4=Maarten |last5=Spencer |first5=Joel |last6=Vardi |first6=Moshe Y. |last7=Venema |first7=Yde |last8=Weinstein |first8=Scott |title=Finite Model Theory and Its Applications |date=2007 |publisher=Springer |isbn=978-3-540-00428-8 |page=232}}&lt;/ref&gt;

==Formal definition==
Let &lt;math&gt;(\Omega,\mathcal{F},P)&lt;/math&gt; be a [[probability space]]. An [[event (probability theory)|event]] &lt;math&gt;E \in \mathcal{F}&lt;/math&gt; happens ''almost surely'' if &lt;math&gt;P(E)=1&lt;/math&gt;. Equivalently, &lt;math&gt;E&lt;/math&gt; happens almost surely if the probability of &lt;math&gt;E&lt;/math&gt; not occurring is [[0 (number)|zero]]: &lt;math&gt;P(E^C) = 0&lt;/math&gt;. More generally, any event &lt;math&gt;E \subseteq \Omega&lt;/math&gt; (not necessarily in &lt;math&gt;\mathcal{F}&lt;/math&gt;) happens almost surely if &lt;math&gt;E^C&lt;/math&gt; is contained in a [[null set]]: a subset of some &lt;math&gt;N\in\mathcal F&lt;/math&gt; such that {{nowrap|&lt;math&gt;P(N)=0&lt;/math&gt;.}}&lt;ref name="Jacod"&gt;{{cite book|last=Jacod|first=Jean|author2=Protter, |year=2004|title=Probability Essentials|publisher=Springer|page=37|isbn=978-3-540-438717}}&lt;/ref&gt; The notion of almost sureness depends on the probability measure &lt;math&gt;P&lt;/math&gt;. If it is necessary to emphasize this dependence, it is customary to say that the event &lt;math&gt;E&lt;/math&gt; occurs ''P''-almost surely, or almost surely (''P'').

==Illustrative examples==
In general, an event can happen "almost surely" even if the probability space in question includes outcomes which do not belong to the event, as is illustrated in the examples below.

===Throwing a dart===
Imagine throwing a dart at a unit square (i.e. a square with area 1) so that the dart always hits exactly one point of the square, and so that each point in the square is equally likely to be hit. 

Now, notice that since the square has area 1, the probability that the dart will hit any particular subregion of the square equals the area of that subregion. For example, the probability that the dart will hit the right half of the square is 0.5, since the right half has area 0.5.

Next, consider the event that "the dart hits a diagonal of the unit square exactly". Since the areas of the diagonals of the square are zero, the probability that the dart lands exactly on a diagonal is zero. So, the dart will '''almost never''' land on a diagonal (i.e. it will '''almost surely''' ''not'' land on a diagonal). Nonetheless the set of points on the diagonals is not empty and a point on a diagonal is no less possible than any other point: the diagonal does contain valid outcomes of the experiment.

===Tossing a coin repeatedly===
Consider the case where a (possibly biased) coin is tossed, corresponding to the probability space &lt;math&gt;(\{H,T\}, 2^{\{H, T\}}, P)&lt;/math&gt;, where the event &lt;math&gt;\{H\}&lt;/math&gt; occurs if heads is flipped, and &lt;math&gt;\{T\}&lt;/math&gt; if tails. For this particular coin, assume the probability of flipping heads is &lt;math&gt;P(H) = p\in (0,1)&lt;/math&gt; from which it follows that the complement event, flipping tails, has &lt;math&gt;P(T) = 1 - p&lt;/math&gt;.

Suppose we were to conduct an experiment where the coin is tossed repeatedly, with outcomes &lt;math&gt;\omega_1,\omega_2,\ldots&lt;/math&gt;, and it is assumed each flip's outcome is independent of all the others. That is, they are [[Independent and identically distributed random variables|''i.i.d.'']]. Define the sequence of random variables on the coin toss space, &lt;math&gt;(X_i)_{i\in\mathbb{N}}&lt;/math&gt; where &lt;math&gt;X_i(\omega)=\omega_i&lt;/math&gt;. ''i.e.'' each &lt;math&gt;X_i&lt;/math&gt; records the outcome of the &lt;math&gt;i&lt;/math&gt;'th flip.

Any infinite sequence of heads and tails is a possible outcome of the experiment.  However, any particular infinite sequence of heads and tails has probability zero of being the exact outcome of the (infinite) experiment.  To see why, note that the [[Independent and identically distributed random variables|''i.i.d.'']] assumption implies that the probability of flipping all heads over &lt;math&gt;n&lt;/math&gt; flips is simply &lt;math&gt;P(X_i = H, \ i=1,2,\dots,n)=\left(P(X_1 = H)\right)^n = p^n&lt;/math&gt;. Letting &lt;math&gt;n\rightarrow\infty&lt;/math&gt; yields zero, since &lt;math&gt;p\in (0,1)&lt;/math&gt; by assumption. Note that the result is the same no matter how much we bias the coin towards heads, so long as we constrain &lt;math&gt;p&lt;/math&gt; to be greater than 0, and less than 1.

In particular, the event "the sequence contains at least one &lt;math&gt;T&lt;/math&gt;" happens almost surely (i.e., with probability 1).
However, if instead of an infinite number of flips we stop flipping after some finite time, say a million flips, then the all-heads sequence has non-zero probability. The all-heads sequence has probability &lt;math&gt;p^{1,000,000}\neq 0&lt;/math&gt;, while the probability of getting at least one tails is &lt;math&gt;1 - p^{1,000,000}&lt;/math&gt; and the event is no longer '''almost sure'''.

==Asymptotically almost surely==
In [[asymptotic analysis]], one says that a property holds '''asymptotically almost surely''' ('''a.a.s.''') if, over a sequence of sets, the probability converges to 1. For instance, a large number is asymptotically almost surely [[composite number|composite]], by the [[prime number theorem]]; and in [[random graph|random graph theory]], the statement "&lt;math&gt;G(n,p_n)&lt;/math&gt; is [[Connectivity (graph theory)|connected]]" (where [[Erdős–Rényi model|&lt;math&gt;G(n,p)&lt;/math&gt;]] denotes the graphs on &lt;math&gt;n&lt;/math&gt; vertices with edge probability &lt;math&gt;p&lt;/math&gt;) is true a.a.s. when, for any &lt;math&gt;\varepsilon &gt; 0&lt;/math&gt;
:&lt;math&gt;p_n &lt; \tfrac{(1+\varepsilon) \ln n}{n}&lt;/math&gt;.&lt;ref name=RandGraph&gt;{{cite journal |last1=Friedgut |first1=Ehud |last2=Rödl |first2=Vojtech |last3=Rucinski |first3=Andrzej |last4=Tetali |first4=Prasad|author4-link= Prasad V. Tetali |date=January 2006 |title=A Sharp Threshold for Random Graphs with a Monochromatic Triangle in Every Edge Coloring |journal=Memoirs of the American Mathematical Society |publisher=AMS Bookstore |volume=179 |issue=845 |pages=3–4 |issn=0065-9266}}&lt;/ref&gt;

In [[number theory]] this is referred to as "[[almost all]]", as in "almost all numbers are composite". Similarly, in graph theory, this is sometimes referred to as "almost surely".&lt;ref name=Springer&gt;{{cite book |last=Spencer |first=Joel H. |title=The Strange Logic of Random Graphs |publisher=Springer |date=2001 |series=Algorithms and Combinatorics |volume=22 |isbn=978-3540416548 |chapter=0. Two Starting Examples |page=4 |url=https://books.google.com/books?id=u2c3LpjWs7EC&amp;pg=PA4 }}&lt;/ref&gt;

==See also==
{{Portal|Mathematics}}
*[[Convergence of random variables]], for "almost sure convergence"
*[[Degenerate distribution]], for "almost surely constant"
*[[Almost everywhere]], the corresponding concept in measure theory
*[[Infinite monkey theorem]], a theorem using the aforementioned terms

==Notes==
{{Reflist|30em}}

==References==
*{{cite book |last=Rogers |first=L. C. G. |last2=Williams |first2=David |title=Diffusions, Markov Processes, and Martingales |publisher=Cambridge University Press |date=2000 |volume=1: Foundations |isbn=978-0521775946}}
*{{cite book |last=Williams |first=David |title=Probability with Martingales |date=1991 |series=Cambridge Mathematical Textbooks |publisher=Cambridge University Press |isbn=978-0521406055}}

[[Category:Probability theory]]
[[Category:Mathematical terminology]]</text>
      <sha1>1cvrhmjweyd5lncxixohgpzttgeccji</sha1>
    </revision>
  </page>
  <page>
    <title>Axioms (journal)</title>
    <ns>0</ns>
    <id>420595</id>
    <revision>
      <id>863791778</id>
      <parentid>863791639</parentid>
      <timestamp>2018-10-13T02:02:27Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <minor/>
      <comment>David Eppstein moved page [[Axioms]] to [[Axioms (journal)]]: not primary topic</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1484">{{about|the academic journal|formalized mathematical assumptions|axiom}}
{{MI|
{{unreferenced|date=October 2018}}
{{notability|date=October 2018}}
}}
{{short description|mathematics journal}}
{{Infobox journal
| title = Axioms (Open Access Journal)
| discipline = [[Mathematics]]
| abbreviation = Axioms
| editor = Humberto Bustince
| publisher = [[MDPI]]
| country =
| frequency = Quarterly
| history = 2012-present
| openaccess = Yes
| impact =
| impact-year = 
| website = https://www.mdpi.com/journal/axioms
| eISSN = 2075-1680
| OCLC = 
| CODEN = 
}}
'''''Axioms''''' is a [[peer-reviewed]] [[open access]] [[scientific journal]] that focuses on all aspects of [[mathematics]], [[mathematical logic]] and [[mathematical physics]]. It was established in June 2012 and is published quarterly by [[MDPI]]. 

The [[editor-in-chief]] is Humberto Bustince ([[ Public University of Navarra]]).
==Abstracting and indexing==
The journal is abstracted and indexed in:
*[[Emerging Sources Citation Index - Web of Science (Clarivate Analytics)]]
*[[Zentralblatt MATH]]
*[[Scopus]]

== References ==
{{reflist|colwidth=30em}}

== External links ==
{{commons category|Images from Axioms}}
* {{Official website|https://www.mdpi.com/journal/axioms}}

[[Category:Mathematics journals]]
[[Category:Open access journals]]
[[Category:Publications established in 2012]]
[[Category:MDPI academic journals]]
[[Category:Quarterly journals]]
[[Category:English-language journals]]


{{math-journal-stub}}</text>
      <sha1>dca9qwlq85zvmoijvhvhez4wbohefh8</sha1>
    </revision>
  </page>
  <page>
    <title>Ax–Grothendieck theorem</title>
    <ns>0</ns>
    <id>21867395</id>
    <revision>
      <id>846494910</id>
      <parentid>814472877</parentid>
      <timestamp>2018-06-19T03:26:56Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 2 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6808">In mathematics, the '''Ax–Grothendieck theorem''' is a result about [[injectivity]] and [[surjectivity]] of [[polynomial]]s that was proved independently by [[James Ax]] and [[Alexander Grothendieck]].&lt;ref&gt;{{citation|last=Ax|first=James|authorlink=James Ax|title=The elementary theory of finite fields|journal=[[Annals of Mathematics]] |series=Second Series|volume=88|year=1968|pages=239–271|doi=10.2307/1970573|issue=2|jstor=1970573}}.&lt;/ref&gt;&lt;ref&gt;{{citation|last=Grothendieck|first=A.|authorlink=Alexander Grothendieck|title=[[Éléments de géométrie algébrique]]. IV. Étude locale des schémas et des morphismes de schémas. III. |pages= 103–104, Theorem 10.4.11|series=Inst. Hautes Études Sci. Publ. Math.|volume=28|year=1966}}.&lt;/ref&gt;&lt;ref name="Terence Tao"&gt;{{cite web |url= http://terrytao.wordpress.com/2009/03/07/infinite-fields-finite-fields-and-the-ax-grothendieck-theorem/#more-1869|title=Infinite fields, finite fields, and the Ax-Grothendieck theorem |accessdate= 2009-03-08|author=[[Terence Tao|Tao, Terence]] |date=2009-03-07|work=What's New| archiveurl= https://web.archive.org/web/20090311031630/http://terrytao.wordpress.com/2009/03/07/infinite-fields-finite-fields-and-the-ax-grothendieck-theorem/| archivedate= 11 March 2009 &lt;!--DASHBot--&gt;| deadurl= no}}&lt;/ref&gt;&lt;ref name="Serre"&gt;{{Citation | last1=Serre | first1=Jean-Pierre | author1-link=Jean-Pierre Serre | title=Arithmetic, geometry, cryptography and coding theory | arxiv=0903.0517 | publisher=Amer. Math. Soc. | location=Providence, R.I. | series=Contemp. Math. | mr=2555994 | year=2009 | volume=487 | chapter=How to use finite fields for problems concerning infinite fields | pages=183–193| bibcode=2009arXiv0903.0517S }}&lt;/ref&gt;

The theorem is often given as this special case: If ''P'' is an [[injective]] polynomial function from an ''n''-dimensional [[complex vector space]] to itself then ''P'' is [[bijective]]. That is, if ''P'' always maps distinct arguments to distinct values, then the values of ''P'' cover all of '''C'''&lt;sup&gt;''n''&lt;/sup&gt;.&lt;ref name="Terence Tao"/&gt;&lt;ref name="Serre"/&gt;

The full theorem generalizes to any [[algebraic variety]] over an [[algebraically closed field]].&lt;ref&gt;[[Éléments de géométrie algébrique]], IV&lt;sub&gt;3&lt;/sub&gt;, Proposition 10.4.11.&lt;/ref&gt;

==Proof via finite fields==
Grothendieck's proof of the theorem&lt;ref name="Terence Tao"/&gt;&lt;ref name="Serre"/&gt; is based on proving the analogous theorem for [[finite field]]s and their [[algebraic closure]]s. That is, for any field ''F'' that is itself finite or that is the closure of a finite field, if a polynomial ''P'' from ''F&lt;sup&gt;n&lt;/sup&gt;'' to itself is injective then it is bijective.

If ''F'' is a finite field, then ''F&lt;sup&gt;n&lt;/sup&gt;'' is finite. In this case the theorem is true for trivial reasons having nothing to do with the representation of the function as a polynomial: any injection of a finite set to itself is a bijection. When ''F'' is the algebraic closure of a finite field, the result follows from [[Hilbert's Nullstellensatz]]. The Ax–Grothendieck theorem for complex numbers can therefore be proven by showing that a counterexample over '''C''' would translate into a counterexample in some algebraic extension of a finite field.

This method of proof is noteworthy in that it is an example of the idea that finitistic algebraic relations in fields of [[Characteristic (algebra)|characteristic]] 0 translate into algebraic relations over finite fields with large characteristic.&lt;ref name="Terence Tao"/&gt; Thus, one can use the arithmetic of finite fields to prove a statement about '''C''' even though there is no [[homomorphism]] from any finite field to '''C'''. The proof thus uses [[model theory|model-theoretic principles]] to prove an elementary statement about polynomials. The proof for the general case uses a similar method.

==Other proofs==
There are other proofs of the theorem. [[Armand Borel]] gave a proof using topology.&lt;ref name="Serre"/&gt; The case of ''n'' = 1 and field '''C''' follows since '''C''' is algebraically closed and can also be thought of as a special case of the result that for any [[analytic function]] ''f'' on '''C''', injectivity of ''f'' implies surjectivity of ''f''. This is a corollary of [[Picard theorem|Picard's theorem]].

==Related results==
Another example of reducing theorems about [[morphism of finite type|morphisms of finite type]] to finite fields can be found in [[Éléments de géométrie algébrique|EGA IV]]: There, it is proved that a [[radicial morphism|radicial]] ''S''-endomorphism of a scheme ''X'' of finite type over ''S'' is bijective (10.4.11), and that if ''X''/''S'' is of finite presentation, and the endomorphism is a monomorphism, then it is an automorphism (17.9.6). Therefore, a scheme of finite presentation over a base ''S'' is a cohopfian object in the category of ''S''-schemes.

The Ax–Grothendieck theorem may also be used to prove the [[Garden of Eden (cellular automaton)|Garden of Eden theorem]], a result that like the Ax–Grothendieck theorem relates injectivity with surjectivity but in [[cellular automaton|cellular automata]] rather than in algebraic fields. Although direct proofs of this theorem are known, the proof via the Ax–Grothendieck theorem extends more broadly, to automata acting on [[amenable group]]s.&lt;ref&gt;{{citation|title=On algebraic cellular automata|first1=Tullio|last1=Ceccherini-Silberstein|first2=Michel|last2=Coornaert|year=2010|arxiv=1011.4759|bibcode=2010arXiv1011.4759C}}.&lt;/ref&gt;

Some partial converses to the Ax-Grothendieck Theorem:

*A generically surjective polynomial map of ''n''-dimensional affine space over a finitely generated extension of '''Z''' or '''Z'''/''p'''''Z'''[''t''] is bijective with a polynomial inverse rational over the same ring (and therefore bijective on affine space of the algebraic closure).
*A generically surjective rational map of ''n''-dimensional affine space over a Hilbertian field is generically bijective with a rational inverse defined over the same field. ("Hilbertian field" being defined here as a field for which Hilbert's Irreducibility Theorem holds, such as the rational numbers and function fields.)&lt;ref&gt;{{citation
 | last1 = McKenna | first1 = Ken
 | last2 = van den Dries | first2 = Lou
 | doi = 10.1007/BF02568417
 | issue = 1
 | journal = Manuscripta Mathematica
 | mr = 1037991
 | pages = 1–15
 | title = Surjective polynomial maps, and a remark on the Jacobian problem
 | volume = 67
 | year = 1990}}.&lt;/ref&gt;

==References==
{{reflist}}

==External links==
*{{citation|url=http://xorshammer.wordpress.com/2008/08/15/axs-theorem/|title=Ax’s Theorem: An Application of Logic to Ordinary Mathematics|first=Michael|last=O’Connor|year=2008}}.

{{DEFAULTSORT:Ax-Grothendieck theorem}}
[[Category:Theorems in algebra]]
[[Category:Model theory]]</text>
      <sha1>q5i3o49h6l7gthpa2a0d1oq5bp1802g</sha1>
    </revision>
  </page>
  <page>
    <title>Bandwidth-sharing game</title>
    <ns>0</ns>
    <id>35831726</id>
    <revision>
      <id>858377423</id>
      <parentid>858328182</parentid>
      <timestamp>2018-09-06T18:54:10Z</timestamp>
      <contributor>
        <username>Widr</username>
        <id>13975403</id>
      </contributor>
      <minor/>
      <comment>Reverted 1 edit by [[Special:Contributions/2405:8A00:A:3:0:0:0:1E|2405:8A00:A:3:0:0:0:1E]] using [[WP:STiki|STiki]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2891">{{Orphan|date=May 2012}}

&lt;!-- EDIT BELOW THIS LINE --&gt;
A '''bandwidth-sharing game''' is a type of [[resource allocation]] game designed to model the real-world allocation of [[Bandwidth (computing)|bandwidth]] to many users in a network. The game is popular in [[game theory]] because the conclusions can be applied to real-life networks. The game is described as follows:

== The game ==
* &lt;math&gt;n&lt;/math&gt; players
* each player &lt;math&gt;i&lt;/math&gt; has utility &lt;math&gt;U_i(x)&lt;/math&gt; for amount &lt;math&gt;x&lt;/math&gt; of bandwidth
* user &lt;math&gt;i&lt;/math&gt; pays &lt;math&gt;w_i&lt;/math&gt; for amount &lt;math&gt;x&lt;/math&gt; of bandwidth and receives net utility of &lt;math&gt;U_i(x)-w_i&lt;/math&gt;
* the total amount of bandwidth available is &lt;math&gt;B&lt;/math&gt;

We also use assumptions regarding &lt;math&gt;U_i(x)&lt;/math&gt;
* &lt;math&gt;U_i(x)\ge0&lt;/math&gt;
* &lt;math&gt;U_i(x)&lt;/math&gt; is increasing and concave
* &lt;math&gt;U(x)&lt;/math&gt; is continuous

The game arises from trying to find a price &lt;math&gt;p&lt;/math&gt; so that every player individually optimizes their own welfare. This implies every player must individually find &lt;math&gt;argmax_xU_i(x)-px&lt;/math&gt;. Solving for the [[maximum yields]] &lt;math&gt;U_i^'(x)=p&lt;/math&gt;.

== The problem ==
With this maximum condition, the game then becomes a matter of finding a price that satisfies an equilibrium. Such a price is called a [[market clearing price]].

== A possible solution ==

A popular idea to find the price is a method called fair sharing.&lt;ref&gt;{{Cite journal|last=Shah|first=D.|last2=Tsitsiklis|first2=J. N.|last3=Zhong|first3=Y.|date=2014|title=Qualitative properties of α-fair policies in bandwidth-sharing networks|url=https://projecteuclid.org/euclid.aoap/1389278720|journal=The Annals of Applied Probability|language=EN|volume=24|issue=1|pages=76–113|doi=10.1214/12-AAP915|issn=1050-5164|via=|arxiv=1104.2340}}&lt;/ref&gt; In this game, every player &lt;math&gt;i&lt;/math&gt; is asked for amount they are willing to pay for the given resource denoted by &lt;math&gt;w_i&lt;/math&gt;. The resource is then distributed in &lt;math&gt;x_i&lt;/math&gt; amounts by the formula &lt;math&gt;x_i=(\frac{w_i}{\sum_jw_j})*(B)&lt;/math&gt;. This method yields an effective price &lt;math&gt;p=\frac{\sum_jw_j}{B}&lt;/math&gt;.
This price can proven to be market clearing thus the distribution &lt;math&gt;x_1,...,x_n&lt;/math&gt; is optimal. The proof is as so:

== Proof ==
&lt;math&gt;argmax_{x_i}U_i(x_i)-w_i&lt;/math&gt;

&lt;math&gt;\implies argmax_{w_i}U_i(\frac{w_i}{\sum_jw_j}*B)-w_i&lt;/math&gt;&lt;br /&gt;
&lt;math&gt;\implies U^'_i(\frac{w_i}{\sum_jw_j}*B)(\frac{1}{\sum_jw_j}*B-\frac{w_i}{(\sum_jw_j)^2}*B)-1=0&lt;/math&gt;&lt;br /&gt;
&lt;math&gt;\implies U^'_i(x_i)(\frac{1}{p}-\frac{1}{p}*\frac{x_i}{B})-1=0&lt;/math&gt;&lt;br /&gt;
&lt;math&gt;\implies U^'_i(x_i)(1-\frac{x_i}{B})=p &lt;/math&gt;

Comparing this result to the equilibrium condition above, we see that when &lt;math&gt;\frac{x_i}{B}&lt;/math&gt; is very small, the two conditions equal each other and thus, the fair sharing game is almost optimal.

==References==

&lt;references /&gt;

[[Category:Game theory]]</text>
      <sha1>441b4njti3j067aeesi0tkjwc60hnrl</sha1>
    </revision>
  </page>
  <page>
    <title>Bucket evaluations</title>
    <ns>0</ns>
    <id>37165004</id>
    <revision>
      <id>777876459</id>
      <parentid>770853476</parentid>
      <timestamp>2017-04-29T21:24:06Z</timestamp>
      <contributor>
        <username>Rjwilmsi</username>
        <id>203434</id>
      </contributor>
      <minor/>
      <comment>Journal cites:, added 2 PMCs using [[Project:AWB|AWB]] (12151)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2108">{{multiple issues|
{{COI|date=August 2013}}
{{primary sources|date=August 2013}}
{{Orphan|date=August 2013}}
}}

In [[statistics]], '''bucket evaluations''' is a method for [[Correlation and dependence|correlating vectors]]. This method is a [[Non-parametric statistics|non-parametric]], [[Unsupervised learning|unsupervised]] correlation method first published in 2012 by [[Daniel Shabtai|Shabtai]] et al.&lt;ref&gt;{{cite journal|last=Shabtai|first=Daniel|author2=Guri Giaever|author3=Corey Nislow|title=An algorithm for chemical genomic profiling that minimizes batch effects: Bucket evaluations|journal=BMC Bioinformatics|date=25 September 2012|doi=10.1186/1471-2105-13-245|pmid=23009392|url=http://www.biomedcentral.com/1471-2105/13/245/abstract|volume=13|pages=245|pmc=3780717}}&lt;/ref&gt;

Bucket evaluations was initially constructed for genetic research, and was used for finding a new potential anti-cancer drug.&lt;ref&gt;{{cite journal|last=Cheung-Ong|first=Kahlin |author2=Kyung Tae Song |author3=Zhidong Ma |author4=Daniel Shabtai |author5=Anna Y. Lee |author6=David Gallo |author7=Lawrence E. Heisler |author8=Grant W. Brown |author9=Ulrich Bierbach |author10=Guri Giaever |author11=Corey Nislow |title=Comparative Chemogenomics To Examine the Mechanism of Action of DNA-Targeted Platinum-Acridine Anticancer Agents|journal=ACS Chem. Biol.|date=August 28, 2012|doi=10.1021/cb300320d|pmid=22928710|url=http://pubs.acs.org/doi/abs/10.1021/cb300320d|pages=120905082953006|volume=7|issue=11 |pmc=3500413}}&lt;/ref&gt;

Bucket evaluations is named after the technique used to compare vectors in a matrix. Values in the [[Random vector|vector]] are compared in sections (buckets). The buckets are set in a descending order, where the smallest buckets hold the highest scores, and have the strongest effect on the final correlation score. The similarity between vectors is calculated by comparing the ranks of the scores in each bucket, which are summed up to a similarity score.

== References ==
{{reflist}}

{{Statistics}}

{{DEFAULTSORT:Bucket evaluations}}
[[Category:Covariance and correlation]]


{{statistics-stub}}</text>
      <sha1>8tccjh6vfbbsxyw09ij6w7azn0xgrl7</sha1>
    </revision>
  </page>
  <page>
    <title>Cabri Geometry</title>
    <ns>0</ns>
    <id>2921396</id>
    <revision>
      <id>839999893</id>
      <parentid>748858601</parentid>
      <timestamp>2018-05-07T02:37:11Z</timestamp>
      <contributor>
        <username>Googol30</username>
        <id>16053044</id>
      </contributor>
      <minor/>
      <comment>removing unknown parameter</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2733">{{Infobox Software
|name                       = Cabri Geometry
|logo                       = 
|screenshot                 = 
|caption                    = 
|collapsible                = 
|author                     = 
|developer                  = Cabrilog
|released                   = &lt;!-- {{Start date|YYYY|MM|DD}} --&gt;
|latest release version     = 2.1.1
|latest release date        = &lt;!-- {{Release date and age|YYYY|MM|DD}} --&gt;
|latest preview version     = 
|latest preview date        = &lt;!-- {{Release date and age|YYYY|MM|DD}} --&gt;
|programming language       = 
|operating system           = [[Mac OS X]], [[Microsoft Windows|Windows]]
|platform                   = 
|size                       = 40.9 [[Megabyte|MB]]
|language                   = English, French, Spanish, Italian, German, Polish, Portuguese, Chinese, Korean, Vietnamese, Japanese, Dutch, Norwegian, Danish, Czech, Slovak, Bosnian
|status                     = 
|genre                      = [[Interactive geometry software]]
|license                    = [[Proprietary software|Proprietary]]
|website                    = {{URL|http://www.cabri.com}}
}}

'''Cabri Geometry''' is a commercial [[interactive geometry software]] produced by the French company Cabrilog for teaching and learning geometry and [[trigonometry]].&lt;ref&gt;{{citation|title=Exploring 2-Dimensional Space: Cabri Geometry II for Years 9–12|first=Jill|last=Vincent|publisher=Mathematical Association of Victoria|year=1999|isbn=9780909315931}}.&lt;/ref&gt;&lt;ref&gt;{{citation
 | last = Straesser | first = Rudolf
 | doi = 10.1023/A:1013361712895
 | issue = 3
 | journal = International Journal of Computers for Mathematical Learning
 | pages = 319–333
 | title = Cabri-géomètre: Does Dynamic Geometry Software (DGS) Change Geometry and its Teaching and Learning?
 | volume = 6
 | year = 2002}}.&lt;/ref&gt; It was designed with ease-of-use in mind.  The program allows the user to animate geometric figures, proving a significant advantage over those drawn on a blackboard. Relationships between points on a geometric object may easily be demonstrated, which can be useful in the learning process.  There are also graphing and display functions which allow exploration of the connections between geometry and algebra. The program can be run under [[Microsoft Windows|Windows]] or the [[Mac OS]].
==See also==
* [[Interactive geometry software]] – alternatives to Cabri Geometry

==References==
{{reflist}}

==External links==
*[http://www.cabri.com/ Cabri Geometry]
* Cabri belongs to the [http://inter2geo.eu Inter2Geo] European project aiming at [[interoperability]] between interactive geometry software.

[[Category:Interactive geometry software]]


{{geometry-stub}}
{{science-software-stub}}</text>
      <sha1>3b8tas8jf4rmwub4bqca3wfq5hy856g</sha1>
    </revision>
  </page>
  <page>
    <title>Casorati–Weierstrass theorem</title>
    <ns>0</ns>
    <id>33868</id>
    <revision>
      <id>871345195</id>
      <parentid>871344840</parentid>
      <timestamp>2018-11-30T12:51:17Z</timestamp>
      <contributor>
        <ip>138.232.105.11</ip>
      </contributor>
      <comment>/* Formal statement of the theorem */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8034">In [[complex analysis]], a branch of mathematics, the '''Casorati–Weierstrass theorem''' describes the behaviour of [[holomorphic function]]s near their [[essential singularity|essential singularities]]. It is named for [[Karl Theodor Wilhelm Weierstrass]] and [[Felice Casorati (mathematician)|Felice Casorati]]. In Russian literature it is called [[Yulian Sokhotski|Sokhotski's]] theorem.

==Formal statement of the theorem==
Start with some [[open set|open subset]] &lt;math&gt;U&lt;/math&gt; in the [[complex number|complex plane]] containing the number &lt;math&gt;z_0&lt;/math&gt;, and a function &lt;math&gt;f&lt;/math&gt; that is [[holomorphic function|holomorphic]] on &lt;math&gt;U\ \backslash\ \{z_0\}&lt;/math&gt;, but has an [[essential singularity]] at &lt;math&gt;z_0&lt;/math&gt;&amp;nbsp;. The ''Casorati–Weierstrass theorem'' then states that 
:if &lt;math&gt;V&lt;/math&gt; is any [[Neighbourhood (mathematics)|neighbourhood]] of &lt;math&gt;z_0&lt;/math&gt; contained in &lt;math&gt;U&lt;/math&gt;, then &lt;math&gt;f(V\ \backslash\ \{z_0\})&lt;/math&gt; is [[dense set|dense]] in &lt;math&gt;\mathbb{C}&lt;/math&gt;.

This can also be stated as follows: 
:for any &lt;math&gt;\varepsilon &gt; 0, \delta &gt;0&lt;/math&gt;, and complex number &lt;math&gt;w&lt;/math&gt;, there exists a complex number &lt;math&gt;z&lt;/math&gt; in &lt;math&gt;U&lt;/math&gt; with &lt;math&gt;|z-z_0|&lt;\delta&lt;/math&gt; and &lt;math&gt;|f(z)-w|&lt;\varepsilon&lt;/math&gt;&amp;nbsp;.

Or in still more descriptive terms:
:&lt;math&gt;f&lt;/math&gt; comes arbitrarily close to ''any'' complex value in every neighbourhood of &lt;math&gt;z_0&lt;/math&gt;.

The theorem is considerably strengthened by [[Picard's great theorem]], which states, in the notation above, that &lt;math&gt;f&lt;/math&gt; assumes ''every'' complex value, with one possible exception, infinitely often on &lt;math&gt;V&lt;/math&gt;.

In the case that &lt;math&gt;f&lt;/math&gt; is an [[entire function]] and &lt;math&gt;a=\infty&lt;/math&gt;, the theorem says that the values &lt;math&gt;f(z)&lt;/math&gt;
approach every complex number and &lt;math&gt;\infty&lt;/math&gt;, as &lt;math&gt;z&lt;/math&gt; tends to infinity.
It is remarkable that this does not hold for  [[holomorphic map]]s in higher dimensions,
as the famous example of [[Pierre Fatou]] shows.&lt;ref&gt;{{cite news|first=P.|last=Fatou|title=Sur les fonctions meromorphes de deux variables|journal=Comptes rendus|volume=175|year=1922|pages=862,1030.}}&lt;/ref&gt;

[[Image:Essential singularity.png|right|220px|thumb|Plot of the function exp(1/''z''), centered on the essential singularity at ''z''&amp;nbsp;=&amp;nbsp;0. The hue represents the complex argument, the luminance represents the absolute value. This plot shows how approaching the essential singularity from different directions yields different behaviors (as opposed to a pole, which would be uniformly white).]]

==Examples==
The function ''f''(''z'') = [[exponential function|exp]](1/''z'') has an essential singularity at 0, but the function ''g''(''z'') = 1/''z''&lt;sup&gt;3&lt;/sup&gt; does not (it has a [[pole (complex analysis)|pole]] at 0).

Consider the function

: &lt;math&gt;f(z)=e^{1/z}.&lt;/math&gt;

This function has the following [[Taylor series]] about the [[essential singularity|essential singular point]] at 0:

: &lt;math&gt;f(z)=\displaystyle\sum_{n=0}^{\infty}\frac{1}{n!}z^{-n}.&lt;/math&gt;

Because &lt;math&gt;f'(z) =\frac{-e^{\frac{1}{z}}}{z^{2}}&lt;/math&gt; exists for all points ''z''&amp;nbsp;≠&amp;nbsp;0 we know that ''ƒ''(''z'') is analytic in a [[punctured neighborhood]] of ''z''&amp;nbsp;=&amp;nbsp;0. Hence it is an [[isolated singularity]], as well as being an [[essential singularity]]. &lt;!-- (a pole that is a cluster point of poles is essential, hence false remark:) like all other essential singularities. --&gt;

Using a change of variable to [[polar coordinates]] &lt;math&gt;z=re^{i \theta }&lt;/math&gt; our function, ''ƒ''(''z'')&amp;nbsp;=&amp;nbsp;''e''&lt;sup&gt;1/''z''&lt;/sup&gt; becomes:

: &lt;math&gt;f(z)=e^{\frac{1}{r}e^{-i\theta}}=e^{\frac{1}{r}\cos(\theta)}e^{-\frac{1}{r}i \sin(\theta)}.&lt;/math&gt;

Taking the [[absolute value]] of both sides:

: &lt;math&gt;\left| f(z) \right| = \left| e^{\frac{1}{r}\cos \theta} \right| \left| e^{-\frac{1}{r}i \sin(\theta)} \right | =e^{\frac{1}{r}\cos \theta}.&lt;/math&gt;

Thus, for values of ''θ'' such that cos&amp;nbsp;''θ''&amp;nbsp;&gt;&amp;nbsp;0, we have &lt;math&gt;f(z)\rightarrow\infty&lt;/math&gt; as &lt;math&gt;r \rightarrow 0&lt;/math&gt;, and for &lt;math&gt;\cos \theta &lt;0&lt;/math&gt;, &lt;math&gt;f(z) \rightarrow 0&lt;/math&gt; as &lt;math&gt;r \rightarrow 0&lt;/math&gt;.

Consider what happens, for example when ''z'' takes values on a circle of diameter 1/''R'' tangent to the imaginary axis. This circle is given by ''r''&amp;nbsp;=&amp;nbsp;(1/''R'')&amp;nbsp;cos&amp;nbsp;''θ''. Then,

: &lt;math&gt;f(z) = e^{R} \left[ \cos \left( R\tan \theta \right) - i \sin \left( R\tan \theta \right) \right] &lt;/math&gt;

and

: &lt;math&gt;\left| f(z) \right| = e^R.&lt;/math&gt;

Thus,&lt;math&gt;\left| f(z) \right|&lt;/math&gt; may take any positive value other than zero by the appropriate choice of ''R''. As &lt;math&gt;z \rightarrow 0&lt;/math&gt; on the circle, &lt;math&gt; \theta \rightarrow \frac{\pi}{2}&lt;/math&gt; with ''R'' fixed. So this part of the equation:

: &lt;math&gt;\left[ \cos \left( R \tan \theta \right) - i \sin \left( R \tan \theta \right) \right] &lt;/math&gt;

takes on all values on the [[unit circle]] infinitely often. Hence ''f''(''z'') takes on the value of every number in the [[complex plane]] except for zero infinitely often.

==Proof of the theorem==
A short proof of the theorem is as follows:

Take as given that function ''f'' is [[meromorphic function|meromorphic]] on some punctured neighborhood ''V''&amp;nbsp;\&amp;nbsp;{''z''&lt;sub&gt;0&lt;/sub&gt;}, and that ''z''&lt;sub&gt;0&lt;/sub&gt; is an essential singularity. Assume by way of contradiction that some value ''b'' exists that the function can never get close to; that is: assume that there is some complex value ''b'' and some ε&amp;nbsp;&gt;&amp;nbsp;0 such that |''f''(''z'') &amp;minus; ''b''| ≥ ε for all ''z'' in ''V'' at which ''f'' is defined.

Then the new function:

:&lt;math&gt;g(z) = \frac{1}{f(z) - b}&lt;/math&gt;

must be holomorphic on ''V''&amp;nbsp;\&amp;nbsp;{''z''&lt;sub&gt;0&lt;/sub&gt;}, with [[Zero (complex analysis)|zeroes]] at the [[Pole (complex analysis)|poles]] of ''f'', and bounded by 1/ε. It can therefore be analytically continued (or continuously extended, or holomorphically extended) to ''all'' of ''V'' by [[Removable singularity#Riemann's theorem|Riemann's analytic continuation theorem]]. So the original function can be expressed in terms of ''g'':

:&lt;math&gt;f(z) = \frac{1}{g(z)} + b&lt;/math&gt;

for all arguments ''z'' in ''V''&amp;nbsp;\&amp;nbsp;{''z''&lt;sub&gt;0&lt;/sub&gt;}. Consider the two possible cases for

:&lt;math&gt;\lim_{z \to z_0} g(z).&lt;/math&gt;

If the limit is 0, then ''f'' has a [[Pole (complex analysis)|pole]] at ''z''&lt;sub&gt;0&lt;/sub&gt;&amp;nbsp;. If the limit is not 0, then ''z''&lt;sub&gt;0&lt;/sub&gt; is a [[removable singularity]] of ''f''&amp;nbsp;. Both possibilities contradict the assumption that the point ''z''&lt;sub&gt;0&lt;/sub&gt; is an [[essential singularity]] of the function ''f''&amp;nbsp;. Hence the assumption is false and the theorem holds.

==History==
The history of this important theorem is described by
[[Edward Collingwood|Collingwood]] and [[Arthur J. Lohwater|Lohwater]].&lt;ref name="CV"&gt;{{cite book|first1=E|last1=Collingwood|first2=A |last2=Lohwater|title=The theory of cluster sets|
publisher=[[Cambridge University Press]]|year=1966}}&lt;/ref&gt;
It was published by Weierstrass in 1876 (in German) and by Sokhotski in 1868 in his Master thesis (in Russian).
So it was called Sokhotski's theorem in the Russian literature and Weierstrass's theorem in
the Western literature. 
The same theorem was published by Casorati in 1868, and
by Briot and Bouquet in the ''first edition'' of their book (1859).&lt;ref name="BB"&gt;{{cite book|first1=Ch|last1= Briot|
first2=C|last2=Bouquet|
title=Theorie des fonctions doublement periodiques, et en particulier, des fonctions elliptiques|place=Paris|year=1859}}&lt;/ref&gt;
However, Briot and Bouquet ''removed'' this theorem from the second edition (1875).

==References==
&lt;references /&gt;

* Section 31, Theorem 2 (pp.&amp;nbsp;124–125) of {{Citation
| last=Knopp
| first=Konrad
| author-link=Konrad Knopp
| title=Theory of Functions
| publisher=[[Dover Publications]]
| year=1996
| isbn=978-0-486-69219-7
}}

{{DEFAULTSORT:Casorati-Weierstrass theorem}}
[[Category:Theorems in complex analysis]]
[[Category:Articles containing proofs]]</text>
      <sha1>5di7rzcgkc85rwy38ap0bt1bozrvhuy</sha1>
    </revision>
  </page>
  <page>
    <title>Center manifold</title>
    <ns>0</ns>
    <id>3948656</id>
    <revision>
      <id>851627982</id>
      <parentid>851625750</parentid>
      <timestamp>2018-07-23T15:22:23Z</timestamp>
      <contributor>
        <username>SaFroeli</username>
        <id>19163914</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13199">[[Image:Saddle-node phase portrait with central manifold.svg|thumb|300px|right|Center (red) and unstable (green) invariant manifolds of [[saddle-node]] equilibrium point of the system &lt;math&gt; \dot x=x^2,&lt;/math&gt; &lt;math&gt;\dot y=y&lt;/math&gt;.]]

In mathematics, the '''center manifold''' of an [[equilibrium point]] of a [[dynamical system]] consists of [[Orbit (dynamics)|orbits]] whose behavior around the equilibrium point is not controlled by either the attraction of the [[stable manifold]] or the repulsion of the [[unstable manifold]]. The first step when studying equilibrium points of dynamical systems is to linearize the system. The [[eigenvectors]] corresponding to [[Eigenvalues and eigenvectors|eigenvalues]] with negative real part form the stable [[eigenspace]], which gives rise to the stable manifold.  Similarly, eigenvalues with positive real part yield the unstable manifold.

This concludes the story if the equilibrium point is [[hyperbolic equilibrium point|hyperbolic]] (i.e., all eigenvalues of the linearization have nonzero real part). However, if there are eigenvalues whose real part is zero, then these give rise to the center manifold.  If the eigenvalues are precisely zero, rather than just real part being zero, then these more specifically give rise to a [[slow manifold]]. The behavior on the center (slow) manifold is generally not determined by the linearization and thus is more difficult to study.

Center manifolds play an important role in: [[bifurcation theory]] because  interesting behavior takes place on the center manifold; and [[multiscale mathematics]] because the long time dynamics often are attracted to a relatively simple center manifold.

== Definition ==

Let &lt;math&gt;\frac{d\textbf{x}}{dt} = \textbf{f}(\textbf{x})&lt;/math&gt; be a [[dynamical system]] with [[equilibrium point]] &lt;math&gt;\textbf{x}^*&lt;/math&gt;. The linearization of the system near the equilibrium point is

:&lt;math&gt;\frac{d\textbf{x}}{dt} = A\textbf{x}, \quad \text{where } A = \frac{d\textbf{f}}{d\textbf{x}}(\textbf{x}^*). &lt;/math&gt;

The [[Jacobian matrix and determinant|Jacobian matrix]] &lt;math&gt;A&lt;/math&gt; defines three main subspaces:
* the stable subspace, which is spanned by the [[generalized eigenvector]]s corresponding to the eigenvalues &lt;math&gt;\lambda&lt;/math&gt; with &lt;math&gt;\operatorname{Re}\lambda&lt;0&lt;/math&gt;;
* the unstable subspace, which is spanned by the generalized eigenvectors corresponding to the eigenvalues &lt;math&gt;\lambda&lt;/math&gt; with &lt;math&gt;\operatorname{Re}\lambda&gt;0&lt;/math&gt;;
* the center subspace, which is spanned by the generalized eigenvectors corresponding to the eigenvalues &lt;math&gt;\lambda&lt;/math&gt; with &lt;math&gt;\operatorname{Re}\lambda=0&lt;/math&gt;.
Depending upon the application, other subspaces of interest include  center-stable, center-unstable, sub-center, slow, and fast subspaces.
These subspaces are all [[invariant subspace]]s of the linearized equation.

Corresponding to the linearized system, the nonlinear system has [[invariant manifold]]s, each consisting of sets of orbits of the nonlinear system.&lt;ref&gt;{{harvtxt|Guckenheimer|Holmes|1997}}, Section 3.2&lt;/ref&gt;
* An invariant manifold tangent to the stable subspace and with the same dimension is the [[stable manifold]]. 
* The unstable manifold is of the same dimension and tangent to the unstable subspace. 
* A center manifold is of the same dimension and tangent to the center subspace.  If, as is common, the eigenvalues of the center subspace are all precisely zero, rather than just real part zero, then a center manifold is often called a [[slow manifold]].

== Center manifold theorems ==

The center manifold existence theorem states that if the right-hand side function &lt;math&gt;\textbf{f}(\textbf{x})&lt;/math&gt; is &lt;math&gt;C^r&lt;/math&gt; (&lt;math&gt;r&lt;/math&gt; times continuously differentiable), then at every equilibrium point there exists a neighborhood of some finite size in which there is at least one of &lt;ref&gt;{{harvtxt|Guckenheimer|Holmes|1997}}, Theorem 3.2.1&lt;/ref&gt;
* a unique &lt;math&gt;C^r&lt;/math&gt; '''stable''' manifold,
* a unique &lt;math&gt;C^r&lt;/math&gt; '''unstable''' manifold, 
* and a (not necessarily unique) &lt;math&gt;C^{r-1}&lt;/math&gt; '''center''' manifold.

In example applications, a nonlinear coordinate transform to a [[normal form (bifurcation theory)|normal form]] can clearly separate these three manifolds.&lt;ref&gt;{{Cite book | last1=Murdock | first1=James | title=Normal forms and unfoldings for local dynamical systems | publisher=[[Springer-Verlag]] | year=2003 }}&lt;/ref&gt; A web service [http://www.maths.adelaide.edu.au/anthony.roberts/sdenf.php] currently undertakes the necessary computer algebra for a range of finite-dimensional systems.

In the case when the unstable manifold does not exist, center manifolds are often relevant to modelling.
The center manifold emergence theorem then says that the neighborhood may be chosen so that all solutions of the system staying in the neighborhood tend exponentially quickly to some solution &lt;math&gt;\textbf{y}(t)&lt;/math&gt; on the center manifold.
That is, 
&lt;math&gt;\textbf{x}(t)=\textbf{y}(t)+\mathcal{O}(e^{-\beta' t}) \quad\text{as } 
    t\to\infty\,,&lt;/math&gt;
for some rate &lt;math&gt;\beta'&lt;/math&gt;.&lt;ref&gt;{{cite book|author1=Iooss, G.  |author2=Adelmeyer, M.|title = Topics in Bifurcation Theory|pages=7|year = 1992}}&lt;/ref&gt;
This theorem asserts that for a wide variety of initial conditions the solutions of the full system decay exponentially quickly to a solution on the relatively low dimensional center manifold.

A third theorem, the approximation theorem, asserts that if an approximate expression for such invariant manifolds, say &lt;math&gt;\textbf{x}=\textbf{X}(\textbf{s})&lt;/math&gt;, satisfies the differential equation for the system to residuals &lt;math&gt;\mathcal{O}(|\textbf{s}|^p)&lt;/math&gt; as &lt;math&gt;\textbf{s}\to\textbf{0}&lt;/math&gt;, then the invariant manifold is approximated by &lt;math&gt;\textbf{x}=\textbf{X}(\textbf{s})&lt;/math&gt; to an error of the same order, namely &lt;math&gt;\mathcal{O}(|\textbf{s}|^p)&lt;/math&gt;.

However, some applications, such as to shear dispersion, require an infinite-dimensional center manifold.&lt;ref&gt;{{cite journal |first=A. J. |last=Roberts |journal=J. Austral. Math. Soc. |series=B |pages=480–500 |title = The application of centre manifold theory to the evolution of systems which vary slowly in space |volume = 29 |year = 1988 |doi=10.1017/S0334270000005968 }}&lt;/ref&gt; The most general and powerful theory was developed by Aulbach and Wanner.&lt;ref&gt;{{cite book |last=Aulbach |first=B. |last2=Wanner |first2=T. |year=1996 |chapter=Integral manifolds for Caratheodory type differential equations in Banach spaces |editor-first=B. |editor-last=Aulbach |editor2-first=F. |editor2-last=Colonius |title=Six Lectures on Dynamical Systems |publisher=World Scientific |location=Singapore |pages=45–119 }}&lt;/ref&gt;&lt;ref&gt;{{cite book |last=Aulbach |first=B. |last2=Wanner |first2=T. |year=1999 |chapter=Invariant foliations for Caratheodory type differential equations in Banach spaces |editor-first=V. |editor-last=Lakshmikantham |editor2-first=A. A. |editor2-last=Martynyuk |title=Advances of Stability Theory at the End of XX Century |publisher=Gordon &amp; Breach }}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last=Aulbach |first=B. |last2=Wanner |first2=T. |year=2000 |title=The Hartman–Grobman theorem for Caratheodory-type differential equations in Banach spaces |journal=Nonlinear Analysis |volume=40 |issue= |pages=91–104 |doi=10.1016/S0362-546X(00)85006-3 }}&lt;/ref&gt; They addressed non-autonomous dynamical systems &lt;math&gt;\frac{d\textbf{x}}{dt} = \textbf{f}(\textbf{x},t)&lt;/math&gt; in infinite dimensions, with potentially infinite dimensional stable, unstable and center manifolds. Further, they usefully generalised the definition of the manifolds so that the center manifold is associated with eigenvalues such that &lt;math&gt;|\operatorname{Re}\lambda|\leq\alpha&lt;/math&gt;, the stable manifold with eigenvalues &lt;math&gt;\operatorname{Re}\lambda\leq-\beta&lt;-r\alpha&lt;/math&gt;, and unstable manifold with eigenvalues  &lt;math&gt;\operatorname{Re}\lambda\geq\beta&gt;r\alpha&lt;/math&gt;. They proved existence of these manifolds, and the emergence of a center manifold, via nonlinear coordinate transforms. Potzsche and Rasmussen established a corresponding approximation theorem for such infinite dimensional, non-autonomous systems.&lt;ref&gt;{{cite journal |last=Potzsche |first=C. |last2=Rasmussen |first2=M. |year=2006 |title=Taylor approximation of integral manifolds |journal=Journal of Dynamics and Differential Equations |volume=18 |issue= |pages=427–460 |doi=10.1007/s10884-006-9011-8 |bibcode = 2006JDDE...18..427P }}&lt;/ref&gt;

==Center manifold and the analysis of nonlinear systems==
As the stability of the equilibrium correlates with the "stability" of its manifolds, the existence of a center manifold brings up the question about the dynamics on the center manifold. This is analyzed by the [[center manifold reduction]], which, in combination with some system parameter μ, leads to the concepts of [[Bifurcation theory|bifurcations]].

Correspondingly, two web services currently undertake the necessary computer algebra to construct just the center manifold for a wide range of finite-dimensional systems (provided they are in multinomial form).  
* One web service [http://www.maths.adelaide.edu.au/anthony.roberts/sdesm.php] constructs [[slow manifold]]s for systems which are linearly diagonalised, but which may be non-autonomous or stochastic.&lt;ref&gt;{{cite journal|author = A.J. Roberts|journal = Physica A|pages = 12–38|title = Normal form transforms separate slow and fast modes in stochastic dynamical systems|volume = 387|year = 2008|doi=10.1016/j.physa.2007.08.023|arxiv = math/0701623 |bibcode = 2008PhyA..387...12R }}&lt;/ref&gt;
* Another web service [http://www.maths.adelaide.edu.au/anthony.roberts/gencm.php] constructs center manifolds for systems with general linearisation, but only for autonomous systems.&lt;ref&gt;{{cite journal|author = A.J. Roberts|journal = Computer Phys. Comm. |pages = 215–230|title = Low-dimensional modelling of dynamics via computer algebra|volume = 100|year = 1997|doi=10.1016/S0010-4655(96)00162-2|bibcode = 1997CoPhC.100..215R |arxiv = chao-dyn/9604012}}&lt;/ref&gt;

== Examples ==
The Wikipedia entry on [[slow manifold]]s gives more examples.

===A simple example===
Consider the system
: &lt;math&gt; \dot x=x^2,\quad \dot y=y.&lt;/math&gt;
The unstable manifold at the origin is the ''y'' axis, and the stable manifold is the trivial set {(0,&amp;nbsp;0)}. Any orbit not on the stable manifold satisfies an equation on the form &lt;math&gt;y=Ae^{-1/x}&lt;/math&gt; for some real constant ''A''. It follows that for any real ''A'', we can create a center manifold by piecing together the curve &lt;math&gt;y=Ae^{-1/x}&lt;/math&gt; for ''x''&amp;nbsp;&gt;&amp;nbsp;0 with the negative ''x'' axis (including the origin). Moreover, all center manifolds have this potential non-uniqueness, although often the non-uniqueness only occurs in unphysical complex values of the variables.

===Delay differential equations often have Hopf bifurcations===
Another example shows how a center manifold
models the [[Hopf bifurcation]] that occurs
for parameter &lt;math&gt;a\approx 4&lt;/math&gt; in the
[[delay differential equation]]
&lt;math&gt;{dx}/{dt}=-ax(t-1)-2x^2-x^3&lt;/math&gt;.  
Strictly, the delay makes this DE infinite-dimensional.

Fortunately, we may approximate such delays by the following trick that keeps the dimensionality finite.
Define &lt;math&gt;u_1(t)=x(t)&lt;/math&gt;
and approximate the time delayed variable, 
&lt;math&gt;x(t-1)\approx u_3(t)&lt;/math&gt;, by using the intermediaries
&lt;math&gt;{du_2}/{dt}=2(u_1-u_2)&lt;/math&gt; and
&lt;math&gt;{du_3}/{dt}=2(u_2-u_3)&lt;/math&gt;.

For parameter near
critical, &lt;math&gt;a=4+\alpha&lt;/math&gt;, the [[delay differential equation]] is then approximated by the system
:&lt;math&gt; \frac{d\textbf{u}}{dt} =\left[\begin{array}{ccc} 0&amp;0&amp;-4\\
2&amp;-2&amp;0\\ 0&amp;2&amp;-2 \end{array}\right] \textbf{u} +
\left[\begin{array}{c}-\alpha u_3-2u_1^2-u_1^3\\ 0\\
0\end{array}\right]. &lt;/math&gt;
Copying and pasting the appropriate entries, 
the web service [http://www.maths.adelaide.edu.au/anthony.roberts/gencm.php] finds that in terms of a [[complex amplitude]] &lt;math&gt;s(t)&lt;/math&gt; 
and its complex conjugate &lt;math&gt;\bar s(t)&lt;/math&gt;, the center manifold
:&lt;math&gt; \textbf{u}=\left[\begin{array}{c} e^{i2t}s+e^{-i2t}\bar s\\
 \frac{1-i}2e^{i2t}s +\frac{1+i}2e^{-i2t}\bar s\\
 -\frac{i}2e^{i2t}s +\frac{i}2e^{-i2t}\bar s 
\end{array}\right]
+{O}(\alpha+|s|^2) &lt;/math&gt;
and the evolution on the center manifold is
:&lt;math&gt;  \frac{ds}{dt}= \left[
\frac{1+2i}{10}\alpha s
-\frac{3+16i}{15}|s|^2s 
\right] +{ O}(\alpha^2+|s|^4)&lt;/math&gt;
This evolution shows the origin is linearly unstable for &lt;math&gt;\alpha&gt;0\ (a&gt;4)&lt;/math&gt;, but the cubic nonlinearity then stabilises nearby limit cycles as in classic [[Hopf bifurcation]].

== Notes ==
&lt;references/&gt;

== References ==
* {{Citation | last1=Guckenheimer | first1=John | last2=Holmes | first2=Philip | author2-link=Philip Holmes | title=Nonlinear Oscillations, Dynamical Systems, and Bifurcations of Vector Fields | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Applied Mathematical Sciences | isbn=978-0-387-90819-9 | id=corrected fifth printing | year=1997 | volume=42}}.

== External links ==
* {{scholarpedia|title=Center manifold|urlname=center_manifold|curator=Jack Carr}}

[[Category:Dynamical systems]]</text>
      <sha1>g6g09vq3h1g8y9wlkz1rvc7ejn42x0b</sha1>
    </revision>
  </page>
  <page>
    <title>Characterization of probability distributions</title>
    <ns>0</ns>
    <id>53165511</id>
    <revision>
      <id>868848183</id>
      <parentid>863655328</parentid>
      <timestamp>2018-11-14T20:58:51Z</timestamp>
      <contributor>
        <username>Texvc2LaTeXBot</username>
        <id>33995001</id>
      </contributor>
      <minor/>
      <comment>Replacing deprecated latex syntax [[mw:Extension:Math/Roadmap]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7112">In mathematics in general, a [[characterization theorem]] says that a particular object – a function, a space, etc. – is the only one that possesses properties specified in the theorem. A '''characterization of a probability distribution''' accordingly states that it is the only [[probability distribution]] that satisfies specified conditions. More precisely, the model of characterization of
probability distribution was described by [https://ru.wikipedia.org/wiki/%D0%97%D0%BE%D0%BB%D0%BE%D1%82%D0%B0%D1%80%D1%91%D0%B2,_%D0%92%D0%BB%D0%B0%D0%B4%D0%B8%D0%BC%D0%B8%D1%80_%D0%9C%D0%B8%D1%85%D0%B0%D0%B9%D0%BB%D0%BE%D0%B2%D0%B8%D1%87 V.M. Zolotarev] &lt;ref&gt;[https://www.researchgate.net/publication/231029496 V.M. Zolotarev (1976). Metric distances in spaces of random variables and their distributions. Matem. Sb., 101 (143), 3 (11)(1976)]&lt;/ref&gt; in such manner. On the probability space we define the space &lt;math&gt; \mathcal{X}=\{ X \} &lt;/math&gt; of random variables with values in measurable metric space &lt;math&gt;(U,d_{u})&lt;/math&gt; and the space &lt;math&gt; \mathcal{Y}=\{ Y \} &lt;/math&gt; of random variables with values in measurable metric space &lt;math&gt;(V,d_{v})&lt;/math&gt;. By characterizations of probability distributions we understand general problems of description of some set &lt;math&gt; \mathcal{C}&lt;/math&gt; in the space &lt;math&gt; \mathcal{X}&lt;/math&gt; by extracting the sets &lt;math&gt; \mathcal{A} \subseteq \mathcal{X} &lt;/math&gt; and &lt;math&gt; \mathcal{B} \subseteq \mathcal{Y} &lt;/math&gt; which describe the properties of random variables &lt;math&gt; X \in\mathcal{A}&lt;/math&gt; and their images &lt;math&gt; Y=\mathbf{F}X \in \mathcal{B} &lt;/math&gt;, obtained by means of a specially chosen mapping &lt;math&gt; \mathbf{F}:\mathcal{X} \to \mathcal{Y} &lt;/math&gt;.
&lt;br&gt;The description of the properties of the random variables &lt;math&gt;X&lt;/math&gt; and of their images &lt;math&gt; Y=\mathbf{F}X &lt;/math&gt; is equivalent to the indication of the set &lt;math&gt; \mathcal{A} \subseteq \mathcal{X} &lt;/math&gt; from which  &lt;math&gt;X&lt;/math&gt;  must be taken and of the set &lt;math&gt; \mathcal{B} \subseteq \mathcal{Y} &lt;/math&gt; into which its image must fall. So, the set which interests us appears therefore in the following form:
:&lt;math&gt;
X\in\mathcal{A},   \mathbf{F} X \in \mathcal{B} \Leftrightarrow X \in \mathcal{C}, i.e. \mathcal{C} = \mathbf{F}^{-1} \mathcal{B},
&lt;/math&gt;

where &lt;math&gt; \mathbf{F}^{-1} \mathcal{B}&lt;/math&gt; denotes the complete inverse image of &lt;math&gt; \mathcal{B}&lt;/math&gt; in &lt;math&gt; \mathcal{A}&lt;/math&gt;. This is the general model of characterization of probability distribution. Some examples of characterization theorems:

* The assumption that two linear (or non-linear) statistics are identically distributed (or independent, or have a constancy regression and so on) can be used to characterize various populations.&lt;ref name=populations&gt;A. M. Kagan, Yu. V. Linnik and C. Radhakrishna Rao (1973). [https://www.researchgate.net/publication/44720749_Characterization_problems_in_mathematical_statistics_by_A_M_Kagan_Yu_V_Linnik_and_C_Radhakrishna_Raotranslated_from_Russian_text_by_B_Ramachandran Characterization Problems in Mathematical Statistics]. John Wiley and Sons, New York, XII+499 pages.&lt;/ref&gt; For example, according to [[George Pólya|George Pólya's]] &lt;ref&gt;[[George Pólya|Pólya, Georg (1923).]][http://eudml.org/doc/167748 "Herleitung des Gaußschen Fehlergesetzes ans einer Funktionalgleichung".] Mathematische Zeitschrift. 18: 96–108. {{ISSN|0025-5874}}; 1432–1823.&lt;/ref&gt; characterization theorem, if &lt;math&gt;X_1&lt;/math&gt; and &lt;math&gt;X_2&lt;/math&gt; are [[independence (probability theory)|independent]] [[identically distributed]] [[random variable]]s with finite [[variance]], then the statistics &lt;math&gt; S_1 = X_1 &lt;/math&gt; and &lt;math&gt;  S_2 = \cfrac{X_1 + X_2}{\sqrt{2}}&lt;/math&gt; are identically distributed if and only if &lt;math&gt; X_1 &lt;/math&gt; and &lt;math&gt; X_2 &lt;/math&gt; have a &lt;u&gt;normal distribution&lt;/u&gt; with zero mean. In this case 
::&lt;math&gt;
\mathbf{F} = \begin{bmatrix}
1 &amp; 0  \\
1/\sqrt{2} &amp; 1/\sqrt{2}
\end{bmatrix}
&lt;/math&gt;,
:&lt;math&gt; \mathcal{A}&lt;/math&gt; is a set of random two-dimensional column-vectors with independent identically distributed components, &lt;math&gt; \mathcal{B}&lt;/math&gt; is a set of random two-dimensional column-vectors with identically distributed components and &lt;math&gt; \mathcal{C}&lt;/math&gt; is a set of two-dimensional column-vectors with independent identically distributed normal components.
* According to generalized [[George Pólya|George Pólya's]] characterization theorem (without condition on finiteness of variance &lt;ref name=populations/&gt;) if &lt;math&gt;X_1 , X_2 , \dots, X_n&lt;/math&gt; are non-degenerate independent identically distributed random variables, statistics &lt;math&gt;X_1&lt;/math&gt; and &lt;math&gt; a_1X_1 + a_2X_2 + \dots + a_nX_n&lt;/math&gt; are identically distributed and &lt;math&gt;\left | a_j \right \vert &lt; 1, a_1^2 + a_2^2 + \dots + a_n^2 = 1 &lt;/math&gt;, then &lt;math&gt; X_j &lt;/math&gt; is normal random variable for any &lt;math&gt; j, j=1,2, \dots, n &lt;/math&gt;. In this case
::&lt;math&gt;
\mathbf{F} = \begin{bmatrix}
1 &amp; 0 &amp; \dots &amp; 0\\
a_1 &amp; a_2 &amp; \dots &amp; a_n
\end{bmatrix}
&lt;/math&gt;,

:&lt;math&gt; \mathcal{A}&lt;/math&gt; is a set of random ''n''-dimensional column-vectors with independent identically distributed components,  &lt;math&gt; \mathcal{B}&lt;/math&gt; is a set of random two-dimensional column-vectors with identically distributed components and &lt;math&gt; \mathcal{C}&lt;/math&gt; is a set of ''n''-dimensional column-vectors with independent identically distributed normal components.&lt;ref&gt;[[Romanas Januškevičius|R. Yanushkevichius.]][https://www.academia.edu/24648381/R.Yanushkevichius._Stability_characterizations_of_distributions._1  Stability for characterizations of distributions.] Vilnius, Mokslas, 1991.&lt;/ref&gt;
* All probability distributions on the half-line &lt;math&gt;\left [ 0, \infty \right )&lt;/math&gt; that are [[memorylessness|memoryless]] are [[exponential distribution]]s. "Memoryless" means that if &lt;math&gt;X&lt;/math&gt; is a random variable with such a distribution, then for any numbers &lt;math&gt; 0 &lt; y &lt; x &lt;/math&gt; ,
:: &lt;math&gt; \Pr(X &gt; x\mid X&gt;y) = \Pr(X&gt;x-y) &lt;/math&gt;.
&lt;br&gt;
Verification of conditions of characterization theorems in practice is possible only with some error &lt;math&gt;\epsilon &lt;/math&gt;, i.e., only to a certain degree of accuracy.&lt;ref&gt;[[Romanas Januškevičius|R. Yanushkevichius.]][https://www.academia.edu/24648382/R.Yanushkevichius._Stability_characterizations_of_distributions._2 Stability characterizations of some probability distributions.] Saarbrücken, LAP LAMBERT Academic Publishing, 2014.&lt;/ref&gt; Such a situation is observed, for instance, in the cases where a sample of finite size is considered. That is why there arises the following natural question. Suppose that the conditions of the characterization theorem are fulfilled not exactly but only approximately. May we assert that the conclusion of the theorem is also fulfilled approximately? The theorems in which the problems of this kind are considered are called stability characterizations of probability distributions.

== See also ==

* [[Characterization (mathematics)]]

== References ==
{{reflist}}

[[Category:Probability theorems]]
[[Category:Statistical theorems]]
[[Category:Characterization of probability distributions]]</text>
      <sha1>1sxbtzgqj3nejw0fjm57frbzvg6tslh</sha1>
    </revision>
  </page>
  <page>
    <title>Common Algebraic Specification Language</title>
    <ns>0</ns>
    <id>2156387</id>
    <revision>
      <id>796283881</id>
      <parentid>767704199</parentid>
      <timestamp>2017-08-19T19:31:01Z</timestamp>
      <contributor>
        <username>Piotr433</username>
        <id>2896094</id>
      </contributor>
      <comment>removed the list of calculators, because they support an unrelated [[ja:CASL]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1991">{{Confuse|Compact Application Solution Language}}
The '''Common Algebraic Specification Language''' ('''CASL''') is a general-purpose [[specification language]] based on [[first-order logic]] with [[Mathematical induction|induction]]. [[Partial function]]s and [[subtype|subsorting]] are also supported.

CASL has been designed by CoFI, the [[Common Framework Initiative]], with the aim to [[Subsumption architecture|subsume]] many existing specification languages.

CASL comprises four levels:
* basic specifications, for the specification of single software modules,
* structured specifications, for the modular specification of modules,
* architectural specifications, for the prescription of the structure of [[implementation]]s,
* specification libraries, for storing specifications distributed over the [[Internet]].

The four levels are orthogonal to each other. In particular, it is possible to use CASL structured and [[Software architecture|architectural]] [[algebraic specification|specifications]] and libraries with logics other than CASL. For this purpose, the logic has to be formalized as an [[Institution (computer science)|institution]]. This feature is also used by the CASL extensions.

==Extensions==
Several extensions of CASL have been designed: 
*HasCASL, a [[Higher-order logic|higher-order]] extension
*CoCASL, a [[F-Coalgebra|coalgebraic]] extension
*CspCASL, a [[Concurrency (computer science)|concurrent]] extension based on [[Communicating sequential processes|CSP]]
*ModalCASL, a [[modal logic]] extension
*CASL-LTL, a [[temporal logic]] extension
*HetCASL, an extension for [[heterogeneous]] specification

==External links==
*[http://www.cofi.info/ Official CoFI website]
*[http://www.informatik.uni-bremen.de/cofi/index.php/CASL CASL]
*[http://www.informatik.uni-bremen.de/agbkb/forschung/formal_methods/CoFI/hets/index_e.htm The heterogeneous tool set Hets, the main analysis tool for CASL]

[[Category:Formal specification languages]]

{{compu-lang-stub}}</text>
      <sha1>dfpb3wbyd2dqyrpzy0ivmgvbcohvzuq</sha1>
    </revision>
  </page>
  <page>
    <title>Constraint counting</title>
    <ns>0</ns>
    <id>2471934</id>
    <revision>
      <id>848067521</id>
      <parentid>673726926</parentid>
      <timestamp>2018-06-29T15:50:43Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* References */[[User:JCW-CleanerBot#Logic|task]], replaced: Class. Quant. Grav. → Class. Quantum Grav. using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6654">In [[mathematics]], '''constraint counting''' is counting the number of [[constraint (mathematics)|constraints]] in order to compare it with the number of [[variable (mathematics)|variables]], [[parameter#Mathematical functions|parameters]], etc. that are free to be determined, the idea being that in most cases the number of independent choices that can be made is the excess of the latter over the former.

For example, in [[linear algebra]] if the number of constraints (independent equations) in a [[system of linear equations]] equals the number of unknowns then precisely one solution exists; if there are fewer independent equations than unknowns, an infinite number of solutions exist; and if the number of independent equations exceeds the number of unknowns, then no solutions exist.

In the context of [[partial differential equation]]s, constraint counting is a crude but often useful way of counting the number of ''free functions'' needed to specify a solution to a [[partial differential equation]].

==Partial differential equations==

Consider a second order partial differential equation in three variables, such as the two-dimensional [[wave equation]]
:&lt;math&gt; u_{tt} = u_{xx} + u_{yy}. &lt;/math&gt;
It is often profitable to think of such an equation as a ''rewrite rule'' allowing us to rewrite arbitrary partial derivatives of the function &lt;math&gt;u(t,x,y)&lt;/math&gt; using fewer partials than would be needed for an arbitrary function.  For example, if &lt;math&gt;u&lt;/math&gt; satisfies the wave equation, we can rewrite 
:&lt;math&gt; u_{tyt} = u_{tty} = u_{xxy} + u_{yyy} &lt;/math&gt;
where in the first equality, we appealed to the fact that ''partial derivatives commute''.

===Linear equations===

To answer this in the important special case of a [[linear]] partial differential equation, Einstein asked: how many of the partial derivatives of a solution can be [[linearly independent]]?  It is convenient to record his answer using an [[ordinary generating function]]
:&lt;math&gt;s(\xi) = \sum_{k=0}^\infty s_k \xi^k &lt;/math&gt;
where &lt;math&gt;s_k&lt;/math&gt; is a natural number counting the number of linearly independent partial derivatives (of order k) of an arbitrary function in the solution space of the equation in question.

Whenever a function satisfies some partial differential equation, we can use the corresponding rewrite rule to eliminate some of them, because ''further mixed partials have necessarily become linearly dependent''.  Specifically, the power series counting the variety of ''arbitrary'' functions of three variables (no constraints) is
:&lt;math&gt;f(\xi) =  \frac{1}{(1-\xi)^3} = 1 + 3 \xi + 6 \xi^2 + 10 \xi^3 + \dots&lt;/math&gt;
but the power series counting those in the solution space of some second order p.d.e. is
:&lt;math&gt;g(\xi) = \frac{1-\xi^2}{(1-\xi)^3} = 1 + 2 \xi + 5 \xi^2 + 7 \xi^3 + \dots &lt;/math&gt;
which records that we can eliminate ''one'' second order partial &lt;math&gt;u_{tt}&lt;/math&gt;, ''three'' third order partials &lt;math&gt;u_{ttt}, \, u_{ttx}, \, u_{tty} &lt;/math&gt;, and so forth.

More generally, the o.g.f. for an arbitrary function of n variables is
:&lt;math&gt;s[n](\xi) = 1/(1-\xi)^n = 1 + n \, \xi + \left( \begin{matrix} n \\ 2 \end{matrix} \right) \, \xi^2 + \left( \begin{matrix} n+1 \\ 3 \end{matrix} \right) \, \xi^3 + \dots &lt;/math&gt;
where the coefficients of the infinite [[power series]] of the generating function are constructed using an appropriate infinite sequence of [[binomial coefficient]]s, and the power series for a function required to satisfy a linear m-th order equation is
:&lt;math&gt;g(\xi) = \frac{1-\xi^m}{(1-\xi)^n} &lt;/math&gt;

Next,
:&lt;math&gt; \frac{1-\xi^2}{(1-\xi)^3} = \frac{1 + \xi}{(1-\xi)^2}&lt;/math&gt;
which can be interpreted to predict that a solution to a second order linear p.d.e. in ''three'' variables is expressible by two ''freely chosen'' functions of ''two'' variables, one of which is used immediately, and the second, only after taking a ''first derivative'', in order to express the solution.

===General solution of initial value problem===

To verify this prediction, recall the solution of the [[initial value problem]]
:&lt;math&gt;u_{tt} = u_{xx} + u_{yy}, \; u(0,x,y) = p(x,y), \; u_t(0,x,y) = q(x,y) &lt;/math&gt;
Applying the [[Laplace transform]] &lt;math&gt;u(t,x,y) \mapsto [Lu](\omega,x,y)&lt;/math&gt; gives
:&lt;math&gt; -\omega^2 \, [Lu] + \omega \, p(x,y) + q(x,y) + [Lu]_x + [Lu]_y&lt;/math&gt;
Applying the [[Fourier transform]] &lt;math&gt;[Lu](\omega,x,y) \mapsto [FLU](\omega,m,n)&lt;/math&gt; to the two spatial variables gives
:&lt;math&gt; -\omega^2 \, [FLu] + \omega \, [Fp] + [Fq] - (m^2+n^2) \, [FLu]&lt;/math&gt;
or
:&lt;math&gt;[FLu](\omega,m,n) = \frac{ \omega \, [Fp](m,n) + [Fq](m,n)}{\omega^2 + m^2 + n^2}&lt;/math&gt;
Applying the inverse Laplace transform gives
:&lt;math&gt; [Fu](t,m,n) = [Fp](m,n) \, \cos( \sqrt{m^2+n^2} \, t ) + \frac{ [Fq](m,n) \, \sin (\sqrt{m^2+n^2} \, t) }{\sqrt{m^2+n^2}} &lt;/math&gt;
Applying the inverse Fourier transform gives
:&lt;math&gt;u(t,x,y) = Q(t,x,y) + P_t(t,x,y)&lt;/math&gt;
where
:&lt;math&gt;P(t,x,y) = \frac{1}{2\pi} \, \int_{(x-x')^2 + (y-y')^2 &lt; t^2} \frac{p(x',y') \, dx' dy'}{ \left[ t^2-(x-x')^2-(y-y')^2 \right]^{1/2}} &lt;/math&gt;
:&lt;math&gt;Q(t,x,y) = \frac{1}{2\pi} \, \int_{(x-x')^2 + (y-y')^2 &lt; t^2} \frac{q(x',y') \, dx' dy'}{ \left[ t^2-(x-x')^2-(y-y')^2 \right]^{1/2}} &lt;/math&gt;
Here, p,q are arbitrary (sufficiently smooth) functions of two variables, so (due their modest time dependence) the integrals P,Q also count as "freely chosen" functions of two variables; as promised, one of them is differentiated once before adding to the other to express the general solution of the initial value problem for the two dimensional wave equation.

===Quasilinear equations===

In the case of a nonlinear equation, it will only rarely be possible to obtain the general solution in closed form.  However, if the equation is ''quasilinear'' (linear in the highest order derivatives), then we can still obtain approximate information similar to the above: specifying a member of the solution space will be "modulo nonlinear quibbles" equivalent to specifying a certain number of functions in a smaller number of variables.  The number of these functions is the ''Einstein strength'' of the p.d.e.  In the simple example above,  the strength is two, although in this case we were able to obtain more precise information.

==References==

*{{cite journal | author=Siklos, S. T. C. | title=Counting solutions of Einstein's equation | journal=Class. Quantum Grav. | year=1996 | volume=13 | pages=1931–1948 | doi=10.1088/0264-9381/13/7/021 | issue=7}}  Application of constraint counting to Riemannian geometry and to general relativity.

[[Category:Combinatorics]]
[[Category:Partial differential equations]]
[[Category:Riemannian geometry]]</text>
      <sha1>2mrgek0rnccutbz5cmao0acampl98pz</sha1>
    </revision>
  </page>
  <page>
    <title>Equational logic</title>
    <ns>0</ns>
    <id>33522862</id>
    <revision>
      <id>760394910</id>
      <parentid>760393978</parentid>
      <timestamp>2017-01-16T18:51:45Z</timestamp>
      <contributor>
        <username>InterruptorJones</username>
        <id>117876</id>
      </contributor>
      <comment>/* Syllogism */ Add "boolean" link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7045">First-order '''equational [[logic]]''' consists of [[Quantification (logic)|quantifier]]-free terms of ordinary [[first-order logic]], with equality as the only [[predicate symbol]]. The [[model theory]] of this logic was developed into [[Universal algebra]] by [[Garrett Birkhoff|Birkhoff]], Grätzer and [[Paul Cohn|Cohn]]. It was later made into a branch of [[category theory]] by [[William Lawvere|Lawvere]] ("algebraic theories").&lt;ref&gt;equational logic. (n.d.). The Free On-line Dictionary of Computing. Retrieved October 24, 2011, from Dictionary.com website: http://dictionary.reference.com/browse/equational+logic&lt;/ref&gt;
	
The terms of equational logic are built up from variables and constants using function symbols (or operations).

==Syllogism==

Here are the four [[inference rule]]s of logic &lt;math display="inline"&gt;E&lt;/math&gt;. &lt;math display="inline"&gt;P[x := E]&lt;/math&gt; denotes textual substitution of expression &lt;math display="inline"&gt;E&lt;/math&gt; for variable &lt;math display="inline"&gt;x&lt;/math&gt; in expression &lt;math display="inline"&gt;P&lt;/math&gt;. &lt;math display="inline"&gt;b = c&lt;/math&gt; denotes equality, for &lt;math display="inline"&gt;b&lt;/math&gt; and &lt;math display="inline"&gt;c&lt;/math&gt; of the same type, while &lt;math display="inline"&gt;b \equiv c&lt;/math&gt;, or equivalence, is defined only for &lt;math display="inline"&gt;b&lt;/math&gt; and &lt;math display="inline"&gt;c&lt;/math&gt; of type [[Boolean algebra|boolean]]. For &lt;math display="inline"&gt;b&lt;/math&gt; and &lt;math display="inline"&gt;c&lt;/math&gt; of type boolean, &lt;math display="inline"&gt;b = c&lt;/math&gt; and &lt;math display="inline"&gt;b \equiv c&lt;/math&gt; have the same meaning.

{| class="wikitable"
|-
! scope="row" style="text-align: left" | [[Substitution (logic)|Substitution]]
| If &lt;math display="inline"&gt;P&lt;/math&gt; is a theorem, then so is &lt;math display="inline"&gt;P[x := E]&lt;/math&gt;.
| &lt;math display="block"&gt;\vdash P \qquad \rightarrow \qquad \vdash P[x := E]&lt;/math&gt;
|-
! scope="row" style="text-align: left" | [[Gottfried Wilhelm Leibniz|Leibniz]]
| If &lt;math display="inline"&gt;P = Q&lt;/math&gt; is a theorem, then so is &lt;math display="inline"&gt;E[x:= P] = E[x:= Q]&lt;/math&gt;.
| &lt;math display="block"&gt;\vdash P = Q \qquad \rightarrow \qquad \vdash E[x := P] = E[x := Q]&lt;/math&gt;
|-
! scope="row" style="text-align: left" style="text-align: left" | [[Transitive relation|Transitivity]]
| If &lt;math display="inline"&gt;P = Q&lt;/math&gt; and &lt;math display="inline"&gt;Q = R&lt;/math&gt; are theorems, then so is &lt;math display="inline"&gt;P = R&lt;/math&gt;.
| &lt;math display="block"&gt;\vdash P = Q, \; \vdash Q = R \qquad \rightarrow \qquad \vdash P = R&lt;/math&gt;
|-
! scope="row" style="text-align: left" | [[Equanimity]]
| If &lt;math display="inline"&gt;P&lt;/math&gt; and &lt;math display="inline"&gt;P \equiv Q&lt;/math&gt; are theorems, then so is &lt;math display="inline"&gt;Q&lt;/math&gt;.
| &lt;math display="block"&gt;\vdash P, \; \vdash P \equiv Q \qquad \rightarrow \qquad \vdash Q&lt;/math&gt;
|}

&lt;ref name="gries"&gt;Gries, D. (2010). Introduction to equational logic . Retrieved from http://www.cs.cornell.edu/gries/logic/Equational.html&lt;/ref&gt;

==History==

Equational logic was developed over the years (beginning in the early 1980s) by researchers in the formal development of programs, who felt a need for an effective style of manipulation, of calculation. Involved were people like [[Roland Carl Backhouse]], [[Edsger W. Dijkstra]], Wim H.J. Feijen, [[David Gries]], [[Carel S. Scholten]], and Netty van Gasteren. Wim Feijen is responsible for important details of the proof format.

The axioms are similar to those use by Dijkstra and Scholten in their monograph ''Predicate calculus and program semantics'' (Springer Verlag, 1990), but our order of presentation is slightly different.

In their monograph, Dijkstra and Scholten use the three inference rules Leibniz, Substitution, and Transitivity. However, Dijkstra/Scholten system is not a logic, as logicians use the word. Some of their manipulations are based on the meanings of the terms involved, and not on clearly presented syntactical rules of manipulation. The first attempt at making a real logic out of it appeared in ''A Logical Approach to Discrete Math''. However, inference rule Equanimity is missing there, and the definition of theorem is contorted to account for it. The introduction of Equanimity and its use in the proof format is due to Gries and Schneider. It is used, for example, in the proofs of soundness and completeness, and it will appear in the second edition of ''A Logical Approach to Discrete Math''.&lt;ref name="gries" /&gt;

==Proof==
We explain how the four inference rules are used in proofs, using the proof of &lt;math display="inline"&gt;\lnot p \equiv p \equiv \bot&lt;/math&gt;. The [[List of logic symbols|logic symbols]] &lt;math display="inline"&gt;\top&lt;/math&gt; and &lt;math display="inline"&gt;\bot&lt;/math&gt; indicate "true" and "false," respectively, and &lt;math display="inline"&gt;\lnot&lt;/math&gt; indicates "not." The theorem numbers refer to theorems of ''A Logical Approach to Discrete Math''.&lt;ref name="gries" /&gt;

&lt;math display="block"&gt;
\begin{array}{lcl}
(0) &amp; &amp; \lnot p \equiv p \equiv \bot \\
(1) &amp; = &amp; \quad \left\langle\; (3.9),\; \lnot(p \equiv q) \equiv \lnot p \equiv q,\; \text{with}\ q := p \;\right\rangle \\
(2) &amp; &amp; \lnot (p \equiv p) \equiv \bot \\
(3) &amp; = &amp; \quad \left\langle\; \text{Identity of}\ \equiv (3.9),\; \text{with}\ q := p \;\right\rangle \\
(4) &amp; &amp; \lnot \top \equiv \bot &amp; (3.8)
\end{array}
&lt;/math&gt;

First, lines &lt;math display="inline"&gt;(0)&lt;/math&gt;&amp;ndash;&lt;math display="inline"&gt;(2)&lt;/math&gt; show a use of inference rule Leibniz:

&lt;math display="block"&gt;
(0) = (2)
&lt;/math&gt;

is the conclusion of Leibniz, and its premise &lt;math display="inline"&gt;\lnot(p \equiv p) \equiv \lnot p \equiv p&lt;/math&gt; is given on line &lt;math display="inline"&gt;(1)&lt;/math&gt;. In the same way, the equality on lines &lt;math display="inline"&gt;(2)&lt;/math&gt;&amp;ndash;&lt;math display="inline"&gt;(4)&lt;/math&gt; are substantiated using Leibniz.

The "hint" on line &lt;math display="inline"&gt;(1)&lt;/math&gt; is supposed to give a premise of Leibniz, showing what substitution of equals for equals is being used. This premise is theorem &lt;math display="inline"&gt;(3.9)&lt;/math&gt; with the substitution &lt;math display="inline"&gt;p := q&lt;/math&gt;, i.e.

&lt;math display="block"&gt;
(\lnot(p \equiv q) \equiv \lnot p \equiv q)[p := q]
&lt;/math&gt;

This shows how inference rule Substitution is used within hints.

From &lt;math display="inline"&gt;(0) = (2)&lt;/math&gt; and &lt;math display="inline"&gt;(2) = (4)&lt;/math&gt;, we conclude by inference rule Transitivity that &lt;math display="inline"&gt;(0) = (4)&lt;/math&gt;. This shows how Transitivity is used.

Finally, note that line &lt;math display="inline"&gt;(4)&lt;/math&gt;, &lt;math display="inline"&gt;\lnot \top \equiv \bot&lt;/math&gt;, is a theorem, as indicated by the hint to its right. Hence, by inference rule Equanimity, we conclude that line &lt;math display="inline"&gt;(0)&lt;/math&gt; is also a theorem. And &lt;math display="inline"&gt;(0)&lt;/math&gt; is what we wanted to prove.&lt;ref name="gries" /&gt;

==References==
{{reflist}}

==External links==
* [http://mathworld.wolfram.com/EquationalLogic.html Sakharov, Alex. "Equational Logic." From MathWorld--A Wolfram Web Resource, created by Eric W. Weisstein.]

[[Category:Mathematical logic]]</text>
      <sha1>diitlfoeoagzkcg4mrp8plvszpkxq75</sha1>
    </revision>
  </page>
  <page>
    <title>Francisco Gomes Teixeira</title>
    <ns>0</ns>
    <id>50704764</id>
    <revision>
      <id>748480501</id>
      <parentid>733715396</parentid>
      <timestamp>2016-11-08T11:25:07Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>/* Eponymous tributes */clean up; http&amp;rarr;https for [[Google Books]] and other Google services using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9642">[[File:Francisco Gomes Teixeira.png|thumb|Francisco Gomes Teixeira, ''ca''. 1899]]
'''Francisco Gomes Teixeira''' (28 January 1851, São Cosmado, [[Armamar]] – 8 February 1933, [[Porto]]) was a Portuguese mathematician and historian of mathematics.

==Biography==
{{blockquote|FRANCISCO GOMES TEIXEIRA completed his course of study in the Faculty of Mathematics at the University of Coimbra in 1874, and was given the degree of doctor the following year, with a thesis on integration of second order partial differential equations. In 1876 he was accepted as a member of the faculty, after presenting a paper on the use of non-orthogonal systems of axes in analytic mechanics. Having observed that papers by Portuguese mathematicians were often ignored (and sometimes the results were independently discovered abroad) because there was no adequate means to make them known, GOMES TEIXEIRA founded the ''Jornal de Sciencias Mathematicas e Astronomicas'' (Journal of Mathematical Sciences and Astronomy) in 1877, which turned out to be the most important Portuguese mathematics journal of the 19th century.&lt;ref name=WritingHistory&gt;{{cite book|editor=Dauben, Joseph  W.|editor2=Scriba, Christoph J.|title=Writing the History of Mathematics: Its Historical Development|year=2002|page=539|url=https://books.google.com/books?id=oXjMYIonXTYC&amp;pg=PA539}}&lt;/ref&gt;}}

In 1876 he became a corresponding member of the [[Lisbon Academy of Sciences|Academia Real das Ciências de Lisboa]].

He published over 140 articles in prestigious international scientific journals. Before the year 1890 most of his publications were on mathematical analysis but from 1890 onwards most were on geometry.&lt;ref name=WritingHistory/&gt;&lt;ref&gt;There are almost 300 publications by Gomes. For an extensive list of these publications consult the following: VILHENA, Henrique de, O Professor Doutor Francisco Gomes Teixeira (Elogio, Notas, Notas de Biografia, Bibliografia, Documentos), Lisboa, 1935.&lt;/ref&gt;
He was named the third astronomer of the [[Astronomical Observatory of Lisbon|Observatório Astronómico de Lisboa]] in 1878, but only held this positions for about four months before returning to the University of Coimbra.

He was elected a parliamentary deputy by the [[Partido Regenerador]] in 1879 and participated in sessions of Parliament for that year and also in 1883 and 1884. In November 1879 he was put in charge of the University of Coimbra's chair of mathematical analysis and in February 1880 was formally appointed to this professorial chair.

In 1884 Gomes Teixeira was appointed to the chair of differential and integral calculus of the ''Academia Politécnica do Porto''. In 1905 the ''Jornal de Sciencias Mathematicas e Astronomicas'' (founded by Gomes in 1877) was integrated into the newly created ''Anais Scientificos da Academia Politécnica do Porto''.

His ''Tratado de las Curvas Especiales Notables'' won an award in 1899 from the [[Spanish Royal Academy of Sciences]]. A 3-volume French translation (with additions) was published in 1908 and 1909 as ''Traité des Courbes Spéciales Remarquables Planes et Gauches''. He received in 1917 the ''prix Binoux d'histoire des sciences'' from the French Academy of Sciences.

Gomes Teixeira received honorary doctorates from the University of Madrid and the University of Toulouse. In 1911 at the newly formed University of Porto he became the first rector, retiring in 1917. 

His body is entombed in the ''Igreja Matriz de São Cosmado''. The tomb consists of a granite sarcophagus with the following inscription:
*SERAPHICO FRANCISCO ASSISIENSI''
*{{spaces|27}}atque 
*{{spaces|3}}DIVO ANTONIO OLYSIPPONENSI
*{{spaces|9}}hoc monumentum erexit''
*{{spaces|3}}FRANCISCUS GOMES TEIXEIRA
*{{spaces|19}}qui hi jacet.&lt;ref&gt;{{cite book|title=Francisco Gomes Teixeira - o Homem, o Cientista, o Pédagogo|year=2012|page=39|url=https://books.google.com/books?id=HwsHOuZOoFAC&amp;pg=PA39}}&lt;/ref&gt;
(''Divo Antonio'' is Latin for St. Anthony. [[Olisipo|Olissipóna]] was the ancient name for Lisbon. Gomes Teixeira wrote a 1931 book ''Santo António de Lisboa (história, tradição e lenda)'' and a 1926 book ''Santuários de montahna (impressões de viagens''.)

==Eponymous tributes==
[[File:Pr Gomes Teixeira (Porto).JPG|thumb|plaque commemorating Gomes Teixeira in Porto's Praça de Gomes Teixeira (where the rector's residence was located)]]
*Praça de Gomes Teixeira (Gomes Teixeira Square), Porto
*Rua Professor Doutor Francisco Gomes Teixeira, Porto
*Rua Professor Doutor Francisco Gomes Teixeira em Carnaxide, Oeiras
*Rua Francisco Gomes Teixeira em Setúbal, Setúbal
*Sala Gomes Teixeira: Piso 4 Edifíco da Reitoria da [[Universidade do Porto]]
*[http://www.pai.pt/escola-e-b-23-de-gomes-teixeira-lordelo-do-ouro-e-massarelos-4150-344/ Agrupamento de Escolas Gomes Teixeira-Praça da Galiza, 4150-344 Porto]
*[http://codigopostal.ciberforma.pt/dir/0/escola-basica-dos-2-e-3-ciclos-gomes-teixeira-arma/ Escola básica dos 2.º e 3.º ciclos Gomes Teixeira - Armamar]
*[https://maps.google.com/?ie=UTF8&amp;t=h&amp;ll=41.063457,-7.644328&amp;spn=0.00195,0.004812&amp;z=18 approximate location of the statue of Dr. Gomes Teixeira in the village of São Cosmado] from [[Google Street View]]

==Selected publications==
*{{cite book|title=Integração das equações às derivadas parciaes de segunda ordem|location=Coimbra|publisher=Imprensa da Universidade|date=1875|url=https://www.fc.up.pt/fa/index.php?p=nav&amp;f=books.0021.0}}
*{{cite book|title=Corso de analyse infinitesmal|volume=vols. 1–3|location=Porto|postscript=; 1892–1896}}&lt;ref&gt;{{cite journal|author=Pierpont, James|authorlink=James Pierpont (mathematician)|title=Review: ''Corso de Analyse Infinitesimal'' by F. Gomes Teixeira|journal=Bull. Amer. Math. Soc.|year=1899|volume=5|issue=10|pages=483–484|url=http://www.ams.org/journals/bull/1899-05-10/S0002-9904-1899-00639-6/S0002-9904-1899-00639-6.pdf|doi=10.1090/s0002-9904-1899-00639-6}}&lt;/ref&gt;
*{{cite book|title=Tratado de las Curvas Especiales Notables|year=1905|location=Madrid|publisher=Imprenta de la "Gaceta de Madrid"|url=https://catalog.hathitrust.org/Record/009371647}}&lt;ref&gt;{{cite journal|author=Sisam, C. H.|authorlink=Charles Herschel Sisam|title=Review: ''Tratado de las Curvas Especiales Notables'' by F. Gomes Teixeira|journal=Bull. Amer. Math. Soc.|year=1907|volume=13|issue=5|pages=249–250|url=http://www.ams.org/journals/bull/1907-13-05/S0002-9904-1907-01459-3/S0002-9904-1907-01459-3.pdf|doi=10.1090/s0002-9904-1907-01459-3}}&lt;/ref&gt;
*{{cite book|title=Traité des Courbes Spéciales Remarquables Planes et Gauches|location=Coimbra|publisher=Imprensa da Universidade|volume=Tome I|date=1908|url=https://babel.hathitrust.org/cgi/pt?id=nyp.33433087543173;view=1up;seq=9}}; {{cite book|title=Tome II|year=1909|url=https://babel.hathitrust.org/cgi/pt?id=nyp.33433090896253;view=1up;seq=7}}; {{cite book|title=Tome III|year=1909}}. translated into French from the Spanish version but with revisions and extensive additions. Re-published in the ''Obras sobre Matemática'', volumes IV, V et VII, 1908–1915; Chelsea Publishing Co, New York, 1971; Éditions Jacques Gabay, Paris, 1995.
*{{cite book|title=Obras sobre Matemática|location=Coimbra|publisher=Imprensa da Universidade|url=http://quod.lib.umich.edu/cgi/t/text/text-idx?c=umhistmath&amp;idno=AAT2332}}, vol. I, 1904; vol. II, 1906; vol. III, 1906; vol. IV, 1908; vol. V, 1909; vol. VI, 1912; vol. VII, 1915.
*{{cite book|title=Sur les Problèmes célèbres de la Géométrie élémentaire non résolubles avec la Règle et le Compas|year=1915|location=Coimbra|publisher=Imprensa da Universidade|url=https://catalog.hathitrust.org/Record/005835051}}&lt;ref&gt;{{cite journal|author=Archibald, R. C.|authorlink=Raymond Clare Archibald|title=Review: ''Sur les Problèmes célèbres de la Géométrie élémentaire non résolubles avec la Règle et le Compas'' by F. Gomes Teixeira|journal=Bull. Amer. Math. Soc.|year=1918|volume=24|issue=4|pages=207–210|url=http://www.ams.org/journals/bull/1918-24-04/S0002-9904-1918-03044-9/S0002-9904-1918-03044-9.pdf|doi=10.1090/s0002-9904-1918-03044-9}}&lt;/ref&gt;
*{{cite book|title=Panegíricos e conferências|location=Coimbra|publisher=Imprensa da Universidade|date=1925}}
*{{cite book|title=História das matemáticas em Portugal|location= Lisboa|publisher=Academia das Ciências de Lisboa|date=1934}}

==References==
{{reflist}}

==External links==
*[http://cvc.instituto-camoes.pt/ciencia/p27.html Gomes Teixeira (1851-1933), Fernando Reis]
*[http://cvc.instituto-camoes.pt/ciencia/p27.html Ciência em Portugal: Personagens e Episódios]
*[http://cvc.instituto-camoes.pt/ciencia/e27.html Matemático por acaso]
*[http://www.mat.uc.pt/~jaimecs/livrogt/livrogt.html História das matemáticas em Portugal]
*[http://www.mat.uc.pt/~jfqueiro/GomesTeixeira.html Francisco Gomes Teixeira]
*[http://www.prof2000.pt/users/mosteiro/pagina%20pessoal/a%20concoidedeSluse.htm A concóide de Sluse]
*[http://www.infopedia.pt/$francisco-gomes-teixeira Francisco Gomes Teixeira. In Infopédia (Em linha).Porto: Porto Editora, 2003-2010.(Consult. 2010-05-09)]
*[http://sigarra.up.pt/up/web_base.gera_pagina?P_pagina=1006586 Francisco Gomes Teixeira, Reitor da Universidade do Porto]

{{Authority control}}
{{DEFAULTSORT:Gomes Teixeira, Francisco}}
[[Category:1851 births]]
[[Category:1933 deaths]]
[[Category:People from Viseu District]]
[[Category:19th-century mathematicians]]
[[Category:20th-century mathematicians]]
[[Category:Portuguese mathematicians]]
[[Category:Historians of mathematics]]
[[Category:University of Coimbra alumni]]
[[Category:University of Coimbra faculty]]
[[Category:University of Porto faculty]]</text>
      <sha1>lpott5r8cyoibqcnap9bsf9z6f858ro</sha1>
    </revision>
  </page>
  <page>
    <title>Frieder Nake</title>
    <ns>0</ns>
    <id>394527</id>
    <revision>
      <id>863588032</id>
      <parentid>863588010</parentid>
      <timestamp>2018-10-11T18:44:59Z</timestamp>
      <contributor>
        <username>MilkGames</username>
        <id>30455002</id>
      </contributor>
      <minor/>
      <comment>Reverted 1 edit by [[Special:Contributions/90.221.88.149|90.221.88.149]] ([[User talk:90.221.88.149|talk]]) to last revision by ClueBot NG. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12518">{{Infobox person
|name         = Frieder Nake
|image        = File:Frieder_Nake_2012.jpg
|image_size   =
|alt          = Head and shoulders photo of Frieder Nake
|caption      = Frieder Nake in 2012
|birth_name   =
|birth_date   = {{Birth date and age|1938|12|16|mf=yes}}
|birth_place  = [[Stuttgart]], [[Germany]]
|residence    = [[Bremen]], [[Germany]]
|nationality  = German
|alma_mater   = University of Stuttgart
|occupation   = Mathematician, computer artist
|years_active =
|website      = 
}}
'''Frieder Nake''' (born December 16, 1938 in [[Stuttgart]], [[Germany]]) is a mathematician, [[computer scientist]], and pioneer of [[computer art]]. He is best known internationally for his contributions to the earliest manifestations of [[computer art]], a field of computing that made its first public appearances with three small exhibitions in 1965.

==Life and work==
Without knowing of each other, A. [[Michael Noll]], [[Georg Nees]], and Frieder Nake in 1963/64 had begun to write [[computer programs]] to automatically generate drawings of an aesthetic quality and without other (technical or economic) purposes. Georg Nees became the first to exhibit his works (February 5–19, 1965, in Stuttgart). A. Michael Noll followed (April 6–24, 1965 in [[New York City]], with [[Bela Julesz]]). Frieder Nake had his first exhibition at Galerie Wendelin Niedlich in Stuttgart (November 5–26, 1965, with Georg Nees).

Until 1969, Nake generated in rapid sequence a large number of works that he showed in many exhibitions over the years. He estimates his production at about 300 to 400 works during those years. A few were limited screenprint editions, single pieces and portfolios. The bulk were done as China ink on paper graphics, carried out by a flatbed high precision [[plotter]] (the Zuse Graphomat Z64).

Nake participated in the important group shows of the 1960s, such as, most prominently, [[Cybernetic Serendipity]] (London, UK, 1968), Tendencies 4: Computers and Visual Research (Zagreb, Yugoslavia, 1968), Ricerca e Progettazione. Proposte per una esposizione sperimentale (35th [[Venice Biennale]], Italy, 1970), Arteonica (São Paulo, Brazil, 1971).

In 1971, he wrote a short and provocative note for Page, the Bulletin of the [[Computer Arts Society]] (whose member he was and still is), under the title „There Should Be No Computer-Art“ (Page No. 18, Oct. 1971, p.&amp;nbsp;1-2. Reprinted in Arie Altena, Lucas van der Velden (eds.): The anthology of computer art. Amsterdam: [[Sonic Acts]] 2006, p.&amp;nbsp;59-60). The note sparked a lively controversial debate among those who had meanwhile started to build an active community of artists, writers, musicians, and designers in the digital domain. His statement was rooted in a moral position. The involvement of computer technology in the Vietnam War and in massive attempts by capital to automate productive processes and, thereby, generate unemployment, should not allow artists to close their eyes and become silent servants of the ruling classes by reconciling high technology with the masses of the poor and suppressed.

Frieder Nake has been a professor of interactive [[computer graphics]] at the Department of Computer Science at [[University of the Arts Bremen|Bremen]], [[University of Bremen|Germany]], since 1972. Since 2005, he has also been teaching digital media design there. After studying mathematics at the [[University of Stuttgart]], where he earned his Diplom and doctoral degrees (in probability theory), he has taught in Stuttgart, [[Toronto]] and [[Vancouver]], before coming to Bremen. His courses and seminars, besides computer graphics, [[interactivity]], and [[digital media]], are in the areas of computer art, [[aesthetics]], [[semiotics]], computers and society, and theory of computing. He has been a visiting professor to [[University of Oslo|Universitetet Oslo]], [[Aarhus Universitet]], [[Universität Wien]], [[Danube University Krems]], [[University of Colorado at Boulder|University of Colorado]], [[University of Lübeck]], [[University of Basel]], [[University of Costa Rica]], [[Xi'an University of Science and Technology]] and [[Tongji University]].

He won the First Prize of the Computer Art Contest of Computers &amp; Automation in 1966. In 1997, his teaching work was honored by the Berninghausen Award for Excellence and Innovation in Teaching (University of Bremen).

His book ''Ästhetik als Informationsverarbeitung'' (1974) is one of the first to study connections between aesthetics, computing, and [[information theory]], which has become important to the transdisciplinary area of digital media. This book and many of his ca. 300 publications (2012) evince his intellectual position between science and the humanities – a position that has always made him critical about the marvels and wonders of information technology.

In his publications, seminars, and lectures, he has developed the following fundamental concepts of a (cultural) theory of computing:

*the machinization of mental labor
*the duplication of computer things
*the instrumental medium (with Heidi Schelhowe)
*the algorithmic sign

==Public collections==
Besides being represented in many private collections, his works are held by [[Abteiberg Museum]] Mönchengladbach (Germany), [[Kunsthalle Bremen]] (Germany), [[Victoria and Albert Museum]] London (UK), [[Museum of Contemporary Art, Zagreb]] (Croatia), [[Sprengel Museum]] Hannover (Germany), [[Mary and Leigh Block Museum of Art]] Evanston (USA), Tama Art University Museum Tokyo (Japan).

==Publications==
*Frieder Nake: Information aesthetics: an heroic experiment. Journal of Mathematics and the Arts 6, 2-3, (2012) p.&amp;nbsp;65-75
*Frieder Nake: Construction and intuition. Creativity in early computer art. In J. McCormack, M. d’Inverno (eds.): Computers and creativity. Berlin, London: Springer 2012, p.&amp;nbsp;61-95
*Frieder Nake: Paragraphs on computer art, past and present. In: N. Lambert et al. (eds.): Ideas before their time. London: BCS 2010, p.&amp;nbsp;55-63
*Frieder Nake: Alles, was fest ist, verdampft. Ästhetik &amp; Kommunikation 144/45 (Sping 2009), p.&amp;nbsp;21-30
*Frieder Nake: The semiotic engine. Notes on the history of algorithmic images in Europe. Art Journal 68,1 (Spring 2009) p.&amp;nbsp;76-89
*Frieder Nake: Work, design, computers, artifacts. In Th. Binder et al. (eds.): (Re)Searching the digital Bauhaus. London: Springer 2009, p.&amp;nbsp;309-331
* Frieder Nake. 2008. Surface, Interface, Subface: Three Cases of Interaction and One Concept. In: Uwe Seifert, Jin Hyun Kim, Anthony Moore (eds.), Paradoxes of Interactivity. Bielefeld: transcript Verlag, pp.&amp;nbsp;92–109.
*Frieder Nake: Zeigen, Zeichnen und Zeichen. Der verschwundene Lichtgriffel. In H. D. Hellige (ed.): Mensch-Computer-Interface. Zur Geschichte und Zukunft der Computerbedienung. Bielefeld: transcript Verlag 2008, p.&amp;nbsp;121-156
*Frieder Nake, Susanne Grabowski: Abstraktion, System, Design. Zur Perspektive von Bildung, aus informatischer Sicht. In: W. Sesink et al. (eds.): Jahrbuch Medienpädagogik 6. Wiesbaden: Verlag für Sozialwissenschaften 2007, p.&amp;nbsp;300-314
*Frieder Nake, Susanne Grabowski: The interface as sign and as aesthetic event. In P. Fishwick (ed.): Aesthetic computing. Cambridge, MA: MIT Press 2006, p.&amp;nbsp;53-70
*Frieder Nake: Das doppelte Bild. Bildwelten des Wissens. Kunsthistorisches Jahrbuch für Bildkritik 3,2 (2006) p.&amp;nbsp;40-50
*Frieder Nake: There should be no computer-art. Page (Bulletin of the Computer Art Society, London) No. 18, Oct. 1971, 1-2. Rpt in A. Altena, L. van der Velden (eds.): The anthology of computer art. Amsterdam: [[Sonic Acts]] 2006, p.&amp;nbsp;59-60
*Frieder Nake: Four spaces. A digital media approach to the history of computer art. Special issue „Searching our origins“, Leonardo Electronic Almanac, 13,5 (May 2005) 
*Frieder Nake: Computer art. A personal recollection. In L. Candy (ed.): Proc. Creativity and Cognition 2005. New York: ACM 2005, p.&amp;nbsp;54-62
*Frieder Nake: The Display as a Looking-Glass: Zu Ivan E. Sutherlands früher Vision der grafischen Datenverarbeitung. In H. D. Hellige (ed.): Geschichten der Informatik. Visionen, Paradigmen, Leitmotive. Berlin, Heidelberg, New York: Springer 2004, p.&amp;nbsp;339-365
*Frieder Nake, Susanne Grabowski: Human-computer interaction viewed as pseudo-communication. Knowledge Based Systems 14 (2001) p.&amp;nbsp;441-447
*Frieder Nake: form.algorithmus.farbe – Manfred Mohr: Algorithmiker. In P. Volkwein (Hrsg.): space.color. Ingolstadt: Museum für konkrete Kunst 2001. p.&amp;nbsp;23-35 (German, English)
*Frieder Nake: Das algorithmische Zeichen. In W. Bauknecht, W. Brauer, Th. Mück (eds.): Informatik 2001. GI/OCG Jahrestagung 2001. Bd. II, p.&amp;nbsp;736-742
*Frieder Nake: Kalkulierte und kalkulierende Zeichen. Der Computer als instrumentales Medium. In V. Demuth, R. Wagner (Hrsg.) Vom Sinn multiplier Welten. Medien und Kunst. Würzburg: Königshausen und Neumann 2000. p.&amp;nbsp;121-140
*Frieder Nake: Work.Computers.Design. Scandinavian Journal of Information Systems 10, 1&amp;2 (1998) p.&amp;nbsp;53-59
*Frieder Nake: Was heißt und zu welchem Ende studiert man Informatik? Ein akademischer Diskursbeitrag nebst Anwendung. In V. Claus (Hrsg.): Informatik und Ausbildung. Berlin, Heidelberg etc.: Springer 1998. p.&amp;nbsp;1-13
*Frieder Nake: Der semiotische Charakter der informatischen Gegenstände. Semiosis 85-90 (1997) p.&amp;nbsp;24-35
*Frieder Nake: How far away are we from the first masterpiece of computer art? In K. Brunnstein, E. Raubold (eds.): Information Processing 94. Proc. of the IFIP Congress 1994, Vol. II (IFIP Transactions A-52). Amsterdam: North-Holland 1994. p.&amp;nbsp;406-413 
*Frieder Nake (ed.): Die erträgliche Leichtigkeit der Zeichen. Ästhetik, Semiotik, Informatik. Baden-Baden: Agis 1993 
*Frieder Nake, Diethelm Stoller (ed.): Algorithmus und Kunst. ”Die präzisen Vergnügen”. Hamburg: Sautter &amp; Lackmann 1993
*W. Coy, F. Nake, J.-M. Pflüger, A. Rolf, J. Seetzen, D. Siefkes, R. Stransfeld (eds.): Sichtweisen der Informatik. Braunschweig: Vieweg 1992
*Frieder Nake: Künstliche Kunst. In der Welt der Berechenbarkeit. Kunstforum 98 (Jan./Feb. 1989) p.&amp;nbsp;85-94
*Frieder Nake (ed.): Graphik in Dokumenten. Berlin, Heidelberg, New York: Springer 1986
*Frieder Nake: Schnittstelle Mensch - Computer. Kursbuch 75. Berlin: Rotbuch 1984. p.&amp;nbsp;109-118
*Frieder Nake: Ästhetik als Informationsverarbeitung. Wien etc.: Springer 1974
*Frieder Nake, Azriel Rosenfeld (eds.): Graphic Languages. Proc. of the IFIP Working Conference on Graphic Languages, Vancouver 1972. Amsterdam: North-Holland 1972
*Frieder Nake: A proposed language for the definition of arbitrary twodimen¬sio¬nal signs. In O.-J. Grüsser, R. Klinke (eds.): Pattern Recognition in Biological and Technical Systems. Berlin, Heidelberg, New York: Springer 1971. p.&amp;nbsp;396-402
*Frieder Nake: On generative aesthetics – two picture generating programs. Proc. of the International Symposium Computer Graphics, Uxbridge: Brunel University 1970
*Frieder Nake: Erzeugung ästhetischer Objekte mit Rechenanlagen. In R. Gunzenhäuser (ed.): Nichtnumerische Informationsverarbeitung. Wien, New York: Springer-Verlag 1968. p.&amp;nbsp;456-472
*Frieder Nake: Notes on the programming of computer graphics. Cybernetic Serendipity. Special Issue of Studio International, London 1968. p.&amp;nbsp;77-78
*Frieder Nake: Bemerkungen zur Programmierung von Computer-Grafiken. Deutsches Rechenzentrum Darmstadt, Programm-Information PI-21. April 1966

==External links==
*[http://www.medienkunstnetz.de/artist/nake/biography/ Biography] at MediaArtNet {{en icon }} {{de icon}}
* [https://scholar.google.com/scholar?hl=en&amp;lr=&amp;client=safari&amp;q=frieder+nake&amp;btnG=Search Google Scholar: numerous links to scientific articles referencing Nake's work]
* [http://dada.compart-bremen.de/node/751 Entry about Frieder Nake in the data base of early computer art]
*[https://collections.vam.ac.uk/name/nake-frieder/A21853/ List of works held by the Victoria and Albert Museum]
* [http://iasl.uni-muenchen.de/links/GCA-III.2e.html#Computergrafik Thomas Dreher: History of Computer Art], chap.II.2.2 Digital Computer Graphics.

{{Authority control}}

{{DEFAULTSORT:Nake, Frieder}}
[[Category:1938 births]]
[[Category:Living people]]
[[Category:People from Stuttgart]]
[[Category:People from the Free People's State of Württemberg]]
[[Category:German computer scientists]]
[[Category:German digital artists]]
[[Category:Communist League of West Germany politicians]]
[[Category:Mathematical artists]]</text>
      <sha1>janfgbgw8mcx9v52gc88ssma5atd49k</sha1>
    </revision>
  </page>
  <page>
    <title>Gabriel's Horn</title>
    <ns>0</ns>
    <id>332256</id>
    <revision>
      <id>870782139</id>
      <parentid>870748158</parentid>
      <timestamp>2018-11-26T23:35:22Z</timestamp>
      <contributor>
        <username>Wcherowi</username>
        <id>13428914</id>
      </contributor>
      <comment>Undid revision 870747136 by [[Special:Contributions/2001:985:783F:1:6D0B:CBC0:CEE7:C1C4|2001:985:783F:1:6D0B:CBC0:CEE7:C1C4]] ([[User talk:2001:985:783F:1:6D0B:CBC0:CEE7:C1C4|talk]]) revert vandalism</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8040">[[File:GabrielHorn.png|thumb|3D illustration of Gabriel's horn.]]

'''Gabriel's horn'''&lt;!--see MOS:CAPS--&gt; (also called '''Torricelli's trumpet''') is a [[geometry|geometric]] figure which has [[infinity|infinite]] [[surface area]] but finite [[volume]]. The name refers to the biblical tradition identifying the [[Gabriel|Archangel Gabriel]] as the angel who blows the horn to announce [[Judgment Day]], associating the divine, or infinite, with the finite. The properties of this figure were first studied by [[Italy|Italian]] physicist and mathematician [[Evangelista Torricelli]] in the 17th century.

==Mathematical definition==
[[File:Rectangular hyperbola.svg|thumb|Graph of &lt;math&gt;x\mapsto\tfrac{1}{x}&lt;/math&gt;]]
Gabriel's horn is formed by taking the [[Graph of a function|graph]] of
:&lt;math&gt;x \mapsto \frac{1} {x},&lt;/math&gt;
with the [[Domain of a function|domain]] {{math|''x'' &gt; 0}} (thus avoiding the [[asymptote]] at {{math|1=''x'' = 0}}) and [[surface of revolution|rotating]] it in three [[dimension]]s about the {{mvar|x}}-axis. The discovery was made using [[Cavalieri's principle]] before the invention of [[calculus]], but today calculus can be used to calculate the volume and surface area of the horn between {{math|1=''x'' = 1}} and {{math|1=''x'' = ''a''}}, where {{math|''a'' &gt; 1}}. Using integration (see [[Solid of revolution]] and [[Surface of revolution]] for details), it is possible to find the volume {{mvar|V}} and the surface area {{mvar|A}}:

:&lt;math&gt;V=\pi\int\limits_1^a\left(\frac{1}{x}\right)^2\mathrm{d}x=\pi\left(1-\frac{1}{a}\right)&lt;/math&gt;

:&lt;math&gt;A=2\pi\int\limits_1^a {\frac{1}{x}}\sqrt{1+\left(-\frac{1}{x^2}\right)^2}\mathrm{d}x &gt; 2\pi\int\limits_1^a \frac{\mathrm{d}x}{x}=2\pi\ln(a).&lt;/math&gt;

{{mvar|a}} can be as large as required, but it can be seen from the equation that the volume of the part of the horn between {{math|1=''x'' = 1}} and {{math|1=''x'' = ''a''}} will never exceed {{pi}}; however, it ''will'' get closer and closer to {{pi}} as {{mvar|a}} becomes larger. Mathematically, the volume ''approaches {{pi}} as {{mvar|a}} approaches infinity''. Using the [[Limit of a function|limit]] notation of calculus:

:&lt;math&gt;\lim_{a\to\infty}V=\lim_{a\to\infty}\pi\left(1-\frac{1}{a}\right)=\pi\cdot\lim_{a\to\infty}\left(1-\frac{1}{a}\right)=\pi.&lt;/math&gt;

The surface area formula above gives a lower bound for the area as 2{{pi}} times the [[natural logarithm]] of {{mvar|a}}. There is no [[upper bound]] for the natural logarithm of {{mvar|a}} as {{mvar|a}} approaches infinity. That means, in this case, that the horn has an infinite surface area. That is to say;

:&lt;math&gt;\lim_{a\to\infty}A\ge\lim_{a\to\infty}2\pi\ln(a)=\infty.&lt;/math&gt;

==Apparent paradox==
When the properties of Gabriel's horn were discovered, the fact that the rotation of an infinitely large section of the {{mvar|xy}}-plane about the {{mvar|x}}-axis generates an object of finite volume was considered [[paradox]]ical. While the section lying in the {{mvar|xy}}-plane has an infinite area, any other section parallel to it has a finite area. Thus the volume, being calculated from the 'weighted sum' of sections, is finite.

Another approach is to treat the horn as a stack of disks with diminishing radii.  The sum of the radii produces a harmonic series that goes to infinity. However, the correct calculation is the sum of their squares. Every disk has a radius {{math|1=''r'' = {{sfrac|1|''x''}}}} and an area {{math|π''r''&lt;sup&gt;2&lt;/sup&gt;}} or {{math|{{sfrac|π|''x''&lt;sup&gt;2&lt;/sup&gt;}}}}. The series {{math|{{sfrac|1|''x''}}}} diverges but {{math|{{sfrac|1|''x''&lt;sup&gt;2&lt;/sup&gt;}}}} converges. In general, for any real {{math|''ε'' &gt; 0}}, {{math|{{sfrac|1|''x''&lt;sup&gt;1+''ε''&lt;/sup&gt;}}}} converges.

The apparent paradox formed part of a dispute over the nature of infinity involving many of the key thinkers of the time including [[Thomas Hobbes]], [[John Wallis]] and [[Galileo Galilei]].&lt;ref&gt;{{cite book|title=Nonplussed!: mathematical proof of implausible ideas|first=Julian|last=Havil|publisher=Princeton University Press|year=2007|isbn=0-691-12056-0|pages=82–91}}&lt;/ref&gt;

There is a similar phenomenon which applies to lengths and areas in the plane. The area between the curves {{math|{{sfrac|1|''x''&lt;sup&gt;2&lt;/sup&gt;}}}} and {{math|{{sfrac|-1|''x''&lt;sup&gt;2&lt;/sup&gt;}}}} from 1 to infinity is finite, but the lengths of the two curves are clearly infinite.

===Painter's paradox===
Since the horn has finite volume but infinite surface area, there is an apparent paradox that the horn could be filled with a finite quantity of paint, and yet that paint would not be sufficient to coat its inner surface. The "paradox" is resolved by realizing that a finite amount of paint can in fact coat an infinite surface area — it simply needs to get thinner at a fast enough rate. (Much like the series {{sfrac|1|2&lt;sup&gt;N&lt;/sup&gt;}} gets smaller fast enough that its sum is finite.) In the case where the horn is filled with paint, this thinning is accomplished by the increasing reduction in diameter of the throat of the horn.

==Converse==
The converse phenomenon of Gabriel's horn – a surface of revolution that has a ''finite'' surface area but an ''infinite'' volume – cannot occur:

===Theorem===
Let {{math|''f'' : [1,∞) → [0,∞)}} be a continuously differentiable function. Write {{mvar|S}} for the [[solid of revolution]] of the graph {{math|1=''y'' = ''f''(''x'')}} about the {{mvar|x}}-axis. ''If the surface area of {{mvar|S}} is finite, then so is the volume.''

===Proof===

Since the lateral surface area {{mvar|A}} is finite, the [[limit superior]]:
:&lt;math&gt;\begin{align}
\lim_{t\to\infty} \sup_{x\ge t} f(x)^2 ~-~ f(1)^2 &amp;= \limsup_{t\to\infty} \int\limits_1^t \left(f(x)^2\right)'\mathrm{d}x \\
&amp;\le\int\limits_1^{\infty} \left|\left(f(x)^2\right)'\right|\mathrm{d}x=\int\limits_1^{\infty} 2f(x)\left|f'(x)\right|\mathrm{d}x \\
&amp;\le\int\limits_1^{\infty} 2f(x)\sqrt{1+f'(x)^2}\mathrm{d}x=\frac{A}{\pi} \\
&amp;&lt;\infty. \end{align}&lt;/math&gt;
Therefore, there exists a {{math|''t''&lt;sub&gt;0&lt;/sub&gt;}} such that the [[supremum]] {{math|sup{&amp;thinsp;''f''(''x'') {{!}} ''x'' ≥ ''t''&lt;sub&gt;0&lt;/sub&gt;}}} is finite. Hence,
:{{math|1=''M'' = sup{&amp;thinsp;''f''(''x'') {{!}} ''x'' ≥ 1}}} must be finite since {{mvar|f}} is a [[continuous function]], which implies that {{mvar|f}} is bounded on the interval {{math|[1,∞)}}.
Finally, the volume:
:&lt;math&gt;\begin{align}
V &amp;=\int\limits_1^{\infty} f(x)\cdot\pi f(x)\mathrm{d}x \\
&amp;\le\int\limits_1^{\infty} \frac{M}{2}\cdot 2\pi f(x)\mathrm{d}x \\
&amp;\le\frac{M}{2}\cdot\int\limits_1^{\infty} 2\pi f(x)\sqrt{1+f'(x)^2}\mathrm{d}x =\frac{M}{2}\cdot A.\end{align}&lt;/math&gt;
Therefore: ''if the area {{mvar|A}} is finite, then the volume {{mvar|V}} must also be finite.''

== See also ==
* [[Hyperbola]]
* [[Koch snowflake]]
* [[Picard horn]]
* [[Pseudosphere]]
* [[Shape of the universe]]
* [[Surface of revolution]]
* [[Zeno's paradoxes]]

==References==
{{Reflist}}

== Further reading ==
* ''Gabriel's Other Possessions'', Melvin Royer, {{DOI|10.1080/10511970.2010.517601}}
* [https://web.archive.org/web/20161213085806/https://people.emich.edu/aross15/math121/misc/gabriels-horn-ma044.pdf ''Gabriel's Wedding Cake''], Julian F. Fleron
* [http://www.maa.org/programs/faculty-and-departments/classroom-capsules-and-notes/a-paradoxical-paint-pail ''A Paradoxical Paint Pail''], Mark Lynch
* ''Supersolids: Solids Having Finite Volume and Infinite Surfaces'', William P. Love, {{jstor|27966098}}

==External links==
*[http://planetmath.org/torricellistrumpet Torricelli's trumpet at PlanetMath]
*{{MathWorld|title=Gabriel's Horn|urlname=GabrielsHorn}}
* [http://demonstrations.wolfram.com/GabrielsHorn/ "Gabriel's Horn"] by John Snyder, the [[Wolfram Demonstrations Project]], 2007.
* [http://www.palmbeachstate.edu/honors/Documents/jeansergejoseph.pdf Gabriel's Horn: An Understanding of a Solid with Finite Volume and Infinite Surface Area] by Jean S. Joseph.

[[Category:Mathematics paradoxes]]
[[Category:Paradoxes of infinity]]
[[Category:Calculus]]
[[Category:Gabriel]]
[[Category:Surfaces]]</text>
      <sha1>nnhpqmy9as06a6xmdz10ivu1n2cmhyl</sha1>
    </revision>
  </page>
  <page>
    <title>Harmonic spectrum</title>
    <ns>0</ns>
    <id>1058719</id>
    <revision>
      <id>817756693</id>
      <parentid>817756607</parentid>
      <timestamp>2017-12-30T11:12:13Z</timestamp>
      <contributor>
        <username>Hyacinth</username>
        <id>17171</id>
      </contributor>
      <comment>/* See also */ * [[Undertone series]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1108">A '''harmonic spectrum''' is a [[spectrum of an operator|spectrum]] containing only frequency components whose [[frequency|frequencies]] are [[Integer|whole number]] multiples of the [[fundamental frequency]]; such frequencies are known as [[harmonic]]s. "The individual partials are not heard separately but are blended together by the ear into a single tone."&lt;ref&gt;Benward, Bruce and Saker, Marilyn (1997/2003). ''Music: In Theory and Practice'', Vol. I, p.xiii. Seventh edition. McGraw-Hill. {{ISBN|978-0-07-294262-0}}.&lt;/ref&gt;

In other words, if &lt;math&gt;\omega&lt;/math&gt; is the fundamental frequency, then a harmonic spectrum has the form 
:&lt;math&gt;\{\dots, -2\omega, -\omega, 0, \omega, 2\omega, \dots\}.&lt;/math&gt;

A standard result of [[Fourier analysis]] is that a function has a harmonic spectrum if and only if it is [[periodic function|periodic]].

==See also==
* [[Fourier series]]
* [[Harmonic series (music)]]
* [[Periodic function]]
* [[Scale of harmonics]]
* [[Undertone series]]

==References==
{{reflist}}

{{Acoustics}}
{{Mathanalysis-stub}}
{{Signal-processing-stub}}
[[Category:Functional analysis]]</text>
      <sha1>ba1k0mr96lm9se4ieyaj8vapw951vbw</sha1>
    </revision>
  </page>
  <page>
    <title>Hartley kernel</title>
    <ns>0</ns>
    <id>55635282</id>
    <redirect title="Hartley transform" />
    <revision>
      <id>807257204</id>
      <parentid>807256788</parentid>
      <timestamp>2017-10-26T21:44:17Z</timestamp>
      <contributor>
        <username>Matthiaspaul</username>
        <id>13467261</id>
      </contributor>
      <minor/>
      <comment>Matthiaspaul moved page [[Hartkey kernel]] to [[Hartley kernel]] without leaving a redirect: fixed typo</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="122">#redirect [[Hartley transform#cas]] {{R to related topic}}

[[Category:Trigonometry]]
[[Category:Mathematical identities]]</text>
      <sha1>9byejpn03w1jzpmv9w14tckdehezlhd</sha1>
    </revision>
  </page>
  <page>
    <title>Hausdorff–Young inequality</title>
    <ns>0</ns>
    <id>22386332</id>
    <revision>
      <id>814474478</id>
      <parentid>746901509</parentid>
      <timestamp>2017-12-09T01:17:23Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* References */[[User:JCW-CleanerBot#Logic|task]], replaced: journal=[[Annals of Mathematics|Annals of Mathematics. Second Series]] → journal=[[Annals of Mathematics]] |series=Second Series using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4138">In mathematics, the '''Hausdorff−Young inequality''' bounds the [[Lp-norm|''L''&lt;sup&gt;''q''&lt;/sup&gt;-norm]] of the [[Fourier coefficient]]s of a [[periodic function]] for ''q''&amp;nbsp;≥&amp;nbsp;2. {{harvs|txt|authorlink=William Henry Young|first=William Henry|last=Young|year=1913}} proved the inequality for some special values of ''q'', and {{harvs|txt|authorlink=Felix Hausdorff|last=Hausdorff|year=1923}} proved it in general. More generally the inequality also applies to the [[Fourier transform]] of a function on a [[locally compact group]], such as '''R'''&lt;sup&gt;''n''&lt;/sup&gt;, and in this case {{harvtxt|Babenko|1961}} and {{harvtxt|Beckner|1975}} gave a sharper form of it called the [[Babenko–Beckner inequality]].

We consider the [[Fourier series|Fourier operator]], namely let ''T'' be the operator that takes a function &lt;math&gt;f&lt;/math&gt; on the [[unit circle]] and outputs 
the sequence of its Fourier coefficients

: &lt;math&gt;\widehat{f}(n)=\frac{1}{2\pi}\int_0^{2\pi}e^{-inx}f(x)\,dx,\quad n=0,\pm1,\pm2,\dots.&lt;/math&gt;

[[Parseval's theorem]] shows that ''T'' is bounded from &lt;math&gt;L^2&lt;/math&gt; to &lt;math&gt;\ell^2&lt;/math&gt; with norm 1. On the other hand, clearly,

:&lt;math&gt;|(Tf)(n)|=|\widehat{f}(n)|=\left|\frac{1}{2\pi}\int_0^{2\pi}e^{-int}f(t)\,dt\right|\leq \frac{1}{2\pi} \int_0^{2\pi}|f(t)|\,dt&lt;/math&gt;

so ''T'' is bounded from &lt;math&gt;L^1&lt;/math&gt; to &lt;math&gt;\ell^\infty&lt;/math&gt; with norm&amp;nbsp;1. Therefore we may invoke the [[Riesz–Thorin theorem]] to get, for any 1&amp;nbsp;&lt;&amp;nbsp;''p''&amp;nbsp;&lt;&amp;nbsp;2 that ''T'', as an operator from &lt;math&gt;L^p&lt;/math&gt; to &lt;math&gt;\ell^q&lt;/math&gt;, is bounded with norm&amp;nbsp;1, where

:&lt;math&gt;\frac{1}{p}+\frac{1}{q}=1.&lt;/math&gt;

In a short formula, this says that

:&lt;math&gt;\left(\sum_{n=-\infty}^\infty |\widehat{f}(n)|^q\right)^{1/q}\leq
\left( \frac{1}{2\pi}\int_0^{2\pi}|f(t)|^p\,dt\right)^{1/p}.&lt;/math&gt;

This is the well known '''Hausdorff–Young inequality'''. For ''p''&amp;nbsp;&gt;&amp;nbsp;2 the natural extrapolation of this inequality fails, and the fact that a function belongs to &lt;math&gt;L^p&lt;/math&gt;, does not give any additional information on the order of growth of its Fourier series beyond the fact that it is in &lt;math&gt;\ell^2&lt;/math&gt;.

==Optimal estimates==
The constant involved in the Hausdorff–Young inequality can be made optimal by using careful estimates from the theory of [[Harmonic analysis (mathematics)|harmonic analysis]].  If &lt;math&gt;f\in L^p&lt;/math&gt; for &lt;math&gt;1&lt;p\leq 2&lt;/math&gt;, the optimal bound is
:&lt;math&gt;\|\hat{f}\|_{L^q}\leq p^{1/2p}q^{-1/2q}\|f\|_{L^p}&lt;/math&gt;
where &lt;math&gt;q=p/(p-1)&lt;/math&gt; is the Hölder conjugate of &lt;math&gt;p&lt;/math&gt; {{harv|Cifuentes|2010}}

==References==
*{{Citation | last1=Babenko | first1=K. Ivan | title=An inequality in the theory of Fourier integrals |mr=0138939 | year=1961 | journal=Izvestiya Akademii Nauk SSSR. Seriya Matematicheskaya | issn=0373-2436 | volume=25 | pages=531–542}} English transl., Amer. Math. Soc. Transl. (2) 44, pp.&amp;nbsp;115–128
*{{Citation | doi=10.2307/1970980 | last1=Beckner | first1=William | author1-link=William Beckner (mathematician) | title=Inequalities in Fourier analysis |mr=0385456 | year=1975 | journal=[[Annals of Mathematics]] |series=Second Series | issn=0003-486X | volume=102 | issue=1 | pages=159–182 | jstor=1970980}}
*{{citation|title=Harmonic Analysis and Partial Differential Equations|volume=505|series=Contemporary Mathematics|first=Patricio|last=Cifuentes|publisher=American Mathematical Society|year=2010|isbn=9780821858318|page=94|url=https://books.google.com/books?id=ern6j-9vjSgC&amp;pg=PA94}}.
*{{Citation | last1=Hausdorff | first1=Felix | author1-link=Felix Hausdorff | title=Eine Ausdehnung des Parsevalschen Satzes über Fourierreihen | doi=10.1007/BF01175679 | year=1923 | volume=16 | pages=163–169 | journal=Mathematische Zeitschrift}}
*{{Citation | last1=Young | first1=W. H. | author1-link=William Henry Young | title=On the Determination of the Summability of a Function by Means of its Fourier Constants | doi=10.1112/plms/s2-12.1.7 | year=1913 | journal=Proc. London Math. Soc. | volume=12 | pages=71–88}}

{{DEFAULTSORT:Hausdorff-Young inequality}}
[[Category:Inequalities]]
[[Category:Fourier analysis]]</text>
      <sha1>c62z9raoogkxhcpmafl510pla94zpkw</sha1>
    </revision>
  </page>
  <page>
    <title>Hautus lemma</title>
    <ns>0</ns>
    <id>32573740</id>
    <revision>
      <id>867881553</id>
      <parentid>828238916</parentid>
      <timestamp>2018-11-08T15:49:53Z</timestamp>
      <contributor>
        <ip>2402:3A80:1283:6BEC:F452:C823:D533:18DB</ip>
      </contributor>
      <comment>/* Hautus Lemma for observability */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3402">{{Orphan|date=July 2011}}

In [[control theory]] and in particular when studying the properties of a [[linear time-invariant]] system in [[state space]] form, the '''Hautus lemma''', named after [http://www.win.tue.nl/~wscomalo/ Malo Hautus], can prove to be a powerful tool. This result appeared first in &lt;ref&gt;{{cite book|last=Belevitch|first=V.|title=Classical Control Theory|year=1968|publisher=Holden–Day|location=San Francisco}}&lt;/ref&gt; and.&lt;ref&gt;{{cite book|last=Popov|first=V. M.|title=Hyperstability of Control Systems|year=1973|publisher=Springer-Verlag|location=Berlin|pages=320}}&lt;/ref&gt; Today it can be found in most textbooks on control theory.

==The main result==
There exist multiple forms of the lemma.
===Hautus Lemma for controllability===
The Hautus lemma for controllability says that given a square matrix &lt;math&gt;\mathbf{A}\in M_n(\Re)&lt;/math&gt; and a &lt;math&gt;\mathbf{B}\in M_{n\times m}(\Re)&lt;/math&gt; the following are equivalent:
# The pair &lt;math&gt;(\mathbf{A},\mathbf{B})&lt;/math&gt; is [[controllable]]
# For all &lt;math&gt;\lambda\in\mathbb{C}&lt;/math&gt; it holds that &lt;math&gt;\operatorname{rank}[\lambda \mathbf{I}-\mathbf{A},\mathbf{B}]=n&lt;/math&gt;
# For all &lt;math&gt;\lambda\in\mathbb{C}&lt;/math&gt; that are eigenvalues of &lt;math&gt;\mathbf{A}&lt;/math&gt; it holds that &lt;math&gt;\operatorname{rank}[\lambda \mathbf{I}-\mathbf{A},\mathbf{B}]=n&lt;/math&gt;

===Hautus Lemma for stabilizability===
The Hautus lemma for stabilizability says that given a square matrix &lt;math&gt;\mathbf{A}\in M_n(\Re)&lt;/math&gt; and a &lt;math&gt;\mathbf{B}\in M_{n\times m}(\Re)&lt;/math&gt; the following are equivalent:
# The pair &lt;math&gt;(\mathbf{A},\mathbf{B})&lt;/math&gt; is [[stabilizable]]
# For all &lt;math&gt;\lambda\in\mathbb{C}&lt;/math&gt; that are eigenvalues of &lt;math&gt;\mathbf{A}&lt;/math&gt; and for which &lt;math&gt;\Re(\lambda)\ge 0&lt;/math&gt; it holds that &lt;math&gt;\operatorname{rank}[\lambda \mathbf{I}-\mathbf{A},\mathbf{B}]=n&lt;/math&gt;
===Hautus Lemma for observability===
The Hautus lemma for observability says that given a square matrix &lt;math&gt;\mathbf{A}\in M_n(\Re)&lt;/math&gt; and a &lt;math&gt;\mathbf{C}\in M_{m\times n}(\Re)&lt;/math&gt; the following are equivalent:
# The pair &lt;math&gt;(\mathbf{A},\mathbf{C})&lt;/math&gt; is [[observable]]
# For all &lt;math&gt;\lambda\in\mathbb{C}&lt;/math&gt; it holds that &lt;math&gt;\operatorname{rank}[\lambda \mathbf{I}-\mathbf{A};\mathbf{C}]=n&lt;/math&gt;
# For all &lt;math&gt;\lambda\in\mathbb{C}&lt;/math&gt; that are eigenvalues of &lt;math&gt;\mathbf{A}&lt;/math&gt; it holds that &lt;math&gt;\operatorname{rank}[\lambda \mathbf{I}-\mathbf{A};\mathbf{C}]=n&lt;/math&gt;

===Hautus Lemma for detectability===
The Hautus lemma for detectability says that given a square matrix &lt;math&gt;\mathbf{A}\in M_n(\Re)&lt;/math&gt; and a &lt;math&gt;\mathbf{C}\in M_{m\times n}(\Re)&lt;/math&gt; the following are equivalent:
# The pair &lt;math&gt;(\mathbf{A},\mathbf{C})&lt;/math&gt; is [[detectable]]
# For all &lt;math&gt;\lambda\in\mathbb{C}&lt;/math&gt; that are eigenvalues of &lt;math&gt;\mathbf{A}&lt;/math&gt; and for which &lt;math&gt;\Re(\lambda)\ge 0&lt;/math&gt; it holds that &lt;math&gt;\operatorname{rank}[\lambda \mathbf{I}-\mathbf{A};\mathbf{C}]=n&lt;/math&gt;

==References==
*{{cite book|last=Sontag|first=Eduard D.|title=Mathematical Control Theory: Deterministic Finite-Dimensional Systems.|year=1998|publisher=Springer|location=New York|isbn=0-387-98489-5}}
*{{cite book|last=Zabczyk|first=Jerzy|title=Mathematical Control Theory – An introduction|year=1995|publisher=Birkhauser|location=Boston|isbn=3-7643-3645-5}}

&lt;references/&gt;



[[Category:Control theory]]
[[Category:Lemmas]]</text>
      <sha1>btcf93co9dlxjzhqvt6ctd34mse4y2c</sha1>
    </revision>
  </page>
  <page>
    <title>Hierarchical temporal memory</title>
    <ns>0</ns>
    <id>11273721</id>
    <revision>
      <id>867873422</id>
      <parentid>867873015</parentid>
      <timestamp>2018-11-08T14:48:47Z</timestamp>
      <contributor>
        <username>Nbro</username>
        <id>23779285</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="31688">{{More citations needed|date=July 2011}}
'''Hierarchical temporal memory''' ('''HTM''') is a biologically constrained theory (or model) of intelligence, originally described in the 2004 book ''[[On Intelligence]]''&lt;ref&gt;{{Cite journal|date=2016-12-04|title=On Intelligence|url=https://en.wikipedia.org/w/index.php?title=On_Intelligence&amp;oldid=752902753|journal=Wikipedia|language=en}}&lt;/ref&gt; by [[Jeff Hawkins]] with [[Sandra Blakeslee]]. HTM is based on [[neuroscience]] and the [[physiology]] and interaction of [[Pyramidal cell|pyramidal neurons]] in the [[neocortex]] of the [[Mammal|mammalian]] (in particular, human) brain. 

At the core of HTM are learning algorithms that can store, learn, infer and recall high-order sequences. Unlike most other machine learning methods, HTM learns (in an [[Unsupervised learning|unsupervised]] fashion) time-based patterns in unlabeled data on a continuous basis. HTM is robust to noise, and it has high capacity, meaning that it can learn multiple patterns simultaneously. When applied to computers, HTM is well suited for prediction,&lt;ref&gt;{{cite journal | doi = 10.1162/NECO_a_00893 | volume=28 | title=Continuous Online Sequence Learning with an Unsupervised Neural Network Model | year=2016 | journal=Neural Computation | pages=2474–2504 | last1 = Cui | first1 = Yuwei | last2 = Ahmad | first2 = Subutai | last3 = Hawkins | first3 = Jeff| arxiv=1512.05463 }}&lt;/ref&gt; anomaly detection,&lt;ref&gt;{{cite journal | doi = 10.1016/j.neucom.2017.04.070 | volume=262 | title=Unsupervised real-time anomaly detection for streaming data | year=2017 | journal=Neurocomputing | pages=134–147 | last1 = Ahmad | first1 = Subutai | last2 = Lavin | first2 = Alexander | last3 = Purdy | first3 = Scott | last4 = Agha | first4 = Zuha}}&lt;/ref&gt; classification and ultimately sensorimotor applications.&lt;ref&gt;{{Cite web|url=https://discourse.numenta.org/t/preliminary-details-about-new-theory-work-on-sensory-motor-inference/697|title=Preliminary details about new theory work on sensory-motor inference|website=HTM Forum|language=en|access-date=2017-03-14}}&lt;/ref&gt;

The theory has been tested and implemented in software through example applications from [[Numenta]] and a few commercial applications from Numenta's partners.

== HTM structure and algorithms ==
A typical HTM network is a [[Tree (data structure)|tree]]-shaped hierarchy of ''levels'' (which should ''not'' be confused with the "''layers''" of the [[neocortex]], as described [[Hierarchical temporal memory#Second generation: cortical learning algorithms|below]]) that are composed of smaller elements called ''region''s (or nodes). A single level in the hierarchy possibly contains several regions. Higher hierarchy levels often have fewer regions. Higher hierarchy levels can reuse patterns learned at the lower levels by combining them to memorize more complex patterns.

Each HTM region has the same basic functionality. In learning and inference modes, sensory data (e.g. data from the eyes) comes into the bottom level regions. In generation mode, the bottom level regions output the generated pattern of a given category. The top level usually has a single region that stores the most general categories (concepts) which determine, or are determined by, smaller concepts in the lower levels which are more restricted in time and space{{clarify|date=August 2018}}. When set in inference mode, a region (in each level) interprets information coming in from its child regions in the lower level as probabilities of the categories it has in memory.

Each HTM region learns by identifying and memorizing spatial patterns, which are combinations of input bits that often occur at the same time. It then identifies temporal sequences of spatial patterns that are likely to occur one after another.

== HTM as an evolving theory==

HTM is an evolving theory (or model), that is, it isn't yet a complete theory, as our knowledge of the [[neocortex]] is incomplete. The new findings on the neocortex are thus progressively incorporated into the HTM model, which can thus change over time. The new findings do not necessarily invalidate the previous ones, so ideas from one generation are not necessarily excluded in its successive one. Because of this evolving nature of the theory, there have been several generations of HTM algorithms &lt;ref&gt;[https://www.youtube.com/watch?v=6_wattbWgiU&amp;t= HTM Retrospective]&lt;/ref&gt;, which are briefly described below.

=== First generation: zeta 1 ===

The first generation of HTM algorithms (or the first version of the HTM theory) is sometimes referred to as ''zeta 1''.

==== Training ====

During ''training'', a node (or region) receives a temporal sequence of spatial patterns as its input. The learning process consists of two stages: 

# The '''spatial pooling''' identifies (in the input) frequently observed patterns and memorizes them as "coincidences". Patterns that are significantly similar to each other are treated as the same coincidence. A large number of possible input patterns are reduced to a manageable number of known coincidences.
# The '''temporal pooling''' partitions coincidences that are likely to follow each other in the training sequence into temporal groups. Each group of patterns represents a "cause" of the input pattern (or "name" in ''On Intelligence'').

The concepts of ''spatial pooling'' and ''temporal pooling'' are still quite important in the current HTM theory. Temporal pooling is not yet well understood, and its meaning has changed over time (as the HTM theory evolved).

==== Inference ==== 

During '''inference''', the node calculates the set of probabilities that a pattern belongs to each known coincidence. Then it calculates the probabilities that the input represents each temporal group. The set of probabilities assigned to the groups is called a node's "belief" about the input pattern. (In a simplified implementation, node's belief consists of only one winning group). This belief is the result of the inference that is passed to one or more "parent" nodes in the next higher level of the hierarchy.

"Unexpected" patterns to the node do not have a dominant probability of belonging to any one temporal group, but have nearly equal probabilities of belonging to several of the groups. If sequences of patterns are similar to the training sequences, then the assigned probabilities to the groups will not change as often as patterns are received.  The output of the node will not change as much, and a resolution in time{{clarify|reason=What exactly is meant by "resolution" and "resolution in time" here?|date=August 2018}} is lost.

In a more general scheme, the node's belief can be sent to the input of any node(s) in any level(s), but the connections between the nodes are still fixed. The higher-level node combines this output with the output from other child nodes thus forming its own input pattern.

Since resolution in space and time is lost in each node as described above, beliefs formed by higher-level nodes represent an even larger range of space and time. This is meant to reflect the organization of the physical world as it is perceived by human brain. Larger concepts (e.g. causes, actions and objects) are perceived to change more slowly and consist of smaller concepts that change more quickly. Jeff Hawkins postulates that brains evolved this type of hierarchy to match, predict, and affect the organization of the external world.


More details about the functioning of Zeta 1 HTM can be found in Numenta's old documentation.&lt;ref&gt;[https://web.archive.org/web/20090527174304/http://numenta.com/for-developers/education/general-overview-htm.php Numenta old documentation]&lt;/ref&gt;

=== Second generation: cortical learning algorithms ===
The second generation of HTM learning algorithms, often referred to as cortical learning algorithms (CLA), was drastically different from zeta 1. It relies on a [[data structure]] called '''[[Sparse coding|sparse distributed representations]]''' (that is, a data structure whose elements are binary, 1 or 0, and whose number of 1 bits is small compared to the number of 0 bits) to represent the brain activity and a more biologically-realistic neuron model (often also referred to as '''cell''', in the context of the HTM theory).&lt;ref&gt;[https://www.youtube.com/watch?v=48r-IeYOvG4 Jeff Hawkins lecture describing cortical learning algorithms]&lt;/ref&gt; There are two core components in this HTM theory: a '''spatial pooling''' algorithm &lt;ref&gt;{{cite journal | doi = 10.3389/fncom.2017.00111 | volume=11 | title=The HTM Spatial Pooler—A Neocortical Algorithm for Online Sparse Distributed Coding | year=2017 | journal=Frontiers in Computational Neuroscience | last1 = Cui | first1 = Yuwei | last2 = Ahmad | first2 = Subutai | last3 = Hawkins | first3 = Jeff}}&lt;/ref&gt;, which outputs [[Sparse distributed representation|sparse distributed representations]] (SDR), and a '''sequence memory''' algorithm&lt;ref name="Neuronpaper"/&gt;, which learns to represent and predict complex sequences.

In this new generation, the '''[[cerebral cortex#Layers|layers]]''' and '''[[Cortical minicolumn|minicolumns]]''' of the [[cerebral cortex]] are addressed and partially modeled. Each HTM layer (not to be confused with an HTM level of an HTM hierarchy, as described [[Hierarchical temporal memory#HTM structure and algorithms|above]]) consists of a number of highly interconnected minicolumns. An HTM layer creates a sparse distributed representation from its input, so that a fixed percentage of ''[[Cortical minicolumn|minicolumns]]'' are active at any one time{{clarify|reason=What is the connection between the sparse distributed representation and the minicolumns?|date=August 2018}}. A minicolumn is understood as a group of cells that have the same [[receptive field]]. Each minicolumn has a number of cells that are able to remember several previous states. A cell can be in one of three states: ''active'', ''inactive'' and ''predictive'' state.

==== Spatial pooling ====

The receptive field of each minicolumn is a fixed number of inputs that are randomly selected from a much larger number of node inputs. Based on the (specific) input pattern, some minicolumns will be more or less associated with the active input values. '''Spatial pooling''' selects a relatively constant number of the most active minicolumns and inactivates (inhibits) other minicolumns in the vicinity of the active ones. Similar input patterns tend to activate a stable set of minicolumns. The amount of memory used by each layer can be increased to learn more complex spatial patterns or decreased to learn simpler patterns.

===== Active, inactive and predictive cells ===== 

As mentioned above, a cell (or a neuron) of a minicolumn, at any point in time, can be in an active, inactive or predictive state. Initially, cells are inactive.

====== How do cells become active? ====== 

If one or more cells in the active minicolumn are in the ''predictive'' state (see below), they will be the only cells to become active in the current time step. If none of the cells in the active minicolumn are in the predictive state (which happens during the initial time step or when the activation of this minicolumn was not expected), all cells are made active.

====== How do cells become predictive? ======

When a cell becomes active, it gradually forms connections to nearby cells that tend to be active during several previous time steps. Thus a cell learns to recognize a known sequence by checking whether the connected cells are active. If a large number of connected cells are active, this cell switches to the ''predictive'' state in anticipation of one of the few next inputs of the sequence. 

===== The ouput of a minicolumn =====

The output of a layer includes minicolumns in both active and predictive states. Thus minicolumns are active over longer periods of time, which leads to greater temporal stability seen by the parent layer.

==== Inference and online learning ====

Cortical learning algorithms are able to learn continuously from each new input pattern, therefore no separate inference mode is necessary. During inference, HTM tries to match the stream of inputs to fragments of previously learned sequences. This allows each HTM layer to be constantly predicting the likely continuation of the recognized sequences. The index of the predicted sequence is the output of the layer. Since predictions tend to change less frequently than the input patterns, this leads to increasing temporal stability of the output in higher hierarchy levels. Prediction also helps to fill in missing patterns in the sequence and to interpret ambiguous data by biasing the system to infer what it predicted.

==== Applications of the CLAs ====

Cortical learning algorithms are currently being offered as commercial [[SaaS]] by Numenta (such as Grok&lt;ref&gt;[http://grokstream.com/product/ Grok Product Page]&lt;/ref&gt;).

==== The validity of the CLAs ====

The following question was posed to Jeff Hawkins September 2011 with regard to cortical learning algorithms: "How do you know if the changes you are making to the model are good or not?" To which Jeff's response was "There are two categories for the answer:  one is to look at neuroscience, and the other is methods for machine intelligence. In the neuroscience realm there are many predictions that we can make, and those can be tested. If our theories explain a vast array of neuroscience observations then it tells us that we’re on the right track. In the machine learning world they don’t care about that, only how well it works on practical problems. In our case that remains to be seen. To the extent you can solve a problem that no one was able to solve before, people will take notice."&lt;ref name="ai.stanford.edu"&gt;[http://ai.stanford.edu/~joni/papers/LasersonXRDS2011.pdf From Neural Networks to Deep Learning: Zeroing in on the Human Brain]&lt;/ref&gt;

=== Third generation: sensorimotor inference ===
The third generation builds on the second generation and adds in a theory of sensorimotor inference in the neocortex.&lt;ref&gt;{{cite journal | doi = 10.3389/fncir.2017.00081 | volume=11 | title=A Theory of How Columns in the Neocortex Enable Learning the Structure of the World | year=2017 | journal=Frontiers in Neural Circuits | last1 = Hawkins | first1 = Jeff | last2 = Ahmad | first2 = Subutai | last3 = Cui | first3 = Yuwei}}&lt;/ref&gt;&lt;ref&gt;[https://www.youtube.com/watch?v=yVT7dO_Tf4E Have We Missed Half of What the Neocortex Does? Allocentric Location as the Basis of Perception]&lt;/ref&gt; This theory proposes that [[cortical column]]s at every level of the hierarchy can learn complete models of objects over time and that features are learned at specific locations on the objects.

== Comparison of neuron models ==

[[File:Neuron comparison.png|thumb|center|upright=1.7|500px|Comparing the artificial neural network (A), the biological neuron (B), and the HTM neuron (C).]]
:      {|class="wikitable" border="1" cellpadding="4"  cellspacing="4"
        |+ Comparison of Neuron Models
        ! Artificial Neural Network (ANN)
        ! Neocortical Pyramidal Neuron (Biological Neuron)
        ! HTM Model Neuron&lt;ref name=Neuronpaper&gt;[https://www.frontiersin.org/articles/10.3389/fncir.2016.00023/full Why Neurons Have Thousands of Synapses, a Theory of Sequence Memory in Neocortex]&lt;/ref&gt;&lt;/center&gt;
        |- style="vertical-align:top"
        | {{bulleted list | Few synapses| No dendrites| Sum input x weights| Learns by modifying weights of synapses}}
        | {{bulleted list | Thousands of synapses on the dendrites| Active dendrites: cell recognizes hundreds of unique patterns
| Co-activation of a set of synapses on a dendritic segment causes an NMDA spike{{clarify|reason=What is a NMDA spike?|date=August 2018}} and depolarization{{clarify|reason=What do we mean by "depolarization" here?|date=August 2018}} at the soma 
| Sources of input to the cell:
# Feedforward inputs which form synapses proximal to the soma and directly lead to action potentials
# NMDA spikes generated in the more distal basal{{clarify|reason=What is the distal basal?|date=August 2018}}
# Apical dendrites that depolarize the soma (usually not sufficient enough to generate a somatic action potential)
| Learns by growing new synapses}}
        | {{bulleted list | Inspired by the pyramidal cells in neocortex layers 2/3 and 5| Thousands of synapses| Active dendrites: cell recognizes hundreds of unique patterns| Models dendrites and NMDA spikes with each array of coincident detectors having a set of synapses| Learns by modeling the growth of new synapses}}
        |}

==Comparing HTM and neocortex==
HTM attempts to implement the functionality that is characteristic of a hierarchically related group of cortical regions in the neocortex. A ''region'' of the neocortex corresponds to one or more ''levels'' in the HTM hierarchy, while the [[hippocampus]] is remotely similar to the highest HTM level. A single HTM node may represent a group of [[cortical column]]s within a certain region.

Although it is primarily a functional model, several attempts have been made to relate the algorithms of the HTM with the structure of neuronal connections in the layers of neocortex.&lt;ref&gt;[[Jeff Hawkins]], [[Sandra Blakeslee]] ''[[On Intelligence]]''&lt;/ref&gt;&lt;ref&gt;[http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000532 Towards a Mathematical Theory of Cortical Micro-circuits. Dileep George and Jeff Hawkins. PLoS Computational Biology 5(10)]&lt;/ref&gt; The neocortex is organized in vertical columns of 6 horizontal layers.  The 6 layers of cells in the neocortex should not be confused with levels in an HTM hierarchy.

HTM nodes attempt to model a portion of cortical columns (80 to 100 neurons) with approximately 20 HTM "cells" per column.  HTMs model only layers 2 and 3 to detect spatial and temporal features of the input with 1 cell per column in layer 2 for spatial "pooling", and 1 to 2 dozen per column in layer 3 for temporal pooling. A key to HTMs and the cortex's is their ability to deal with noise and variation in the input which is a result of using a "sparse distributive representation" where only about 2% of the columns are active at any given time.

An HTM attempts to model a portion of the cortex's learning and plasticity as described above. Differences between HTMs and neurons include:&lt;ref&gt;[https://numenta.org/resources/HTM_CorticalLearningAlgorithms.pdf HTM Cortical Learning Algorithms]&lt;/ref&gt;
* strictly binary signals and synapses
* no direct inhibition of synapses or dendrites (but simulated indirectly)
* currently only models layers 2/3 and 4 (no 5 or 6)
* no "motor" control (layer 5)
* no feed-back between regions (layer 6 of high to layer 1 of low)

==Sparse distributed representations==
Integrating memory component with neural networks has a long history dating back to early research in distributed representations&lt;ref&gt;[http://repository.cmu.edu/cgi/viewcontent.cgi?article=2841&amp;context=compsci Hinton, Geoffrey E. "Distributed representations." (1984).]&lt;/ref&gt;&lt;ref&gt;[https://www.ijcai.org/Proceedings/91-1/Papers/006.pdf Plate, Tony. "Holographic Reduced Representations: Convolution Algebra for Compositional Distributed Representations." IJCAI, 1991.]&lt;/ref&gt; and [[self-organizing map]]s. For example, in [[sparse distributed memory]] (SDM), the patterns encoded by neural networks are used as memory addresses for [[content-addressable memory]], with "neurons" essentially serving as address [[encoder]]s and decoders.&lt;ref name=kanerva1988&gt;[https://mitpress.mit.edu/books/sparse-distributed-memory Kanerva, Pentti. Sparse distributed memory. MIT press, 1988.]&lt;/ref&gt;&lt;ref&gt;[https://pdfs.semanticscholar.org/9810/4c7fabf6232715ef2bea1f5b3a3425e1c3af.pdf Snaider, Javier, and Stan Franklin. "Integer sparse distributed memory." Twenty-fifth international flairs conference, 2012.]&lt;/ref&gt;

Computers store information in "dense" representations such as a 32 bit word where all combinations of 1s and 0s are possible.
By contrast, brains use sparse distributed representations (SDR).&lt;ref&gt;{{cite journal|url = http://www.sciencedirect.com/science/article/pii/S0042698997001697 | doi=10.1016/S0042-6989(97)00169-7 | volume=37 | title=Sparse coding with an overcomplete basis set: A strategy employed by V1? | year=1997 | journal=Vision Research | pages=3311–3325 | last1 = Olshausen | first1 = Bruno A. | last2 = Field | first2 = David J.}}&lt;/ref&gt; The human neocortex has roughly 100 billion neurons, but at any given time only a small percent are active. The activity of neurons are like bits in a computer, and therefore the representation is sparse. Similarly to [[Sparse distributed memory|SDM]] developed by [[NASA]] in the 80s&lt;ref name="kanerva1988"/&gt; and [[vector space]] models used in [[Latent semantic analysis]], HTM also uses Sparse Distributed Representations.&lt;ref name="nupicSDRs"&gt;[https://arxiv.org/abs/1601.00720 Numenta NUPIC  - Sparse Distributed representations]&lt;/ref&gt;

The SDRs used in HTM are binary representations of data consisting of many bits with a small percentage of the bits active (1s); a typical implementation might have 2048 columns and 64K artificial neurons where as few as 40 might be active at once.  Although it may seem less efficient for the majority of bits to go "unused" in any given representation, SDRs have two major advantages over traditional dense representations.  First, SDRs are tolerant of corruption and ambiguity due to the meaning of the representation being shared (''distributed'') across a small percentage (''sparse'') of active bits.  In a dense representation, flipping a single bit completely changes the meaning, while in an SDR a single bit may not affect the overall meaning much.  This leads to the second advantage of SDRs: because the meaning of a representation is distributed across all active bits, similarity between two representations can be used as a measure of [[semantic]] similarity in the objects they represent.  That is, if two vectors in an SDR have 1s in the same position, then they are semantically similar in that attribute.  The bits in SDRs have semantic meaning, and that meaning is distributed across the bits.&lt;ref name="nupicSDRs"/&gt;

The [[semantic folding]] theory&lt;ref&gt;[https://arxiv.org/abs/1511.08855 Semantic Folding Theory And its Application in Semantic Fingerprinting by Francisco De Sousa Webber]&lt;/ref&gt; builds on these SDR properties to propose a new model for language semantics, where words are encoded into word-SDRs and the similarity between terms, sentences and texts can be calculated with simple distance measures.

== Similarity to other models ==

=== Bayesian networks ===
Likened to a [[Bayesian network]], an HTM comprises a collection of nodes that are arranged in a tree-shaped hierarchy. Each node in the hierarchy discovers an array of causes in the input patterns and temporal sequences it receives. A Bayesian [[belief revision]] algorithm is used to propagate feed-forward and feedback beliefs from child to parent nodes and vice versa. However, the analogy to Bayesian networks is limited, because HTMs can be self-trained (such that each node has an unambiguous family relationship), cope with time-sensitive data, and grant mechanisms for covert attention.

A theory of hierarchical cortical computation based on Bayesian [[belief propagation]] was proposed earlier by Tai Sing Lee and [[David Mumford]].&lt;ref&gt;[http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.12.2565 Tai Sing Lee, David Mumford "Hierarchical Bayesian Inference in the Visual Cortex"], 2002&lt;/ref&gt; While HTM is mostly consistent with these ideas, it adds details about handling invariant representations in the visual cortex.&lt;ref&gt;[http://dileepgeorge.com/blog/?p=5 Hierarchical Bayesian inference in the visual cortex]&lt;/ref&gt;

=== Neural networks ===
Like any system that models details of the neocortex, HTM can be viewed as an [[artificial neural network]]. The tree-shaped hierarchy commonly used in HTMs resembles the usual topology of traditional neural networks. HTMs attempt to model cortical columns (80 to 100 neurons) and their interactions with fewer HTM "neurons". The goal of current HTMs is to capture as much of the functions of neurons and the network (as they are currently understood) within the capability of typical computers and in areas that can be made readily useful such as image processing.  For example, feedback from higher levels and motor control are not attempted because it is not yet understood how to incorporate them and binary instead of variable synapses are used because they were determined to be sufficient in the current HTM capabilities.

LAMINART and similar neural networks researched by Stephen Grossberg attempt to model both the infrastructure of the cortex and the behavior of neurons in a temporal framework to explain neurophysiological and psychophysical data.  However, these networks are, at present, too complex for realistic application.&lt;ref&gt;[http://cns.bu.edu/Profiles/Grossberg/GroCisek2007.pdf Grossberg, S. (2007). Towards a unified theory of neocortex: Laminar cortical circuits for vision and cognition. Technical Report CAS/CNS-TR-2006-008. For Computational Neuroscience: From Neurons to Theory and Back Again, eds: Paul Cisek, Trevor Drew, John Kalaska; Elsevier, Amsterdam, pp. 79-104.]&lt;/ref&gt;

HTM is also related to work by [[Tomaso Poggio]], including an approach for modeling the ventral stream of the visual cortex known as HMAX. Similarities of HTM to various AI ideas are described in the December 2005 issue of the Artificial Intelligence journal.&lt;ref&gt;[http://www.sciencedirect.com/science?_ob=PublicationURL&amp;_tockey=%23TOC%235617%232005%23998309997%23611936%23FLP%23&amp;_cdi=5617&amp;_pubType=J&amp;_auth=y&amp;_acct=C000050221&amp;_version=1&amp;_urlVersion=0&amp;_userid=10&amp;md5=f615b2c83ddfc9cbdf503c1f05f173d8 ScienceDirect - Artificial Intelligence, Volume 169, Issue 2, Page 103-212 (December 2005)]&lt;/ref&gt;

=== Neocognitron ===
[[Neocognitron]], a hierarchical multilayered neural network proposed by Professor Kunihiko Fukushima in 1987, is one of the first Deep Learning Neural Networks models.&lt;ref&gt;[http://www.scholarpedia.org/article/Neocognitron Neocognitron at Scholarpedia]&lt;/ref&gt;

== NuPIC platform and development tools ==

The [https://github.com/numenta/nupic Numenta Platform for Intelligent Computer (NuPIC)] is one of several available [https://numenta.org/implementations/ HTM implementations]. Some are provided by [https://numenta.com/ Numenta], while some are developed and maintained by the [https://numenta.org/ HTM open source community].

NuPIC includes implementations of Spatial Pooling and Temporal Memory in both C++ and Python. It also includes [http://nupic.docs.numenta.org/stable/api/ 3 APIs]. Users can construct HTM systems using direct implementations of the [http://nupic.docs.numenta.org/stable/quick-start/algorithms.html algorithms], or construct a Network using the [http://nupic.docs.numenta.org/stable/quick-start/network.html Network API], which is a flexible framework for constructing complicated associations between different Layers of cortex.

[https://github.com/numenta/nupic/releases/tag/1.0.0 NuPIC 1.0] was released on July 2017, after which the codebase was put into maintenance mode. Current research continues in Numenta [https://github.com/numenta/htmresearch research codebases].

==Applications==
The following commercial applications are available using NuPIC: 
* Grok - anomaly detection for IT servers, see [http://www.grokstream.com www.grokstream.com]
* Cortical.io - advanced natural language processing, see [http://www.cortical.io www.cortical.io]
The following tools are available on NuPIC:
* HTM Studio - find anomalies in time series using your own data, see www.[http://www.Numenta.com/htm-studio/ numenta.com/htm-studio/]
* Numenta Anomaly Benchmark - compare HTM anomalies with other anomaly detection techniques, see https://numenta.com/numenta-anomaly-benchmark/
The following example applications are available on NuPIC, see http://numenta.com/applications/:
* HTM for stocks - example of tracking anomalies in the stock market (sample code)
* Rogue behavior detection - example of finding anomalies in human behavior (white paper and sample code)
* Geospatial tracking - example of finding anomalies in objectives moving through space and time (white paper and sample code)

== See also ==
*[[Neocognitron]]
*[[Deep learning]]
*[[Convolutional neural network]]
*[[Artificial general intelligence|Strong AI]]
*[[Artificial consciousness]]
*[[Cognitive architecture]]
*''[[On Intelligence]]''
*[[Memory-prediction framework]]
*[[Belief revision]]
*[[Belief propagation]]
*[[Bionics]]
*[[List of artificial intelligence projects]]
*[[Memory Network]]
*[[Neural Turing Machine]]
*[[Multiple trace theory]]

=== Related models ===
*[[Hierarchical hidden Markov model]]
*[[Bayesian networks]]
*[[Neural networks]]

== References ==
{{Reflist}}

== External links ==

=== Official ===
*[https://www.youtube.com/watch?v=nBYddmFg4nQ Cortical Learning Algorithm overview] (Accessed May 2013)
*[http://www.numenta.com/htm-overview/education/HTM_CorticalLearningAlgorithms.pdf HTM Cortical Learning Algorithms] (PDF Sept. 2011)
*[http://www.numenta.com Numenta, Inc.]
*[https://web.archive.org/web/20110714212402/http://www.numenta.com/htm-overview/education.php HTM Cortical Learning Algorithms Archive]
*[http://fora.tv/2009/09/09/Hierarchical_Temporal_Memory_Subutai_Ahmad#fullprogram Association for Computing Machinery talk from 2009 by Subutai Ahmad from Numenta]
*[http://www.onintelligence.org/forum OnIntelligence.org Forum], an [[Internet forum]] for the discussion of relevant topics, especially relevant being the [http://www.onintelligence.org/forum/viewforum.php?f=3 Models and Simulation Topics] forum.
*[http://www.almaden.ibm.com/institute/resources/2006/Almaden%20Institute%20Jeff%20Hawkins.ppt Hierarchical Temporal Memory] (Microsoft PowerPoint presentation)
*[https://www.youtube.com/watch?v=z6r3ekreRzY Cortical Learning Algorithm Tutorial: CLA Basics], talk about the cortical learning algorithm (CLA) used by the HTM model on [[YouTube]]

=== Other ===
*[http://bias.csr.unibo.it/maltoni/HTM_TR_v1.0.pdf Pattern Recognition by Hierarchical Temporal Memory] by Davide Maltoni, April 13, 2011
*[http://vicarious.com/ Vicarious] Startup rooted in HTM by Dileep George
*[http://www.gartner.com/research/fellows/fellows_interview_jeff_hawkins_tom_austin.jsp The Gartner Fellows: Jeff Hawkins Interview] by Tom Austin, ''[[Gartner]]'', March 2, 2006
*[http://www.cioinsight.com/article2/0,1540,1955963,00.asp Emerging Tech: Jeff Hawkins reinvents artificial intelligence] by Debra D'Agostino and Edward H. Baker, ''CIO Insight'', May 1, 2006
*[http://insight.zdnet.co.uk/hardware/emergingtech/0,39020439,39268542,00.htm "Putting your brain on a microchip"] by Stefanie Olsen, ''[[CNET|CNET News.com]]'', May 12, 2006
*[https://www.wired.com/wired/archive/15.03/hawkins.html "The Thinking Machine"] by Evan Ratliff, [[Wired (magazine)|Wired]], March 2007
*[http://spectrum.ieee.org/apr07/4982 Think like a human] by Jeff Hawkins, [[IEEE Spectrum]], April 2007
*[http://sourceforge.net/projects/neocortex Neocortex - Memory-Prediction Framework] — [[Open Source]] Implementation with [[GNU General Public License]]
*[https://web.archive.org/web/20130820231210/http://blog.mohammadzadeh.info/index.php/hierarchical-temporal-memory-related-papers Hierarchical Temporal Memory related Papers and Books]

[[Category:Belief revision]]
[[Category:Artificial neural networks]]
[[Category:Deep learning]]
[[Category:Unsupervised learning]]
[[Category:Semisupervised learning]]</text>
      <sha1>sh2rlx9kzxqzifrkjjcv68mwycanbzj</sha1>
    </revision>
  </page>
  <page>
    <title>Holland's schema theorem</title>
    <ns>0</ns>
    <id>4329360</id>
    <revision>
      <id>842274286</id>
      <parentid>818139598</parentid>
      <timestamp>2018-05-21T11:40:10Z</timestamp>
      <contributor>
        <username>Jtaylor100</username>
        <id>32780519</id>
      </contributor>
      <minor/>
      <comment>/* Description */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5650">'''Holland's schema theorem''', also called the '''fundamental theorem of genetic algorithms''',&lt;ref&gt;{{cite conference |last1=Bridges |first1=Clayton L. |first2=David E. |last2=Goldberg |title=An analysis of reproduction and crossover in a binary-coded genetic algorithm |conference=2nd Int'l Conf. on Genetic Algorithms and their applications |year=1987|url=https://books.google.com/books?id=MYJ_AAAAQBAJ&amp;printsec=frontcover#v=onepage&amp;q=%22An%20analysis%20of%20reproduction%20and%20crossover%20in%20a%20binary-coded%20genetic%20algorithm%22&amp;f=false}}&lt;/ref&gt; is an inequality that results from coarse-graining an equation for evolutionary dynamics.  The Schema Theorem says that short, low-order schemata with above-average fitness increase exponentially in frequency in successive generations. The theorem was proposed by [[John Henry Holland|John Holland]] in the 1970s. It was initially widely taken to be the foundation for explanations of the power of [[genetic algorithm]]s. However, this interpretation of its implications has been criticized in several publications reviewed in &lt;ref&gt;Altenberg, L. (1995). [http://dynamics.org/Altenberg/FILES/LeeSTPT.pdf The Schema Theorem and Price’s Theorem]. Foundations of genetic algorithms, 3, 23-49.&lt;/ref&gt;, where the Schema Theorem is shown to be a special case of the [[Price equation]] with the schema indicator function as the macroscopic measurement.  

A [[schema (genetic algorithms)|schema]] is a template that identifies a [[subset]] of strings with similarities at certain string positions. Schemata are a special case of [[cylinder set]]s, and hence form a [[topological space]].

== Description ==

Consider binary strings of length 6. The schema &lt;code&gt;1*10*1&lt;/code&gt; describes the set of all strings of length 6 with 1's at positions 1, 3 and 6 and a 0 at position 4. The * is a [[Wildcard character|wildcard]] symbol, which means that positions 2 and 5 can have a value of either 1 or 0. The ''order of a schema'' &lt;math&gt; o(H)&lt;/math&gt; is defined as the number of fixed positions in the template, while the ''[[defining length]]'' &lt;math&gt; \delta(H) &lt;/math&gt; is the distance between the first and last specific positions. The order of &lt;code&gt;1*10*1&lt;/code&gt; is 4 and its defining length is 5. The ''fitness of a schema'' is the average fitness of all strings matching the schema. The fitness of a string is a measure of the value of the encoded problem solution, as computed by a problem-specific evaluation function. Using the established methods and [[genetic operator]]s of [[genetic algorithms]], the schema theorem states that short, low-order schemata with above-average fitness increase exponentially in successive generations. Expressed as an equation:

:&lt;math&gt;\operatorname{E}(m(H,t+1)) \geq {m(H,t) f(H) \over a_t}[1-p].&lt;/math&gt;

Here &lt;math&gt;m(H,t)&lt;/math&gt; is the number of strings belonging to schema &lt;math&gt;H&lt;/math&gt; at generation &lt;math&gt;t&lt;/math&gt;, &lt;math&gt;f(H)&lt;/math&gt; is the ''observed'' average fitness of schema &lt;math&gt;H&lt;/math&gt; and &lt;math&gt;a_t&lt;/math&gt; is the ''observed'' average fitness at generation &lt;math&gt;t&lt;/math&gt;. The probability of disruption &lt;math&gt;p&lt;/math&gt; is the probability that crossover or mutation will destroy the schema &lt;math&gt;H&lt;/math&gt;. It can be expressed as:

:&lt;math&gt;p = {\delta(H) \over l-1}p_c + o(H) p_m&lt;/math&gt;

where &lt;math&gt; o(H)&lt;/math&gt; is the order of the schema, &lt;math&gt;l&lt;/math&gt; is the length of the code, &lt;math&gt; p_m&lt;/math&gt; is the probability of mutation and &lt;math&gt; p_c &lt;/math&gt; is the probability of crossover. So a schema with a shorter defining length &lt;math&gt; \delta(H) &lt;/math&gt; is less likely to be disrupted.&lt;br /&gt;An often misunderstood point is why the Schema Theorem is an ''inequality'' rather than an equality. The answer is in fact simple: the Theorem neglects the small, yet non-zero, probability that a string belonging to the schema &lt;math&gt;H&lt;/math&gt; will be created "from scratch" by mutation of a single string (or recombination of two strings) that did ''not'' belong to &lt;math&gt;H&lt;/math&gt; in the previous generation.

==Limitation==
[[File:Bimodal-bivariate-small.png|thumb|right|Plot of a multimodal function in two variables.]]
The schema theorem holds under the assumption of a genetic algorithm that maintains an infinitely large population, but does not always carry over to (finite) practice: due to [[sampling error]] in the initial population, genetic algorithms may converge on schemata that have no selective advantage. This happens in particular in [[multimodal distribution|multimodal optimization]], where a function can have multiple peaks: the population may [[genetic drift|drift]] to prefer one of the peaks, ignoring the others.&lt;ref&gt;{{cite conference |first1=Goldberg |last1=David E. |first2=Jon |last2=Richardson |title=Genetic algorithms with sharing for multimodal function optimization |conference=2nd Int'l Conf. on Genetic Algorithms and their applications |year=1987|url=https://books.google.com/books?id=MYJ_AAAAQBAJ&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false}}&lt;/ref&gt;

The reason that the Schema Theorem cannot explain the power of genetic algorithms is that it holds for all problem instances, and cannot distinguish between problems in which genetic algorithms perform poorly, and problems for which genetic algorithms perform well.

==References==
{{reflist}}

* J. Holland, ''[https://books.google.com/books?id=5EgGaBkwvWcC&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false Adaptation in Natural and Artificial Systems]'', The MIT Press; Reprint edition 1992 (originally published in 1975).
* J. Holland, ''Hidden Order: How Adaptation Builds Complexity'', Helix Books; 1996.

[[Category:Genetic algorithms]]
[[Category:Theorems in discrete mathematics]]</text>
      <sha1>ruko64je4dis7icq4k8dt6jb0rwzvxy</sha1>
    </revision>
  </page>
  <page>
    <title>Horatio Scott Carslaw</title>
    <ns>0</ns>
    <id>25302674</id>
    <revision>
      <id>831041615</id>
      <parentid>831041537</parentid>
      <timestamp>2018-03-18T11:27:55Z</timestamp>
      <contributor>
        <username>Gomach</username>
        <id>17706726</id>
      </contributor>
      <minor/>
      <comment>category</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4877">Dr '''Horatio Scott Carslaw''' [[FRSE]] LLD (12 February 1870, [[Helensburgh]], [[Dumbartonshire]], [[Scotland]] &amp;ndash; 11 November 1954, [[Burradoo]], [[New South Wales]], [[Australia]]) was a [[Scotland|Scottish]]-[[Australia]]n mathematician.&lt;ref name=ADB&gt;{{cite AuDB | first = J. C. | last = Jaeger | authorlink = John Conrad Jaeger | title = Carslaw, Horatio Scott (1870–1954) | volume = 7 | year = 1979 | id2 = carslaw-horatio-scott-5518}}&lt;/ref&gt;&lt;ref&gt;{{acad|id=CRSW891HS|name=Carslaw, Horatio Scott}}&lt;/ref&gt;  The book he wrote with his colleague [[John Conrad Jaeger]], ''Conduction of Heat in Solids'', remains a classic in the field.

==Life==

He was born in [[Helensburgh]] the son of the Rev Dr William Henderson Carslaw&lt;ref&gt;http://www-history.mcs.st-and.ac.uk/Biographies/Carslaw.html&lt;/ref&gt; (a Free Church minister) and his wife, Elizabeth Lockhead.&lt;ref name="ADB"/&gt; He was educated at [[The Glasgow Academy]]. He went on to study at [[Cambridge University]] and then obtained a postgraduate doctorate at [[Glasgow University]]. He was elected a Fellow of the [[Royal Society of Edinburgh]] in 1901.&lt;ref name="royalsoced.org.uk"&gt;https://www.royalsoced.org.uk/cms/files/fellows/biographical_index/fells_indexp1.pdf&lt;/ref&gt;

In 1903, upon the retirement of Theodore Thomas Gurney,&lt;ref&gt;{{acad|id=GNY869|name=Gurney, Theodore Thomas}}&lt;/ref&gt; Carslaw was appointed Professor and the Chair of Pure and Applied Mathematics in the now [[Sydney School of Mathematics and Statistics|School of Mathematics and Statistics]] at the [[University of Sydney]]. He retired in 1935&lt;ref&gt;http://www.maths.usyd.edu.au/u/About/&lt;/ref&gt; to his house in Burradoo where he produced most of his best work.&lt;ref name=ADB /&gt;  The Carslaw Building at the University, completed in the 1960s and containing the School, is named after him.&lt;ref&gt;http://www.maths.usyd.edu.au/u/About/Carslaw.html&lt;/ref&gt;

He died at home in Burradoo and was buried in the Anglican section of [[Bowral]] Cemetery.&lt;ref name="ADB"/&gt;

==Family==

He married Ethel Maude Clarke (daughter of [[Sir William Clarke, 1st Baronet]]&lt;ref name="ADB"/&gt;)in 1907 but she died later in the same year.&lt;ref name="royalsoced.org.uk"/&gt;

==Works==
* [https://catalog.hathitrust.org/Record/000616514 ''An introduction to infinitesimal calculus''], 1905
* [https://catalog.hathitrust.org/Record/008882245 ''Introduction to the theory of Fourier's series and integrals and the mathematical theory of the conduction of heat''], London 1906, [https://catalog.hathitrust.org/Record/009404302 revised 2nd edn.] 1921, published under the title ''Introduction to the mathematical theory of the conduction of heat in solids'';&lt;ref&gt;{{cite journal|author=Moore, Charles N.|authorlink=Charles Napoleon Moore|title=Review: H. S. Carslaw, ''Introduction to the Mathematical Theory of the Conduction of Heat in Solids''|journal=Bull. Amer. Math. Soc.|year=1923|volume=29|issue=7|pages=326–327|url=http://projecteuclid.org/euclid.bams/1183485619|doi=10.1090/s0002-9904-1923-03740-3}}&lt;/ref&gt; revised and enlarged 3rd edn. 1930, published under the title ''Introduction to the theory of Fourier's series and integrals''&lt;ref&gt;{{cite journal|author=Moore, C. N.|authorlink=Charles Napoleon Moore|title=Review: H.S. Carslaw, ''Introduction to the Theory of Fourier's Series and Integrals'', and Werner Rogosinski, ''Fouriersche Reihen''|journal=Bulletin of the American Mathematical Society|volume=37|issue=7|year=1931|pages=510–511|doi=10.1090/S0002-9904-1931-05176-4|url=http://projecteuclid.org/euclid.bams/1183494882}}&lt;/ref&gt;
* [https://catalog.hathitrust.org/Record/000385524 ''The Elements of Non-Euclidean Plane Geometry and Trigonometry''], London 1916
* with John Conrad Jaeger: ''Operational methods in applied mathematics'', 1941,&lt;ref&gt;{{cite journal|author=Bateman, H.|authorlink=Harry Bateman|title=Review: H. S. Carslaw and J. C. Jaeger, ''Operational Methods in Applied Mathematics''|journal=Bull. Amer. Math. Soc.|year=1942|volume=48|issue=7|pages=510–511|url=http://projecteuclid.org/euclid.bams/1183504440|doi=10.1090/s0002-9904-1942-07701-9}}&lt;/ref&gt; 1948
* with Jaeger: ''Conduction of Heat in Solids'', Oxford 1947, 1959

==See also==

*[[Diffusion equation]]
*[[Heat equation]]
*[[Horosphere]]
*[[Thermal diffusivity]]

==References==
{{reflist}}

==External links==
* {{Internet Archive author |sname=Horatio Scott Carslaw}}
* [http://adbonline.anu.edu.au/biogs/A070583b.htm Horatio Scott Carslaw at the Australian Dictionary of Biography Online]
* {{MacTutor Biography|id=Carslaw}}
{{Authority control}}

{{DEFAULTSORT:Carslaw, Horatio Scott}}
[[Category:1870 births]]
[[Category:1954 deaths]]
[[Category:People educated at the Glasgow Academy]]
[[Category:Australian mathematicians]]
[[Category:Scottish mathematicians]]
[[Category:University of Sydney faculty]]


{{Australia-scientist-stub}}
{{Mathematician-stub}}
{{UK-mathematician-stub}}</text>
      <sha1>5ifi3g7an6nx435a8mzyujzuu2iut4m</sha1>
    </revision>
  </page>
  <page>
    <title>Horrocks construction</title>
    <ns>0</ns>
    <id>37542163</id>
    <revision>
      <id>819195043</id>
      <parentid>798237962</parentid>
      <timestamp>2018-01-08T00:31:57Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* References */[[User:JCW-CleanerBot#Logic|task]], replaced: Proceedings of the London Mathematical Society. Third Series → Proceedings of the London Mathematical Society |series=Third Series using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1301">In mathematics, the '''Horrocks construction''' is a method for constructing [[vector bundle]]s, especially over [[projective space]]s, introduced by {{harvs|txt|first=Geoffrey |last=Horrocks|authorlink= Geoffrey Horrocks|year=1964|loc=section 10}}. His original construction gave an example of an indecomposable rank 2 vector bundle over 3-dimensional projective space, and generalizes to give examples of vector bundles of higher ranks over other projective spaces. The Horrocks construction is used in the [[ADHM construction]] to construct [[instanton]]s over the [[4-sphere]].

==References==
*{{Citation | authorlink1=Wolf Barth | last1=Barth | first1=Wolf | last2=Hulek | first2=Klaus | title=Monads and moduli of vector bundles | url=https://dx.doi.org/10.1007/BF01168047 | doi=10.1007/BF01168047 |mr=509589 | year=1978 | journal=Manuscripta Mathematica | issn=0025-2611 | volume=25 | issue=4 | pages=323–347}}
*{{Citation | last1=Horrocks | first1=G. | author1-link=Geoffrey Horrocks | title=Vector bundles on the punctured spectrum of a local ring | doi=10.1112/plms/s3-14.4.689  |mr=0169877 | year=1964 | journal=Proceedings of the London Mathematical Society |series=Third Series | issn=0024-6115 | volume=14 | issue=4 | pages=689–713}}

[[Category:Vector bundles]]


{{topology-stub}}</text>
      <sha1>k2dxc2eq5u2nlam69vmg4pcuxgy9dnb</sha1>
    </revision>
  </page>
  <page>
    <title>Ignaz Schütz</title>
    <ns>0</ns>
    <id>54978454</id>
    <revision>
      <id>860209078</id>
      <parentid>828669680</parentid>
      <timestamp>2018-09-19T02:35:13Z</timestamp>
      <contributor>
        <username>Smasongarrison</username>
        <id>16185737</id>
      </contributor>
      <comment>copy edit with [[Wikipedia:AutoWikiBrowser/General_fixes|General fixes]], replaced: n’s → n's</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2087">'''Ignaz Robert Schütz''' (1867, Březová ([[Moravia]]) – 1927, [[Brno]])&lt;ref&gt;{{Citation
|last = Darrigol
|first = O.
|author-link = 
|title = Atoms, Mechanics, and Probability: Ludwig Boltzmann's Statistico-Mechanical
|trans-title=
|place = 
|volume=
|publisher = Oxford University Press
|year = 2018
|page = 376
|url = https://books.google.it/books?id=APBIDwAAQBAJ&amp;pg=PA376&amp;lpg=PA376
|others = 
|mr =
|zbl =
|isbn = 978-0-19-881617-1
}}&lt;/ref&gt; was a Czech–German [[mathematician]] and a [[physicist]].

He studied at the [[University of Munich]] where in 1894 he obtained a [[Ph.D]]&lt;ref&gt;{{citation|title=Allgemeine Lösung der Magnetisirungs-Gleichungen für den Ring |last=Schütz |first=I. R.|author-link= |journal=Journal für die reine und angewandte Mathematik |volume=113|pages=161–178 |year=1894|url=http://gdz.sub.uni-goettingen.de/dms/load/img/?PPN=PPN243919689_0113&amp;DMDID=DMDLOG_0014 }}&lt;/ref&gt; in [[physics]]. Schütz was assistant to [[Ludwig Boltzmann]] in [[Munich]] from 1891 to 1894, the year of Boltzmann's departure from Munich. In 1897, Ignaz R. Schütz, then a member of the Institute for Theoretical Physics at [[Göttingen]],  showed how time translational symmetry induces conservation of energy.&lt;ref&gt;{{citation|title=Prinzip der absoluten Erhaltung der Energie|last=Schütz |first=I. R.|author-link= |journal=Nachrichten von der Königliche Gesellschaft der Wissenschaften zu Göttingen|volume=|pages=110–123 |year=1897}}&lt;/ref&gt;

==Notes==
{{reflist}}

==References==
*{{Citation
|last = Darrigol
|first = Olivier 
|author-link = 
|title = Atoms, Mechanics, and Probability: Ludwig Boltzmann's Statistico-Mechanical
|trans-title=
|place = 
|volume=
|publisher = [[Oxford University Press]]
|year = 2018
|page = 376
|url = https://books.google.it/books?id=APBIDwAAQBAJ&amp;pg=PA376&amp;lpg=PA376
|others = 
|mr =
|zbl =
|isbn = 978-0-19-881617-1
}}

== External links ==
* {{MathGenealogy|id=66578|title=Ignaz Robert Schütz }}

{{Authority control}}

{{DEFAULTSORT:Schütz, Ignaz Robert}}
[[Category:1867 births]]
[[Category:1920 deaths]]


{{mathematician-stub}}</text>
      <sha1>df3lvf9mfmr9mjamdq4bvpqxgdug5rg</sha1>
    </revision>
  </page>
  <page>
    <title>Inequality (mathematics)</title>
    <ns>0</ns>
    <id>89489</id>
    <revision>
      <id>863547681</id>
      <parentid>863190974</parentid>
      <timestamp>2018-10-11T13:40:38Z</timestamp>
      <contributor>
        <username>JackintheBox</username>
        <id>30011325</id>
      </contributor>
      <minor/>
      <comment>stylised version is in all caps</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="22553">{{distinguish|Inequation}}
{{redirect2|Less than|Greater than|the use of the "&lt;" and "&gt;" signs as punctuation|Bracket|the Nine Inch Nails song|Less Than (song)}}
{{for|the UK insurance brand "MORE TH&gt;N"|More Than (company)}}
{{No footnotes|date=May 2017}}
[[File:Linear Programming Feasible Region.svg|frame|The [[feasible region]]s of [[linear programming]] are defined by a set of inequalities.]]

In [[mathematics]], an '''inequality''' is a relation that holds between two values when they are different (see also: [[equality (mathematics)|equality]]).
*The notation ''a'' ≠ ''b'' means that ''a'' is '''not equal to''' ''b''.
:It does not say that one is greater than the other, or even that they can be compared in size.

If the values in question are elements of an [[ordered set]], such as the [[integer]]s or the [[real number]]s, they can be compared in size.
*The notation ''a'' &lt; ''b'' means that ''a'' is '''less than''' ''b''.
*The notation ''a'' &gt; ''b'' means that ''a'' is '''greater than''' ''b''.
:In either case, ''a'' is not equal to ''b''. These relations are known as '''strict inequalities'''. The notation ''a'' &lt; ''b'' may also be read as "''a'' is strictly less than ''b''".

In contrast to strict inequalities, there are two types of inequality relations that are not strict:
*The notation ''a'' ≤ ''b'' means that ''a'' is '''less than or equal to''' ''b'' (or, equivalently, '''not greater than''' ''b'', or '''at most''' ''b''); "not greater than" can also be represented by the symbol for "greater than" bisected by a vertical line, "not." (The [[unicode]] for ≤ is "U+ 2264".)
*The notation ''a'' ≥ ''b'' means that ''a'' is '''greater than or equal to''' ''b'' (or, equivalently, '''not less than''' ''b'', or '''at least''' ''b''),; "not less than" can also be represented by the symbol for "less than" bisected by a vertical line, "not." (The unicode for ≥ is "U+ 2265".)

In engineering sciences, a less formal use of the notation is to state that one quantity is "much greater" than another, normally by several [[Order of magnitude|orders of magnitude]].

*The notation ''a'' ≪ ''b'' means that ''a'' is '''much less than''' ''b''. (In [[measure theory]], however, this notation is used for [[Absolute continuity#Absolute continuity of measures|absolute continuity]], an unrelated concept.)
*The notation ''a'' ≫ ''b'' means that ''a'' is '''much greater than''' ''b''.

==Properties==
Inequalities are governed by the following [[Property (philosophy)|properties]]. All of these properties also hold if all of the non-strict inequalities (≤ and ≥) are replaced by their corresponding strict inequalities (&lt; and &gt;) and (in the case of applying a function) monotonic
functions are limited to ''strictly'' [[Monotonic function|monotonic functions]].

===Transitivity===

The transitive property of inequality states:
* For any [[real number]]s ''a'', ''b'', ''c'':
** If ''a'' ≥ ''b'' and ''b'' ≥ ''c'', then ''a'' ≥ ''c''.
** If ''a'' ≤ ''b'' and ''b'' ≤ ''c'', then ''a'' ≤ ''c''.
* If ''either'' of the premises is a strict inequality, then the conclusion is a strict inequality:
** If ''a'' ≥ ''b'' and ''b'' &gt; ''c'', then ''a'' &gt; ''c''
** If ''a'' &gt; ''b'' and ''b'' ≥ ''c'', then ''a'' &gt; ''c''
* Since ''a'' = ''b'' implies ''a'' ≥ ''b'' these imply:
** If ''a'' = ''b'' and ''b'' &gt; ''c'', then ''a'' &gt; ''c''
** If ''a'' &gt; ''b'' and ''b'' = ''c'', then ''a'' &gt; ''c''

===Converse===
The relations ≤ and ≥ are each other's [[Converse relation|converse]]:
* For any [[real number]]s ''a'' and ''b'':
**If ''a'' ≤ ''b'', then ''b'' ≥ ''a''.
**If ''a'' ≥ ''b'', then ''b'' ≤ ''a''.

===Addition and subtraction===
[[File:Translation invariance of less-than-relation.svg|thumb|300px|If ''x'' &lt; ''y'', then ''x'' + ''a'' &lt; ''y'' + ''a''.]]
A common constant ''c'' may be [[addition|added]] to or [[subtraction|subtracted]] from both sides of an inequality:
* For any [[real number]]s ''a'', ''b'', ''c''
**If ''a'' ≤ ''b'', then ''a'' + ''c'' ≤ ''b'' + ''c'' and ''a'' − ''c'' ≤ ''b'' − ''c''.
**If ''a'' ≥ ''b'', then ''a'' + ''c'' ≥ ''b'' + ''c'' and ''a'' − ''c'' ≥ ''b'' − ''c''.
i.e., the real numbers are an [[Partially ordered group|ordered group]] under addition.

===Multiplication and division===
[[File:Invariance of less-than-relation by multiplication with positive number.svg|thumb|If ''x'' &lt; ''y'' and ''a'' &gt; 0, then ''ax'' &lt; ''ay''.]]
[[File:Inversion of less-than-relation by multiplication with negative number.svg|thumb|If ''x'' &lt; ''y'' and ''a'' &lt; 0, then ''ax'' &gt; ''ay''.]]
The properties that deal with [[multiplication]] and [[division (mathematics)|division]] state:
* For any real numbers, ''a'', ''b'' and non-zero ''c'':
** If ''c'' is [[positive number|positive]], then multiplying or dividing by ''c'' does not change the inequality:
*** If ''a'' ≥ ''b'' and ''c'' &gt; 0, then ''ac'' ≥ ''bc'' and ''a/c'' ≥ ''b/c''.
*** If ''a'' ≤ ''b'' and ''c'' &gt; 0, then ''ac'' ≤ ''bc'' and ''a/c'' ≤ ''b/c''.
** If ''c'' is [[negative number|negative]], then multiplying or dividing by ''c'' inverts the inequality:
*** If ''a'' ≥ ''b'' and ''c'' &lt; 0, then ''ac'' ≤ ''bc'' and ''a/c'' ≤ ''b/c''.
*** If ''a'' ≤ ''b'' and ''c'' &lt; 0, then ''ac'' ≥ ''bc'' and ''a/c'' ≥ ''b/c''.

More generally, this applies for an [[ordered field]]; see [[#Ordered fields]].

===Additive inverse===

The properties for the [[additive inverse]] state:

*For any real numbers ''a'' and ''b'', negation inverts the inequality:
**If ''a'' ≤ ''b'', then −''a'' ≥ −''b''.
**If ''a'' ≥ ''b'', then −''a'' ≤ −''b''.

===Multiplicative inverse===

The properties for the [[multiplicative inverse]] state:

*For any non-zero real numbers ''a'' and ''b'' that are both [[Positive number|positive]] or both [[Negative number|negative]]:
**If ''a'' ≤ ''b'', then 1/''a'' ≥ 1/''b''.
**If ''a'' ≥ ''b'', then 1/''a'' ≤ 1/''b''.
*If one of ''a'' and ''b'' is positive and the other is negative, then:
**If ''a'' &lt; ''b'', then 1/''a'' &lt; 1/''b''.
**If ''a'' &gt; ''b'', then 1/''a'' &gt; 1/''b''.

These can also be written in [[#Chained notation|chained notation]] as:
* For any non-zero real numbers ''a'' and ''b'':
** If 0 &lt; ''a'' ≤ ''b'', then 1/''a'' ≥ 1/''b'' &gt; 0.
** If ''a'' ≤ ''b'' &lt; 0, then 0 &gt; 1/''a'' ≥ 1/''b''.
** If ''a'' &lt; 0 &lt; ''b'', then 1/''a'' &lt; 0 &lt; 1/''b''.
** If 0 &gt; ''a'' ≥ ''b'', then 1/''a'' ≤ 1/''b'' &lt; 0.
** If ''a'' ≥ ''b'' &gt; 0, then 0 &lt; 1/''a'' ≤ 1/''b''.
** If ''a'' &gt; 0 &gt; ''b'', then 1/''a'' &gt; 0 &gt; 1/''b''.

===Applying a function to both sides===
[[File:Log.svg|right|thumb|The graph of ''y'' = ln ''x'']]
Any [[Monotonic function|monotonic]]ally increasing [[function (mathematics)|function]] may be applied to both sides of an inequality (provided they are in the [[Domain of a function|domain]] of that function) and it will still hold. Applying a monotonically decreasing function to both sides of an inequality means the opposite inequality now holds.  The rules for the additive inverse, and the multiplicative inverse for positive numbers, are both examples of applying a monotonically decreasing function.

If the inequality is strict (''a'' &lt; ''b'', ''a'' &gt; ''b'') ''and'' the function is strictly monotonic, then the inequality remains strict.  If only one of these conditions is strict, then the resultant inequality is non-strict.  The rules for additive and multiplicative inverses are both examples of applying a ''strictly'' monotonically decreasing function.

A few examples of this rule are: 
* Exponentiating both sides of an inequality by ''n'' &gt; 0 when ''a'' and ''b'' are positive real numbers:
:''a'' ≤ ''b'' ⇔ ''a''&lt;sup&gt;''n''&lt;/sup&gt; ≤ ''b''&lt;sup&gt;''n''&lt;/sup&gt;.
:''a'' ≤ ''b'' ⇔ ''a''&lt;sup&gt;−''n''&lt;/sup&gt; ≥ ''b''&lt;sup&gt;−''n''&lt;/sup&gt;.
* Taking the [[natural logarithm]] to both sides of an inequality when ''a'' and ''b'' are positive real numbers:
:''a'' ≤ ''b'' ⇔ ln(''a'') ≤ ln(''b'').
:''a'' &lt; ''b'' ⇔ ln(''a'') &lt; ln(''b'').
:This is true because the natural logarithm is a strictly increasing function.

==Ordered fields==
If (''F'', +, ×) is a [[Field (mathematics)|field]] and ≤ is a [[total order]] on ''F'', then (''F'', +, ×, ≤) is called an [[ordered field]] if and only if:
* ''a'' ≤ ''b'' implies ''a'' + ''c'' ≤ ''b'' + ''c'';
* 0 ≤ ''a'' and 0 ≤ ''b'' implies 0 ≤ ''a'' × ''b''.

Note that both ('''Q''', +, ×, ≤) and ('''R''', +, ×, ≤) are [[ordered field]]s, but ≤ cannot be defined in order to make ('''C''', +, ×, ≤) an [[ordered field]], because −1 is the square of ''i'' and would therefore be positive.

The non-strict inequalities ≤ and ≥ on real numbers are [[total order]]s. That is, given arbitrary ''a'',''b''∈'''R''', at least one of ''a''≤''b'' and ''b''≤''a'' holds; at the same time, at least one of ''a''≥''b'' and ''b''≥''a'' holds. The strict inequalities &lt; and &gt; on real numbers are [[Total order#Strict total order|strict total orders]]. That is, &lt; on '''R''' has [[trichotomy property]]: given arbitrary ''a'',''b''∈'''R''', exactly one of ''a''&lt;''b'', ''b''&lt;''a'' and ''a''=''b'' is true; likewise, &gt; on '''R''' has the [[Trichotomy (mathematics)|trichotomy property]].

== Chained notation ==

The notation '''''a'' &lt; ''b'' &lt; ''c''''' stands for "''a'' &lt; ''b'' and ''b'' &lt; ''c''", from which, by the transitivity property above, it also follows that ''a'' &lt; ''c''. By the above laws, one can add or subtract the same number to all three terms, or multiply or divide all three terms by same nonzero number and reverse all inequalities if that number is negative. Hence, for example, ''a'' &lt; ''b'' + ''e'' &lt; ''c'' is equivalent to ''a'' − ''e'' &lt; ''b'' &lt; ''c'' − ''e''.

This notation can be generalized to any number of terms: for instance, '''''a''&lt;sub&gt;1&lt;/sub&gt; ≤ ''a''&lt;sub&gt;2&lt;/sub&gt; ≤ ... ≤ ''a''&lt;sub&gt;''n''&lt;/sub&gt;''' means that ''a''&lt;sub&gt;''i''&lt;/sub&gt; ≤ ''a''&lt;sub&gt;''i''+1&lt;/sub&gt; for ''i'' = 1, 2, ..., ''n'' − 1.  By transitivity, this condition is equivalent to ''a''&lt;sub&gt;''i''&lt;/sub&gt; ≤ ''a''&lt;sub&gt;''j''&lt;/sub&gt; for any 1 ≤ ''i'' ≤ ''j'' ≤ ''n''.

When solving inequalities using chained notation, it is possible and sometimes necessary to evaluate the terms independently. For instance to solve the inequality 4''x'' &lt; 2''x'' + 1 ≤ 3''x'' + 2, it is not possible to isolate ''x'' in any one part of the inequality through addition or subtraction. Instead, the inequalities must be solved independently, yielding ''x'' &lt; 1/2 and ''x'' ≥ −1 respectively, which can be combined into the final solution −1 ≤ ''x'' &lt; 1/2.

Occasionally, chained notation is used with inequalities in different directions, in which case the meaning is the [[logical conjunction]] of the inequalities between adjacent terms.  For instance, ''a'' &lt; ''b'' = ''c'' ≤ ''d'' means that ''a'' &lt; ''b'', ''b'' = ''c'', and ''c'' ≤ ''d''.  This notation exists in a few [[programming language]]s such as [[Python (programming language)|Python]].
&lt;!--
== Representing inequalities on the real number line ==
Every inequality involving real numbers can be represented on the real [[number line]] showing darkened regions on the line. A "&lt;" or "&gt;" is graphed by an open circle on the number. A "≤" or "≥" is graphed with a closed or black circle.
{{Expand section|date=May 2008}} --&gt;

==Sharp inequalities==

An inequality is said to be ''sharp'', if it cannot be ''relaxed'' and still be valid in general. Formally, a [[universally quantified]] inequality ''φ'' is called sharp if, for every valid universally quantified inequality ''ψ'', if {{nowrap|''ψ'' [[material conditional|⇒]] ''φ''}} holds, then {{nowrap|''ψ'' [[equivalence (logic)|⇔]] ''φ''}} also holds. For instance, the inequality {{nowrap|[[universal quantification|∀]]''a'' ∈ [[real number|ℝ]]. ''a''&lt;sup&gt;2&lt;/sup&gt; ≥ 0}} is sharp, whereas the inequality {{nowrap|∀''a'' ∈ ℝ. ''a''&lt;sup&gt;2&lt;/sup&gt; ≥ −1}} is not sharp.{{cn|date=May 2017}}

==Inequalities between means==
{{see also|Inequality of arithmetic and geometric means}}

There are many inequalities between means. For example, for any positive numbers ''a''&lt;sub&gt;1&lt;/sub&gt;, ''a''&lt;sub&gt;2&lt;/sub&gt;, …, ''a''&lt;sub&gt;''n''&lt;/sub&gt; we have {{nowrap|''H'' ≤ ''G'' ≤ ''A'' ≤ ''Q'',}} where

:{| style="height:200px"
|-
|&lt;math&gt;H = \frac{n}{1/a_1 + 1/a_2 + \cdots + 1/a_n}&lt;/math&gt;   || ([[harmonic mean]]),
|-
|&lt;math&gt;G = \sqrt[n]{a_1 \cdot a_2 \cdots a_n} &lt;/math&gt;             || ([[geometric mean]]),
|-
|&lt;math&gt;A = \frac{a_1 + a_2 + \cdots + a_n}{n}&lt;/math&gt;              || ([[arithmetic mean]]),
|-
|&lt;math&gt;Q = \sqrt{\frac{a_1^2 + a_2^2 + \cdots + a_n^2}{n}}&lt;/math&gt; || ([[Root mean square|quadratic mean]]).
|}

==Power inequalities==
A "'''power inequality'''" is an inequality containing terms of the form ''a''&lt;sup&gt;''b''&lt;/sup&gt;, where ''a'' and ''b'' are real positive numbers or variable expressions. They often appear in [[mathematical olympiads]] exercises.

===Examples===

* For any real  ''x'',
:: &lt;math&gt;e^x \ge 1+x.&lt;/math&gt;
* If ''x'' &gt; 0 and ''p'' &gt; 0, then
:: &lt;math&gt;(x^p - 1)/p \ge \ln(x) \ge (1 - {1}/{x^p})/p.&lt;/math&gt;
: In the limit of ''p'' → 0, the upper and lower bounds converge to ln(''x''). 
* If ''x'' &gt; 0, then
:: &lt;math&gt;x^x \ge \left( \frac{1}{e}\right)^{1/e}.&lt;/math&gt;
* If ''x'' ≥ 1, then
:: &lt;math&gt;x^{x^x} \ge x.&lt;/math&gt;
* If ''x'', ''y'', ''z'' &gt; 0, then
:: &lt;math&gt;(x+y)^z + (x+z)^y + (y+z)^x &gt; 2.&lt;/math&gt;
* For any real distinct numbers ''a'' and ''b'',
:: &lt;math&gt;\frac{e^b-e^a}{b-a} &gt; e^{(a+b)/2}.&lt;/math&gt;
* If ''x'', ''y'' &gt; 0 and 0 &lt; ''p'' &lt; 1, then
:: &lt;math&gt;x^p+y^p &gt; (x+y)^p.&lt;/math&gt;
* If ''x'', ''y'', ''z'' &gt; 0, then
:: &lt;math&gt;x^x y^y z^z \ge (xyz)^{(x+y+z)/3}.&lt;/math&gt;
* If ''a'', ''b'' &gt; 0, then
:: &lt;math&gt;a^a + b^b \ge a^b + b^a.&lt;/math&gt;
: This inequality was solved by I.Ilani in JSTOR,AMM,Vol.97,No.1,1990.
* If ''a'', ''b'' &gt; 0, then
:: &lt;math&gt;a^{ea} + b^{eb} \ge a^{eb} + b^{ea}.&lt;/math&gt;
: This inequality was solved by S.Manyama in AJMAA,Vol.7,Issue 2,No.1,2010 and by V.Cirtoaje in JNSA, Vol.4, Issue 2, 130–137, 2011.
* If ''a'', ''b'', ''c'' &gt; 0, then
:: &lt;math&gt;a^{2a} + b^{2b} + c^{2c} \ge a^{2b} + b^{2c} + c^{2a}.&lt;/math&gt;
* If ''a'', ''b'' &gt; 0, then
:: &lt;math&gt;a^b + b^a &gt; 1.&lt;/math&gt;

== Well-known inequalities ==
{{see also|List of inequalities}}

[[Mathematician]]s often use inequalities to bound quantities for which exact formulas cannot be computed easily.  Some inequalities are used so often that they have names:
{{div col}}
* [[Azuma's inequality]]
* [[Bernoulli's inequality]]
* [[Bell's inequality]]
* [[Boole's inequality]]
* [[Cauchy–Schwarz inequality]]
* [[Chebyshev's inequality]]
* [[Chernoff's inequality]]
* [[Cramér–Rao inequality]]
* [[Hoeffding's inequality]]
* [[Hölder's inequality]]
* [[Inequality of arithmetic and geometric means]]
* [[Jensen's inequality]]
* [[Kolmogorov's inequality]]
* [[Markov's inequality]]
* [[Minkowski inequality]]
* [[Nesbitt's inequality]]
* [[Pedoe's inequality]]
* [[Poincaré inequality]]
* [[Samuelson's inequality]]
* [[Triangle inequality]]
{{div col end}}

==Complex numbers and inequalities==
The set of [[complex number]]s &lt;math&gt;\mathbb{C}&lt;/math&gt; with its operations of [[addition]] and [[multiplication]] is a [[field (mathematics)|field]], but it is impossible to define any relation ≤ so that &lt;math&gt;(\mathbb{C},+,\times,\le)&lt;/math&gt; becomes an [[ordered field]]. To make &lt;math&gt;(\mathbb{C},+,\times,\le)&lt;/math&gt; an [[ordered field]], it would have to satisfy the following two properties:

* if ''a'' ≤ ''b'' then ''a'' + ''c'' ≤ ''b'' + ''c''
* if 0 ≤ ''a'' and 0 ≤ ''b'' then 0 ≤ ''a b''

Because ≤ is a [[total order]], for any number ''a'',  either 0 ≤ ''a'' or ''a'' ≤ 0 (in which case the first property above implies that 0 ≤ −''a''). In either case 0 ≤ ''a''&lt;sup&gt;2&lt;/sup&gt;; this means that &lt;math&gt;i^2&gt;0&lt;/math&gt; and &lt;math&gt;1^2&gt;0&lt;/math&gt;; so &lt;math&gt;-1&gt;0&lt;/math&gt; and &lt;math&gt;1&gt;0&lt;/math&gt;, which means &lt;math&gt;(-1+1)&gt;0&lt;/math&gt;; contradiction.

However, an operation ≤ can be defined so as to satisfy only the first property (namely, "if ''a'' ≤ ''b'' then ''a'' + ''c'' ≤ ''b'' + ''c''"). Sometimes the [[lexicographical order]] definition is used:
*  &lt;math&gt;a \le b&lt;/math&gt; if &lt;math&gt; \mathrm{Re}(a) &lt; \mathrm{Re}(b)&lt;/math&gt; or &lt;math&gt;\left(\mathrm{Re}(a) = \mathrm{Re}(b)\right.&lt;/math&gt; and &lt;math&gt;\left.\mathrm{Im}(a) \le \mathrm{Im}(b)\right)&lt;/math&gt;
It can easily be proven that for this definition ''a'' ≤ ''b'' implies ''a'' + ''c'' ≤ ''b'' + ''c''.

==Vector inequalities==
Inequality relationships similar to those defined above can also be defined for [[column vector]]s.  If we let the vectors &lt;math&gt;x,y\in\mathbb{R}^n&lt;/math&gt; (meaning that &lt;math&gt;x = \left(x_1,x_2,\ldots,x_n\right)^\mathsf{T}&lt;/math&gt; and &lt;math&gt;y = \left(y_1,y_2,\ldots,y_n\right)^\mathsf{T}&lt;/math&gt; where &lt;math&gt;x_i&lt;/math&gt; and &lt;math&gt;y_i&lt;/math&gt; are real numbers for &lt;math&gt;i=1,\ldots,n&lt;/math&gt;), we can define the following relationships.

* &lt;math&gt;x = y &lt;/math&gt; if &lt;math&gt;x_i = y_i&lt;/math&gt; for &lt;math&gt;i=1,\ldots,n&lt;/math&gt;
* &lt;math&gt;x &lt; y &lt;/math&gt; if &lt;math&gt;x_i &lt; y_i&lt;/math&gt; for &lt;math&gt;i=1,\ldots,n&lt;/math&gt;
* &lt;math&gt;x \leq y &lt;/math&gt; if &lt;math&gt;x_i \leq y_i &lt;/math&gt; for &lt;math&gt;i=1,\ldots,n&lt;/math&gt; and &lt;math&gt;x \neq y&lt;/math&gt;
* &lt;math&gt;x \leqq y &lt;/math&gt; if &lt;math&gt;x_i \leq y_i &lt;/math&gt; for &lt;math&gt;i=1,\ldots,n&lt;/math&gt;

Similarly, we can define relationships for &lt;math&gt; x &gt; y &lt;/math&gt;, &lt;math&gt; x \geq y &lt;/math&gt;, and &lt;math&gt; x \geqq y &lt;/math&gt;.  We note that this notation is consistent with that used by Matthias Ehrgott in ''Multicriteria Optimization'' (see References).

The [[trichotomy property]] (as stated [[#Ordered fields|above]]) is not valid for vector relationships.  For example, when &lt;math&gt;x = \left[ 2, 5 \right]^\mathsf{T} &lt;/math&gt; and &lt;math&gt;y = \left[ 3, 4 \right]^\mathsf{T} &lt;/math&gt;,  there exists no valid inequality relationship between these two vectors.  Also, a [[multiplicative inverse]] would need to be defined on a vector before this property could be considered.   However, for the rest of the aforementioned properties, a parallel property for vector inequalities exists.

== General existence theorems ==
For a general system of polynomial inequalities, one can find a condition for a solution to exist. Firstly, any system of polynomial inequalities can be reduced to a system of quadratic inequalities by increasing the number of variables and equations (for example by setting a square of a variable equal to a new variable). A single quadratic polynomial inequality in ''n'' − 1 variables can be written as:

: &lt;math&gt;X^T A X \geq 0 &lt;/math&gt;

where ''X'' is a vector of the variables &lt;math&gt;X=(x,y,z,\ldots,1)^T&lt;/math&gt; and ''A'' is a matrix. This has a solution, for example, when there is at least one positive element on the main diagonal of ''A''.

Systems of inequalities can be written in terms of matrices A, B, C, etc. and the conditions for existence of solutions can be written as complicated expressions in terms of these matrices. The solution for two polynomial inequalities in two variables tells us whether two [[conic section]] regions overlap or are inside each other. The general solution is not known but such a solution could be theoretically used to solve such unsolved problems as the [[kissing number problem]]. However, the conditions would be so complicated as to require a great deal of computing time or clever algorithms.

==See also==
*[[Binary relation]]
*[[Bracket (mathematics)]], for the use of similar ‹ and › signs as [[bracket]]s
*[[Fourier–Motzkin elimination]]
*[[Inclusion (set theory)]]
*[[Inequation]]
*[[Interval (mathematics)]]
*[[List of inequalities]]
*[[List of triangle inequalities]]
*[[Partially ordered set]]
*[[Relational operator]]s, used in programming languages to denote inequality
&lt;!--
==Notes==  
{{Reflist}}--&gt;

==References==  
*{{cite book | author=Hardy, G., Littlewood J.E., Pólya, G.| title=Inequalities| publisher=Cambridge Mathematical Library, Cambridge University Press | year=1999 | isbn=0-521-05206-8}}
*{{cite book | author=Beckenbach, E.F., Bellman, R.| title=An Introduction to Inequalities| publisher=Random House Inc | year=1975 | isbn=0-394-01559-2}}
*{{cite book | author=Drachman, Byron C., Cloud, Michael J.| title=Inequalities: With Applications to Engineering| publisher=Springer-Verlag | year=1998 | isbn=0-387-98404-6}}
*{{Citation | last1=Grinshpan | first1=A. Z. | title=General inequalities, consequences, and applications | doi=10.1016/j.aam.2004.05.001 | year=2005 | 
journal=Advances in Applied Mathematics | volume=34 | issue=1 | pages=71–100 }}
*{{cite journal|title='Quickie' inequalities|author=Murray S. Klamkin|url=https://www.math.ualberta.ca/pi/issue7/page26-29.pdf|format=PDF|work=Math Strategies}}
*{{cite web|title=Introduction to Inequalities|url=http://www.mediafire.com/?1mw1tkgozzu |author=Arthur Lohwater|year=1982|publisher=Online e-book in PDF format}}
*{{cite web|title=Mathematical Problem Solving|url=http://www.math.kth.se/math/TOPS/index.html|author=Harold Shapiro|date=2005, 1972–1985|publisher=Kungliga Tekniska högskolan|work=The Old Problem Seminar}}
*{{cite web|title=3rd USAMO |url=http://www.kalva.demon.co.uk/usa/usa74.html |archiveurl=https://web.archive.org/web/20080203070350/http://www.kalva.demon.co.uk/usa/usa74.html |archivedate=2008-02-03 |deadurl=yes |df= }}
*{{cite book
 | last = Pachpatte
 | first = B.G.
 | title = Mathematical Inequalities
 | publisher = [[Elsevier]]
 | series = North-Holland Mathematical Library
 | volume = 67
 | edition = first
 | year = 2005
 | location = Amsterdam, The Netherlands
 | isbn = 0-444-51795-2
 | issn = 0924-6509
 | mr = 2147066
 | zbl = 1091.26008}}
*{{cite book | author=Ehrgott, Matthias| title=Multicriteria Optimization| publisher=Springer-Berlin| year=2005| isbn=3-540-21398-8}}
*{{cite book | last=Steele | first=J. Michael | authorlink=J. Michael Steele | title=The Cauchy-Schwarz Master Class: An Introduction to the Art of Mathematical Inequalities | publisher=Cambridge University Press | year=2004 | isbn=978-0-521-54677-5 | url=http://www-stat.wharton.upenn.edu/~steele/Publications/Books/CSMC/CSMC_index.html}}

== External links ==
{{commons category|Inequalities (mathematics)}}
* {{springer|title=Inequality|id=p/i050790}}
* [http://demonstrations.wolfram.com/GraphOfInequalities/ Graph of Inequalities] by [[Ed Pegg, Jr.]], [[Wolfram Demonstrations Project]].
* [http://www.artofproblemsolving.com/wiki/index.php/Inequality AoPS Wiki entry about Inequalities]

{{Authority control}}

[[Category:Inequalities| ]]
[[Category:Elementary algebra]]</text>
      <sha1>7exgkz1q891pwmovxzvl1hajhum09h0</sha1>
    </revision>
  </page>
  <page>
    <title>Integral of inverse functions</title>
    <ns>0</ns>
    <id>41385213</id>
    <revision>
      <id>871660181</id>
      <parentid>870864786</parentid>
      <timestamp>2018-12-02T16:45:56Z</timestamp>
      <contributor>
        <ip>181.231.250.131</ip>
      </contributor>
      <comment>changed "proof without words" by "illustration" in the description of the image</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7880">In [[mathematics]], '''[[integrals]] of [[inverse functions]]''' can be computed by means of a formula that expresses the [[antiderivative]]s of the inverse &lt;math&gt;f^{-1}&lt;/math&gt; of a [[continuous function|continuous]] and [[inverse functions|invertible function]] &lt;math&gt;f&lt;/math&gt;, in terms of &lt;math&gt;f^{-1}&lt;/math&gt; and an antiderivative of &lt;math&gt;f&lt;/math&gt;.  This formula was published in 1905 by [[Charles-Ange Laisant]].&lt;ref name=Laisant&gt;{{cite journal|last=Laisant|first=C.-A.|title=Intégration des fonctions inverses|year=1905|pages = 253–257|issue=4|volume=5|journal=[[Nouvelles annales de mathématiques, journal des candidats aux écoles polytechnique et normale]]}}&lt;/ref&gt;

==Statement of the theorem==
Let &lt;math&gt;I_1&lt;/math&gt; and &lt;math&gt;I_2&lt;/math&gt; be two [[interval (mathematics)|intervals]] of &lt;math&gt;\mathbb{R}&lt;/math&gt;. 
Assume that &lt;math&gt;f: I_1\to I_2&lt;/math&gt; is a continuous and invertible function, and let &lt;math&gt;f^{-1}&lt;/math&gt; denote its inverse &lt;math&gt;I_2\to I_1&lt;/math&gt;.
Then &lt;math&gt;f&lt;/math&gt; and &lt;math&gt;f^{-1}&lt;/math&gt; have antiderivatives, and if &lt;math&gt;F&lt;/math&gt; is an antiderivative of &lt;math&gt;f&lt;/math&gt;, the possible antiderivatives of &lt;math&gt;f^{-1}&lt;/math&gt; are:
:&lt;math&gt;\int f^{-1}(y)\,dy= y f^{-1}(y)-F\circ f^{-1}(y)+C,&lt;/math&gt;
where &lt;math&gt;C&lt;/math&gt; is an arbitrary real number.

[[File:FunktionUmkehrIntegral2.svg|thumb|Illustration of the theorem]]

In his 1905 article, Laisant gave three proofs.  First, under the additional hypothesis that &lt;math&gt;f^{-1}&lt;/math&gt; is [[Differentiable function|differentiable]], one may differentiate the above formula, which completes the proof immediately.  His second proof was geometric.  If &lt;math&gt;f(a)=c&lt;/math&gt; and &lt;math&gt;f(b)=d&lt;/math&gt;, the theorem can be written: 
:&lt;math&gt;\int_c^df^{-1}(y)\,dy+\int_a^bf(x)\,dx=bd-ac.&lt;/math&gt;
The figure on the right is a [[proof without words]] of this formula.  Laisant does not discuss the hypotheses necessary to make this proof rigorous, but it can be made explicit with the help of the [[Darboux integral]]&lt;ref name=Key/&gt; (or [[Fubini's theorem]]&lt;ref name=Bensimhoun&gt;{{cite arXiv|last=Bensimhoun|first=Michael|title=On the antiderivative of inverse functions|year=2013 |arxiv=1312.3839}}&lt;/ref&gt; if a demonstration based on the Lebesgue integral is desired).  Laisant's third proof uses the additional hypothesis that &lt;math&gt;f&lt;/math&gt; is differentiable.  Beginning with &lt;math&gt;f^{-1}(f(x)) = x&lt;/math&gt;, one multiplies by &lt;math&gt;f'(x)&lt;/math&gt; and integrates both sides.  The right-hand side is calculated using integration by parts to be &lt;math&gt;xf(x) - \textstyle\int f(x)\,dx&lt;/math&gt;, and the formula follows.

Nevertheless, it can be shown that this theorem holds even if &lt;math&gt;f&lt;/math&gt; or &lt;math&gt;f^{-1}&lt;/math&gt; is not differentiable:&lt;ref name=Key/&gt;&lt;ref name=Bensimhoun/&gt; it suffices, for example, to use the Stieltjes integral in the previous argument.  On the other hand, even though general monotonic functions are differentiable almost everywhere, the proof of the general formula does not follow, unless &lt;math&gt;f^{-1}&lt;/math&gt; is [[absolutely continuous]].&lt;ref name=Bensimhoun/&gt;

It is also possible to check that for every &lt;math&gt;y&lt;/math&gt; in &lt;math&gt;I_2&lt;/math&gt;, the derivative of the function &lt;math&gt;y \to y f^{-1}(y) -F(f^{-1}(y))&lt;/math&gt; is equal to &lt;math&gt;f^{-1}(y)&lt;/math&gt;.&lt;ref&gt;This very simple proof of the general theorem, the only one that does not make use of integrals, was communicated by the French mathematician and Wikipedian Anne Bauval in the corresponding pages in French. It seems to have escaped the persons who published proofs of this result.&lt;/ref&gt; In other words:
:&lt;math&gt;\forall x\in I_1\quad\lim_{h\to 0}\frac{(x+h)f(x+h)-xf(x)-\left(F(x+h)-F(x)\right)}{f(x+h)-f(x)}=x.&lt;/math&gt;
To this end, it suffices to apply the [[mean value theorem]] to &lt;math&gt;F&lt;/math&gt; between &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;x+h&lt;/math&gt;, taking into account that &lt;math&gt;f&lt;/math&gt; is monotonic.

==Examples==
#Assume that &lt;math&gt;f(x)=\exp(x)&lt;/math&gt;, hence &lt;math&gt;f^{-1}(y)=\ln(y).&lt;/math&gt; The formula above gives immediately&lt;br /&gt;&lt;math&gt;\quad\int \ln(y) \, dy = y\ln(y)-y + C.&lt;/math&gt;
#Similarly, with &lt;math&gt;f(x)=\cos(x)&lt;/math&gt; and &lt;math&gt;f^{-1}(y)=\arccos(y),&lt;/math&gt;&lt;br /&gt;&lt;math&gt;\quad\int \arccos(y) \, dy = y\arccos(y) - \sin(\arccos(y))+C.&lt;/math&gt;
#With &lt;math&gt;f(x) = \tan(x)&lt;/math&gt; and &lt;math&gt; f^{-1}(y) = \arctan(y),&lt;/math&gt;&lt;br /&gt;&lt;math&gt;\quad\int \arctan(y) \, dy = y\arctan(y) + \ln|\cos(\arctan(y))| + C. &lt;/math&gt;

==History==
Apparently, this theorem of integration was discovered for the first time in 1905 by [[Charles-Ange Laisant]],&lt;ref name="Laisant"/&gt; who "could hardly believe that this theorem is new", and hoped its use would henceforth spread out among students and teachers. This result was published independently in 1912 by an Italian engineer, Alberto Caprilli, in an opuscule entitled "Nuove formole d'integrazione".&lt;ref name="Caprilli"&gt;[http://ebooks.library.cornell.edu/cgi/t/text/pageviewer-idx?c=math&amp;cc=math&amp;idno=00420001&amp;view=image&amp;seq=5&amp;size=100 Read online]&lt;/ref&gt; It was rediscovered in 1955 by Parker,&lt;ref name=Parker&gt;{{cite journal|last=Parker|first=F. D.|title=Integrals of inverse functions|date=Jun–Jul 1955|pages = 439–440|volume=62|journal=[[The American Mathematical Monthly]]|doi=10.2307/2307006|issue=6}}&lt;/ref&gt; and by a number of mathematicians following him.&lt;ref&gt;It is equally possible that some or all of them simply recalled this result in their paper, without referring to previous authors.&lt;/ref&gt; Nevertheless, they all assume that {{math|''f''}} or {{math|''f''&lt;sup&gt;−1&lt;/sup&gt;}} is [[Differentiable function|differentiable]]. 
The general version of the [[theorem]], free from this additional assumption, was proposed by Michael Spivak in 1965, as an exercise in the ''Calculus'',&lt;ref&gt;[[Michael Spivak]], ''Calculus'' (1967), chap. 13, pp. 235.&lt;/ref&gt; and a  fairly complete proof following the same lines was published by Eric Key in 1994.&lt;ref name=Key&gt;{{cite journal|last=Key|first=E. |title=Disks, Shells, and Integrals of Inverse Functions|date=Mar 1994|pages = 136–138|volume=25|journal=[[The College Mathematics Journal]]|issue=2|doi=10.2307/2687137}}&lt;/ref&gt;
This proof relies on the very definition of the [[Darboux integral]], and consists in showing that the upper [[Darboux integral|Darboux sums]] of the function {{math|f}} are in 1-1 correspondence with the lower Darboux sums of {{math|''f''&lt;sup&gt;−1&lt;/sup&gt;}}.   
In 2013, Michael Bensimhoun, estimating that the general theorem was still insufficiently known, gave two other proofs:&lt;ref name="Bensimhoun"/&gt; The second proof, based on the [[Stieltjes integral]] and on its formulae of [[integration by parts]] and of [[homeomorphic]] [[integration by substitution|change of variables]], is the most suitable to establish more complex formulae.&lt;ref&gt;See for instance the formula at the end of his article.&lt;/ref&gt;

==Generalization to holomorphic functions==
The above theorem generalizes in the obvious way to holomorphic functions:
Let &lt;math&gt;U&lt;/math&gt; and &lt;math&gt;V&lt;/math&gt; be two open and simply connected sets of &lt;math&gt;\mathbb{C}&lt;/math&gt;, and assume that &lt;math&gt;f: U\to V&lt;/math&gt; is a [[biholomorphism]].  Then &lt;math&gt;f&lt;/math&gt; and &lt;math&gt;f^{-1}&lt;/math&gt; have antiderivatives, and if &lt;math&gt;F&lt;/math&gt; is an antiderivative of &lt;math&gt;f&lt;/math&gt;, the general antiderivative of &lt;math&gt;f^{-1}&lt;/math&gt; is
:&lt;math&gt;G(z)= z f^{-1}(z)-F\circ f^{-1}(z)+C.&lt;/math&gt;

Because all holomorphic functions are differentiable, the proof is immediate by complex differentiation.

== References ==
{{Reflist}}

{{refbegin}}
* {{ Cite journal | first = J. H. | last = Staib | title=The Integration of Inverse Functions | journal = [[Mathematics Magazine]]|date=Sep 1966 | volume=39 | pages=223–224 | issue=4 | postscript = &lt;!-- Bot inserted parameter. Either remove it; or change its value to "." for the cite to end in a ".", as necessary. --&gt;{{inconsistent citations}} | doi = 10.2307/2688087}}
{{refend}}

==See also==

* [[Young's inequality for products]]

[[Category:Calculus]]</text>
      <sha1>qvuuxtgyjqeefqjtmofvdpq0u28t2he</sha1>
    </revision>
  </page>
  <page>
    <title>L(h, k)-coloring</title>
    <ns>0</ns>
    <id>47161006</id>
    <revision>
      <id>843601563</id>
      <parentid>722758523</parentid>
      <timestamp>2018-05-30T06:20:55Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>[[Ping Zhang (graph theorist)]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="939">'''L(''h'', ''k'') coloring''' in [[graph theory]], is a [[Graph coloring|(proper) vertex coloring]] in which every pair of adjacent vertices has color numbers that differ by at least ''h'', and any pair of vertices at distance 2 have their colors differ by at least ''k''.&lt;ref name="e01"&gt;{{cite book |last1=Chartrand |first1=Gary |last2=Zhang |first2=Ping|author2-link=Ping Zhang (graph theorist) |authorlink1=Gary Chartrand |title=Chromatic Graph Theory |year=2009 |publisher=CRC Press |chapter=14. Colorings, Distance, and Domination |pages=397-438}}&lt;/ref&gt; When ''h''=1 and ''k''=0, it is the usual [[Graph coloring|(proper) vertex coloring]].
== References ==
{{reflist}}

[[Category:Computational problems in graph theory]]
[[Category:Extensions and generalizations of graphs]]
[[Category:Graph theory]]
[[Category:Graph coloring]]
[[Category:NP-complete problems]]
[[Category:NP-hard problems]]
[[Category:Radio resource management]]</text>
      <sha1>rgsskghkx5pn6ogq8idewe67w6cqks6</sha1>
    </revision>
  </page>
  <page>
    <title>List of Fields medalists affiliated with the Institute for Advanced Study</title>
    <ns>0</ns>
    <id>48539131</id>
    <revision>
      <id>853119345</id>
      <parentid>831034246</parentid>
      <timestamp>2018-08-02T15:22:05Z</timestamp>
      <contributor>
        <username>Lsandberg205</username>
        <id>34334365</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4535">This is a comprehensive list of Fields Medal winners affiliated with the [[Institute for Advanced Study]] in Princeton, New Jersey as current and former faculty members, visiting scholars, and other affiliates.  Of the 56 individuals who have received the [[Fields Medal]] as of 2015, 41 are mathematicians who have been affiliated with the IAS as some point in their career.&lt;ref&gt;[http://www.mathunion.org/general/prizes/fields/prizewinners/ International Mathematical Union: List of Fields Medallists]&lt;/ref&gt;&lt;ref&gt;[https://www.ias.edu/sites/default/files/pdfs/fields-medalists-8-14-14.pdf Fields Medal Winners Affiliated with the Institute for Advanced Study] as of August 2014&lt;/ref&gt; 

The Fields Medal is the world’s most prestigious award in mathematics.  It is presented every four years by the [[International Mathematical Union]] and is often referred to as the "Nobel prize of mathematics."   It is generally shared by four different researchers.  Members of the IAS have dominated the award since its inception in 1936 and in 2010 they took all four of them.&lt;ref&gt;[https://www.ias.edu/news/press-releases/2010/fields-2010 Institute for Advanced Study: Fields Medal Awarded to Four Former Members of the Institute for Advanced Study]&lt;/ref&gt;

{| class="wikitable"
! colspan="4" | Fields Medal Winners
|-
| '''Year''' || '''Prize winner''' || '''Country''' || '''Years affiliated with IAS'''
|-
| rowspan="2" | 1936
| [[Lars V. Ahlfors]]
| Finland
| 1962, 1966–1967
|-
| [[Jesse Douglas]]
| United States
| 1934–1935, 1938–1939
|-
| rowspan="1" | 1950
| [[Atle Selberg]]
| Norway
| 1947–1951, 1951–1987
|-
| rowspan="2" | 1954
| [[Kunihiko Kodaira]]
| Japan
| 1949–1952, 1956–1961
|-
| [[Jean-Pierre Serre]]
| France
| 1955–1964, 1967–1968, 1970–1973, 1978, 1983–1984, 1999
|-
| rowspan="1" | 1958
| [[René Thom]]
| France
| 1956, 1961–1962
|-
| rowspan="2" | 1962
| [[Lars Valter Hörmander]]
| Sweden
| 1960–1961, 1971, 1977–1978
|-
| [[John Willard Milnor]]
| United States
| 1966, 1970–1990, 1999, 2002
|-
| rowspan="3" | 1966
| [[Michael Atiyah]]
| United Kingdom
| 1955–1956, 1959, 1969–1972, 1976, 1987
|-
| [[Paul J. Cohen]]
| United States
| 1959–1961, 1967
|-
| [[Stephen Smale]]
| United States
| 1958–60, 1966–1967
|-
| rowspan="3" | 1970
| [[Alan Baker (mathematician) | Alan Baker]]
| United Kingdom
| 1970
|-
| [[Heisuke Hironaka]]
| Japan
| 1962–1963
|-
| [[John G. Thompson]]
| United States
| 1978
|-
| rowspan="2" | 1974
| [[Enrico Bombieri]]
| Italy
| 1974, 1984–present
|-
| [[David B. Mumford]]
| United States
| 1962–1963, 1981–1982
|-
| rowspan="3" | 1978
| [[Pierre Deligne]]
| Belgium
| 1972–1973, 1977, 1981, 1984–present 
|-
| [[Grigori Margulis]]
| Russia
| 1991, 2006
|-
| [[Daniel G. Quillen]]
| United States
| 1969–1970
|-
| rowspan="3" | 1982
| [[Alain Connes]]
| France
| 1978–1979
|-
| [[William P. Thurston]]
| United States
| 1972–1973, 1976, 1984–1985
|-
| [[Shing-Tung Yau]]
| China
| 1971–1972, 1979–1984
|-
| rowspan="3" | 1986
| [[Simon K. Donaldson]]
| United Kingdom
| 1983–1984
|-
| [[Gerd Faltings]]
| Germany
| 1988, 1992–1993
|-
| [[Michael H. Freedman]]
| United States
| 1975–1976, 1980–1981
|-
| rowspan="3" | 1990
| [[Vladimir Drinfeld]]
| Russia
| 1990, 1997–1998
|-
| [[Shigefumi Mori]]
| Japan
| 1981–1982
|-
| [[Edward Witten]]
| United States
| 1984, 1987–present
|-
| rowspan="1" | 1994
| [[Jean Bourgain]]
| Belgium
| 1994–present
|-
| rowspan="3" | 1998
| [[Maxim Kontsevich]]
| Russia
| 1992–1993, 2002
|-
| [[Curtis T. McMullen]]
| United States
| 1986–1987
|-
| [[Andrew Wiles]]
| United Kingdom
| 1981–1982, 1992, 1995–1996, 1998–2004, 2007–2011
|-
| rowspan="1" | 2002
| [[Vladimir Voevodsky]]
| Russia
| 1992–1993, 1998–2017
|-
| rowspan="1" | 2006
| [[Andrei Okounkov]]
| Russia
| 1996
|-
| rowspan="4" | 2010
| [[Elon Lindenstrauss]]
| Israel
| 2000–2001, 2007
|-
| [[Ngô Bảo Châu]]
| Vietnam
| 2006, 2007–2010
|-
| [[Stanislav Smirnov]]
| Russia
| 1998, 2003
|-
| [[Cédric Villani]]
| France
| 2009
|-
| rowspan="3" | 2014
| [[Manjul Bhargava]]
| United States
| 2001–2002
|-
| [[Maryam Mirzakhani]]
| Iran
| 2015
|-
| [[Martin Hairer]]
| Austria
| 2014
|-
| rowspan="1" | 2018
| [[Akshay Venkatesh]]
| Australia
| 2005–2006, 2017–present
|-
|}

==See also==
* [[List of countries by number of Fields Medallists]]

==References==
{{reflist}}

{{DEFAULTSORT:Fields medalists}}

[[Category:Institute for Advanced Study]]
[[Category:Fields Medalists|*]]</text>
      <sha1>o92nmypx21gxd8h4vak9ohy2cbmnaii</sha1>
    </revision>
  </page>
  <page>
    <title>Locally finite variety</title>
    <ns>0</ns>
    <id>34559803</id>
    <revision>
      <id>607160846</id>
      <parentid>592293074</parentid>
      <timestamp>2014-05-05T12:09:21Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>[[WP:CHECKWIKI]] error fixes using [[Project:AWB|AWB]] (10093)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1913">In [[universal algebra]], a [[variety (universal algebra)|variety]] of algebras means the class of all algebraic structures of a given signature satisfying a given set of identities.  One calls a variety '''locally finite''' if every finitely generated algebra has finite [[cardinality]], or equivalently, if every finitely generated free algebra has finite cardinality.

The variety of [[Boolean algebras]] constitutes a famous example.  The free Boolean algebra on ''n'' generators has cardinality 2&lt;sup&gt;2&lt;sup&gt;''n''&lt;/sup&gt;&lt;/sup&gt;, consisting of the ''n''-ary operations 2&lt;sup&gt;''n''&lt;/sup&gt;→2.

The variety of [[Set (mathematics)|sets]] constitutes a degenerate example: the free set on ''n'' generators has cardinality ''n'', consisting of just the generators themselves.

The variety of [[pointed set]]s constitutes a trivial example: the free pointed set on ''n'' generators has cardinality ''n''+1, consisting of the generators along with the basepoint.

The variety of graphs defined as follows constitutes a combinatorial example.  Define a graph ''G'' = (''E'',''s'',''t'') to be a set ''E'' of edges and unary operations ''s'', ''t'' of source and target satisfying ''s''(''s''(''e'')) = ''t''(''s''(''e'')) and ''s''(''t''(''e'')) = ''t''(''t''(''e'')).  Vertices are those edges in the (common) image of ''s'' and ''t''.  The free graph on ''n'' generators has cardinality 3''n'' and consists of ''n'' edges ''e'' each with two endpoints ''s''(''e'') and ''t''(''e'').  Graphs with nontrivial incidence relations arise as quotients of free graphs, most usefully by identifying vertices.

The variety of sets and the variety of graphs so defined each forms a [[presheaf category]] and hence a [[topos]].  This is not the case for the variety of Boolean algebras or of pointed sets.

==References==
*http://www.math.mcmaster.ca/~matt/publications/novo.pdf

[[Category:Universal algebra]]


{{algebra-stub}}</text>
      <sha1>pwzh7eo8lzvgakxea6ja1o7rk9iz886</sha1>
    </revision>
  </page>
  <page>
    <title>Lubell–Yamamoto–Meshalkin inequality</title>
    <ns>0</ns>
    <id>748686</id>
    <revision>
      <id>634685421</id>
      <parentid>621102532</parentid>
      <timestamp>2014-11-20T12:48:48Z</timestamp>
      <contributor>
        <ip>50.65.99.31</ip>
      </contributor>
      <comment>/* Lubell's proof */ Clarify how permutations are meant here. (Not a selfbijective function, but the resulting order of the elements.)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3502">In [[combinatorics|combinatorial]] [[mathematics]], the '''Lubell–Yamamoto–Meshalkin inequality''', more commonly known as the '''LYM inequality''', is an inequality on the sizes of sets in a [[Sperner family]], proved by {{harvtxt|Bollobás|1965}}, {{harvtxt|Lubell|1966}}, {{harvtxt|Meshalkin|1963}}, and  {{harvtxt|Yamamoto|1954}}. It is named for the initials of three of its discoverers.

This inequality belongs to the field of [[combinatorics]] of sets, and has many applications in combinatorics. In particular, it can be used to prove [[Sperner's theorem]]. Its name is also used for similar inequalities.

==Statement of the theorem==
Let ''U'' be an ''n''-element set, let ''A'' be a family of subsets of ''U'' such that no set in ''A'' is a subset of another set in ''A'', and let ''a&lt;sub&gt;k&lt;/sub&gt;'' denote the number of sets of size ''k'' in ''A''. Then
: &lt;math&gt;\sum_{k=0}^n\frac{a_k}{{n \choose k}} \le 1.&lt;/math&gt;

==Lubell's proof==
{{harvtxt|Lubell|1966}} proves the Lubell–Yamamoto–Meshalkin inequality by a [[double counting (proof technique)|double counting argument]] in which he counts the [[permutation]]s of ''U'' in two different ways. First, by counting all permutations of ''U'' directly, one finds that there are ''n''! of them. But secondly, one can generate a permutation (i.e., an order) of the elements of ''U'' by selecting a set ''S'' in ''A'' and concatenating a permutation of the elements of ''S'' with a permutation of the nonmembers (elements of ''U\S''). If |''S''|&amp;nbsp;=&amp;nbsp;''k'', it will be associated in this way with ''k''!(''n''&amp;nbsp;&amp;minus;&amp;nbsp;''k'')! permutations, and in each of them the first ''k'' elements will be just the elements of ''S''. Each permutation can only be associated with a single set in ''A'', for if two prefixes of a permutation both formed sets in ''A'' then one would be a subset of the other. Therefore, the number of permutations that can be generated by this procedure is
:&lt;math&gt;\sum_{S\in A}|S|!(n-|S|)!=\sum_{k=0}^n a_k k! (n-k)!.&lt;/math&gt;
Since this number is at most the total number of all permutations,
:&lt;math&gt;\sum_{k=0}^n a_k k! (n-k)!\le n!.&lt;/math&gt;
Finally dividing the above inequality by ''n''! leads to the result.

== References ==

*{{citation
 | first = B. | last = Bollobás | authorlink = Béla Bollobás
 | title = On generalized graphs
 | journal = Acta Mathematica Academiae Scientiarum Hungaricae
 | volume = 16 | issue = 3–4 | pages = 447–452 | year = 1965
 | doi = 10.1007/BF01904851 |mr=0183653 }}.

*{{citation
 | last = Lubell | first = D.
 | year = 1966
 | title = A short proof of Sperner's lemma
 | journal = Journal of Combinatorial Theory
 | volume = 1 | issue = 2 | pages = 299
 | doi = 10.1016/S0021-9800(66)80035-2 |mr=0194348 }}.

*{{citation
 | last = Meshalkin | first = L. D.
 | year = 1963
 | title = Generalization of Sperner's theorem on the number of subsets of a finite set
 | journal = Theory of Probability and its Applications
 | volume = 8 | issue = 2 | pages = 203–204
 | doi = 10.1137/1108023 |mr=0150049 }}.

*{{citation
 | last = Yamamoto | first = Koichi
 | year = 1954
 | title = Logarithmic order of free distributive lattice
 | journal = Journal of the Mathematical Society of Japan
 | volume = 6 | pages = 343–353
 |mr=0067086
 | doi=10.2969/jmsj/00630343}}.

{{DEFAULTSORT:Lubell-Yamamoto-Meshalkin inequality}}
[[Category:Combinatorics]]
[[Category:Inequalities]]
[[Category:Order theory]]
[[Category:Set families]]
[[Category:Articles containing proofs]]</text>
      <sha1>5t7r1b2x9csoojr54xuo93flru12uh9</sha1>
    </revision>
  </page>
  <page>
    <title>Mathematicism</title>
    <ns>0</ns>
    <id>52806824</id>
    <revision>
      <id>856250081</id>
      <parentid>856250016</parentid>
      <timestamp>2018-08-23T22:19:41Z</timestamp>
      <contributor>
        <username>Omnipaedista</username>
        <id>8524693</id>
      </contributor>
      <comment>add new item</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3909">'''Mathematicism''' is any [[opinion]], [[Point of view (philosophy)|viewpoint]], [[school of thought]], or [[philosophy]] that states that everything can be described/defined/modelled ultimately by [[mathematics]], or that the [[universe]] and [[reality]] (both [[matter (philosophy)|material]] and [[mind|mental]]/[[spirit]]ual) are fundamentally/fully/only mathematical, i.e. that 'everything is mathematics' necessitating the ideas of [[logic]], [[reason]], [[mind]], and [[spirit]].

==Overview==
Mathematicism is a form of [[rationalist]] [[idealist]] or [[mentalism (philosophy)|mentalist]]/[[spiritualism (philosophy)|spiritualist]] [[monism]]).  The idea started in [[Western civilization|the West]] with [[ancient Greece]]'s [[Pythagoreanism]], and continued in other rationalist idealist schools of thought such as [[Platonism]].&lt;ref&gt;[[Markus Gabriel|Gabriel, Markus]]. ''Fields of Sense: A New Realist Ontology''. Edinburgh: Edinburgh Univ. Press, 2015, ch. 4. Limits of Set-Theoretical Ontology and Contemporary Nihilism.&lt;/ref&gt; The term 'mathematicism' has additional meanings among Cartesian idealist philosophers and mathematicians, such as describing the ability and process to study reality mathematically.&lt;ref&gt;Sasaki, Chikara, ''Descartes’s Mathematical Thought'', Springer, 2013, p. 283.&lt;/ref&gt;&lt;ref name=Gilson&gt;[[Étienne Gilson|Gilson, Étienne]]. ''The Unity of Philosophical Experience. San Francisco, CA: Ignatius Press'', 1999, p. 133.&lt;/ref&gt;

Mathematicism includes (but is not limited to) the following (chronological order):
* [[Pythagoreanism]] ([[Pythagoras]] said 'All things are numbers,' 'Number rules all,' though contemporary mathematicists exclude numerology, etc., from mathematicism)
* [[Platonism]] (paraphrases [[Pythagoras]]' mathematicism)
* [[Neopythagoreanism]]
* [[Neoplatonism]] (brought [[Aristoteleanism|Aristotelean]] [[mathematical logic]] to Platonism)
* [[Cartesianism]] ([[René Descartes]] applied mathematical reasoning to philosophy)&lt;ref name=Gilson /&gt;
* [[Leibnizianism]] ([[Gottfried Leibniz]] was a [[mathematician]], called beings '[[monad (philosophy)|monad]]s,' which also means 'units')
* [[Alain Badiou]]'s philosophy
* [[Physicist]] [[Max Tegmark]]'s [[mathematical universe hypothesis]] (MUH) described as Pythagoreanism–Platonism
* [[Tim Maudlin]]'s project of 'philosophical mathematics,' a project aiming at constructing 'a rigorous mathematical structure using primitive terms that give a natural fit with physics' and investigating 'why mathematics should provide such a powerful language for describing the physical world.'&lt;ref name=Maudlin&gt;Maudlin, Tim. ''New Foundations for Physical Geometry: The Theory of Linear Structures''. Oxford University Press. 2014, p. 52.&lt;/ref&gt; According to Maudlin, 'the most satisfying possible answer to such a question is: Because the physical world literally has a mathematical structure.'&lt;ref name=Maudlin/&gt;

==See also==
* [[Modern Platonism]]
* [[Pancomputationalism]]

==Notes==
{{Reflist}}

==References==
* {{cite web|title=mathematicism|url=https://www.britannica.com/topic/mathematicism|website=Britannica}}
* {{cite web|title=mathematicism|url=https://www.collinsdictionary.com/us/dictionary/english/mathematicism|website=Collins Dictionary}}
* {{cite web|title=mathematicism|url=https://en.oxforddictionaries.com/definition/mathematicism|website=Oxford Living Dictionary}}

[[Category:Contemporary philosophy]]
[[Category:Continental philosophy]]
[[Category:Epistemology]]
[[Category:Gnosticism]]
[[Category:Idealism]]
[[Category:Logic]]
[[Category:Metaphysics]]
[[Category:Monism]]
[[Category:Neopythagoreanism]]
[[Category:Ontology]]
[[Category:Philosophical theories]]
[[Category:Philosophy of mathematics]]
[[Category:Philosophy of mind]]
[[Category:Platonism]]
[[Category:Pythagoreanism]]
[[Category:Rationalism]]
[[Category:Theories in ancient Greek philosophy]]


{{metaphysics-stub}}</text>
      <sha1>r7rsfc7krd5v0xwt3hnzc2v74wyc0k3</sha1>
    </revision>
  </page>
  <page>
    <title>Millionth</title>
    <ns>0</ns>
    <id>1653013</id>
    <revision>
      <id>732091932</id>
      <parentid>732091807</parentid>
      <timestamp>2016-07-29T15:24:38Z</timestamp>
      <contributor>
        <username>Bear-rings</username>
        <id>28216728</id>
      </contributor>
      <comment>/* See also */ Parts-per notation</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1897">One '''millionth''' is equal to 0.000 001, or 1 x 10&lt;sup&gt;−6&lt;/sup&gt; in [[scientific notation]].  It is the [[Multiplicative inverse|reciprocal]] of a [[million]], and can be also written as 1/1 000 000.&lt;ref&gt;{{citation|title=Science and Sensibility: The Elegant Logic of the Universe|first=Keith J.|last=Laidler|publisher=Prometheus Books|isbn=9781615927036|page=15|url=https://books.google.com/books?id=Z_qP62qOhvYC&amp;pg=PA15}}.&lt;/ref&gt;  Units using this fraction can be indicated using the prefix "micro-" from [[Greek language|Greek]], meaning "small".&lt;ref&gt;{{citation|title=The American Heritage Guide to Contemporary Usage and Style|publisher=Houghton Mifflin Company|year=2005|isbn=9780618604999|page=300|url=https://books.google.com/books?id=xb6ie6PqYhwC&amp;pg=PA300}}.&lt;/ref&gt; Numbers of this quantity are expressed in terms of µ (the Greek letter [[mu (letter)|mu]]).&lt;ref&gt;{{citation|title=Principles of Engineering|first1=Brett|last1=Handley|first2=Craig|last2=Coon|first3=David|last3=Marshall|publisher=Cengage Learning|year=2011|isbn=9781435428362|page=212|url=https://books.google.com/books?id=3YBeXkp-AacC&amp;pg=PT212}}.&lt;/ref&gt;

"Millionth" can also mean the [[ordinal number]] that comes after the nine hundred, ninety-nine thousand, nine hundred, ninety-ninth and before the million and first.&lt;ref&gt;{{citation|title=Grammar: A Student's Guide|first=James R.|last=Hurford|authorlink=James Hurford|publisher=Cambridge University Press|year=1994|isbn=9780521456272|page=146|url=https://books.google.com/books?id=ZaBKd8pT6kgC&amp;pg=PA146}}.&lt;/ref&gt;

== See also ==
* [[International System of Units]]
* [[Micro-]]
* [[International Map of the World]]
* [[Order of magnitude (numbers)]]
* [[Order of magnitude]]
* [[Parts-per notation]]
* [[Per mille]]

==References==
{{reflist}}

{{sequence|
prev=[[Thousandth]]|
next=[[Billionth]]|
list=[[Decimal]]s
}}

[[Category:Fractions (mathematics)]]

{{num-stub}}</text>
      <sha1>n2ewqgrywt2x4vfjnonk14ox5azg8qd</sha1>
    </revision>
  </page>
  <page>
    <title>Modern elementary mathematics</title>
    <ns>0</ns>
    <id>34609626</id>
    <revision>
      <id>786600076</id>
      <parentid>752624886</parentid>
      <timestamp>2017-06-20T12:46:10Z</timestamp>
      <contributor>
        <username>CBM</username>
        <id>1108292</id>
      </contributor>
      <minor/>
      <comment>Manually reviewed edit to replace magic words per [[Special:PermanentLink/772743896#Future_of_magic_links|local rfc]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16856">'''Modern elementary mathematics''' is the theory and practice of teaching [[elementary mathematics]] according to contemporary research and thinking about learning. This can include  [[pedagogy|pedagogical]] ideas, [[mathematics education]] research frameworks, and [[curriculum|curricular]] material. 

In practicing modern elementary mathematics, teachers may use new and emerging media and technologies like [[social media]] and [[video games]], as well as applying new teaching techniques based on the individualization of learning, in-depth study of the [[psychology]] of mathematics education,  and integrating mathematics with [[science]], [[technology]], [[engineering]] and the [[arts]].

== General practice ==

=== Areas of mathematics ===
Making all areas of mathematics accessible to young children is a key goal of modern elementary mathematics. Author and academic Liping Ma calls for "profound understanding of fundamental mathematics" by elementary teachers and parents of learners, as well as learners themselves.&lt;ref&gt;Liping Ma, ''Knowing and Teaching Elementary Mathematics: Teachers' Understanding of Fundamental Mathematics in China and the United States (Studies in Mathematical Thinking and Learning.)'', Lawrence Erlbaum, 1999, {{isbn|978-0-8058-2909-9}}.&lt;/ref&gt;

* [[Algebra]]: Early algebra covers the approach to elementary mathematics which helps children generalize number and set ideas. 
* [[Probability]] and [[statistics]]: Modern technologies make probability and statistics accessible to elementary learners with tools such as computer-assisted data visualization. 
* [[Geometry]]: Specially developed physical and [[Virtual manipulatives for mathematics|virtual manipulatives]], as well as interactive geometry software, can make geometry (beyond basic sorting and measuring) available to elementary learners. 
* [[Calculus]]: New innovations, such as Don Cohen's map to calculus,&lt;ref&gt;{{cite web|url=http://www.mathman.biz/html/map.html |title=Don Cohen - The Mathman: A Map to Calculus |publisher=Mathman.biz |date= |accessdate=2012-02-11}}&lt;/ref&gt; which was developed using children's work and level of understanding, is making calculus accessible to elementary learners.  
* [[Problem solving]]: Creative problem solving, which contrasts with exercises in arithmetic, such as adding or multiplying numbers, is now a major part of elementary mathematics. 

Other areas of mathematics such as [[logic|logical reasoning]] and [[paradox|paradoxes]], which used to be reserved for advanced groups of learners, are now being integrated into more mainstream curricula.

=== Use of psychology ===
[[Psychology]] in mathematics education is an applied research domain, with many recent developments relevant to elementary mathematics. A major aspect is the study of motivation; while most young children enjoy some mathematical practices, by the age of seven to ten many lose interest and begin to experience [[mathematical anxiety]]. [[Constructivism (learning theory)|Constructivism]] and other learning theories consider the ways young children learn mathematics, taking child developmental psychology into account.

Both practitioners and researchers focus on children's memory, [[mnemonic]] devices, and computer-assisted techniques such as [[Spaced repetition|spaces repetition]]. There is an ongoing discussion of relationships between memory, procedural fluency with [[Standard algorithms|algorithms]], and conceptual understanding of elementary mathematics. Sharing songs, rhymes, visuals and other mnemonics is popular in teacher social networks.&lt;ref&gt;{{cite web|url=http://www.kindergartenworks.com/2011/08/monster-numbers.html |title=monster numbers |publisher=KindergartenWorks |date=2011-08-24 |accessdate=2012-02-11}}&lt;/ref&gt;

The understanding that young children benefit from hands-on learning is more than a century old, going back to the work of [[Maria Montessori]]. However, there are modern developments of the theme. Traditional manipulatives are now available on computers as [[Virtual manipulatives for mathematics|virtual manipulatives]], with many offering options not available in the physical world, such as zoom or cross-section of geometric shapes. [[Embodied cognition|Embodied]] mathematics, such as studies of [[numerical cognition]] or gestures in learning, are growing research topics in mathematics education.

=== Accommodating individual students ===
Modern tools such as computer-based [[expert system]]s allow higher individualization of learning. Students do mathematical work at their own pace, providing for each student's [[learning style]], and scaling the same activity for multiple levels. [[Special education]] and [[gifted education]] in particular require level and style accommodations, such as using different presentation and response options.&lt;ref&gt;{{cite web|author=Paula Bliss |url=http://www.paulabliss.com/math.htm |title=Math Remediation and Learning Strategies |publisher=Paulabliss.com |date= |accessdate=2012-02-11}}&lt;/ref&gt; Changing some aspects of the environment, such as giving an auditory learner headphones with quiet music,&lt;ref&gt;{{cite web|url=http://www.riverspringscharter.org/elementary-k-6/curriculum/learning-resources/learning-styles/Auditory-learners |title=Auditory Learners |publisher=Riverspringscharter.org |date= |accessdate=2012-02-11}}&lt;/ref&gt; can help children concentrate on mathematical tasks.

Modern learning materials, both computer and physical, accommodate learners through the use of [[Multiple representations (mathematics education)|multiple representation]], such as graphs, pictures, words, animations, symbols, and sounds. For example, recent research suggests that sign language isn’t only a means of speaking for those who are deaf, but also a visual approach to communication and learning, appealing to many others students and particularly helping with mathematics.&lt;ref&gt;{{cite web|url=http://www2.tech.purdue.edu/cgt/I3/SMILE/522-054.pdf |title=3D SIGN LANGUAGE MATHEMATICS IN IMMERSIVE ENVIRONMENT |format=PDF |date= |accessdate=2012-02-11}}&lt;/ref&gt;

Another aspect of individual education is child-led learning, which is called [[unschooling]] when it encompasses most of the child's experiences. Child-led learning means incorporating mathematically rich projects that stem from personal interests and passions. Educators who support child-led learning need to provide tasks that are open to interpretation, and be ready to improvise, rather than prepare lessons ahead of time.  This modern approach often involves seizing opportunities for discovery, and learning as the child's curiosity demands.  This departure from conventional structured learning leaves the child free to explore his/her innate desires and curiosities.  Child-led learning taps into the child's intrinsic love of learning.

[[Problem solving]] can be an intensely individualized activity, with students working in their own ways and also sharing insights and results within groups.&lt;ref&gt;{{cite web|url=http://crisscrossapplesauce.typepad.com/blog/math-problemsolving.html |title=Math Problem-Solving - Kindergarten Kindergarten |publisher=Crisscrossapplesauce.typepad.com |date= |accessdate=2012-02-11}}&lt;/ref&gt; There are many means to one end, emphasizing the importance of creative approaches. Promoting discourse and focusing on language are important concepts for helping each students participate in problem solving meaningfully.&lt;ref&gt;{{cite web|url=http://teachingtoday.glencoe.com/howtoarticles/promoting-problem-solving-skills-in-elementary-mathematics |title=Teaching Today &amp;#124; How-To Articles &amp;#124; Promoting Problem-Solving Skills in Elementary Mathematics |publisher=Teachingtoday.glencoe.com |date= |accessdate=2012-02-11}}&lt;/ref&gt;

Data-based assessment and comparison of learning methods, and ways children learn, is another big aspect of modern elementary mathematics.

== Use of emerging technologies ==

=== Computation technology ===
Modern computation technologies change elementary mathematics in several ways. Technology reduces the amount of attention, memory, and computation required by users, making higher mathematical topics accessible to young children. However, the main opportunity technology provides is not in making traditional mathematical tasks more accessible, but in introducing children to novel activities that are not possible without computers.

For example, computer modeling allows children to change parameters in virtual systems created by educators and observe emergent mathematical behaviors, or remix and create their own models. The pedagogical approach of [[Constructionist learning|constructionism]] describes how creating algorithms, programs and models on computers promotes deep mathematical thinking. Technology allows children to experience these complex concepts in a more visual manner.
[[File:Interactive whiteboard at CeBIT 2007.jpg|thumb|right|Children use an interactive whiteboard.]]

[[Computer algebra system]]s are software environments that support and scaffold working with symbolic expressions. Some computer algebra systems have intuitive, child-friendly interfaces and therefore can be used in [[Early Algebra]]. [[List of interactive geometry software|Interactive geometry software]] supports creation and manipulation of geometric constructions. Both computer algebra systems and interactive geometry software help with several cognitive limitations of young children, such as attention and memory. The software scaffolds step-by-step procedures, helping children focus attention. It has "undo" capabilities, lowering frustration when errors happen, and promoting creativity and exploration. Also, such software supports [[metacognition]] by making all steps in a problem or a construction visible and editable, so children can reflect on individual steps or the whole journey.

=== Social media ===
Online communities and forums allow educators, researchers and students to share, discuss and remix elementary mathematical content they find or create. Sometimes, traditional media such as texts, pictures and movies are digitized and turned into online social objects, such as [[open textbook]]s. Other times, web-native mathematical objects are created, remixed and shared within the integrated authoring and discussion environment, such as applets made with [[Scratch (programming language)|Scratch]] or [[Geogebra]] constructions.

[[Rich media]], including video, virtual manipulatives, interactive models and mobile applications is a characteristic feature of online mathematical communication. Some global collaboration projects between teachers or groups of students with teachers use the web mostly for communication, but others happen in virtual worlds, such as [[Whyville]].

Professional development for elementary mathematics educators uses social media in the form of online courses, discussion forums, webinars, and web conferences. This supports teachers in forming [[Personal Learning Networks|PLNs]] (Personal Learning Networks). Some communities include both students and teachers, such as Art of Problem Solving.&lt;ref&gt;{{cite web|url=http://www.artofproblemsolving.com/Forum/index.php |title=AoPS Forums • Art of Problem Solving |publisher=Artofproblemsolving.com |date= |accessdate=2012-02-11}}&lt;/ref&gt;

== Teaching mathematics in context ==

=== Games and play ===
Learning through play is not new, but the themes of computer and mobile games are relatively more modern. Most teachers now use games in elementary classrooms, and most children in developed countries play learning games at home. Computer games with intrinsically mathematical [[game mechanics]] can help children learn novel topics. More extrinsic game mechanics and [[gamification]] can be used for time and task management, fluency, and memorization. Sometimes it's not obvious what mathematics children learn by "just playing," but basic spatial and numerical skills gained in free play help with mathematical concepts.&lt;ref&gt;{{cite web|url=http://www.dreambox.com/blog/learning-math-through-play-from-guest-blogger-dawn-morris |title=DreamBox Learning : Learning math through play from guest blogger Dawn Morris |publisher=Dreambox.com |date= |accessdate=2012-02-11}}&lt;/ref&gt;

Some [[Abstract strategy game|abstract games]] such as [[chess]] can benefit learning mathematics by developing systems thinking, logic, and reasoning. [[Role-playing game|Roleplaying games]] invite children to become a character who uses mathematics in daily life or epic adventures, and often use mathematical storytelling. Sandbox, also called [[open world]] games, such as [[Minecraft]] help children explore patterns, improvise, be mathematically artistic, and develop their own algorithms. [[Board game]]s can have all of the above aspects, and also promote communication about mathematics in small groups.

Teachers working with disadvantaged kids note especially large mathematical skill gains after using games in the classroom, possibly because kids don't play such games at home.&lt;ref&gt;{{cite web|url=http://eclkc.ohs.acf.hhs.gov/hslc/tta-system/family/For%20Parents/Everyday%20Parenting/Parents%20as%20Teachers/PlayingGamesin.htm |title=Playing Games in Classroom Helping Pupils (Children) Grasp Math - Head Start |publisher=Eclkc.ohs.acf.hhs.gov |date= |accessdate=2012-02-11}}&lt;/ref&gt;

Many teachers, parents and students design their own games or create versions of existing games. Designing mathematically rich games is one of staple tasks in [[Constructionist learning|constructionism]].

There is a concern that children who use computer games and technology in general may be more stressed when exposed to pen-and-paper tests.&lt;ref&gt;{{cite web|url=http://audio-mastering-ebook.com/teaching-basic-mathematics-in-an-age-of-technology-practice/ |title=Teaching Basic Mathematics in an Age of Technology: Practice |publisher=Audio-mastering-ebook.com |date=2012-01-25 |accessdate=2012-02-11}}&lt;/ref&gt;

=== Family mathematics and everyday mathematics ===
While learning mathematics in daily life, such as cooking and shopping, can't be considered modern, social media provides new twists. Online networks help parents and teachers share tips on how to integrate daily routines and more formal mathematical learning for children. For example, the "Let's play math" blog hosts carnivals for sharing family mathematics ideas,&lt;ref&gt;{{cite web|url=http://letsplaymath.net/ |title=Let's Play Math! |publisher=Letsplaymath.net |date= |accessdate=2012-02-11}}&lt;/ref&gt; such as using egg cartoons for quick mathematical games.

School tasks may involve families collecting data and aggregating it online for mathematical explorations. Pastimes such as [[geocaching]] involve families sharing mathematically rich sporting activities that depend on GPS systems or mobile devices. Museums, clubs, stores, and other public places provide [[blended learning]] opportunities, with visiting families accessing science and mathematics activities related to the place on their mobile devices.

=== {{abbr|STEM|Science Technology Engineering Mathematics}}, social sciences, and the arts ===
In the last several decades, many prominent mathematicians and mathematics enthusiasts embraced mathematical arts, from popular [[fractal art]] to [[origami]]. Likewise, elementary mathematics is becoming more artistic. Some popular topics for children include [[tessellation]], [[computer art]], [[symmetry]], patterns, transformations and reflections.&lt;ref&gt;{{cite web|url=http://apexart.blogspot.com/2012/01/mixing-math-and-art.html |title=Apex Elementary Art: Mixing Math and Art |publisher=Apexart.blogspot.com |date=2012-01-12 |accessdate=2012-02-11}}&lt;/ref&gt; The discipline of [[ethnomathematics]] studies relationships between mathematics and cultures, including arts and crafts. Some hands-on activities, such as creating tiling, can help children and grown-ups see mathematical art all around them.&lt;ref&gt;{{cite web|url=http://mrhonner.com/2012/01/05/math-encounters-craig-kaplan-on-math-and-art/ |title=Math Encounters: Craig Kaplan on Math and Art « Mr Honner |publisher=Mrhonner.com |date=2012-01-05 |accessdate=2012-02-11}}&lt;/ref&gt;

[[Project-based learning]] approaches help students explore mathematics together with other disciplines. For example, children's [[robotics]] projects and competitions include mathematical tasks.

Some elementary mathematical topics, such as [[measurement]], apply to tasks in many professions and subject areas. [[Homeschooling#Unit studies|Unit studies]] centered on such concepts&lt;ref&gt;{{cite web|url=http://fossweb.com/modules3-6/Measurement/index.html |title=Earth Materials |publisher=FOSSweb |date=2011-11-10 |accessdate=2012-02-11}}&lt;/ref&gt; contrast with project-based learning, where students use many concepts to achieve the project's goal.

== References ==
{{Reflist}}

[[Category:Mathematics education]]</text>
      <sha1>jrtafddgpmdj55xh59w1xs9uyxlwplo</sha1>
    </revision>
  </page>
  <page>
    <title>Oberwolfach problem</title>
    <ns>0</ns>
    <id>55972236</id>
    <revision>
      <id>814461238</id>
      <parentid>814316199</parentid>
      <timestamp>2017-12-08T23:29:13Z</timestamp>
      <contributor>
        <username>Ira Leviton</username>
        <id>25046916</id>
      </contributor>
      <minor/>
      <comment>Deleted a duplicate 'the'.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9939">{{unsolved|mathematics|For which 2-regular &lt;math&gt;n&lt;/math&gt;-vertex graphs &lt;math&gt;G&lt;/math&gt; can the complete graph &lt;math&gt;K_n&lt;/math&gt; be decomposed into edge-disjoint copies of &lt;math&gt;G&lt;/math&gt;?}}
[[File:Oberwolfach-3-4.svg|thumb|upright=1.2|Decomposition of the complete graph &lt;math&gt;K_7&lt;/math&gt; into three copies of &lt;math&gt;C_3+C_4&lt;/math&gt;, solving the Oberwolfach problem for the input &lt;math&gt;(3,4)&lt;/math&gt;]]
The '''Oberwolfach problem''' is an unsolved problem in mathematics that may be formulated either as a problem scheduling seating assignments for diners,
or more abstractly as a problem in [[graph theory]], on the [[edge cycle cover]]s of [[complete graph]]s. It is named after the [[Mathematical Research Institute of Oberwolfach]], where the problem was posed in 1967 by [[Gerhard Ringel]].{{r|lr}}

==Formulation==
In conferences held at Oberwolfach, it is the custom for the participants to dine together in a room with circular tables, not all the same size, and with assigned seating that rearranges the participants from meal to meal. The Oberwolfach problem asks how to make a seating chart for a given set of tables so that all tables are full at each meal and all pairs of conference participants are seated next to each other exactly once. An instance of the problem can be denoted as &lt;math&gt;OP(x,y,z,\dots)&lt;/math&gt; where &lt;math&gt;x,y,z,\dots&lt;/math&gt; are the given table sizes. Alternatively, when some table sizes are repeated, they may be denoted using exponential notation; for instance, &lt;math&gt;OP(5^3)&lt;/math&gt; describes an instance with three tables of size five.{{r|lr}}

Formulated as a problem in graph theory, the pairs of people sitting next to each other at a single meal can be represented as a [[disjoint union of graphs|disjoint union]] of [[cycle graph]]s &lt;math&gt;C_x+C_y+C_z+\cdots&lt;/math&gt; of the specified lengths, with one cycle for each of the dining tables. This union of cycles is a [[regular graph|2-regular graph]], and every 2-regular graph has this form. If &lt;math&gt;G&lt;/math&gt; is this 2-regular graph and has &lt;math&gt;n&lt;/math&gt; vertices, the question is whether the complete graph &lt;math&gt;K_n&lt;/math&gt; can be represented as an edge-disjoint union of copies of &lt;math&gt;G&lt;/math&gt;.{{r|lr}}

In order for a solution to exist, the total number of conference participants (or equivalently, the total capacity of the tables, or the total number of vertices of the given cycle graphs) must be an odd number. For, at each meal, each participant sits next to two neighbors, so the total number of neighbors of each participant must be even, and this is only possible when the total number of participants is odd. The problem has, however, also been extended to even values of &lt;math&gt;n&lt;/math&gt; by asking, for those &lt;math&gt;n&lt;/math&gt;, whether all of the edges of the complete graph except for a [[perfect matching]] can be covered by copies of the given 2-regular graph. Like the [[ménage problem]] (a different mathematical problem involving seating arrangements of diners and tables), this variant of the problem can be formulated by supposing that the &lt;math&gt;n&lt;/math&gt; diners are arranged into &lt;math&gt;n/2&lt;/math&gt; married couples, and that the seating arrangements should place each diner next to each other diner except their own spouse exactly once.{{r|hkr}}

==Known results==
The only instances of the Oberwolfach problem that are known not to be solvable are &lt;math&gt;OP(3^2)&lt;/math&gt;, &lt;math&gt;OP(3^4)&lt;/math&gt;, &lt;math&gt;OP(4,5)&lt;/math&gt;, and &lt;math&gt;OP(3,3,5)&lt;/math&gt;. It is widely believed that all other instances have a solution, but only special cases have been provable to be solvable.

The cases for which a solution is known include:
*All instances &lt;math&gt;OP(x^y)&lt;/math&gt; except &lt;math&gt;OP(3^2)&lt;/math&gt; and &lt;math&gt;OP(3^4)&lt;/math&gt;.{{r|h|ah|assw|hs|hkr}}
*All instances in which all of the cycles have even length.{{r|h|bd}}
*All instances (other than the known exceptions) with &lt;math&gt;n\le 40&lt;/math&gt;.{{r|dfhmr}}
*All instances for certain choices of &lt;math&gt;n&lt;/math&gt;, belonging to an infinite subset of the [[prime number]]s.{{r|bs|abhms}}
*All instances &lt;math&gt;OP(x,y)&lt;/math&gt; other than the known exceptions &lt;math&gt;OP(3,3)&lt;/math&gt; and &lt;math&gt;OP(4,5)&lt;/math&gt;.{{r|t}}

==Related problems==
[[Kirkman's schoolgirl problem]], of grouping fifteen schoolgirls into rows of three in seven different ways so that each pair of girls appears once in each triple, is a special case of the Oberwolfach problem, &lt;math&gt;OP(3^5)&lt;/math&gt;. The problem of [[Hamiltonian decomposition]] of a complete graph &lt;math&gt;K_n&lt;/math&gt; is another special case, &lt;math&gt;OP(n)&lt;/math&gt;.{{r|bd}}

[[Alspach's conjecture]], on the decomposition of a complete graph into cycles of given sizes, is related to the Oberwolfach problem, but neither is a special case of the other.
If &lt;math&gt;G&lt;/math&gt; is a 2-regular graph, with &lt;math&gt;n&lt;/math&gt; vertices, formed from a disjoint union of cycles of certain lengths, then a solution to the Oberwolfach problem for &lt;math&gt;G&lt;/math&gt; would also provide a decomposition of the complete graph into &lt;math&gt;(n-1)/2&lt;/math&gt; copies of each of the cycles of &lt;math&gt;G&lt;/math&gt;. However, not every decomposition of &lt;math&gt;K_n&lt;/math&gt; into this many cycles of each size can be grouped into disjoint cycles that form copies of &lt;math&gt;G&lt;/math&gt;, and on the other hand not every instance of Alspach's conjecture involves sets of cycles that have &lt;math&gt;(n-1)/2&lt;/math&gt; copies of each cycle.

==References==
{{reflist|30em|refs=

&lt;ref name=abhms&gt;{{citation
 | last1 = Alspach | first1 = Brian | author1-link = Brian Alspach
 | last2 = Bryant | first2 = Darryn
 | last3 = Horsley | first3 = Daniel
 | last4 = Maenhaut | first4 = Barbara
 | last5 = Scharaschkin | first5 = Victor
 | issue = 1
 | journal = [[Ars Mathematica Contemporanea]]
 | mr = 3546656
 | pages = 157–173
 | title = On factorisations of complete graphs into circulant graphs and the Oberwolfach problem
 | url = https://amc-journal.eu/index.php/amc/article/view/770
 | volume = 11
 | year = 2016}}&lt;/ref&gt;

&lt;ref name=ah&gt;{{citation
 | last1 = Alspach | first1 = Brian | author1-link = Brian Alspach
 | last2 = Häggkvist | first2 = Roland
 | doi = 10.1002/jgt.3190090114
 | issue = 1
 | journal = [[Journal of Graph Theory]]
 | mr = 785659
 | pages = 177–187
 | title = Some observations on the Oberwolfach problem
 | volume = 9
 | year = 1985}}&lt;/ref&gt;

&lt;ref name=assw&gt;{{citation
 | last1 = Alspach | first1 = Brian | author1-link = Brian Alspach
 | last2 = Schellenberg | first2 = P. J.
 | last3 = Stinson | first3 = D. R. | author3-link = Doug Stinson
 | last4 = Wagner | first4 = David
 | doi = 10.1016/0097-3165(89)90059-9
 | issue = 1
 | journal = [[Journal of Combinatorial Theory]]
 | mr = 1008157
 | pages = 20–43
 | series = Series A
 | title = The Oberwolfach problem and factors of uniform odd length cycles
 | volume = 52
 | year = 1989}}&lt;/ref&gt;

&lt;ref name=bd&gt;{{citation
 | last1 = Bryant | first1 = Darryn
 | last2 = Danziger | first2 = Peter
 | doi = 10.1002/jgt.20538
 | issue = 1
 | journal = [[Journal of Graph Theory]]
 | mr = 2833961
 | pages = 22–37
 | title = On bipartite 2-factorizations of &lt;math&gt;K_n-I&lt;/math&gt; and the Oberwolfach problem
 | url = https://people.smp.uq.edu.au/DarrynBryant/Preprints/BryDanBipartiteOberwolfach.pdf
 | volume = 68
 | year = 2011}}&lt;/ref&gt;

&lt;ref name=bs&gt;{{citation
 | last1 = Bryant | first1 = Darryn
 | last2 = Scharaschkin | first2 = Victor
 | doi = 10.1016/j.jctb.2009.03.003
 | issue = 6
 | journal = [[Journal of Combinatorial Theory]]
 | mr = 2558441
 | pages = 904–918
 | series = Series B
 | title = Complete solutions to the Oberwolfach problem for an infinite set of orders
 | volume = 99
 | year = 2009}}&lt;/ref&gt;

&lt;ref name=dfhmr&gt;{{citation
 | last1 = Deza | first1 = A.
 | last2 = Franek | first2 = F.
 | last3 = Hua | first3 = W.
 | last4 = Meszka | first4 = M.
 | last5 = Rosa | first5 = A.
 | journal = Journal of Combinatorial Mathematics and Combinatorial Computing
 | mr = 2675892
 | pages = 95–102
 | title = Solutions to the Oberwolfach problem for orders 18 to 40
 | url = http://www.cas.mcmaster.ca/~deza/jcmcc2010.pdf
 | volume = 74
 | year = 2010}}&lt;/ref&gt;

&lt;ref name=h&gt;{{citation
 | last = Häggkvist | first = Roland
 | contribution = A lemma on cycle decompositions
 | doi = 10.1016/S0304-0208(08)73015-9
 | mr = 821524
 | pages = 227–232
 | publisher = North-Holland | location = Amsterdam
 | series = North-Holland Math. Stud.
 | title = Cycles in graphs (Burnaby, B.C., 1982)
 | volume = 115
 | year = 1985}}&lt;/ref&gt;

&lt;ref name=hkr&gt;{{citation
 | last1 = Huang | first1 = Charlotte
 | last2 = Kotzig | first2 = Anton | author2-link = Anton Kotzig
 | last3 = Rosa | first3 = Alexander
 | doi = 10.1016/0012-365X(79)90162-6
 | issue = 3
 | journal = Discrete Mathematics
 | mr = 541472
 | pages = 261–277
 | title = On a variation of the Oberwolfach problem
 | volume = 27
 | year = 1979}}&lt;/ref&gt;

&lt;ref name=hs&gt;{{citation
 | last1 = Hoffman | first1 = D. G.
 | last2 = Schellenberg | first2 = P. J.
 | doi = 10.1016/0012-365X(91)90440-D
 | issue = 1-3
 | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | mr = 1140806
 | pages = 243–250
 | title = The existence of &lt;math&gt;C_k&lt;/math&gt;-factorizations of &lt;math&gt;K_{2n}-F&lt;/math&gt;
 | volume = 97
 | year = 1991}}&lt;/ref&gt;

&lt;ref name=lr&gt;{{citation
 | last1 = Lenz | first1 = Hanfried | author1-link = Hanfried Lenz
 | last2 = Ringel | first2 = Gerhard | author2-link = Gerhard Ringel
 | doi = 10.1016/0012-365X(91)90416-Y
 | issue = 1-3
 | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | mr = 1140782
 | pages = 3–16
 | title = A brief review on Egmont Köhler's mathematical work
 | volume = 97
 | year = 1991}}&lt;/ref&gt;

&lt;ref name=t&gt;{{citation
 | last = Traetta | first = Tommaso
 | issue = 5
 | journal = [[Journal of Combinatorial Theory]]
 | mr = 3033656
 | pages = 984–997
 | series = Series A
 | title = A complete solution to the two-table Oberwolfach problems
 | doi = 10.1016/j.jcta.2013.01.003
 | volume = 120
 | year = 2013}}&lt;/ref&gt;

}}

[[Category:Graph theory]]</text>
      <sha1>36ajscqpxl370d8js4crpyiuklkceuf</sha1>
    </revision>
  </page>
  <page>
    <title>Ogive (statistics)</title>
    <ns>0</ns>
    <id>55155568</id>
    <revision>
      <id>868433794</id>
      <parentid>832605163</parentid>
      <timestamp>2018-11-12T04:55:32Z</timestamp>
      <contributor>
        <username>JMtB03</username>
        <id>15580005</id>
      </contributor>
      <comment>Added {{[[Template:Statistics-stub|statistics-stub]]}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="937">In [[statistics]], an '''ogive''' is a free-hand graph showing the curve of a [[cumulative distribution function]].&lt;ref&gt;{{cite book |first=Ken |last=Black |title=Business Statistics: Contemporary Decision Making |location= |publisher=John Wiley &amp; Sons |year=2009 |page=24 |url=https://books.google.com/books?id=KQ25WExx5usC&amp;pg=PA24 }}&lt;/ref&gt; The points plotted are the upper class limit and the corresponding cumulative frequency.&lt;ref&gt;{{cite book|last=Everitt|first=B.S.|title=The Cambridge Dictionary of Statistics|publisher=Cambridge University Press|location=Cambridge|year=2002|edition=2nd|isbn=0-521-81099-X}}&lt;/ref&gt; (which, for the [[normal distribution]], resembles one side of an [[Arabesque (European art)|Arabesque]] or [[Ogive|ogival]] arch). The term can also be used to refer to the empirical [[cumulative distribution function]].

==References==
{{reflist}}

[[Category:Statistical charts and diagrams]]


{{statistics-stub}}</text>
      <sha1>3c5ei49z8xcwtz4zn10cc3nyarwpeto</sha1>
    </revision>
  </page>
  <page>
    <title>Panlogism</title>
    <ns>0</ns>
    <id>24184879</id>
    <revision>
      <id>791461873</id>
      <parentid>757976668</parentid>
      <timestamp>2017-07-20T12:20:56Z</timestamp>
      <contributor>
        <username>Fadesga</username>
        <id>5042921</id>
      </contributor>
      <comment>/* References */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="798">In [[philosophy]], '''panlogism''' is a [[Hegelianism|Hegelian]] doctrine that holds that the [[universe]] is the act or realization of [[Logos]].&lt;ref&gt;[http://www.ditext.com/runes/p.html "Dagobert D. Runes, Dictionary of Philosophy, 1942"] Retrieved September 1, 2009&lt;/ref&gt;&lt;ref&gt;[http://www.thefreedictionary.com/panlogism "Panlogism" at the free dictionary] Retrieved September 1, 2009&lt;/ref&gt;  According to the doctrine of panlogism, [[logic]] and [[ontology]] are the same study.&lt;ref&gt;[http://atheism.about.com/library/glossary/general/bldef_panlogism.htm "Panlogism" at About.com] Retrieved September 1, 2009&lt;/ref&gt;

==References==
{{reflist}}

[[Category:Georg Wilhelm Friedrich Hegel]]
[[Category:Metaphysical theories]]
[[Category:Ontology]]
[[Category:Theories of deduction]]


{{Ontology-stub}}</text>
      <sha1>muslped4rmo0f9jmev0do0wdz583zcj</sha1>
    </revision>
  </page>
  <page>
    <title>Pernicious number</title>
    <ns>0</ns>
    <id>36585685</id>
    <revision>
      <id>862702631</id>
      <parentid>799996051</parentid>
      <timestamp>2018-10-06T04:06:07Z</timestamp>
      <contributor>
        <username>Zaslav</username>
        <id>88809</id>
      </contributor>
      <comment>Ce for grammar.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2074">In [[number theory]], a '''pernicious number''' is a positive integer such that the [[Hamming weight]] (or [[digit sum]]) of its [[Binary numeral system|binary representation]] is [[prime number|prime]].

==Examples==
The first pernicious number is 3, since 3&amp;nbsp;=&amp;nbsp;11&lt;sub&gt;2&lt;/sub&gt; and 1&amp;nbsp;+&amp;nbsp;1&amp;nbsp;=&amp;nbsp;2, which is a prime. The next pernicious number is 5, since 5&amp;nbsp;=&amp;nbsp;101&lt;sub&gt;2&lt;/sub&gt;, followed by 6, 7 and 9 {{OEIS|id=A052294}}.

==Properties==
* No power of two is a pernicious number. This is trivially true, because powers of two in binary form are represented as a one followed by zeros. So each power of two has a Hamming weight of one, and [[prime number#Primality of one|one is not considered to be a prime]].
* Every number of the form {{nowrap|2&lt;sup&gt;''n''&lt;/sup&gt; + 1}} with {{nowrap|''n'' &gt; 0}}, including every [[Fermat number]], is a pernicious number. This is because the sum of the digits in binary form is 2, which is a prime number.
* Every even [[perfect number]] is a pernicious number. This is based on the fact that every even perfect number can be represented as {{nowrap|2&lt;sup&gt;''p''−1&lt;/sup&gt;(2&lt;sup&gt;''p''&lt;/sup&gt; − 1)}} with ''p'' a prime. Owing to this form, every even perfect number is represented in binary as ''p'' ones followed by ''p''&amp;nbsp;&amp;minus;&amp;nbsp;1 zeros.
* A number of the form {{nowrap|2&lt;sup&gt;''p''&lt;/sup&gt; &amp;minus; 1}} with prime ''p'' is a pernicious number known as a [[Mersenne number]] (although sometimes Mersenne numbers are defined as {{nowrap|2&lt;sup&gt;''n''&lt;/sup&gt; &amp;minus; 1}} for any natural number ''n'').

==Related numbers==
* [[Odious number]]s are numbers with an odd number of 1s in their binary expansion {{OEIS|id=A000069}}.
* [[Evil number]]s are numbers with an even number of 1s in their binary expansion {{OEIS|id=A001969}}.

==References==
*[http://www.doc.ic.ac.uk/~sgc/papers/colton_aim02_1.pdf The NumbersWithNames Program] pp. 6–7.

==External links==
*[http://mathworld.wolfram.com/OdiousNumber.html Odious Numbers]

{{Classes of natural numbers |state=collapsed}}
[[Category:Number theory]]</text>
      <sha1>3ikugr6h6qqefr8s7klulnl5rsctrm1</sha1>
    </revision>
  </page>
  <page>
    <title>Point (geometry)</title>
    <ns>0</ns>
    <id>593693</id>
    <revision>
      <id>865784693</id>
      <parentid>865755467</parentid>
      <timestamp>2018-10-26T03:41:58Z</timestamp>
      <contributor>
        <username>Wcherowi</username>
        <id>13428914</id>
      </contributor>
      <minor/>
      <comment>Reverted 1 edit by [[Special:Contributions/66.234.201.60|66.234.201.60]] ([[User talk:66.234.201.60|talk]]) to last revision by Wcherowi. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9637">{{General geometry |0d/1d}}

In modern [[mathematics]], a '''point''' refers usually to an [[Element (mathematics)|element]] of some [[Set (mathematics)|set]] called a [[Space (mathematics)|space]].

More specifically, in [[Euclidean geometry]], a point is a [[primitive notion]] upon which the geometry is built, meaning that a point cannot be defined in terms of previously defined objects. That is, a point is defined only by some properties, called [[axiom]]s, that it must satisfy. In particular, the geometric points do not have any [[length]], [[area]], [[volume]] or any other [[dimension]]al attribute. A common interpretation is that the concept of a point is meant to capture the notion of a unique location in [[Euclidean space]].

==Points in Euclidean geometry==
[[Image:ACP 3.svg|thumb|A finite set of points (blue) in two-dimensional [[Euclidean space]].]]
Points, considered within the framework of [[Euclidean geometry]], are one of the most fundamental objects. [[Euclid]] originally defined the point as "that which has no part". In two-dimensional [[Euclidean space]], a point is represented by an [[ordered pair]] ({{mvar|x}}, {{mvar|y}}) of numbers, where the first number [[Convention (norm)|conventionally]] represents the [[Horizontal plane|horizontal]] and is often denoted by {{mvar|x}}, and the second number conventionally represents the [[Vertical direction|vertical]] and is often denoted by {{mvar|y}}. This idea is easily generalized to three-dimensional Euclidean space, where a point is represented by an ordered triplet ({{mvar|x}}, {{mvar|y}}, {{mvar|z}}) with the additional third number representing depth and often denoted by {{mvar|z}}. Further generalizations are represented by an ordered [[tuple]]t of {{mvar|n}} terms, {{math|(''a''&lt;sub&gt;1&lt;/sub&gt;, ''a''&lt;sub&gt;2&lt;/sub&gt;, … , ''a''&lt;sub&gt;''n''&lt;/sub&gt;)}} where {{mvar|n}} is the [[dimension (mathematics)|dimension]] of the space in which the point is located.

Many constructs within Euclidean geometry consist of an [[infinity|infinite]] collection of points that conform to certain axioms.  This is usually represented by a [[Set (mathematics)|set]] of points; As an example, a [[line (mathematics)|line]] is an infinite set of points of the form &lt;math&gt;\scriptstyle {L = \lbrace (a_1,a_2,...a_n)|a_1c_1 + a_2c_2 + ... a_nc_n = d \rbrace}&lt;/math&gt;, where {{math|''c''&lt;sub&gt;1&lt;/sub&gt;}} through {{math|''c&lt;sub&gt;n&lt;/sub&gt;''}} and {{mvar|d}} are constants and {{mvar|n}} is the dimension of the space. Similar constructions exist that define the [[plane (geometry)|plane]], [[line segment]] and other related concepts. A line segment consisting of only a single point is called a [[degeneracy (mathematics)|degenerate]] line segment.

In addition to defining points and constructs related to points, Euclid also postulated a key idea about points, that any two points can be connected by a straight line. This is easily confirmed under modern extensions of Euclidean geometry, and had lasting consequences at its introduction, allowing the construction of almost all the geometric concepts known at the time. However, Euclid's postulation of points was neither complete nor definitive, and he occasionally assumed facts about points that did not follow directly from his axioms, such as the ordering of points on the line or the existence of specific points. In spite of this, modern expansions of the system serve to remove these assumptions.

==Dimension of a point==

There are several inequivalent definitions of [[dimension (mathematics and physics)|dimension]]  in mathematics. In all of the common definitions, a point is 0-dimensional.

=== Vector space dimension ===
{{Main|Dimension (vector space)}}

The dimension of a vector space is the maximum size of a [[linearly independent]] subset. In a vector space consisting of a single point (which must be the zero vector '''0'''), there is no linearly independent subset. The zero vector is not itself linearly independent, because there is a non trivial linear combination making it zero: &lt;math&gt;1 \cdot \mathbf{0}=\mathbf{0}&lt;/math&gt;.

===Topological dimension===
{{Main|Lebesgue covering dimension}}

The topological dimension of a topological space ''X'' is defined to be the minimum value of ''n'', such that every finite [[open cover]] &lt;math&gt;\mathcal{A}&lt;/math&gt; of ''X'' admits a finite open cover &lt;math&gt;\mathcal{B}&lt;/math&gt; of ''X'' which [[refinement (topology)|refines]] &lt;math&gt;\mathcal{A}&lt;/math&gt; in which no point is included in more than ''n''+1 elements. If no such minimal ''n'' exists, the space is said to be of infinite covering dimension.

A point is [[zero-dimensional space|zero-dimensional]] with respect to the covering dimension because every open cover of the space has a refinement consisting of a single open set.

=== Hausdorff dimension ===
Let ''X'' be a [[metric space]]. If ''S'' ⊂ ''X'' and ''d'' ∈ [0, ∞), the ''d''-dimensional '''Hausdorff content''' of ''S'' is the [[infimum]] of the set of numbers δ ≥ 0 such that there is some (indexed) collection of [[metric space|balls]] &lt;math&gt;\{B(x_i,r_i):i\in I\}&lt;/math&gt; covering ''S'' with ''r&lt;sub&gt;i&lt;/sub&gt;'' &gt; 0 for each ''i'' ∈ ''I'' that satisfies &lt;math&gt;\sum_{i\in I} r_i^d&lt;\delta &lt;/math&gt;.

The '''Hausdorff dimension''' of ''X'' is defined by
:&lt;math&gt;\operatorname{dim}_{\operatorname{H}}(X):=\inf\{d\ge 0: C_H^d(X)=0\}.&lt;/math&gt;

A point has Hausdorff dimension 0 because it can be covered by a single ball of arbitrarily small radius.

==Geometry without points==

Although the notion of a point is generally considered fundamental in mainstream geometry and topology, there are some systems that forgo it, e.g. [[noncommutative geometry]] and [[pointless topology]]. A "pointless" or "pointfree" space is defined not as a [[set (mathematics)|set]], but via some structure ([[C*-algebra|algebraic]] or [[complete Heyting algebra|logical]] respectively) which looks like a well-known function space on the set: an algebra of [[continuous function]]s or an [[algebra of sets]] respectively. More precisely, such structures generalize well-known spaces of [[Function (mathematics)|functions]] in a way that the operation "take a value at this point" may not be defined.
A further tradition starts from some books of [[A. N. Whitehead]] in which the notion of region is assumed as a primitive together with the one of ''inclusion'' or ''connection''.

==Point masses and the Dirac delta function ==
{{Main|Dirac delta function}}

Often in physics and mathematics, it is useful to think of a point as having non-zero mass or charge (this is especially common in [[classical electromagnetism]], where electrons are idealized as points with non-zero charge). The '''Dirac delta function''', or '''{{mvar|δ}} function''', is (informally) a [[generalized function]] on the real number line that is zero everywhere except at zero, with an [[integral]] of one over the entire real line.&lt;ref name=Dirac1958p58&gt;{{harvnb|Dirac|1958|loc=§15 The δ function}}, p. 58&lt;/ref&gt;&lt;ref&gt;{{harvnb|Gel'fand|Shilov|1968|loc=Volume I, §§1.1, 1.3}}&lt;/ref&gt;&lt;ref&gt;{{harvnb|Schwartz|1950|p=3}}&lt;/ref&gt;  The delta function is sometimes thought of as an infinitely high, infinitely thin spike at the origin, with total area one under the spike, and physically represents an idealized [[point mass]] or [[point charge]].&lt;ref&gt;{{harvnb|Arfken|Weber|2000|p=84}}&lt;/ref&gt;  It was introduced by theoretical physicist [[Paul Dirac]].  In the context of [[signal processing]] it is often referred to as the '''unit impulse symbol''' (or function).&lt;ref name="Bracewell 1986 loc=Chapter 5"&gt;{{harvnb|Bracewell|1986|loc=Chapter 5}}&lt;/ref&gt;  Its discrete analog is the [[Kronecker delta]] function which is usually defined on a finite domain and takes values 0 and 1.

==See also==
*[[Accumulation point]]
*[[Affine space]]
*[[Boundary point]]
*[[critical point (mathematics)|Critical point]]
*[[Cusp (singularity)|Cusp]]
*[[Foundations of geometry]]
*[[Position (geometry)]]
*[[Pointwise]]
*[[Singular point of a curve]]
*[[Whitehead point-free geometry]]

==References==
{{reflist}}
* Clarke, Bowman, 1985, "[http://projecteuclid.org/DPubS/Repository/1.0/Disseminate?view=body&amp;id=pdf_1&amp;handle=euclid.ndjfl/1093870761 Individuals and Points,]" ''Notre Dame Journal of Formal Logic 26'': 61–75.
* De Laguna, T., 1922, "Point, line  and surface as sets of solids," ''The Journal of Philosophy 19'': 449–61.
* Gerla, G., 1995, "[https://web.archive.org/web/20110717210751/http://www.dmi.unisa.it/people/gerla/www/Down/point-free.pdf Pointless Geometries]" in Buekenhout, F., Kantor, W. eds., ''Handbook of incidence geometry: buildings and foundations''. North-Holland: 1015–31.
* [[Alfred North Whitehead| Whitehead, A. N.]], 1919. ''An Enquiry Concerning the Principles of Natural Knowledge''. Cambridge Univ. Press. 2nd ed., 1925.
* Whitehead, A. N., 1920. ''[http://www.gutenberg.org/files/18835/18835-h/18835-h.htm The Concept of Nature]''. Cambridge Univ. Press. 2004 paperback, Prometheus Books. Being the 1919 Tarner Lectures delivered at [[Trinity College, Cambridge|Trinity College]].
* Whitehead, A. N., 1979 (1929). ''[[Process and Reality]]''. Free Press.

==External links==
{{commons category|Points (mathematics)}}
*[http://www.mathopenref.com/point.html Definition of Point] with interactive applet
*[http://www.mathopenref.com/tocs/pointstoc.html Points definition pages], with interactive animations that are also useful in a classroom setting. Math Open Reference
*{{PlanetMath reference|id=8173|title=Point}}
*{{MathWorld |title=Point |id=Point}}
{{Dimension topics}}

[[Category:Elementary geometry]]
[[Category:Mathematical concepts]]</text>
      <sha1>eyxaxf06s7st3til9qhc8uo5qlxu101</sha1>
    </revision>
  </page>
  <page>
    <title>Predictive state representation</title>
    <ns>0</ns>
    <id>11360852</id>
    <revision>
      <id>783667875</id>
      <parentid>766039393</parentid>
      <timestamp>2017-06-03T21:44:22Z</timestamp>
      <contributor>
        <username>Me, Myself, and I are Here</username>
        <id>17619453</id>
      </contributor>
      <minor/>
      <comment>/* top */ adjust bold, punct.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2771">{{notability|date=March 2011}}

In [[computer science]], a '''predictive state representation''' ('''PSR''') is a way to model a state of controlled [[dynamical system]] from a history of actions taken and resulting observations. PSR captures the state of a system as a vector of predictions for future tests (experiments) that can be done on the system.&lt;ref&gt;{{Cite journal|last=James|first=Michael R.|last2=Singh|first2=Satinder|date=2004-01-01|title=Learning and Discovery of Predictive State Representations in Dynamical Systems with Reset|url=http://doi.acm.org/10.1145/1015330.1015359|journal=Proceedings of the Twenty-first International Conference on Machine Learning|series=ICML '04|location=New York, NY, USA|publisher=ACM|pages=53–|doi=10.1145/1015330.1015359|isbn=1581138385}}&lt;/ref&gt; A test is a sequence of action-observation pairs and its prediction is the probability of the test's observation-sequence happening if the test's action-sequence were to be executed on the system. One of the advantage of using PSR is that the predictions are directly related to observable quantities.  This is in contrast to other models of dynamical systems, such as [[partially observable Markov decision process]]es (POMDPs) where the state of the system is represented as a [[probability distribution]] over unobserved nominal states.&lt;ref&gt;{{Cite web|url=https://www.semanticscholar.org/paper/A-Planning-Algorithm-for-Predictive-State-Izadi-Precup/b0bb9a5a8acd36692c13992151dfd812df24da81/pdf|title=A Planning Algorithm for Predictive State Representations (PDF) - Semantic Scholar|website=www.semanticscholar.org|language=en-US|access-date=2016-07-14}}&lt;/ref&gt;

==References==
{{Reflist}}
* {{cite conference
  | last = Littman | first = Michael L. | authorlink = Michael L. Littman |author2=[[Richard S. Sutton]] |author3=Satinder Singh
  | title = Predictive Representations of State
  | booktitle = Advances in Neural Information Processing Systems 14 (NIPS)
  | pages = 1555–1561
  | year = 2002
  | url = http://www.eecs.umich.edu/~baveja/Papers/psr.pdf}}

* {{cite conference
  | last =Singh | first = Satinder |author2=Michael R. James |author3=Matthew R. Rudary
  | title = Predictive State Representations: A New Theory for Modeling Dynamical Systems
  | booktitle = Uncertainty in Artificial Intelligence: Proceedings of the Twentieth Conference (UAI)
  | pages = 512–519
  | year = 2004
  | url = http://www.eecs.umich.edu/~baveja/Papers/uai2004psr.pdf}}

* {{Citation
  | last = Wiewiora | first = Eric Walter 
  | title = Modeling Probability Distributions with Predictive State Representations
  | year = 2008 
  | url = http://cseweb.ucsd.edu/~ewiewior/dissertation.pdf}}

[[Category:Machine learning]]
[[Category:Dynamical systems]]


{{Compu-AI-stub}}</text>
      <sha1>afiyx1a0u559sfk7jt2ax4fqn2d5njp</sha1>
    </revision>
  </page>
  <page>
    <title>Rational series</title>
    <ns>0</ns>
    <id>42993804</id>
    <revision>
      <id>790774428</id>
      <parentid>622586068</parentid>
      <timestamp>2017-07-16T00:11:50Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <minor/>
      <comment>/* Definition */LaTeX spacing clean up, replaced: \ &lt;/math&gt; → &lt;/math&gt; (3) using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3807">In mathematics and computer science, a '''rational series''' is a generalisation of the concept of [[formal power series]] over a [[Ring (mathematics)|ring]] to the case when the basic algebraic structure is no longer a ring but a [[semiring]], and the [[Indeterminate (variable)|indeterminate]]s adjoined are not assumed to [[Commutative property|commute]].  They can be regarded as algebraic expressions of a [[formal language]] over a finite [[Alphabet (computer science)|alphabet]].

==Definition==
Let ''R'' be a [[semiring]] and ''A'' a finite alphabet.

A ''noncommutative polynomial'' over ''A'' is a finite formal sum of words over ''A''.  They form a semiring &lt;math&gt;R\langle A \rangle&lt;/math&gt;.

A ''formal series'' is a ''R''-valued function ''c'', on the [[free monoid]] ''A''&lt;sup&gt;*&lt;/sup&gt;, which may be written as

:&lt;math&gt;\sum_{w \in A^*} c(w) w \ . &lt;/math&gt;

The set of formal series is denoted &lt;math&gt;R\langle\langle A \rangle\rangle&lt;/math&gt; and becomes a semiring under the operations

:&lt;math&gt;c+d : w \mapsto c(w) + d(w) &lt;/math&gt;
:&lt;math&gt;c\cdot d : w \mapsto \sum_{uv = w} c(u) \cdot d(v) \ . &lt;/math&gt;

A non-commutative polynomial thus corresponds to a function ''c'' on ''A''&lt;sup&gt;*&lt;/sup&gt; of finite support.

In the case when ''R'' is a ring, then this is the ''Magnus ring'' over ''R''.&lt;ref&gt;{{cite book | first=Helmut | last=Koch | title=Algebraic Number Theory | publisher=[[Springer-Verlag]] | year=1997 | isbn=3-540-63003-1 | zbl=0819.11044 | series=Encycl. Math. Sci. | volume=62 | edition=2nd printing of 1st | page=167 }}&lt;/ref&gt;

If ''L'' is a language over ''A'', regarded as a subset of ''A''&lt;sup&gt;*&lt;/sup&gt; we can form the ''characteristic series'' of ''L'' as the formal series

:&lt;math&gt;\sum_{w \in L} w &lt;/math&gt;

corresponding to the [[Indicator function |characteristic function]] of ''L''.

In &lt;math&gt;R\langle\langle A \rangle\rangle&lt;/math&gt; one can define an operation of [[Kleene star|iteration]] expressed as

:&lt;math&gt; S^* = \sum_{n \ge 0} S^n &lt;/math&gt;

and formalised as

:&lt;math&gt;c^*(w) = \sum_{u_1 u_2 \cdots u_n = w} c(u_1)c(u_2) \cdots c(u_n) \ . &lt;/math&gt;

The ''rational operations'' are the addition and multiplication of formal series, together with iteration.
A '''rational series''' is a formal series obtained by rational operations from &lt;math&gt;R\langle A \rangle&lt;/math&gt;.

==See also==
* [[Formal power series]]
* [[Rational language]] 
* [[Rational set]]
* [[Hahn series]] (Malcev–Neumann series)
* [[Weighted automaton]]

==References==
{{reflist}}
* {{cite book | last1=Berstel | first1=Jean | last2=Reutenauer | first2=Christophe | title=Noncommutative rational series with applications | series=Encyclopedia of Mathematics and Its Applications | volume=137 | location=Cambridge | publisher=[[Cambridge University Press]] | year=2011 | isbn=978-0-521-19022-0 | zbl=1250.68007 }}

== Further reading ==
* {{cite book | last=Sakarovitch | first=Jacques | title=Elements of automata theory | others=Translated from the French by Reuben Thomas | location=Cambridge | publisher=[[Cambridge University Press]] | year=2009 | isbn=978-0-521-84425-3 | zbl=1188.68177 | at=Part IV (where they are called &lt;math&gt;\mathbb{K}&lt;/math&gt;-rational series)}}
* Droste, M., &amp; Kuich, W. (2009). Semirings and Formal Power Series. ''Handbook of Weighted Automata'', 3–28. {{doi|10.1007/978-3-642-01492-5_1}}
* Sakarovitch, J. Rational and Recognisable Power Series. ''Handbook of Weighted Automata'', 105–174 (2009). {{doi|10.1007/978-3-642-01492-5_4}}
* W. Kuich. Semirings and formal power series: Their relevance to formal languages and automata theory. In G. Rozenberg and A. Salomaa, editors, Handbook of Formal Languages, volume 1, Chapter 9, pages 609–677. Springer, Berlin, 1997

[[Category:Abstract algebra]]
[[Category:Formal languages]]
[[Category:Mathematical series]]

{{algebra-stub}}</text>
      <sha1>32xfebz8u48w7c8214p99tk0hs3nugf</sha1>
    </revision>
  </page>
  <page>
    <title>Right conoid</title>
    <ns>0</ns>
    <id>23756785</id>
    <revision>
      <id>790774774</id>
      <parentid>786092750</parentid>
      <timestamp>2017-07-16T00:14:20Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <minor/>
      <comment>LaTeX spacing clean up, replaced: \,&lt;/math&gt; → &lt;/math&gt; (7) using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1739">[[Image:Right concoid.svg|right|thumb|240px|A right conoid as a ruled surface.]]

In [[geometry]], a '''right [[conoid]]''' is a [[ruled surface]] generated by a family of [[straight line]]s that all intersect [[perpendicular]]ly to a fixed straight line, called the ''axis'' of the right conoid.

Using a [[Cartesian coordinate system]] in [[three-dimensional space]], if we take the z-axis to be the axis of a right conoid, then the right conoid can be represented by the [[parametric equation]]s:

:&lt;math&gt;x=v\cos u, y=v\sin u, z=h(u) &lt;/math&gt;

where ''h''(''u'') is some [[function (mathematics)|function]] for representing the ''height'' of the moving line.

==Examples==
[[Image:Conoid.gif|right|thumb|300px|Generation of a typical right conoid]]

A typical example of right conoids is given by the parametric equations
: &lt;math&gt;x=v\cos u, y=v\sin u, z=2\sin u&lt;/math&gt;

The image on the right shows how the coplanar lines generate the right conoid.

Other right conoids include:
*[[Helicoid]]: &lt;math&gt;x=v\cos u, y=v\sin u, z=cu.&lt;/math&gt;
*[[Whitney umbrella]]: &lt;math&gt;x=vu, y=v, z=u^2.&lt;/math&gt;
*[[Wallis’s conical edge]]: &lt;math&gt;x=v\cos u, y=v \sin u, z=c\sqrt{a^2-b^2\cos^2u}.&lt;/math&gt;
*[[Plücker’s conoid]]: &lt;math&gt; x=v\cos u, y=v\sin u, z=c\sin nu.&lt;/math&gt;
*[[hyperbolic paraboloid]]: &lt;math&gt; x=v, y=u, z=uv&lt;/math&gt; (with x-axis and y-axis as its axes).

== See also ==

* [[Conoid]]
* [[Helicoid]]
* [[Whitney umbrella]]
* [[Ruled surface]]

==External links==
* {{springer|title=Conoid|id=p/c025210}}
* [http://mathworld.wolfram.com/RightConoid.html Right Conoid] from MathWorld.
* [http://mathworld.wolfram.com/PlueckersConoid.html Plücker's conoid] from MathWorld

[[Category:Surfaces]]
[[Category:Geometric shapes]]


{{geometry-stub}}</text>
      <sha1>cze5e0zcxnugilitnf2zrdz704wgst3</sha1>
    </revision>
  </page>
  <page>
    <title>Robert Edmund Edwards</title>
    <ns>0</ns>
    <id>46418011</id>
    <revision>
      <id>839859114</id>
      <parentid>784323068</parentid>
      <timestamp>2018-05-06T04:50:19Z</timestamp>
      <contributor>
        <username>Chris the speller</username>
        <id>525927</id>
      </contributor>
      <minor/>
      <comment>/* top */per [[MOS:JOBTITLES]], replaced: Professorial Fellow → professorial fellow, Professor → professor, Lecturer → lecturer, etc. using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2280">'''Robert Edmund Edwards''' (1926–2000),&lt;ref&gt;[http://www.eoas.info/biogs/P002338b.htm Encyclopedia of Australian Science]&lt;/ref&gt;&lt;ref&gt;[http://oa.anu.edu.au/obituary/gaudry-garth-ian-16493 Obituary of Edwards' student Garth Ian Gaudry]&lt;/ref&gt;&lt;ref&gt;[http://trove.nla.gov.au/people/618125?c=people National Library of Australia]&lt;/ref&gt; usually cited simply as '''R. E. Edwards''', was a British-born Australian [[mathematician]] who specialized in [[functional analysis]].
He is the author of several volumes in Springer's [[Graduate Texts in Mathematics]].

He received his PhD at [[Birkbeck, University of London|Birkbeck College, University of London]] in 1951 under [[Lionel Cooper (mathematician)|Lionel Cooper]]. His dissertation topic was ''Theory of Normed Rings, and Translations in Function Spaces''.&lt;ref&gt;{{cite web|url=http://www.genealogy.math.ndsu.nodak.edu/id.php?id=42237|title=Robert Edmund Edwards|work=The Mathematics Genealogy Project|accessdate=31 May 2015}}&lt;/ref&gt; He continued to teach there as a lecturer until 1959, and then spent a few years at [[University of Manchester|Manchester]], before migrating to Australia in 1961, where he worked at the Institute of Advanced Studies at [[ANU]] as a professorial fellow (1961-1970) and professor of mathematics (1970-1978).

==Selected publications==
*''Functional Analysis: Theory and Applications.'' Holt, Rinehart, and Winston, 1965; revised edition Dover Publications, 1995; {{ISBN|0-486-68143-2}}.
*''A Formal Background to Mathematics: Volume 1, Logic, Sets and Numbers''. Springer-Verlag, 1979; {{ISBN|978-0-387-90431-3}}.
*''A Formal Background to Mathematics: Volume 2, A Critical Approach to Elementary Analysis''. Springer-Verlag, 1980; {{ISBN|978-0-387-90513-6}}.
*''Graduate Texts in Mathematics: Fourier Series, A Modern Introduction''. Volumes 1 and 2. Holt, Rinehart, and Winston, 1967; 2nd edition, Springer-Verlag, 1982; {{ISBN|978-1-4613-8158-7}}.
*''Integration and Harmonic Analysis on Compact Groups''. Cambridge University Press, 1972; {{ISBN|978-0-521-09717-8}}.

==References==
{{Reflist}}

{{Authority control}}
{{DEFAULTSORT:Edwards, Robert Edmund}}
[[Category:Australian mathematicians]]
[[Category:1926 births]]
[[Category:Year of death missing]]


{{Australia-bio-stub}}
{{math-bio-stub}}</text>
      <sha1>bxxz0hylfmrwfj19nu2f4dfghsl1g36</sha1>
    </revision>
  </page>
  <page>
    <title>Shearer's inequality</title>
    <ns>0</ns>
    <id>29618699</id>
    <revision>
      <id>810226479</id>
      <parentid>731134393</parentid>
      <timestamp>2017-11-14T01:24:51Z</timestamp>
      <contributor>
        <username>Headbomb</username>
        <id>1461430</id>
      </contributor>
      <comment>ce</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1096">{{context|date=November 2010}}

In [[information theory]], '''Shearer's inequality''',&lt;ref&gt;{{cite journal|last1=Chung|first1=F.R.K.|last2=Graham|first2=R.L.|last3=Frankl|first3=P.|last4=Shearer|first4=J.B.|title=Some Intersection Theorems for Ordered Sets and Graphs|journal=J. Comb. Theory A|date=1986|volume=43|pages=23–37}}&lt;/ref&gt; named after James Shearer, states that if ''X''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;...,&amp;nbsp;''X''&lt;sub&gt;''d''&lt;/sub&gt; are [[random variable]]s and ''S''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;...,&amp;nbsp;''S''&lt;sub&gt;''n''&lt;/sub&gt; are subsets of {1,&amp;nbsp;2,&amp;nbsp;...,&amp;nbsp;''d''} such that every integer between 1 and ''d'' lies in at least ''r'' of these subsets, then

: &lt;math&gt; H[(X_1,\dots,X_d)] \leq \frac{1}{r}\sum_{i=1}^n H[(X_j)_{j\in S_i}]&lt;/math&gt;

where &lt;math&gt; (X_{j})_{j\in S_{i}}&lt;/math&gt; is the [[Cartesian product]] of random variables &lt;math&gt;X_{j}&lt;/math&gt; with indices ''j'' in &lt;math&gt;S_{i}&lt;/math&gt; (so the dimension of this vector is equal to the size of &lt;math&gt;S_{i}&lt;/math&gt;).

== References ==
{{Reflist}}

{{DEFAULTSORT:Shearer's Inequality}}
[[Category:Information theory]]
[[Category:Inequalities]]</text>
      <sha1>p7hesszh01sfid19mwgcthu04ah1cb5</sha1>
    </revision>
  </page>
  <page>
    <title>Slope field</title>
    <ns>0</ns>
    <id>1866685</id>
    <revision>
      <id>826413267</id>
      <parentid>788313868</parentid>
      <timestamp>2018-02-18T23:54:32Z</timestamp>
      <contributor>
        <username>I dream of horses</username>
        <id>9676078</id>
      </contributor>
      <minor/>
      <comment>Cleaning up a [[WP:RANPP|randomly generated list]], [[WP:AWB/T|typo(s) fixed]]: e.g  → e.g. using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6184">[[File:Slope Field.png|thumb|right|250px|The slope field of dy/dx=x&lt;sup&gt;2&lt;/sup&gt;-x-2, with the blue, red, and turquoise lines being (x&lt;sup&gt;3&lt;/sup&gt;/3)-(x&lt;sup&gt;2&lt;/sup&gt;/2)-2x+4, (x&lt;sup&gt;3&lt;/sup&gt;/3)-(x&lt;sup&gt;2&lt;/sup&gt;/2)-2x, and (x&lt;sup&gt;3&lt;/sup&gt;/3)-(x&lt;sup&gt;2&lt;/sup&gt;/2)-2x-4, respectively.]]
The solutions of a first-order [[differential equation]]&lt;ref&gt;{{cite book|author=Vladimir A. Dobrushkin|title=Applied Differential Equations: The Primary Course|url=https://books.google.com/books?id=d-5MBgAAQBAJ&amp;pg=PA13|year=2014|publisher=CRC Press|isbn=978-1-4987-2835-5|page=13}}&lt;/ref&gt; of a scalar function  y(x) can be drawn in a 2-dimensional space with the x in horizontal and y in vertical direction. Possible solutions are functions y(x) drawn as solid curves. Sometimes it is too cumbersome solving the differential equation [[Analytical solution|analytically]]. Then one can still draw the tangents of the function curves e.g. on a regular grid.  The tangents are touching the functions at the grid points.   However, the direction field is rather agnostic about chaotic aspects of  the differential equation.

==Definition==

===Standard case===
The slope field can be defined for the following type of differential equations 
:&lt;math&gt;y'=f(x,y)&lt;/math&gt;,
which can be interpreted geometrically as giving the [[slope]] of the [[tangent]] to the [[Graph of a function|graph]] of the differential equation's solution (''[[integral curve]]'') at each point (''x'', ''y'') as a function of the point coordinates.&lt;ref&gt;{{cite book|author1=Andrei D. Polyanin|author2=Alexander V. Manzhirov|title=Handbook of Mathematics for Engineers and Scientists|url=https://books.google.com/books?id=ge6nk9W0BCcC&amp;pg=PA453|year=2006|publisher=CRC Press|isbn=978-1-58488-502-3|page=453}}&lt;/ref&gt;

It can be viewed as a creative way to plot a real-valued function of two real variables &lt;math&gt;f(x,y)&lt;/math&gt; as a planar picture. Specifically, for a given pair &lt;math&gt;x,y&lt;/math&gt;, a vector with the components &lt;math&gt;[1, f(x,y)]&lt;/math&gt; is drawn at the point &lt;math&gt;x,y&lt;/math&gt; on the &lt;math&gt;x,y&lt;/math&gt;-plane. Sometimes, the vector &lt;math&gt;[1, f(x,y)]&lt;/math&gt; is normalized to make the plot better looking for a human eye. A set of pairs &lt;math&gt;x,y&lt;/math&gt; making a rectangular grid is typically used for the drawing.

An [[isocline]] (a series of lines with the same slope) is often used to supplement the slope field. In an equation of the form &lt;math&gt;y'=f(x,y)&lt;/math&gt;, the isocline is a line in the &lt;math&gt;x,y&lt;/math&gt;-plane obtained by setting &lt;math&gt;f(x,y)&lt;/math&gt; equal to a constant.

===General case of a system of differential equations===
Given a system of differential equations,
:&lt;math&gt;\frac{dx_1}{dt}=f_1(t,x_1,x_2,\ldots,x_n)&lt;/math&gt;
:&lt;math&gt;\frac{dx_2}{dt}=f_2(t,x_1,x_2,\ldots,x_n)&lt;/math&gt;
:::&lt;math&gt;\vdots&lt;/math&gt;
:&lt;math&gt;\frac{dx_n}{dt}=f_n(t,x_1,x_2,\ldots,x_n)&lt;/math&gt;
the slope field is an array of slope marks in the [[phase space]] (in any number of dimensions depending on the number of relevant variables; for example, two in the case of a first-order linear [[ordinary differential equation|ODE]], as seen to the right).  Each slope mark is centered at a point &lt;math&gt;(t,x_1,x_2,\ldots,x_n)&lt;/math&gt; and is parallel to the vector

:&lt;math&gt;\begin{pmatrix} 1 \\ f_1(t,x_1,x_2,\ldots,x_n) \\ f_2(t,x_1,x_2,\ldots,x_n) \\ \vdots \\ f_n(t,x_1,x_2,\ldots,x_n) \end{pmatrix}&lt;/math&gt;.
The number, position, and length of the slope marks can be arbitrary.  The positions are usually chosen such that the points &lt;math&gt;(t,x_1,x_2,\ldots,x_n)&lt;/math&gt; make a uniform grid. The standard case, described above, represents &lt;math&gt;n=1&lt;/math&gt;. The general case of the slope field for systems of differential equations is not easy to visualize for &lt;math&gt;n&gt;2&lt;/math&gt;.

==General application==
With computers, complicated slope fields can be quickly made without tedium, and so an only recently practical application is to use them merely to get the feel for what a solution should be before an explicit general solution is sought.  Of course, computers can also just solve for one, if it exists.

If there is no explicit general solution, computers can use slope fields (even if they aren’t shown) to numerically find graphical solutions.  Examples of such routines are [[Euler's method]], or better, the [[Runge–Kutta methods]].

==Software for plotting slope fields==
Different software packages can plot slope fields.

===direction field code in [[GNU Octave]]/[[MATLAB]] ===
&lt;source lang="matlab"&gt;
funn = @(x,y)y-x;                        % function f(x,y)=y-x
[x,y]=meshgrid(-5:0.5:5);                % intervals for x and y
slopes=funn(x,y);                        % matrix of slope values
dy=slopes./sqrt(1+slopes.^2);            % normalize the line element...
dx=ones(length(dy))./sqrt(1+slopes.^2);  % ...magnitudes for dy and dx
h=quiver(x,y,dx,dy,0.5);                 % plot the direction field
set (h, "maxheadsize", 0.1);             % alter head size
&lt;/source&gt;

=== Example code for [[Maxima (software)|Maxima]] ===

 /* field for y'=xy (click on a point to get an integral curve) */
 plotdf( x*y, [x,-2,2], [y,-2,2]);

=== Example code for [[Mathematica]] ===
&lt;source lang="mathematica"&gt;
(* field for y'=xy *)
VectorPlot[{1,x*y},{x,-2,2},{y,-2,2}]
&lt;/source&gt;

==Examples==
&lt;gallery Caption="y' = xy"&gt;
Image:Slope_field_1.svg|Slope field
Image:Slope_field_with_integral_curves_1.svg|Integral curves
image:Isocline_3.png|Isoclines (blue), slope field (black), and some solution curves (red)
&lt;/gallery&gt;

==See also==
*[[Examples of differential equations]]
*[[Vector field]]
*[[Laplace transform applied to differential equations]]
*[[List of dynamical systems and differential equations topics]]
*[[Qualitative theory of differential equations]]

==References==
{{Reflist}}
* Blanchard, Paul; [[Robert L. Devaney|Devaney, Robert L.]]; and Hall, Glen R. (2002). ''Differential Equations'' (2nd ed.). Brooks/Cole: Thompson Learning. {{ISBN|0-534-38514-1}}

==External links==
* {{MathWorld |title = Slope field |urlname = SlopeField}}
* [http://www.math.psu.edu/cao/DFD/Dir.html Slope field plotter]

[[Category:Calculus]]
[[Category:Differential equations]]
[[Category:Articles with example MATLAB/Octave code]]
[[Category:Plots (graphics)]]</text>
      <sha1>juuamt9k0bq7t9rmmf52i19o1kik9nl</sha1>
    </revision>
  </page>
  <page>
    <title>Symplectic representation</title>
    <ns>0</ns>
    <id>19411601</id>
    <revision>
      <id>783795331</id>
      <parentid>543115989</parentid>
      <timestamp>2017-06-04T18:17:33Z</timestamp>
      <contributor>
        <username>Nyktos</username>
        <id>1058639</id>
      </contributor>
      <minor/>
      <comment>fix G being bolded in only one place</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1629">In [[mathematics|mathematical]] field of [[representation theory]], a '''symplectic representation''' is a [[group representation|representation]] of a [[group (mathematics)|group]] or a [[Lie algebra representation|Lie algebra]] on a [[symplectic vector space]] (''V'', ''ω'') which preserves the symplectic form ''ω''. Here ''ω'' is a nondegenerate skew symmetric bilinear form
:&lt;math&gt;\omega\colon V\times V \to \mathbb F&lt;/math&gt;
where '''F''' is the [[field (mathematics)|field]] of scalars. A representation of a group ''G'' preserves ''ω'' if
:&lt;math&gt;\omega(g\cdot v,g\cdot w)= \omega(v,w)&lt;/math&gt;
for all ''g'' in ''G'' and ''v'', ''w'' in ''V'', whereas a representation of a [[Lie algebra]] '''g''' preserves ''ω'' if
:&lt;math&gt;\omega(\xi\cdot v,w)+\omega(v,\xi\cdot w)=0&lt;/math&gt;
for all ''ξ'' in '''g''' and ''v'', ''w'' in ''V''. Thus a representation of ''G'' or '''g''' is equivalently a group or Lie algebra homomorphism from ''G'' or '''g''' to the [[symplectic group]] Sp(''V'',''ω'') or its Lie algebra '''sp'''(''V'',''ω'')

If ''G'' is a [[compact group]] (for example, a [[finite group]]), and '''F''' is the field of complex numbers, then by introducing a compatible unitary structure (which exists by an averaging argument), one can show that any complex symplectic representation is a [[quaternionic representation]]. Quaternionic representations of finite or compact groups are often called symplectic representations, and may be identified using the [[Frobenius-Schur indicator]].

==References==
*{{Fulton-Harris}}.

[[Category:Representation theory]]
[[Category:Symplectic geometry]]


{{algebra-stub}}</text>
      <sha1>sw0396t5vffdxdo0tgkfusdrvqu94lw</sha1>
    </revision>
  </page>
  <page>
    <title>Vectors in three-dimensional space</title>
    <ns>0</ns>
    <id>16303447</id>
    <revision>
      <id>788889472</id>
      <parentid>727545339</parentid>
      <timestamp>2017-07-04T02:41:25Z</timestamp>
      <contributor>
        <username>Magic links bot</username>
        <id>30707369</id>
      </contributor>
      <minor/>
      <comment>Replace [[Help:Magic links|magic links]] with templates per [[Special:Permalink/772743896#Future of magic links|local RfC]] and [[:mw:Requests for comment/Future of magic links|MediaWiki RfC]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2406">{{italic title}}
{{one source|date=September 2013}}
'''''Vectors in three-dimensional space''''' (1978) is a book concerned with [[physical quantities]] defined in "ordinary" [[3-space]].  It was written by [[John Stephen Roy Chisholm|J.S.R.Chisholm]], an English [[mathematical physicist]], and published by [[Cambridge University Press]].  According to the author, such [[physical quantities]] are studied in [[Newtonian mechanics]], [[fluid mechanics]], theories of [[Elasticity (physics)|elasticity]] and [[Plasticity (physics)|plasticity]], non-relativistic [[quantum mechanics]], and many parts of [[solid state physics]].  The author further states that "the vector concept developed in two different ways: in a wide variety of physical applications, vector notation and techniques became, by the middle of this century, almost universal; on the other hand, pure mathematicians reduced vector algebra to an axiomatic system, and introduced wide [[generalization|generalisations]] of the concept of a three-dimensional 'vector space'."  Chisholm explains that since these two developments proceeded largely independently, there is a need to show how one can be applied to the other.&lt;ref&gt;Chisholm, J.S.R. (1978) p. vii-viii&lt;/ref&gt;

==Summary==
''Vectors in three-dimensional space'' has six chapters, each divided into five or more subsections. The first on '''[[Vector space|linear spaces]] and [[displacement (vector)|displacements]]''' including these sections: Introduction, Scalar multiplication of vectors, Addition and subtraction of vectors, Displacements in Euclidean space, Geometrical applications.  The second on '''[[dot product|Scalar products]] and components''' including these sections: Scalar products, [[Linear dependence]] and dimension, Components of a vector, Geometrical applications, [[Coordinate system]]s.  The third on '''Other products of vectors'''.  The last three chapters round out Chisholm's integration of these two largely independent developments.

==Notes==
{{reflist}}

==References==
* ''Vectors in three-dimensional space'' has been cited by the 2002 [[Encyclopedia Americana]] article on '''Vector Analysis''' 
* [[John Stephen Roy Chisholm|Chisholm, J.S.R.]] ''Vectors in three-dimensional space'', Cambridge University Press, 1978, {{ISBN|0-521-29289-1}}

[[Category:1978 books]]
[[Category:Mathematics books]]


{{mathematics-lit-stub}}
{{physics-book-stub}}</text>
      <sha1>nmcd1lxms5knyl3mk5wi4xente1rhfp</sha1>
    </revision>
  </page>
  <page>
    <title>Wilhelm Winkler</title>
    <ns>0</ns>
    <id>51347294</id>
    <revision>
      <id>838046047</id>
      <parentid>822208834</parentid>
      <timestamp>2018-04-24T16:06:37Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>+{{[[Template:Authority control|Authority control]]}} (6 sources from Wikidata), [[WP:GenFixes]] on, using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6270">{{Infobox scientist
| honorific_prefix =
| name        = Wilhelm Winkler
| birth_date  = {{birth date |1884|6|29}}
| birth_place = [[Prague]], [[Bohemia]] (now [[Czech Republic]])
| death_date  = {{death date and age|1984|9|3|1884|6|29}}
| death_place = [[Vienna]], Austria
| resting_place_coordinates =  &lt;!--{{coord|LAT|LONG|type:landmark|display=inline,title}}--&gt;
| alma_mater  = [[Charles University|Karl Friedrich University]], Prague
| known_for   = Population statistics
| awards      = Honorary member of the International Statistical Institute, President of the International Statistical Institute, Austrian Academy of Sciences, Royal Statistical Society, Honorary Degrees from [[University of Munich]] and [[University of Vienna]].
| spouse      = Clara Deutch, 1918
}}

'''Wilhelm Winkler''' (June 29, 1884 – September 3, 1984) had successful careers as both an academic [[statistician]] (despite receiving no formal academic training in the field), and a program director in the Austrian government.

==Biography==

===Early life===
Wilhelm was the fifth&lt;ref name="Pinw"&gt;{{cite book|last1=Pinwinkler|first1=Alexander|editor1-last=Heyde|editor1-first=C. C.|editor2-last=Seneta|editor2-first=E.|editor3-last=Crepel|editor3-first=P.|editor4-last=Fienberg|editor4-first=S. E.|editor5-last=Gani|editor5-first=J.|title=Statisticians of the centuries|date=2001|publisher=Springer|location=New York, NY|isbn=978-0-387-95283-3|pages=369–372|doi=10.1007/978-1-4613-0179-0_79|chapter=Wilhelm Winkler}}&lt;/ref&gt; of the eight children of Anne and music teacher Julius Winkler, a family situation that required him to work starting at age 13.&lt;ref name="MacTutor"&gt;{{cite web|last1=O'Connor|first1=J. J.|last2=Robertson|first2=E. F.|title=Winkler biography|url=http://www-history.mcs.st-andrews.ac.uk/Biographies/Winkler.html|publisher=MacTutor Biographies|accessdate=17 August 2016}}&lt;/ref&gt; He attended law school at Karl Friedrich University (now [[Charles University]]) in Prague, practiced law briefly in 1908, did a stint in the Austrian army, then settled into a position at the Statistical Bureau of Bohemia&lt;ref name="MacTutor"/&gt; as the sole German-speaking statistician.&lt;ref name="Pinw"/&gt; While working there, he attended many university classes and reached the conclusion that "the German statistical literature did not offer too many ideas. New life came into statistics from England and Russia where the importance of mathematical tools was recognized."&lt;ref name="100bday"&gt;{{cite journal|last1=Schmetterer|first1=L.|title=Tribute to Wilhelm Winkler at His 100th Anniversary|journal=International Statistical Review / Revue Internationale de Statistique|date=1984|volume=52|issue=3|pages=227–228|jstor=1403044}}&lt;/ref&gt;

===War years===
Winkler re-enlisted in the Austrian army at the outbreak of [[World War I]] in 1914, and was decorated twice for bravery before being wounded in November 1915.&lt;ref name="MacTutor"/&gt; During a lengthy recovery, he worked for the War Economy committee; his talents were recognized and he was appointed Secretary of State for Military Affairs at the end of the war in 1918 and he was a delegate to the [[Paris Peace Conference, 1919|Versailles Peace Conference]]. That year, he also married a Jewish woman named Clara Deutch. He joined the Austrian Central Statistics Office in 1920, and was promoted to director of its department of population statistics in 1925.&lt;ref name="Pinw"/&gt; Concurrently, he became a ''Privat-Dozent'' (assistant professor) at the University of Vienna in 1921 and an ''Ausserordentlicher Professor'' in 1929. He founded an institute for the study of minority populations,&lt;ref name="Pinw"/&gt; which published a constant stream of progressive and influential papers that made him unpopular with colleagues in his government job.&lt;ref name="MacTutor"/&gt; Despite his lack of formal education, he was elected a member of the International Statistical Institute in 1926 where he actively promoted applied and precise mathematical formulations in contrast to the wordy generalizations that he had criticized 20 years earlier.&lt;ref name="Pinw"/&gt; As both the husband of a Jew and an outspoken critic of the unfair treatment of European minorities, Winkler was promptly fired from both his government and academic positions following the 1938 [[Anschluss|Nazi annexation of Austria]].&lt;ref name="Pinw"/&gt; Despite severe persecution from the Nazi party, he wrote the textbook ''Basic Course in Demography'' during the occupation.&lt;ref name="MacTutor"/&gt;

===Later years===
At the end of the war, he was rehired by the University of Vienna as the first full professor of statistics since 1883, and became Dean of the School of Law and Statecraft from 1950 to 1955. He was also restored as Austria's lead government statistician from 1945 to 1955.&lt;ref name="Pinw"/&gt; Despite these influential positions and growing international recognition, Winkler spent many years defending the statistical department from opposition within the university.&lt;ref name="Pinw"/&gt; The regressive attitude of Austrian and German academics towards statistics as a truly independent discipline meant that his contributions to international developments became more difficult.&lt;ref name="Pinw2"&gt;{{cite book |last1=Heyde|first1=C. C.|last2=Seneta|first2=E.|title=Statisticians of the Centuries|publisher=Springer Science &amp; Business Media |isbn=9781461301790 |edition=2nd |url=https://books.google.com/books?id=nAPrBwAAQBAJ }}&lt;/ref&gt; He did not retire until age 71, and continued to publish and vigorously promote statistics thereafter. He died just after his 100th birthday, having published 20 textbooks and over 200 papers, founded two statistical societies, edited two statistical journals, been awarded two honorary degrees, and reshaped the development of German-speaking statistics through his progressive education initiatives.&lt;ref name="100bday"/&gt;

== References ==
{{Reflist}}

== Further reading ==
* Pinwinkler, Alexander. ''Wilhelm Winkler (1884–1984): Eine Biographie: Zur Geschichte Der Statistik Und Demographie in Osterreich Und Deutschland''. Duncker &amp; Humblot: Berlin. {{de icon}}

{{Authority control}}

{{DEFAULTSORT:Winkler, Wilhelm}}
&lt;!--- Categories ---&gt;
[[Category:1884 births]]
[[Category:1984 deaths]]
[[Category:Mathematicians]]</text>
      <sha1>g39z4cbk9sqwwnd1ht5azmjg5vhruyp</sha1>
    </revision>
  </page>
  <page>
    <title>William Gooch (astronomer)</title>
    <ns>0</ns>
    <id>40249069</id>
    <revision>
      <id>856617854</id>
      <parentid>794163494</parentid>
      <timestamp>2018-08-26T14:01:13Z</timestamp>
      <contributor>
        <username>FeanorStar7</username>
        <id>160806</id>
      </contributor>
      <comment>/* Biography */ layout</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9762">{{EngvarB|date=September 2014}}
{{Use dmy dates|date=September 2014}}
{{Infobox person
| name        = William Gooch
| image       = 
| alt         = 
| caption     = 
| birth_name  = William Gooch
| birth_date  = {{Birth date|df=yes|1770|04|03}}
| birth_place = [[Brockdish]], Norfolk 
| death_date  = {{Death date and age|df=yes|1792|05|12|1770|04|03}}
| death_place = [[Waimea Bay, Hawaii|Waimea]], [[Oahu]], Hawaii
| death_cause = Murder
| nationality = [[United Kingdom of Great Britain and Ireland|British]]
| other_names = 
| occupation  = Astronomer
| known_for   = 
| alma_mater  = [[Gonville and Caius College, Cambridge]]
}}

'''William Gooch''' (3 April 1770 – 12 May 1792) was an English [[astronomer]].

==Biography==
===Early life===
Gooch was born on 3 April 1770 to William and Sarah Gooch and baptised on 8 May 1770&lt;ref&gt;{{cite book|last=Dening|first=Greg|title=The Death of William Gooch: A History's Anthropology|date=1995|publisher=University of Hawaii Press|location=Honolulu|isbn=0-8248-1754-0|page=65}}&lt;/ref&gt; at the church of St. Peter and St. Paul, [[Brockdish]] near [[Diss]] in Norfolk. William was schooled in nearby [[Redenhall with Harleston|Harleston]], Norfolk and later [[Stradbroke]] School in [[Suffolk]].&lt;ref&gt;{{cite web|last=Venn|first=John|title=A Cambridge Alumni Database|url=http://venn.lib.cam.ac.uk/cgi-bin/search-130418.pl?sur=gooch&amp;suro=w&amp;fir=william&amp;firo=w&amp;cit=&amp;cito=c&amp;c=all&amp;tex=&amp;sye=&amp;eye=&amp;col=CAIUS&amp;maxcount=50|publisher=Cambridge University Library|accessdate=12 August 2013}}&lt;/ref&gt; His sister, Sarah, succumbed to smallpox at the age of 10 in 1777 and so, in "tender solicitude", his parents were protective over their son and would not let him "mix with other children, except in their presence".&lt;ref&gt;{{cite web|last=Nichols|first=C.|title=Letter from C. Nichols to Dawson Turner|url=http://cudl.lib.cam.ac.uk/view/MS-MM-00006-00048/404|publisher=Cambridge Digital Library|accessdate=13 August 2013}}&lt;/ref&gt;

Gooch's father was barber and peruke maker to the gentry of Brockdish, church warden and also fulfilled the role of village constable for a short time.&lt;ref&gt;{{cite book|last=Dening|first=Greg|title=The Death of William Gooch: A History's Anthropology|date=1995|publisher=University of Hawaii Press|location=Honolulu|isbn=0-8248-1754-0|pages=65–69}}&lt;/ref&gt; It was due to his father's services that the young William came to the attention of the owner of the village hall, Thomas Maynard (later Sir Thomas Maynard Hesilrige, [[Baron Hazlerigg|10th Baronet of Noseley Hall]]), who proved key in providing Gooch with the opportunity to go to [[Gonville and Caius College, Cambridge]].

===Cambridge education===
William Gooch was admitted as a [[sizar]] to Gonville and Caius College, Cambridge at the age of 16 on 30 May 1786, [[Matriculation|matriculated]] in the [[Michaelmas term]] of 1787, achieved his B.A. ([[Senior Wrangler (University of Cambridge)#Senior Wranglers and Second Wranglers, 1748–1909|Second Wrangler]]) in 1791 being awarded with the [[Smith's Prize]] and the Schuldham college prize and became a junior Fellow until his death in 1792.&lt;ref&gt;{{cite web|last=Venn|first=John|title=A Cambridge Alumni Database|url=http://venn.lib.cam.ac.uk/cgi-bin/search-130418.pl?sur=gooch&amp;suro=w&amp;fir=william&amp;firo=w&amp;cit=&amp;cito=c&amp;c=all&amp;tex=&amp;sye=&amp;eye=&amp;col=CAIUS&amp;maxcount=50|publisher=Cambridge University Library|accessdate=12 August 2013}}&lt;/ref&gt;

At Cambridge, Gooch formed a friendship with a Miss Sally Smithson, the daughter of a cook at [[St John's College, Cambridge]], with whom he continued to correspond after setting sail to join the [[Vancouver Expedition]]. He affectionately referred to her as "little goody two-shoes".&lt;ref&gt;{{cite web|last=Gooch|first=William|title=Letter from William Gooch to his parents|url=http://cudl.lib.cam.ac.uk/view/MS-MM-00006-00048/137|publisher=Cambridge Digital Library|accessdate=13 August 2013}}&lt;/ref&gt;

===From student to astronomer===
It had been presumed that Gooch would follow his academic career into the priesthood, but perhaps being aware of the need for an astronomer to join the Vancouver Expedition, before he had sat his final exams, his Cambridge associates [[Samuel Vince]] and [[John Brinkley (astronomer)|John Brinkley]], who had both attended the same school as Gooch at Harleston, suggested him to [[Nevil Maskelyne]], the [[Astronomer Royal]], who sat on the [[Board of Longitude]].&lt;ref&gt;{{cite book|last=Dening|first=Greg|title=The Death of William Gooch: A History's Anthropology|date=1995|publisher=University of Hawaii Press|location=Honolulu|isbn=0-8248-1754-0|page=113}}&lt;/ref&gt;

After some lobbying from his Cambridge supporters and friends,&lt;ref&gt;{{cite web|last=Gooch|first=William|title=Letter from William Gooch to his parents|url=http://cudl.lib.cam.ac.uk/view/MS-MM-00006-00048/51|publisher=Cambridge Digital Library|accessdate=15 August 2013}}&lt;/ref&gt; Gooch travelled to London in April 1791, and Maskelyne began preparing him for the expedition. He also received advice on his forthcoming adventure from [[William Wales (astronomer)|William Wales]], who had served as astronomer to [[James Cook|Cook]].&lt;ref&gt;{{cite web|last=Gooch|first=William|title=Letter from William Gooch to his parents|url=http://cudl.lib.cam.ac.uk/view/MS-MM-00006-00048/75|publisher=Cambridge Digital Library|accessdate=15 August 2013}}&lt;/ref&gt; In July 1791, Gooch was making his final preparations and boarding the ''Daedalus'' at [[Deptford]].&lt;ref&gt;{{cite web|last=Gooch|first=William|title=Letter from William Gooch to his father|url=http://cudl.lib.cam.ac.uk/view/MS-MM-00006-00048/99|publisher=Cambridge Digital Library|accessdate=15 August 2013}}&lt;/ref&gt;

Gooch was appointed at a salary of £400 a year and issued with a suit of navigational and astronomical instruments.&lt;ref&gt;{{cite web|last=Maskelyne|first=Nevil|title=List of instruments to be sent with the astronomer going to the North West coast of America, March 5, 1791|url=http://cudl.lib.cam.ac.uk/view/MS-RGO-00014-00013/257|publisher=Cambridge Digital Library|accessdate=30 August 2013}}&lt;/ref&gt; He sailed on the storeship ''Daedelus'' in August 1791, aiming to meet [[George Vancouver]] at [[Nootka Sound]].

===Death and legacy===
In Gooch's final letter to his parents, written on 2 May 1792, he speaks of his concerns over having used a false meridian and his hopes of being re-united with them in the autumn of 1794.&lt;ref&gt;{{cite web|last=Gooch|first=William|title=Final letter from William Gooch to his parents|url=http://cudl.lib.cam.ac.uk/view/MS-MM-00006-00048/184|publisher=Cambridge Digital Library|accessdate=15 August 2013}}&lt;/ref&gt; On 11 May 1792, Lieutenant Richard Hergest, commander of the ''Daedalus'', embarked on the ship's cutter along with Gooch and a small crew to trade with the locals and re-supply with fresh water at [[Waimea Bay, Hawaii|Waimea]] on [[Oahu]], in the [[Hawaiian islands]]. The party was attacked by ''Pahupu'' (Hawaiian warriors) on 12 May. Hergest, Gooch and a sailor were cut off from the rest of the group and killed.

Gooch's story is recorded in his letters, many of which were to his parents, and journal which are housed as part of the [[Board of Longitude]] archive at [[Cambridge University Library]].&lt;ref&gt;{{cite web|title=Board of Longitude Collection|url=http://cudl.lib.cam.ac.uk/collections/longitude|publisher=Cambridge Digital Library|accessdate=15 August 2013}}&lt;/ref&gt;

His biography, ''The Death of William Gooch: A History's Anthropology'', was written in 1995 by Greg Dening and illustrates the dangers of cross-cultural encounters in the exploration era.&lt;ref name=Quanchi&gt;{{cite book | last = Quanchi | first = Max|authorlink=| year = 2005 | title = Historical Dictionary of the Discovery and Exploration of the Pacific Islands | publisher = The Scarecrow Press  | location =  |page=76| isbn = 0810853957}}&lt;/ref&gt;

==Bibliography==
* {{cite web|title=Letters, memoranda and journal containing the history of Mr William Gooch|url=http://cudl.lib.cam.ac.uk/view/MS-MM-00006-00048|publisher=Cambridge Digital Library|accessdate=15 August 2013}}
* {{cite web|title=Observations in the voyage of the Daedalus: Volume 1|url=http://cudl.lib.cam.ac.uk/view/MS-RGO-00014-00062|publisher=Cambridge Digital Library|accessdate=15 August 2013}}
* {{cite web|title=Observations in the voyage of the Daedalus: Volume 2|url=http://cudl.lib.cam.ac.uk/view/MS-RGO-00014-00063|publisher=Cambridge Digital Library|accessdate=15 August 2013}}
* {{cite book|last=Bown|first=Stephen.|title=Madness, Betrayal and the Lash: The Epic Voyage of Captain George Vancouver|location=Canada|publisher=Douglas &amp; McIntyre|date=2008|isbn=1553653394}}
* {{cite book|last=Dening|first=Greg.|title=The Death of William Gooch: A History's Anthropology|location=Honolulu|publisher=University of Hawaiʻi Press|date=1995|isbn=0-8248-1754-0}}
* {{cite book|last=Howse|first=Derek.|title=Nevil Maskelyne: The Seaman's Astronomer|location=Cambridge|publisher=Cambridge University Press|date=1989|isbn=0-521-36261-X}}
* {{cite book|title=From Maps to Metaphors: The Pacific World of George Vancouver|date=1993|publisher=UBC Press|location=Vancouver|isbn=0-7748-0470-X|editor=Robin Fisher|editor2=Hugh Johnston}}

==See also==
* [[National Maritime Museum]], Greenwich
* [[Vancouver Expedition]]

==References==
{{reflist}}

==External links==
*[http://pleasantfields.com/luakini/x/ Article about Gooch's death]
*[http://waimeavalley.net/ahupuaa.aspx A history of Waimmea Valley including a section about the Daedalus killings]

{{Authority control}}

{{DEFAULTSORT:Gooch, William}}
[[Category:English astronomers]]
[[Category:Second Wranglers]]
[[Category:1770 births]]
[[Category:1792 deaths]]
[[Category:People from South Norfolk (district)]]
[[Category:English people murdered abroad]]</text>
      <sha1>opuqxbnq36tl422qitsoqwq4cveaxph</sha1>
    </revision>
  </page>
</mediawiki>
