{"id": "55657946", "url": "https://en.wikipedia.org/wiki?curid=55657946", "title": "Adaptation (arts)", "text": "Adaptation (arts)\n\nAn adaptation is a transfer of a work of art from one medium to another.\n\nSome common examples are:\n\nThere is, however, no end to potential media involved in adaptation. Adaptation is the practice of transcoding (changing the code or 'language' used in a medium) as well as the assimilation of a work of art to other cultural, linguistic, semiotic, aesthetic or other norms. Recent approaches to the expanding field Adaptation Studies reflect these expansion of our perspective. Adaptation occurs as a special case of intertextual and intermedial exchange and the copy-paste culture of digital technologies has produced \"new intertextual forms engendered by emerging technologies—mashups, remixes, reboots, samplings, remodelings, transformations— \" that \"further develop the impulse to adapt and appropriate, and the ways in which they challenge the theory and practice of adaptation and appropriation.\"\n\n\n"}
{"id": "49704717", "url": "https://en.wikipedia.org/wiki?curid=49704717", "title": "Ameson Year in China", "text": "Ameson Year in China\n\nAmeson Year in China (AYC) (Chinese Simplified: 美国青年教学使者; Pinyin: měiguó qīngnián jiàoxué shǐzhě) is a program offering opportunities for college graduates to become Educational Ambassadors by spending a year teaching, learning, and making a difference at public schools across China.\n\nAs the 21st century unfolded, Ameson Education and Cultural Exchange Foundation saw the U.S.-China relations continuing to become more important. Under their idea that lasting stability can be achieved through dialogue and exchange, the organization began seeking for future leaders to fulfill that mission through the Ameson Year in China (AYC) program.\n\nAmeson Year in China is a program for college graduates to provide future career awareness by spending one academic year by teaching and studying in an assigned site across China. Each week, AYC participants spend twenty hours teaching, ten hours in the office or in support of students' activities, and ten hours in collaborative or self-directed pursuits, such as language learning, exploration, and community engagement.\n\n"}
{"id": "2633667", "url": "https://en.wikipedia.org/wiki?curid=2633667", "title": "Article (publishing)", "text": "Article (publishing)\n\nAn article is a written work published in a print or electronic medium. It may be for the purpose of propagating news, research results, academic analysis, or debate.\n\nA news article discusses current or recent news of either general interest (i.e. daily newspapers) or of a specific topic (i.e. political or trade news magazines, club newsletters, or technology news websites).\n\nA news article can include accounts of eyewitnesses to the happening event. It can contain photographs, accounts, statistics, graphs, recollections, interviews, polls, debates on the topic, etc. Headlines can be used to focus the reader’s attention on a particular (or main) part of the article. The writer can also give facts and detailed information following answers to general questions like who, what, when, where, why and how.\n\nQuoted references can also be helpful. References to people can also be made through the written accounts of interviews and debates confirming the factuality of the writer’s information and the reliability of his source. The writer can use redirection to ensure that the reader keeps reading the article and to draw her attention to other articles. For example, phrases like \"Continued on page 3” redirect the reader to a page where the article is continued.\n\nWhile a good conclusion is an important ingredient for newspaper articles, the immediacy of a deadline environment means that copy editing often takes the form of deleting everything past an arbitrary point in the story corresponding to the dictates of available space on a page. Therefore, newspaper reporters are trained to write in inverted pyramid style, with all the most important information in the first paragraph or two. If the less vital details are pushed towards the end of the story, then the potentially destructive impact of draconian copy editing will be minimized.\n\nA headline is text above a newspaper article, indicating its topic. The headline catches the attention of the reader and relates well to the topic. Modern headlines are typically written in an abbreviated style omitting many elements of a complete sentence and almost always including a non-copular verb.\n\nA byline gives the name and often the position of the writer, along with the date.\n\nThe lead (sometimes spelled \"lede\") sentence captures the attention of the reader and sums up the focus of the story. The lead also establishes the subject, sets the tone and guides reader into the article.\n\nIn a news story, the introductory paragraph includes the most important facts and answers the questions: \"who\", \"what\", \"where\", \"when\", \"why\" and\" how\". In a featured story, the author may choose to open in any number of ways, often using a narrative hook, possibly one of the following:\nan anecdote, a shocking or startling statement, a generalization, pure information, a description, a quote, a question or a comparison.\nFor the news story, details and elaboration are evident in the body or running text of the news story and flow smoothly from the lead. Quotes are used to add interest and support to the story. Most news stories are structured using what is called an inverted pyramid. The \"angle\" (also called a \"hook\" or \"peg\") is usually the most newsworthy aspect of the story and is specifically highlighted and elaborated upon.\nA featured article will follow a format appropriate for its type. Structures for featured articles may include, but are not limited to:\nThe conclusion will sum up the article, possibly including a final quote, a descriptive scene, a play on the title or lead, a summary statement, or the writer's opinion. Make the conclusion attention-grabbing.\n\nThe article is usually on a well-defined topic or topics that are related in some way, such as a factual account of a newsworthy event.\nThe writer of a well-written article is seen as objective and showing all sides to an issue.\nThe sources for a news story should be identified and reliable.\nThe technique of show, don't tell is applied.\n\nPublications obtain articles in a few different ways:\n\n\n"}
{"id": "18290472", "url": "https://en.wikipedia.org/wiki?curid=18290472", "title": "Artificiality", "text": "Artificiality\n\nArtificiality (also called factitiousness, or the state of being artificial or man-made) is the state of being the product of intentional human manufacture, rather than occurring naturally through processes not involving or requiring human activity.\n\nArtificiality often carries with it the implication of being false, counterfeit, or deceptive. The philosopher Aristotle wrote in his \"Rhetoric\":\n\nHowever, artificiality does not necessarily have a negative connotation, as it may also reflect the ability of humans to replicate forms or functions arising in nature, as with an artificial heart or artificial intelligence. Political scientist and artificial intelligence expert Herbert A. Simon observes that \"some artificial things are imitations of things in nature, and the imitation may use either the same basic materials as those in the natural object or quite different materials. Simon distinguishes between the artificial and the synthetic, the former being an imitation of something found in nature (for example, an artificial sweetener which generates sweetness using a formula not found in nature), and the latter being a replication of something found in nature (for example, a sugar created in a laboratory that is chemically indistinguishable from a naturally occurring sugar). Some philosophers have gone further and asserted that, in a deterministic world, \"everything is natural and nothing is artificial\", because everything in the world (including everything made by humans) is a product of the physical laws of the world.\n\nIt is generally possible for humans, and in some instances, for computers, to distinguish natural from artificial environments. The artificial environment tends to have more physical regularity both spatially and over time, with natural environments tending to have both irregular structures and structures that change over time. However, on close observation it is possible to discern some mathematical structures and patterns in natural environments, which can then be replicated to create an artificial environment with a more natural appearance.\n\nFor example, by identifying and imitating natural means of pattern formation, some types of automata have been used to generate organic-looking textures for more realistic shading of 3D objects.\n\n"}
{"id": "168536", "url": "https://en.wikipedia.org/wiki?curid=168536", "title": "Bulimia nervosa", "text": "Bulimia nervosa\n\nBulimia nervosa, also known as simply bulimia, is an eating disorder characterized by binge eating followed by purging. Binge eating refers to eating a large amount of food in a short amount of time. Purging refers to the attempts to get rid of the food consumed. This may be done by vomiting or taking laxatives. Other efforts to lose weight may include the use of diuretics, stimulants, water fasting, or excessive exercise. Most people with bulimia are at a normal weight. The forcing of vomiting may result in thickened skin on the knuckles and breakdown of the teeth. Bulimia is frequently associated with other mental disorders such as depression, anxiety, and problems with drugs or alcohol. There is also a higher risk of suicide and self-harm.\nBulimia is more common among those who have a close relative with the condition. The percentage risk that is estimated to be due to genetics is between 30% and 80%. Other risk factors for the disease include psychological stress, cultural pressure to attain a certain body type, poor self-esteem, and obesity. Living in a culture that promotes dieting and having parents that worry about weight are also risks. Diagnosis is based on a person's medical history; however, this is difficult, as people are usually secretive about their binge eating and purging habits. Further, the diagnosis of anorexia nervosa takes precedence over that of bulimia. Other similar disorders include binge eating disorder, Kleine-Levin syndrome, and borderline personality disorder.\nCognitive behavioral therapy is the primary treatment for bulimia. Antidepressants of the selective serotonin reuptake inhibitor (SSRI) or tricyclic antidepressant classes may have a modest benefit. While outcomes with bulimia are typically better than in those with anorexia, the risk of death among those affected is higher than that of the general population. At 10 years after receiving treatment about 50% of people are fully recovered.\nGlobally, bulimia was estimated to affect 3.6 million people in 2015. About 1% of young women have bulimia at a given point in time and about 2% to 3% of women have the condition at some point in their lives. The condition is less common in the developing world. Bulimia is about nine times more likely to occur in women than men. Among women, rates are highest in young adults. Bulimia was named and first described by the British psychiatrist Gerald Russell in 1979.\n\nBulimia typically involves rapid and out-of-control eating, which may stop when the bulimic is interrupted by another person or the stomach hurts from over-extension, followed by self-induced vomiting or other forms of purging. This cycle may be repeated several times a week or, in more serious cases, several times a day and may directly cause:\n\nThese are some of the many signs that may indicate whether someone has bulimia nervosa:\n\nAs with many psychiatric illnesses, delusions can occur, in conjunction with other signs and symptoms, leaving the person with a false belief that is not ordinarily accepted by others.\n\nPeople with bulimia nervosa may also exercise to a point that excludes other activities.\n\nWith regards to interoception, people with bulimia report reduced sensitivity to many kinds of internal and external sensations. For example, some show increased thresholds to heat pain compared and report the same level of satiety after consuming more calories than do healthy subjects.\n\nBulimics are much more likely than non-bulimics to have an affective disorder, such as depression or general anxiety disorder: A 1985 Columbia University study on female bulimics at New York State Psychiatric Institute found 70% had suffered depression some time in their lives (as opposed to 25.8% for adult females in a control sample from the general population), rising to 88% for all affective disorders combined. Another study by the Royal Children's Hospital in Melbourne on a cohort of 2,000 adolescents similarly found that those meeting at least two of the DSM-IV criteria for bulimia nervosa or anorexia nervosa had a sixfold increase in risk of anxiety and a doubled risk for substance dependency.\nSome sufferers of anorexia nervosa exhibit episodes of bulimic tendencies through purging (either through self-induced vomiting or laxatives) as a way to quickly remove food in their system. There may be an increased risk for diabetes mellitus type 2. Bulimia also has negative effects on a person's teeth due to the acid passed through the mouth from frequent vomiting causing acid erosion, mainly on the posterior dental surface.\n\nAs with anorexia nervosa, there is evidence of genetic predispositions contributing to the onset of this eating disorder. Abnormal levels of many hormones, notably serotonin, have been shown to be responsible for some disordered eating behaviors. Brain-derived neurotrophic factor (BDNF) is under investigation as a possible mechanism.\n\nThere is evidence that sex hormones may influence appetite and eating in women, and the onset of bulimia nervosa. Studies have shown that women with hyperandrogenism and polycystic ovary syndrome have a dysregulation of appetite, along with carbohydrates and fats. This dysregulation of appetite is also seen in women with bulimia nervosa. In addition, gene knockout studies in mice have shown that mice that have the gene encoding estrogen receptors have decreased fertility due to ovarian dysfunction and dysregulation of androgen receptors. In humans, there is evidence that there is an association between polymorphisms in the ERβ (estrogen receptor β) and bulimia, suggesting there is a correlation between sex hormones and bulimia nervosa.\n\nBulimia has been compared to drug addiction, though the empirical support for this characterization is limited. However, people with bulimia nervosa may share dopamine D2 receptor-related vulnerabilities with those with substance abuse disorders.\n\nDieting, a common behaviour in bulimics, is associated with lower plasma tryptophan levels. Decreased tryptophan levels in the brain, and thus the synthesis of serotonin, increases bulimic urges in currently and formerly bulimic individuals within hours.\n\nAbnormal blood levels of peptides important for the regulation of appetite and energy balance are observed in individuals with bulimia nervosa, but it remains unknown if this is a state or trait.\n\nMedia portrayals of an 'ideal' body shape are widely considered to be a contributing factor to bulimia. In a 1991 study by Weltzin, Hsu, Pollicle, and Kaye, it was stated that 19% of bulimics undereat, 37% of bulimics eat an amount of food that is normal for an average human being, and 44% of bulimics overeat. A survey of 15- to 18-year-old high school girls in Nadroga, Fiji, found the self-reported incidence of purging rose from 0% in 1995 (a few weeks after the introduction of television in the province) to 11.3% in 1998. In addition, the suicide rate among people with bulimia nervosa is 7.5 times higher than in the general population.\n\nWhen attempting to decipher the origin of bulimia nervosa in a cognitive context, Christopher Fairburn \"et al.\"s cognitive behavioral model is often considered the golden standard. Fairburn et al.'s model discusses the process in which an individual falls into the binge-purge cycle and thus develops bulimia. Fairburn \"et al.\" argue that extreme concern with weight and shape coupled with low self-esteem will result in strict, rigid, and inflexible dietary rules. Accordingly, this would lead to unrealistically restricted eating, which may consequently induce an eventual \"slip\" where the individual commits a minor infraction of the strict and inflexible dietary rules. Moreover, the cognitive distortion due to dichotomous thinking leads the individual to binge. The binge subsequently should trigger a perceived loss of control, promoting the individual to purge in hope of counteracting the binge. However, Fairburn \"et al.\" assert the cycle repeats itself, and thus consider the binge-purge cycle to be self-perpetuating.\n\nIn contrast, Byrne and Mclean's findings differed slightly from Fairburn \"et al.\"s cognitive behavioral model of bulimia nervosa in that the drive for thinness was the major cause of purging as a way of controlling weight. In turn, Byrne and Mclean argued that this makes the individual vulnerable to binging, indicating that it is not a binge-purge cycle but rather a purge-binge cycle in that purging comes before bingeing. Similarly, Fairburn \"et al.\"s cognitive behavioral model of bulimia nervosa is not necessarily applicable to every individual and is certainly reductionist. Everyone differs from another, and taking such a complex behavior like bulimia and applying the same one theory to everyone would certainly be invalid. In addition, the cognitive behavioral model of bulimia nervosa is very cultural bound in that it may not be necessarily applicable to cultures outside of the Western society. To evaluate, Fairburn \"et al.\".'s model and more generally the cognitive explanation of bulimia nervosa is more descriptive than explanatory, as it does not necessarily explain how bulimia arises. Furthermore, it is difficult to ascertain cause and effect, because it may be that distorted eating leads to distorted cognition rather than vice versa.\n\nA considerable amount of literature has identified a correlation between sexual abuse and the development of bulimia nervosa. The reported incident rate of unwanted sexual contact is higher among those with bulimia nervosa than anorexia nervosa.\n\nWhen exploring the etiology of bulimia through a socio-cultural perspective, the \"thin ideal internalization\" is significantly responsible. The thin ideal internalization is the extent to which individuals adapt to the societal ideals of attractiveness. Studies have shown that young females that read fashion magazines tend to have more bulimic symptoms than those females who do not. This further demonstrates the impact of media on the likelihood of developing the disorder. Individuals first accept and \"buy into\" the ideals, and then attempt to transform themselves in order to reflect the societal ideals of attractiveness. J. Kevin Thompson and Eric Stice claim that family, peers, and most evidently media reinforce the thin ideal, which may lead to an individual accepting and \"buying into\" the thin ideal. In turn, Thompson and Stice assert that if the thin ideal is accepted, one could begin to feel uncomfortable with their body shape or size since it may not necessarily reflect the thin ideal set out by society. Thus, people feeling uncomfortable with their bodies may result in suffering from body dissatisfaction and may develop a certain drive for thinness. Consequently, body dissatisfaction coupled with a drive for thinness is thought to promote dieting and negative effects, which could eventually lead to bulimic symptoms such as purging or bingeing. Binges lead to self-disgust which causes purging to prevent weight gain.\n\nA study dedicated to investigating the thin ideal internalization as a factor of bulimia nervosa is Thompson's and Stice's research. The aim of their study was to investigate how and to what degree media affects the thin ideal internalization. Thompson and Stice used randomized experiments (more specifically programs) dedicated to teaching young women how to be more critical when it comes to media, in order to reduce thin ideal internalization. The results showed that by creating more awareness of the media's control of the societal ideal of attractiveness, the thin ideal internalization significantly dropped. In other words, less thin ideal images portrayed by the media resulted in less thin ideal internalization. Therefore, Thompson and Stice concluded that media greatly affected the thin ideal internalization. Papies showed that it is not the thin ideal itself, but rather the self-association with other persons of a certain weight that decide how someone with bulimia nervosa feels. People that associate themselves with thin models get in a positive attitude when they see thin models and people that associate with overweight get in a negative attitude when they see thin models. Moreover, it can be taught to associate with thinner people.\n\nThe onset of bulimia nervosa is often during adolescence, between 13 and 20 years of age, and many cases have previously suffered from obesity, with many sufferers relapsing in adulthood into episodic bingeing and purging even after initially successful treatment and remission. A lifetime prevalence of 0.5 percent and 0.9 percent for adult and adolescent sufferers, respectively, is estimated among the United States population. Bulimia nervosa may affect up to 1% of young women and, after 10 years of diagnosis, half will recover fully, a third will recover partially, and 10–20% will still have symptoms.\n\nAdolescents with bulimia nervosa are more likely to have self-imposed perfectionism and compulsivity issues in eating compared to their peers. This means that the high expectations and unrealistic goals that these individuals set for themselves are internally motivated rather than by social views or expectations.\n\nBulimia nervosa can be difficult to detect, compared to anorexia nervosa, because bulimics tend to be of average or slightly above or below average weight. Many bulimics may also engage in significantly disordered eating and exercise patterns without meeting the full diagnostic criteria for bulimia nervosa. Recently, the \"Diagnostic and Statistical Manual of Mental Disorders\" was revised, which resulted in the loosening of criteria regarding the diagnoses of bulimia nervosa and anorexia nervosa. The diagnostic criteria utilized by the DSM-5 includes repetitive episodes of binge eating (a discrete episode of overeating during which the individual feels out of control of consumption) compensated for by excessive or inappropriate measures taken to avoid gaining weight. The diagnosis also requires the episodes of compensatory behaviors and binge eating to happen a minimum of once a week for a consistent time period of 3 months. The diagnosis is made only when the behavior is not a part of the symptom complex of anorexia nervosa and when the behavior reflects an overemphasis on physical mass or appearance. Purging often is a common characteristic of a more severe case of bulimia nervosa.\n\nThere are two main types of treatment given to those suffering with bulimia nervosa; psychopharmacological and psychosocial treatments.\n\nThere are several supported psychosocial treatments for bulimia. Cognitive behavioral therapy (CBT), which involves teaching a person to challenge automatic thoughts and engage in behavioral experiments (for example, in session eating of \"forbidden foods\") has a small amount of evidence supporting its use.\n\nBy using CBT people record how much food they eat and periods of vomiting with the purpose of identifying and avoiding emotional fluctuations that bring on episodes of bulimia on a regular basis. Barker (2003) states that research has found 40–60% of people using cognitive behaviour therapy to become symptom free. He states in order for the therapy to work, all parties must work together to discuss, record and develop coping strategies. Barker (2003) claims by making people aware of their actions they will think of alternatives. People undergoing CBT who exhibit early behavioral changes are most likely to achieve the best treatment outcomes in the long run. Researchers have also reported some positive outcomes for interpersonal psychotherapy and dialectical behavior therapy.\n\nMaudsley family therapy, developed at the Maudsley Hospital in London for the treatment of anorexia has been shown promising results in bulimia.\n\nThe use of Cognitive Behavioral Therapy (CBT) has been shown to be quite effective for treating bulimia nervosa (BN) in adults, but little research has been done on effective treatments of BN for adolescents. Although CBT is seen as more cost efficient and helps individuals with BN in self-guided care, Family Based Treatment (FBT) might be more helpful to younger adolescents who need more support and guidance from their families. Adolescents are at the stage where their brains are still quite malleable and developing gradually. Therefore, young adolescents with BN are less likely to realize the detrimental consequences of becoming bulimic and have less motivation to change, which is why FBT would be useful to have families intervene and support the teens. Working with BN patients and their families in FBT can empower the families by having them involved in their adolescent's food choices and behaviors, taking more control of the situation in the beginning and gradually letting the adolescent become more autonomous when they have learned healthier eating habits.\n\nAntidepressants of the selective serotonin reuptake inhibitors (SSRI) class may have a modest benefit. This includes fluoxetine, which is FDA approved, for the treatment of bulimia, other antidepressants such as sertraline may also be effective against bulimia. Topiramate may also be useful but has greater side effects.\n\nIt is not known if combining medication with counseling improves the outcomes. Any trials which originally suggested that such combinations should improve the outcome have not proven to be exceptionally powerful. Some positive outcomes of treatments can include: abstinence from binge eating, a decrease in obsessive behaviors to lose weight and in shape preoccupation, less severe psychiatric symptoms, a desire to counter the effects of binge eating, as well as an improvement in social functioning and reduced relapse rates.\n\nSome researchers have also claimed positive outcomes in hypnotherapy.\n\nThere is little data on the percentage of people with bulimia in general populations. Most studies conducted thus far have been on convenience samples from hospital patients, high school or university students. These have yielded a wide range of results: between 0.1% and 1.4% of males, and between 0.3% and 9.4% of females. Studies on time trends in the prevalence of bulimia nervosa have also yielded inconsistent results. According to Gelder, Mayou and Geddes (2005) bulimia nervosa is prevalent between 1 and 2 percent of women aged 15–40 years. Bulimia nervosa occurs more frequently in developed countries and in cities, with one study finding that bulimia is five times more prevalent in cities than in rural areas. There is a perception that bulimia is most prevalent amongst girls from middle-class families; however, in a 2009 study girls from families in the lowest income bracket studied were 153 percent more likely to be bulimic than girls from the highest income bracket.\n\nThere are higher rates of eating disorders in groups involved in activities which idealize a slim physique, such as dance, gymnastics, modeling, cheerleading, running, acting, swimming, diving, rowing and figure skating. Bulimia is thought to be more prevalent among Caucasians; however, a more recent study showed that African-American teenage girls were 50 percent more likely than white girls to exhibit bulimic behavior, including both binging and purging.\n\nThe term \"bulimia\" comes from Greek \"boulīmia\", \"ravenous hunger\", a compound of βοῦς \"bous\", \"ox\" and λιμός, \"līmos\", \"hunger\". Literally, the scientific name of the disorder, \"bulimia nervosa\", translates to \"nervous ravenous hunger\".\n\nAlthough diagnostic criteria for bulimia nervosa did not appear until 1979, evidence suggests that binging and purging were popular in certain ancient cultures. The first documented account of behavior resembling bulimia nervosa was recorded in Xenophon's Anabasis around 370 B.C, in which Greek soldiers purged themselves in the mountains of Asia Minor. It is unclear whether this purging was preceded by binging. In ancient Egypt, physicians recommended purging once a month for three days in order to preserve health. This practice stemmed from the belief that human diseases were caused by the food itself. In ancient Rome, elite society members would vomit in order to \"make room\" in their stomachs for more food at all day banquets. Emperors Claudius and Vitellius both were gluttonous and obese, and they often resorted to habitual purging.\n\nHistorical records also suggest that some saints who developed anorexia (as a result of a life of asceticism) may also have displayed bulimic behaviors. Saint Mary Magdalen de Pazzi (1566–1607) and Saint Veronica Giuliani (1660–1727) were both observed binge eating—giving in, as they believed, to the temptations of the devil. Saint Catherine of Siena (1347–1380) is known to have supplemented her strict abstinence from food by purging as reparation for her sins. Catherine died from starvation at age thirty-three.\n\nWhile the psychological disorder \"bulimia nervosa\" is relatively new, the word \"bulimia,\" signifying overeating, has been present for centuries. The Babylon Talmud referenced practices of \"bulimia,\" yet scholars believe that this simply referred to overeating without the purging or the psychological implications bulimia nervosa. In fact, a search for evidence of bulimia nervosa from the 17th to late 19th century revealed that only a quarter of the overeating cases they examined actually vomited after the binges. There was no evidence of deliberate vomiting or an attempt to control weight.\n\nAt the turn of the century, bulimia (overeating) was described as a clinical symptom, but rarely in the context of weight control. Purging, however, was seen in anorexic patients and attributed to gastric pain rather than another method of weight control.\n\nIn 1930, admissions of anorexia nervosa patients to the Mayo Clinic from 1917 to 1929 were compiled. Fifty-five to sixty-five percent of these patients were reported to be voluntarily vomiting in order to relieve weight anxiety. Records show that purging for weight control continued throughout the mid-1900s. Several case studies from this era reveal patients suffering from the modern description of bulimia nervosa. In 1939, Rahman and Richardson reported that out of their six anorexic patients, one had periods of overeating and another practiced self-induced vomiting. Wulff, in 1932, treated \"Patient D,\" who would have periods of intense cravings for food and overeat for weeks, which often resulted in frequent vomiting. Patient D, who grew up with a tyrannical father, was repulsed by her weight and would fast for a few days, rapidly losing weight. Ellen West, a patient described by Ludwig Binswanger in 1958, was teased by friends for being fat and excessively took thyroid pills to lose weight, later using laxatives and vomiting. She reportedly consumed dozens of oranges and several pounds of tomatoes each day, yet would skip meals. After being admitted to a psychiatric facility for depression, Ellen ate ravenously yet lost weight, presumably due to self-induced vomiting. However, while these patients may have met modern criteria for bulimia nervosa, they cannot technically be diagnosed with the disorder, as it had not yet appeared in the Diagnostic and Statistical Manual of Mental Disorders at the time of their treatment.\n\nAn explanation for the increased instances of bulimic symptoms may be due to the 20th century's new ideals of thinness. The shame of being fat emerged in the 1940s, when teasing remarks about weight became more common. The 1950s, however, truly introduced the trend of an aspiration for thinness.\n\nIn 1979, Gerald Russell first published a description of bulimia nervosa, in which he studied patients with a \"morbid fear of becoming fat\" who overate and purged afterwards. He specified treatment options and indicated the seriousness of the disease, which can be accompanied by depression and suicide. In 1980, bulimia nervosa first appeared in the DSM-III.\n\nAfter its appearance in the DSM-III, there was a sudden rise in the documented incidences of bulimia nervosa. In the early 1980s, incidences of the disorder rose to about 40 in every 100,000 people. This decreased to about 27 in every 100,000 people at the end of the 1980s/early 1990s. However, bulimia nervosa's prevalence was still much higher than anorexia nervosa's, which at the time occurred in about 14 people per 100,000.\n\nIn 1991, Kendler et al. documented the cumulative risk for bulimia nervosa for those born before 1950, from 1950 to 1959, and after 1959. The risk for those born after 1959 is much higher than those in either of the other cohorts.\n\n"}
{"id": "228998", "url": "https://en.wikipedia.org/wiki?curid=228998", "title": "Christopher Hitchens", "text": "Christopher Hitchens\n\nChristopher Eric Hitchens (13 April 1949 – 15 December 2011) was an Anglo-American author, columnist, essayist, orator, religious, literary and social critic, and journalist. Hitchens was the author, co-author, editor or co-editor of over 30 books, including five collections of essays on culture, politics and literature. A staple of public discourse, his confrontational style of debate made him both a lauded intellectual and a controversial public figure. He contributed to \"New Statesman\", \"The Nation\", \"The Weekly Standard\", \"The Atlantic\", \"London Review of Books\", \"The Times Literary Supplement\", \"Slate\", \"Free Inquiry\" and \"Vanity Fair\".\n\nHaving long described himself as a democratic socialist, Marxist and an anti-totalitarian, he broke from the political left after what he called the \"tepid reaction\" of the Western left to the \"Satanic Verses\" controversy, followed by the left's embrace of Bill Clinton and the antiwar movement's opposition to NATO intervention in Bosnia and Herzegovina in the 1990s. His support of the Iraq War separated him further. His writings include critiques of public figures Bill Clinton, Henry Kissinger, Mother Teresa and Diana, Princess of Wales. He was the elder brother of the conservative journalist and author Peter Hitchens. He also advocated for the separation of church and state.\n\nAs an antitheist, he regarded concepts of a god or supreme being as a totalitarian belief that impedes individual freedom. He argued in favour of free expression and scientific discovery, and that it was superior to religion as an ethical code of conduct for human civilization. The dictum \"What can be asserted without evidence can be dismissed without evidence\" has become known as Hitchens's razor.\n\nHitchens was born the elder of two boys in Portsmouth, Hampshire. Even when they were children Christopher never got on well with his brother Peter Hitchens, a Christian and socially conservative journalist. His parents, Eric Ernest Hitchens (1909–1987) and Yvonne Jean Hitchens (née Hickman; 1921–1973), met in Scotland when both were serving in the Royal Navy during World War II. Christopher often referred to Eric as simply the 'commander'. Eric was deployed on which took part in the sinking of the in the Battle of the North Cape on 26 December 1943. Christopher would pay tribute to his father's contribution to the war: \"Sending a Nazi convoy raider to the bottom is a better day's work than any I have ever done.\" He also stated that \"the remark that most summed him [his father] up was the flat statement that the war of 1939 to 1945 had been 'the only time when I really felt I knew what I was doing'.\" Eric Hitchens would later work as a bookkeeper for boatbuilders, speedboat-manufacturers and at a prep school. Later in life, Hitchens identified as a secular Jew—since Judaism is matrilineal and he discovered his mother was Jewish. His mother was a 'Wren' (a member of the Women's Royal Naval Service). His father's naval career required the family to move a number of times from base to base throughout Britain and its dependencies, including to Malta, where Christopher's brother Peter was born in Sliema in 1951.\n\nHitchens attended Mount House School (now absorbed into Mount Kelly) in Tavistock, Devon, from the age of eight, followed by the independent Leys School in Cambridge. In 1967, Hitchens enrolled at Balliol College, Oxford, where he was tutored by Steven Lukes and Anthony Kenny and read Philosophy, Politics and Economics, graduating in 1970 with a third-class degree. Hitchens was 'bowled over' in his adolescence by Richard Llewellyn's \"How Green Was My Valley\", Arthur Koestler's \"Darkness at Noon,\" Fyodor Dostoyevsky's \"Crime and Punishment\", R. H. Tawney's critique on \"Religion and the Rise of Capitalism,\" and the works of George Orwell. In 1968, he took part in the TV quiz show \"University Challenge\".\n\nIn the 1960s, Hitchens joined the political left, drawn by disagreement over the Vietnam War, nuclear weapons, racism, and oligarchy, including that of \"the unaccountable corporation\". He expressed affinity with the politically charged countercultural and protest movements of the 1960s and 1970s. He avoided the recreational drug use of the time, saying \"in my cohort we were slightly anti-hedonistic...it made it very much easier for police provocation to occur, because the planting of drugs was something that happened to almost everyone one knew.\" Hitchens was inspired to become a journalist after reading a piece by James Cameron. Hitchens was bisexual during his younger days. He claimed to have had sexual relations with two male students at Oxford who would later become Tory ministers during the prime ministership of Margaret Thatcher, although he would not reveal their names publicly.\n\nHitchens joined the Labour Party in 1965, but along with the majority of the Labour students' organisation was expelled in 1967, because of what Hitchens called \"Prime Minister Harold Wilson's contemptible support for the war in Vietnam\". Under the influence of Peter Sedgwick, who translated the writings of Russian revolutionary and Soviet dissident Victor Serge, Hitchens forged an ideological interest in Trotskyism and anti-Stalinist socialism. Shortly after, he joined \"a small but growing post-Trotskyist Luxemburgist sect\".\n\nEarly in his career Hitchens began working as a correspondent for the magazine \"International Socialism\", published by the International Socialists, the forerunners of today's British Socialist Workers Party. This group was broadly Trotskyist, but differed from more orthodox Trotskyist groups in its refusal to defend communist states as \"workers' states\". Their slogan was \"Neither Washington nor Moscow but International Socialism\".\n\nIn 1971 Hitchens went to work at the \"Times Higher Education Supplement\" where he served as a social science correspondent. Hitchens admitted that he hated the position, and was fired after six months in the job. Next he was a researcher for ITV's \"Weekend World\". In 1973 he went to work for the \"New Statesman\", where his colleagues included the authors Martin Amis, whom he had briefly met at Oxford, Julian Barnes and James Fenton, with whom he had shared a house in Oxford. Around that time, the Friday lunches began, which were attended by writers including Clive James, Ian McEwan, Kingsley Amis, Terence Kilmartin, Robert Conquest, Al Alvarez, Peter Porter, Russell Davies and Mark Boxer. At the \"New Statesman\" Hitchens acquired a reputation as a left-winger, reporting internationally from areas of conflict such as Northern Ireland, Libya, and Iraq.\n\nIn November 1973, while in Greece, Hitchens reported on the constitutional crisis of the military junta. It became his first leading article for the \"New Statesman\". In December 1977, Hitchens interviewed Argentine dictator Jorge Rafael Videla, a conversation he later described as \"horrifying\". In 1977, unhappy at the \"New Statesman\", Hitchens defected to the \"Daily Express\" where he became a foreign correspondent. He returned to the \"New Statesman\" in 1979 where he became foreign editor.\n\nHitchens went to the United States in 1981 as part of an editor exchange programme between the \"New Statesman\" and \"The Nation\". After joining \"The Nation\", he penned vociferous critiques of Ronald Reagan, George H. W. Bush and American foreign policy in South and Central America. He became a contributing editor of \"Vanity Fair\" in 1992, writing ten columns a year. He left \"The Nation\" in 2002 after profoundly disagreeing with other contributors over the Iraq War. There is speculation that Hitchens was the inspiration for Tom Wolfe's character Peter Fallow in the 1987 novel \"The Bonfire of the Vanities\", but others—including Hitchens—believe it to be \"Spy Magazine\"s \"Ironman Nightlife Decathlete\", Anthony Haden-Guest. In 1987, Hitchens's father died from cancer of the oesophagus, the same disease that would later claim his own life. In April 2007, Hitchens became a US citizen; he later stated that he saw himself as Anglo-American.\n\nHe became a media fellow at the Hoover Institution in September 2008. At \"Slate\", he usually wrote under the news-and-politics column \"Fighting Words\".\n\nHitchens spent part of his early career in journalism as a foreign correspondent in Cyprus. Through his work there he met his first wife Eleni Meleagrou, a Greek Cypriot, with whom he had two children, Alexander and Sophia. His son, Alexander Meleagrou-Hitchens, born in 1984, has worked as a policy researcher in London. Hitchens continued writing essay-style correspondence pieces from a variety of locales, including Chad, Uganda and the Darfur region of Sudan. In 1991, he received a Lannan Literary Award for Nonfiction.\n\nHitchens met Carol Blue in Los Angeles in 1989 and they married in 1991. Hitchens called it love at first sight. In 1999, Hitchens and Blue, both harsh critics of President Clinton, submitted an affidavit to the trial managers of the Republican Party in the impeachment of Bill Clinton. Therein they swore that their then friend Sidney Blumenthal had described Monica Lewinsky as a stalker. This allegation contradicted Blumenthal's own sworn deposition in the trial, and it resulted in a hostile exchange of opinion in the public sphere between Hitchens and Blumenthal. Following the publication of Blumenthal's \"The Clinton Wars,\" Hitchens wrote several pieces in which he accused Blumenthal of manipulating the facts. The incident ended their friendship and sparked a personal crisis for Hitchens, who was stridently criticised by friends for what they saw as a cynical and ultimately politically futile act.\n\nBefore Hitchens's political shift, the American author and polemicist Gore Vidal was apt to speak of Hitchens as his \"dauphin\" or \"heir\". In 2010, Hitchens attacked Vidal in a \"Vanity Fair\" piece headlined \"Vidal Loco\", calling him a \"crackpot\" for his adoption of 9/11 conspiracy theories. On the back of Hitchens's memoir \"Hitch-22,\" among the praise from notable figures, Vidal's endorsement of Hitchens as his successor is crossed out in red and annotated \"NO, C.H.\" Hitchens's strong advocacy of the war in Iraq gained him a wider readership, and in September 2005 he was named as fifth on the list of the \"Top 100 Public Intellectuals\" by \"Foreign Policy\" and \"Prospect\" magazines. An online poll ranked the 100 intellectuals, but the magazines noted that the rankings of Hitchens (5), Noam Chomsky (1), and Abdolkarim Soroush (15) were partly due to their respective supporters' publicising of the vote. Hitchens later responded to his ranking with a few articles about his status as such.\n\nHitchens did not leave his position writing for \"The Nation\" until after the September 11 attacks, stating that he felt the magazine had arrived at a position \"that John Ashcroft is a greater menace than Osama bin Laden\". The 11 September attacks \"exhilarated\" him, bringing into focus \"a battle between everything I love and everything I hate\" and strengthening his embrace of an interventionist foreign policy that challenged \"fascism with an Islamic face.\" His numerous editorials in support of the Iraq War caused some to label him a neoconservative, although Hitchens insisted he was not \"a conservative of any kind\", and his friend Ian McEwan described him as representing the anti-totalitarian left. Hitchens recalls in his memoir having been \"invited by Bernard-Henri Levy to write an essay on political reconsiderations for his magazine \"La Regle du Jeu\". I gave it the partly ironic title: 'Can One Be a Neoconservative?' Impatient with this, some copy editor put it on the cover as 'How I Became a Neoconservative.' Perhaps this was an instance of the Cartesian principle as opposed to the English empiricist one: It was decided that I evidently was what I apparently only thought.\" Indeed, in a 2010 BBC interview, he stated that he \"still [thought] like a Marxist\" and considered himself \"a leftist.\"\n\nIn 2007, Hitchens's work for \"Vanity Fair\" won the National Magazine Award in the category \"Columns and Commentary\".\nHe was a finalist in the same category in 2008 for some of his columns in \"Slate\" but lost out to Matt Taibbi of \"Rolling Stone\".\nHe won the National Magazine Award for Columns about Cancer in 2011. Hitchens also served on the Advisory Board of Secular Coalition for America and offered advice to the Coalition on the acceptance and inclusion of nontheism in American life. In December 2011, prior to his death, Asteroid 57901 Hitchens was named after him.\n\nHitchens wrote a monthly essay in \"The Atlantic\" and occasionally contributed to other literary journals. One of his books, \"Unacknowledged Legislation: Writers in the Public Sphere\", collected these works. In \"Why Orwell Matters\", he defends Orwell's writings against modern critics as relevant today and progressive for his time. In the 2008 book \"Christopher Hitchens and His Critics: Terror, Iraq, and the Left\", many literary critiques are included of essays and other books of writers, such as David Horowitz and Edward Said.\n\nDuring a three-hour \"In Depth\" interview on \"Book TV\", he named authors who influenced his views, including Aldous Huxley, George Orwell, Evelyn Waugh, Kingsley Amis, P. G. Wodehouse and Conor Cruise O'Brien.\n\nIn 2009 Hitchens was listed by \"Forbes\" magazine as one of the \"25 most influential liberals in the U.S. media\". The same article noted, however, that he would \"likely be aghast to find himself on this list\", as it reduces his self-styled radicalism to mere liberalism. Hitchens's political perspectives also appear in his wide-ranging writings, which include many dialogues. He said of objectivism, \"I have always found it quaint, and rather touching, that there is a movement in the US that thinks Americans are not yet selfish enough.\"\n\nWhile Hitchens supported Israel's right to exist, he was critical of the Israeli government's handling of the Israeli–Palestinian conflict. Having long described himself as a socialist and a Marxist, Hitchens began his break from the established political left after what he called the \"tepid reaction\" of the Western left to the controversy over \"The Satanic Verses\", followed by the left's embrace of Bill Clinton, and the antiwar movement's opposition to NATO intervention in Bosnia and Herzegovina in the 1990s. He later became a liberal hawk and supported the War on Terror, but he had some reservation, such as his characterization of waterboarding as torture after voluntarily undergoing the procedure. In January 2006, he joined with four other individuals and four organizations, including the ACLU and Greenpeace, as plaintiffs in a lawsuit, \"ACLU v. NSA\", challenging Bush's NSA warrantless surveillance; the lawsuit was filed by the ACLU.\n\nHitchens wrote book-length biographical essays on Thomas Jefferson (\"\"), Thomas Paine (\"\") and George Orwell (\"Why Orwell Matters\"). He also became known for his excoriating critiques of public contemporary figures including Mother Teresa, Bill Clinton and Henry Kissinger, the subjects of three full-length texts: \"\", \"\", and \"The Trial of Henry Kissinger\" respectively. In 2007, while promoting his book \"God Is Not Great: How Religion Poisons Everything\", Hitchens described the Christian evangelist Billy Graham as \"a self-conscious fraud\" and \"a disgustingly evil man\". Hitchens claimed that the evangelist, who had recently been hospitalized for intestinal bleeding, made a living by \"going around spouting lies to young people. What a horrible career. I gather it's soon to be over. I certainly hope so.\"\n\nIn response to the comments, writers Nancy Gibbs and Michael Duffy published an article in \"Time Magazine\" in which, among other things, they refuted Hitchens's suggestion that Graham went into ministry to make money. They argued that during his career Graham 'turn[ed] down million-dollar television and Hollywood offers'. They also pointed out that having established the Billy Graham Evangelistic Association in 1950, Graham drew a straight salary, comparable to that of a senior minister, irrespective of the money raised by his meetings.\n\nHitchens was an antitheist, and said that a person \"could be an atheist and wish that belief in God were correct\", but that \"an antitheist, a term I'm trying to get into circulation, is someone who is relieved that there's no evidence for such an assertion.\" He often spoke against the Abrahamic religions. In a 2010 interview at New York Public Library, Hitchens stated that he was against infant circumcision. When asked by readers of \"The Independent\" (London) what he considered to be the \"axis of evil\", Hitchens replied \"Christianity, Judaism, Islam—the three leading monotheisms\".\n\nIn his bestseller \"God Is Not Great\", Hitchens expanded his criticism to include all religions, including those rarely criticised by Western secularists, such as Buddhism and neo-paganism.\nHitchens said that organised religion is \"the main source of hatred in the world\", calling it \"[v]iolent, irrational, intolerant, allied to racism, tribalism, and bigotry, invested in ignorance and hostile to free inquiry, contemptuous of women and coercive toward children: [it] ought to have a great deal on its conscience\". Hitchens therefore says in \"God Is Not Great\" that humanity is in need of a renewed Enlightenment. The book received mixed responses, ranging from praise in \"The New York Times\" for his \"logical flourishes and conundrums\" to accusations of \"intellectual and moral shabbiness\" in the \"Financial Times\". \"God Is Not Great\" was nominated for a National Book Award on 10 October 2007.\n\n\"God Is Not Great\" affirmed Hitchens's position in the \"New Atheism\" movement. Hitchens was made an Honorary Associate of the Rationalist International and the National Secular Society shortly after its release, and he was later named to the Honorary Board of distinguished achievers of the Freedom From Religion Foundation. He also joined the advisory board of the Secular Coalition for America, a group of atheists and humanists. Hitchens said he would accept an invitation from any religious leader who wished to debate with him. On 30 September 2007, Richard Dawkins, Hitchens, Sam Harris, and Daniel Dennett met at Hitchens's residence for a private, unmoderated discussion that lasted two hours. The event was videotaped and titled \"The Four Horsemen\". In it, Hitchens stated at one point that he considered the Maccabean Revolt the most unfortunate event in human history due to the reversion from Hellenistic thought and philosophy to messianism and fundamentalism that its success constituted.\n\nThat year, Hitchens began a series of written debates on the question \"Is Christianity Good for the World?\" with Christian theologian and pastor Douglas Wilson, published in \"Christianity Today\" magazine. This exchange eventually became a book with the same title published in 2008. During their promotional tour of the book, they were accompanied by the producer Darren Doane's film crew. Thence Doane produced the film \"Collision: Is Christianity GOOD for the World?,\" which was released on 27 October 2009. On 4 April 2009, Hitchens debated William Lane Craig on the existence of God at Biola University. On 19 October 2009, Intelligence Squared explored the question \"Is the Catholic Church a force for good in the world?\". John Onaiyekan and Ann Widdecombe argued that it was, while Hitchens joined Stephen Fry in arguing that it was not. The latter side won the debate according to an audience poll. On 26 November 2010, Hitchens appeared in Toronto, Ontario, at the Munk Debates, where he debated religion with former British Prime Minister Tony Blair, a convert to Roman Catholicism. Blair argued religion is a force for good, while Hitchens argued against that.\n\nThroughout these debates, Hitchens became known for his use of persuasive and enthusiastic rhetoric in public speaking. \"Wit and eloquence\", \"verbal barbs and linguistic dexterity\" and \"self-reference, literary engagement and hyperbole\" are all elements of his speeches. The term \"Hitch-slap\" has come about as an informal term among his supporters for a carefully crafted remark designed to humiliate his opponents. Hitchens's line \"one asks wistfully if there is no provision in the procedures of military justice for them to be taken out and shot\", condemning the perpetrators of the Abu Ghraib torture and prisoner abuse, was cited by \"The Humanist\" as an example. A tribute in \"Politico\" stated that this was a trait Hitchens shared with fellow atheist and intellectual, Gore Vidal.\n\nHitchens was raised nominally Christian and attended Christian boarding schools, but from an early age he declined to participate in communal prayers. Later in life, Hitchens discovered that he was of Jewish descent on his mother's side and that his Jewish-born ancestors were immigrants from Eastern Europe (including Poland). Hitchens was married twice, first to Eleni Meleagrou, a Greek Cypriot in 1981; the couple had a son, Alexander, and a daughter, Sophia. In 1991, Hitchens married his second wife, Carol Blue, an American screenwriter, in a ceremony held at the apartment of Victor Navasky, editor of \"The Nation.\" They had a daughter together, Antonia.\n\nIn November 1973, Hitchens's mother committed suicide in Athens in a pact with her lover, a defrocked clergyman named Timothy Bryan. The pair overdosed on sleeping pills in adjoining hotel rooms, and Bryan slashed his wrists in the bathtub. Hitchens flew alone to Athens to recover his mother's body, initially under the impression that she had been murdered. Both her children were then independent adults.\n\nIn June 2010, Hitchens was on tour in New York promoting his memoirs \"Hitch-22\" when he was taken into emergency care suffering from a severe pericardial effusion. Soon after he announced he was postponing his tour to undergo treatment for esophageal cancer. In a \"Vanity Fair\" piece titled \"Topic of Cancer\", he stated that he was undergoing treatment for the cancer. He said that he recognised the long-term prognosis was far from positive, and that he would be a \"very lucky person to live another five years\". A heavy smoker and drinker since his teenage years, Hitchens acknowledged that these habits likely contributed to his illness. During his illness, Hitchens was under the care of Francis Collins and was the subject of Collins' new cancer treatment, which maps out the human genome and selectively targets damaged DNA.\n\nHitchens died of hospital-acquired pneumonia on 15 December 2011 in the University of Texas MD Anderson Cancer Center, Houston, aged 62. In accordance with his wishes, his body was donated to medical research. 'Mortality', a collection of seven of Hitchen's \"Vanity Fair\" essays about his illness, was published posthumously in September 2012.\n\nFormer British prime minister Tony Blair said, \"Christopher Hitchens was a complete one-off, an amazing mixture of writer, journalist, polemicist, a unique character. He was fearless in the pursuit of truth and any cause in which he believed. And there was no belief he held that he did not advocate with passion, commitment, and brilliance. He was an extraordinary, compelling, and colourful human being whom it was a privilege to know.\"\n\nRichard Dawkins, a friend of Hitchens, said, \"I think he was one of the greatest orators of all time. He was a polymath, a wit, immensely knowledgeable, and a valiant fighter against all tyrants, including imaginary supernatural ones.\"\n\nAmerican theoretical physicist and cosmologist Lawrence Krauss said, \"Christopher was a beacon of knowledge and light in a world that constantly threatens to extinguish both. He had the courage to accept the world for just what it is and not what he wanted it to be. That's the highest praise, I believe, one can give to any intellect. He understood that the universe doesn't care about our existence or welfare, and he epitomized the realization that our lives have meaning only to the extent that we give them meaning.\" Bill Maher paid tribute to Hitchens on his show \"Real Time with Bill Maher\", saying, \"We lost a hero of mine, a friend, and one of the great talk show guests of all time.\" Salman Rushdie and English comedian Stephen Fry paid tribute at the Christopher Hitchens Vanity Fair Memorial 2012. Three weeks before Hitchens's death, George Eaton of the \"New Statesman\" wrote, \"He is determined to ensure that he is not remembered simply as a 'lefty who turned right' or as a contrarian and provocateur. Throughout his career, he has retained a commitment to the Enlightenment values of reason, secularism and pluralism. His targets—Mother Teresa, Bill Clinton, Henry Kissinger, God—are chosen not at random, but rather because they have offended one or more of these principles. The tragedy of Hitchens's illness is that it came at a time when he enjoyed a larger audience than ever. The great polemicist is certain to be remembered, but, as he was increasingly aware, perhaps not as he would like.\" \"The Chronicle of Higher Education\" asked if Hitchens was the last public intellectual.\n\nIn 2015, an annual prize of $50,000 was established in his honour by The Dennis and Victoria Ross Foundation for \"an author or journalist whose work reflects a commitment to free expression and inquiry, a range and depth of intellect, and a willingness to pursue the truth without regard to personal or professional consequence\".\n\n\n"}
{"id": "165270", "url": "https://en.wikipedia.org/wiki?curid=165270", "title": "Cultural behavior", "text": "Cultural behavior\n\nCultural behavior is behavior exhibited by humans (and, some would argue, by other species as well, though to a much lesser degree) that is extrasomatic or extragenetic—in other words, learned.\n\nThere is a species of ant that builds nests made of leaves. To build a nest, some of these ants pull the edges of two leaves together and hold them in place, while others carry larva in their jaws and 'sew' them together with the silk they secrete. This is certainly a complex feat of engineering, but it is not cultural. This behavior is instinctive, built into the ants' behavior mechanisms. They cannot alter their plans or think of better ways to join leaves. They cannot teach or be taught to do so. \n\nBut there are examples of animals that can learn behaviors, such as dogs and cats. A dog doesn't know instinctively not to urinate or defecate indoors, but it can be taught not to do so. Dogs are capable of learning specific behaviors.\n\nA dog's acquisition of a behavior satisfies one of the requirements of culture, but it also fulfills another. If you were to take a dog that has learned not to eliminate indoors to a different house, it would still know not to urinate there. This is because the dog has made a generalization. It knows not to urinate or defecate in any house, not just the one in which it was taught. However, this behavior only makes two of the four requirements.\n\nFor a behavior to be considered cultural it must be shared extragenetically; that is, it must be taught. If a trained dog is introduced to a puppy that doesn't know not to urinate in a house, it cannot teach it not to do so. A particularly intelligent puppy might eventually get used to not eliminate in people's houses by observing the older dog, but no active teaching would have taken place.\n\nContrast this with an observed group of macaque monkeys. Some scientists wanted to learn about eating behaviors in macaque monkeys, so they put some sweet potatoes on a beach near where they lived. The sweet potatoes got sandy and, as the monkeys disliked dirty food, they would spend some time picking the sand off. One young female, however started taking her potatoes to a freshwater pool to rinse off. She showed the others how to do so as well. The scientists then threw wheat on the sand, hoping the monkeys would spend more time picking the food out so they would have more time to observe them. The same young female just scooped up handfuls of wheat and sand and dumped them in the water. The sand sank and the wheat floated, which she ate. This practice also quickly spread through the group. This is what humans could call a proto-cultural behavior. It is learned, it involves concepts and generalisations, and it is taught. There is only one thing missing.\n\nCultural behavior must involve the use of artifacts. The most famous example in the animal world is the termite stick. Some chimpanzees in Tanzania have learned to fish termites out of their nests using sticks. They select a stick and modify it to fit down an opening in a termite nest, insert it, wiggle it around and withdraw it, eating the termites that have attacked the stick and stuck to it. This fits our criteria for cultural behavior. It is not genetically programmed. Not all chimps do it, as would happen if it were built into the chimps' genes. It involves several complex generalisations and ideas, involving understanding the termites' behavior and how to exploit it, and conceiving of a tool with which to do so. It is taught by mother chimps to their offspring. And it involves the use of an artifact: the stick itself. \n\nThe difference between the culture of humans and the behaviors exhibited by others is that humans cannot survive without culture. Everything they see, touch, interact with and think about is cultural. It is the major adaptive mechanism for humans. They cannot survive winters in upper latitudes without protective clothing and shelter, which are provided culturally. They cannot obtain food without being taught how. Whereas other organisms that exhibit cultural behavior don't necessarily need it for the perpetuation of their species, they absolutely cannot live without it. \n\nLanguage is an important element in human culture. It is the primary abstract artifact by which culture is transmitted extragenetically (fulfilling points 3 and 4). Only so few can be shown, much more must be explained. Most transmission of the knowledge, ideas, and values that make up a given culture, from the ten commandments to this entry, is done through language. Again, language is an aspect from which humans differ from other animals in degree rather than kind. Once more it is other apes who share the greatest similarities with humans. Though these primates lack the larynx structure that allows for sophisticated vocalization, there are other ways of communicating. The famous female gorilla, Koko, was taught to communicate in American sign language, and she taught it to other gorillas as well.\n\nCulture does not mean civilization. It's not necessary to have cities in order to have a culture. Every society does the best it can with its circumstances. Any given social group, and therefore the culture that reflects it, is therefore neither more advanced nor more backward than any other; it is simply the way it is because that way works. If the circumstances should change due to environmental change, population pressure, or historical events, then the culture changes. From an anthropological perspective, none is wrong, and none is right.\n\n"}
{"id": "9057549", "url": "https://en.wikipedia.org/wiki?curid=9057549", "title": "Cultural mediation", "text": "Cultural mediation\n\nCultural mediation describes a profession that studies the cultural differences between people, using the data in problem solving.\nIt is one of the fundamental mechanisms of distinctly human development according to cultural–historical psychological theory introduced by Lev Vygotsky and developed in the work of his numerous followers worldwide.\n\nVygotsky investigated child development and how this was guided by the role of culture and interpersonal communication. Vygotsky observed how higher mental functions developed through social interactions with significant people in a child's life, particularly parents, but also other adults. Through these interactions, a child came to learn the habits of mind of her/his culture, including speech patterns, written language, and other symbolic knowledge through which the child derives meaning and affects a child's construction of his or her knowledge. This key premise of Vygotskian psychology is often referred to as \"cultural mediation\". The specific knowledge gained by a child through these interactions also represented the shared knowledge of a culture. This process is known as internalization.\n\nThe easiest way to understand mediation is to start with an example and follow with the Vygotskian principles behind it.\n\nAt a North American girl's fourth birthday, she sits at the table with friends and family. As the candles on her birthday cake are lit and it is placed on the table, the child gains a feeling of deeply felt joy. This is not only because she knows the cake is sweet and she likes sweet food, nor that the candles' sparkling is pleasing to her eyes. While these would be sufficient reason to arouse an emotional response in an ape, there are mental processes in a four-year-old that extend well beyond this. She patiently waits as her family and friends sing \"Happy Birthday to You\". The joy is not in the cake itself but in the cake's specific meaning to her. It is a sign that today is a special day for her in which she is the center of attention and that her friends and family are praising her. It's also a sign that she is bigger and as such has higher status among her peers. It's not just a cake, it is a birthday cake and, more specifically, it is her own. The true significance of the birthday cake then, is not in its physical properties at all, but rather in the significance bestowed upon it by the culture the daughter is growing into. This is not restricted to such artifacts as a birthday cake. A classroom, a game of soccer, a fire engine are all first and foremost cultural artifacts from which children derive meaning.\n\nThis example can help us understand Vygotsky's approach to human development. Like animals, we have lower mental functions tied closely to biological processes. In our birthday cake example, a toddler may well have reached out to take a handful of cream from the cake as soon as she saw it and the four-year-old may have been tempted to do the same. In humans, however, lower mental functions facilitate a new line of development qualitatively unique to humans. Vygotsky referred to this as the higher mental functions. The lower mental functions cannot be equated to those of an ape as they are interwoven with the line of higher mental functions and are essential to them.\nHowever, it is this higher line of development that explains the birthday cake example with profound insight.\n\nFrom the perspective of an individual child's development, the higher psychological line of development is one guided by the development of \"tools\" and \"signs\" within the culture. In our example above, the birthday cake is much more than a source of nourishment, it is a sign with much deeper and broader meaning. The sign \"mediates\" between the immediate sensory input and the child's response, and in so doing allows for a moment of reflection and self-regulation that would not otherwise be possible. To the extent that these signs can be used to influence or change our physical or social environment they are tools. Even the birthday cake can be considered as a tool in that the parents use it to establish that their daughter is now older and has a new status in society.\n\nThe cake is a sophisticated example. Tools and signs can be much simpler, such as an infant pointing to an object she desires. At first she may simply be trying to reach the object, but the mother's response of passing the object helps the infant realize that the action of pointing is a tool to change the environment according to her needs. It is from these simple inter-subjective beginnings that the world of meaning in the child mediated by tools and signs, including language, develops.\n\nA fundamental premise of Vygotsky's therefore, is that tools and signs are first and foremost shared between individuals in society and only then can they be internalized by individuals developing in the society as is reflected in this famous quote:\n\n"}
{"id": "5903", "url": "https://en.wikipedia.org/wiki?curid=5903", "title": "Cultural movement", "text": "Cultural movement\n\nA cultural movement is a change in the way a number of different disciplines approach their work. This embodies all art forms, the sciences, and philosophies. Historically, different nations or regions of the world have gone through their own independent sequence of movements in culture, but as world communications have accelerated this geographical distinction has become less distinct. When cultural movements go through revolutions from one to the next, genres tend to get attacked and mixed up, and often new genres are generated and old ones fade. These changes are often reactions against the prior cultural form, which typically has grown stale and repetitive. An obsession emerges among the mainstream with the new movement, and the old one falls into neglect – sometimes it dies out entirely, but often it chugs along favored in a few disciplines and occasionally making reappearances (sometimes prefixed with \"neo-\").\n\nThere is continual argument over the precise definition of each of these periods, and one historian might group them differently, or choose different names or descriptions. As well, even though in many cases the popular change from one to the next can be swift and sudden, the beginning and end of movements are somewhat subjective, as the movements did not spring fresh into existence out of the blue and did not come to an abrupt end and lose total support, as would be suggested by a date range. Thus use of the term \"period\" is somewhat deceptive. \"Period\" also suggests a linearity of development, whereas it has not been uncommon for two or more distinctive cultural approaches to be active at the same time. Historians will be able to find distinctive traces of a cultural movement before its accepted beginning, and there will always be new creations in old forms. So it can be more useful to think in terms of broad \"movements\" that have rough beginnings and endings. Yet for historical perspective, some rough date ranges will be provided for each to indicate the \"height\" or accepted time span of the movement.\n\nThis current article covers western, notably European and American cultural movements. They have, however, been paralleled by cultural movements in the Orient and elsewhere. In the late 20th and early 21st century in Thailand, for example, there has been a cultural shift away from western social and political values more toward Japanese and Chinese. As well, That culture has reinvigorated monarchical concepts to accommodate state shifts away from western ideology regarding democracy and monarchies. \n\n\n\n\n"}
{"id": "6355878", "url": "https://en.wikipedia.org/wiki?curid=6355878", "title": "Culture during the Cold War", "text": "Culture during the Cold War\n\nThe Cold War was reflected in culture through music, movies, books, television and other media, as well as sports and social beliefs and behavior. One major element of the Cold War was the threat of a nuclear war; another was espionage. Many works use the Cold War as a backdrop, or directly take part in fictional conflict between the United States and the Soviet Union. The period 1953–62 saw Cold War themes first enter the mainstream culture as a public preoccupation. For the historical context in America see United States in the 1950s.\n\nCloak and dagger stories became part of the popular culture of the Cold War in both East and West, with innumerable novels and movies that showed how polarized and dangerous the world was. Soviet audiences thrilled at spy stories showing how their KGB agents protected the motherland by foiling dirty work by America's nefarious CIA, Britain's devious MI-6, and Israel's devilish Mossad. After 1963, Hollywood increasingly depicted the CIA as clowns (as in the comedy TV series \"Get Smart\") or villains (as in Oliver Stone's \"JFK\" (1992).\n\n\nDuring the Cold War, films functioned as a means to influence and control public opinion internally. The United States and the Soviet Union invested heavily in propaganda designed to influence the hearts and minds of people around the world, especially using motion pictures. Cold War films produced by both sides attempted to address different facets of the superpower conflict and sought to influence both domestic and foreign opinion. The gap between American and Soviet film gave the Americans a distinct advantage over the Soviet Union; America was readily prepared to utilize their cinematic achievements as a way to effectively impact the public opinion in a way the Soviet Union could not. Cinema, Americans hoped, would help close the gap caused by Soviet development of nuclear weapons and advancements in space technology. The use of film as an effective form of widespread propaganda transformed cinema into another Cold War battlefront.\n\nThe Americans took advantage of their pre-existing cinematic advantage over the Soviet Union, using movies as another way to create the Communist enemy. In the early years of the Cold War (between 1948–53), seventy explicitly anti-communist films were released. American films incorporated a wide scale of Cold War themes and issues into all genres of film, which gave American motion pictures a particular lead over Soviet film. Despite the audiences' lack of zeal for Anti-Communist/Cold War related cinema, the films produced evidently did serve as successful propaganda in both America and the USSR. The films released during this time received a response from the Soviet Union, which subsequently released its own array of films to combat the depiction of the Communist threat.\n\nSeveral organizations played a key role in ensuring that Hollywood acted in the national best interest of the U.S. Catholic Legion of Decency and the Production Code Administration acted as two conservative groups that controlled a great deal of the national repertoire during the early stages of the Cold War. These groups filtered out politically subversive or morally questionable movies. More blatantly illustrating the shift from cinema as an art form to cinema as a form of strategic weapon, the Motion Picture Alliance for the Preservation of American Ideals ensured that filmmakers adequately expressed their patriotism. Beyond these cinema-specific efforts, the FBI played a surprisingly large role in the production of movies, instituting a triangular-shaped film strategy: FBI set up a surveillance operation in Hollywood, made efforts to pinpoint and blacklist Communists, secretly laundered intelligence through HUAC, and further helped in producing movies that \"fostered [the FBI] image as the protector of the American people.\" The FBI additionally endorsed films, including Oscar winner \"The Hoaxsters.\"\n\nIn the 1960s, Hollywood began using spy films to create the enemy through film. Previously, the influence of the Cold War could be seen in many, if not all, genres of American film. By the 1960s, spy films were effectively a \"weapon of confrontation between the two world systems.\" Both sides heightened paranoia and created a sense of constant unease in viewers through the increased production of spy films. Film depicted the enemy in a way that caused both sides to increase general suspicion of foreign and domestic threat.\n\nBetween 1946–54, the Soviet Union mimicked the US adoption of cinema as a weapon. The Central United Film Studios and the Committee on Cinema Affairs were committed to the Cold War battle. Under Stalin's rule, movies could only be made within strict confines. Cinema and government were, as it stood, inextricably linked. Many films were banned for being insufficiently patriotic. Nonetheless, the Soviet Union produced a plethora of movies with the aim to blatantly function as negative propaganda.\n\nIn the same fashion as the United States, the Soviets were eager to depict their enemy in the most unflattering light possible. Between 1946 and 1950, 45.6% of on-screen villains in Soviet films were either American or British. Films addressed non-Soviet themes that emerged in American film in an attempt to derail the criticism and paint the U.S. as the enemy. Attacks made by the United States against the U.S.S.R were simply used as material by Soviet filmmakers for their own attacks on the US. Soviet cinema during this time took its liberty with history: \"Did the Red Army engage in the mass rapes of German women and pillage German art treasures, factories, and forests? In Soviet cinema, the opposite was true [in \"The Meeting on the Elbe\"].\" This demonstrated the heightened paranoia of the Soviet Union.\n\nDespite efforts made to elevate the status of cinema, such as changing the Committee of Cinema Affairs to the Ministry of Cinematography, cinema did not seem to work as invigorating propaganda as was planned. Although the Anti-American films were notably popular with audiences, the Ministry did not feel the message had reached the general public, perhaps due to the fact that the majority of moviegoers seeing the films produced were, perhaps, the Soviets most likely to admire American culture.\n\nAfter Stalin's death, a Main Administration of Cinema Affairs replaced the Ministry, allowing the filmmakers more freedom due to the lack of direct government control. Many of the films released throughout the late 1950s and 1960s focused on spreading a positive image of Soviet life, intent to prove that Soviet life was indeed better than American life.\n\nRussian science fiction emerged from a prolonged period of censorship in 1957, opened up by de-Stalinization and real Soviet achievements in the space race, typified by Ivan Efremov's galactic epic, \"Andromeda\" (1957). Official Communist science fiction transposed the laws of historical materialism to the future, scorning Western nihilistic writings and predicting a peaceful transition to universal communism. Scientocratic visions of the future nevertheless implicitly critiqued the bureaucratically developed socialism of the present. Dissident science fiction writers emerged, such as the Strugatski brothers, Boris and Arkadi, with their \"social fantasies,\" problematizing the role of intervention in the historical process, or Stanislaw Lem's tongue-in-cheek exposures of man's cognitive limitations.\n\n\nIn addition to fears of a nuclear war between the United States and the Soviet Union, during the Cold War, there were also fears of a direct, large scale conventional conflict between the two superpowers.\n\n\n\n\nWendy's Hamburger Chain ran a television commercial showing a supposed \"Soviet Fashion Show\", which featured the same large, unattractive woman wearing the same dowdy outfit in a variety of situations, the only difference being the accessory she carried (for example, a flashlight for 'nightwear' or a beach ball for 'swimwear'). This was supposedly a lampoon on how the Soviet society is characterised with uniformity and standardisation, in contrast to the U.S. characterised with freedom of choice, as highlighted in the Wendy's commercial.\n\nApple Computer's \"1984\" ad, despite paying homage to George Orwell's novel of the same name, follows a more serious yet ambitious take on the freedom vs. totalitarianism theme evident between the US and Soviet societies at the time.\n\n\"Daisy\" was the most famous campaign commercial of the Cold War. Aired only once, on 7 September 1964, it was a factor in Lyndon B. Johnson's defeat of Barry Goldwater in the 1964 presidential election. The contents of the commercial were controversial, and their emotional impact was searing.\n\nThe commercial opens with a very young girl standing in a meadow with chirping birds, slowly counting the petals of a daisy as she picks them one by one. Her sweet innocence, along with mistakes in her counting, endear her to the viewer. When she reaches \"9\", an ominous-sounding male voice is suddenly heard intoning the countdown of a rocket launch. As the girl's eyes turn toward something she sees in the sky, the camera zooms in until one of her pupils fills the screen, blacking it out. The countdown reaches zero, and the blackness is instantly replaced by a simultaneous bright flash and thunderous sound which is then followed by footage of a nuclear explosion, an explosion similar in appearance to the near surface burst Trinity test of 1945, followed by another cut to footage of a billowing mushroom cloud.\n\nAs the fireball ascends, an edit cut is made, this time to a close-up section of incandescence in the mushroom cloud, over which a voiceover from Johnson is played, which states emphatically, \"These are the stakes! To make a world in which all of God's children can live, or to go into the dark. We must either love each other, or we must die.\" Another voiceover then says, \"Vote for President Johnson on November 3. The stakes are too high for you to stay home.\" (Two months later, Johnson won the election in an electoral landslide.)\n\nBear in the woods was a 1984 campaign advertisement endorsing Ronald Reagan for President. This campaign ad depicted a brown bear wandering through the woods (likely implying the Soviet Union) and suggested that Reagan was more capable of dealing with the Soviets than his opponent, in spite of the fact that the ad never explicitly mentioned the Soviet Union, the Cold War or Walter Mondale.\n\nThe 1984 \"We begin bombing in five minutes\" incident is an example of cold war dark humor. It was a personal microphone gaffe joke between Ronald Reagan, his White House staff and radio technicians that was accidentally leaked to the US populace. At the time, Reagan was well known before this incident for telling Soviet/Russian jokes in televised debates, many of which have now been uploaded to video hosting websites.\n\nThe joke was a parody of the opening line of that day's speech:\n\nFollowing his trip to Los Angeles in 1959 and being refused entry into Disneyland, on security grounds, a dejected Soviet Premier Nikita Khrushchev joked, \"...just now I was told that I could not go to Disneyland, I asked \"Why not?\" What is it, do you have rocket launching pads there?\n\nThe United States and the Soviet Union engaged in competition vis-à-vis the arts. Cultural competition played out in Moscow, New York, London, and Paris. The Soviets excelled at ballet and chess, the Americans at jazz and abstract expressionist paintings. The US funded its own ballet troupes, and both used ballet as political propaganda, using dance to reflect life style in the \"battle for the hearts and minds of men.\" The defection of a premier dancer became a major coup.\n\nFrom 1956 through the late 1970s, the U.S. State Department sent its finest jazz musicians to show off music that appealed to youth, to demonstrate racial harmony at home, and to undergird freedom as jazz was a democratic music form, free flowing and improvised. Jazz tours of the Soviet Union were organized in 1956, and lasted through the 1970s.\n\nChess was inexpensive enough—and the Russians always won until America unleashed Bobby Fischer. Vastly more expensive was the Space Race, as a proxy for scientific supremacy (with a technology with obvious military uses). As well when it came to sports the two countries both competed in the Olympics during the Cold War period which also created severe tension when the West boycotted the first Russian Olympics in 1980.\n\nMusicians of these decades, especially in Jazz and Folk Music, were influenced by the shadow of nuclear war. Probably the most famous, passionate and influential of all was Bob Dylan, notably in his songs Masters of War and A Hard Rain's a-Gonna Fall (written just before the Cuban Missile Crisis). In 1965 Barry McGuire's version of P. F. Sloan's apocalyptic Eve of Destruction was a number one hit in the United States and elsewhere.\n\nVan Cliburn was a pianist who was celebrated with a ticker tape parade after winning a musical competition in the Soviet Union.\n\nMany protest songs during the 1980s reflected general unease with escalating tensions between the Soviet Union and the United States brought on by Ronald Reagan's and Margaret Thatcher's hard line against the Soviets. For example, various musical artists wore military uniform-like costumes, as a reflection of the increased feeling of militarism seen in the 1980s. Songs symbolically showed the superpowers going to war, as in the Frankie Goes to Hollywood song \"Two Tribes\". This song's MTV music video featured caricatures of United States President Ronald Reagan and Soviet President Konstantin Chernenko in a wrestling match.\n\nOther songs expressed fear of World War III, as in the Sting song, \"Russians\", with lyrics such as \"I don't subscribe to his [Reagan's or Khrushchev's] point of view\" (that Reagan would protect Europe, or that Khrushchev would \"bury\" the West). Other examples include Sly Fox's \"Let's go all the way\", a song about \"going all the way\" to nuclear war; The Escape Club's \"Wild Wild West\" with its various references to the Cold War. The Genesis song \"Land of Confusion\" expressed a desire to make some sense out of the world, especially in relation to nuclear war.\n\nA number of punk rock bands from the 1980s attacked Cold War era politics, such as Reagan's and Thatcher's nuclear deterrence brinkmanship. A small sampling includes The Clash, Dead Kennedys, Government Issue, Fear, Suicidal Tendencies, Toxic Reasons, Reagan Youth, etc. Noted punk compilation \"P.E.A.C.E.\" included bands from around the world in an attempt to promote international peace. The Scars covered apocalyptic poem \"Your Attention Please\" by Peter Porter, a radio broadcast announcing nuclear war.\n\nProbably the most famous of the 1980s songs against increased confrontation between the Soviets and the Americans was Nena's \"99 Luftballons\", which described the events - ostensibly starting with the innocent release of 99 (red) toy balloons - that could lead to a nuclear war.\n\nImperiet – \"Coca Cola Cowboys\" – a Swedish rock song about how the world is divided by two super powers that both claim to represent justice.\n\nRoman Palester, a classical music composer had his works banned and censored in Poland and the Soviet Union, as a result of his work for Radio Free Europe, even though he was thought to be Poland's greatest living composer at the time.\n\n\nHistorians debate whether the spread of American-style consumerism to Western Europe (and Japan) was part of the Cold War. Steigerwald reviews the debate by looking at the book \"Trams or Tailfins? Public and Private Prosperity in Postwar West Germany and the United States\" (2012) by Jan L. Logemann:\n\nCold war tensions between the U.S. and the U.S.S.R. were the backdrop of sports competitions, especially in hockey and in the Olympics of 1980 and 1984.\n\nPlayground equipment constructed during the Cold War was intended to foster children's curiosity and excitement about the Space Race. It was installed in both Communist and non-Communist countries throughout the Cold War.\n\n\nAnti-nuclear protests first emerged in the late 1950s and early 1960s. In the United Kingdom, the first Aldermaston March, organised by the Campaign for Nuclear Disarmament, took place in 1958. In 1961, at the height of the Cold War, about 50,000 women brought together by Women Strike for Peace marched in 60 cities in the United States to demonstrate against nuclear weapons. In 1964, Peace Marches in several Australian capital cities featured \"Ban the bomb\" placards.\n\nIn the early 1980s, the revival of the nuclear arms race triggered large protests about nuclear weapons. In October 1981 half a million people took to the streets in several cities in Italy, more than 250,000 people protested in Bonn, 250,000 demonstrated in London, and 100,000 marched in Brussels. The largest anti-nuclear protest was held on June 12, 1982, when one million people demonstrated in New York City against nuclear weapons. In October 1983, nearly 3 million people across western Europe protested nuclear missile deployments and demanded an end to the arms race; the largest crowd of almost one million people assembled in the Hague in the Netherlands. In Britain, 400,000 people participated in what was probably the largest demonstration in British history.\n\n\n"}
{"id": "22562859", "url": "https://en.wikipedia.org/wiki?curid=22562859", "title": "Do-it-yourself biology", "text": "Do-it-yourself biology\n\nDo-it-yourself biology (DIY biology, DIY bio) is a growing biotechnological social movement in which individuals, communities, and small organizations study biology and life science using the same methods as traditional research institutions. DIY biology is primarily undertaken by individuals with extensive research training from academia or corporations, who then mentor and oversee other DIY biologists with little or no formal training. This may be done as a hobby, as a not-for-profit endeavor for community learning and open-science innovation, or for profit, to start a business.\n\nThe term \"biohacking\" as well as the concept of do-it-yourself biology has been known as early as 1988.\n\nBiohacking entered the San Francisco programmer and maker communities as early as 2005, through simple demonstrations of basic experiments. As DIYbio experiments became the focus of SuperHappyDevHouse hackers, the hobby gained additional momentum.\n\nIn 2005 Rob Carlson wrote in an article in \"Wired\": \"The era of garage biology is upon us. Want to participate? Take a moment to buy yourself a lab on eBay.\" He then set up a garage lab the same year, working on a project he had previously worked at the Molecular Sciences Institute in Berkeley, California.\n\nIn 2008, the DIYbio organization was founded by Jason Bobe and Mackenzie Cowell and its first meeting held.\n\nIn 2010, Genspace opened the first community biology lab, Ten months later it was followed by BioCurious, and Victoria Makerspace. Many other labs and organizations followed, including but not limited to Counter Culture Labs in Oakland, CA, Baltimore Underground Science Space in Baltimore, MD, TheLab in Los Angeles, CA and Denver Biolabs in Denver, CO.\n\nIn 2016, the first conference to focus specifically on biohacking was announced to take place in Sept. in Oakland, CA.\n\nThe DIYbio movement seeks to revise the notion that one must be an academic with an advanced degree to make any significant contribution to the biology community. It allows large numbers of small organizations and individuals to participate in research and development, with spreading knowledge a higher priority than turning profits.\n\nThe motivations for DIY biology include (but aren't limited to) lowered costs, entertainment, medicine, biohacking, life extension, and education. Recent work combining open-source hardware of microcontrollers like the Arduino and RepRap 3-D printers, very low-cost scientific instruments have been developed.\n\nMany organizations maintain a laboratory akin to a wet-lab makerspace, providing equipment and supplies for members. Many organizations also run classes and provide training. For a fee (usually between $50 and $100), members can join some spaces and do experiments on their own.\n\nThe DIY biology movement attempts to make available the tools and resources necessary for anyone, including non-professionals, to conduct biological engineering. One of the first pieces of open source laboratory equipment developed was the Dremelfuge by Irish biohacker Cathal Garvey, which uses a 3D printed tube holder attached to a Dremel rotary tool to spin tubes at high speeds, replacing often expensive centrifuges. Many other devices like PCR machines have been recreated extensively. In recent times, more complex devices have been created such as the OpenDrop digital microfluidics platform and the DIY NanoDrop both developed by GaudiLabs. Opentrons makes open-source, affordable lab robots, and got its start as a DIY biology collaboration at Genspace.\n\nMost advocacy in biohacking is about the safety, accessibility and future legality of experimentation. Todd Kuiken of the Woodrow Wilson Center proposes that through safety and self-governance, DIY biologists won't be in need of regulation. However, Josiah Zayner has proposed that safety is inherent in biohacking and that accessibility should be the foremost concern as there is large underrepresentation of social and ethnic minorities in biohacking.\n\nMany biohacking projects revolve around the modification of life and molecular and genetic engineering.\n\nBioinformatics is another popular target for do-it-yourself biology research. As in other fields, many programming languages can be used in DIY biology, but most of the languages that are used are those with large bioinformatics libraries.\n\nExamples include BioPerl or BioPython, which use the languages Perl and Python, respectively.\n\nGenetic Engineers are a subculture of biohackers as one of the most accessible forms of biohacking is through engineering microorganisms or plants. Experiments can range from using plasmids to fluorescent bacteria, controlling gene expression using light in bacteria, even using CRISPR to engineer the genome of bacteria or yeast.\n\nRestricted access to medical care and medicine has pushed biohackers to start experimenting in medically related fields. The Open Insulin project aims to make the recombinant protein insulin more accessible by creating an open source protocol for expression and purification. Other experiments that have involved medical treatments include a whole body microbiome transplant and the creation of open source artificial pancreases for diabetics.\n\nGrinders are a subculture of biohackers that focus on implanting technology or introducing chemicals into the body to enhance or change their bodies' functionality. \n\nSome biohackers can now sense which direction they face using a magnetic implant that vibrates against the skin.\n\nIn 2000, controversial and self-described \"transgenic artist\" Eduardo Kac appropriated standard laboratory work by biotechnology and genetics researchers in order to both utilize and critique such scientific techniques. In the only putative work of transgenic art by Kac, the artist claimed to have collaborated with a French laboratory (belonging to the Institut National de la Recherche Agronomique) to procure a green-fluorescent rabbit: a rabbit implanted with a green fluorescent protein gene from a type of jellyfish [\"Aequorea victoria\"] in order for the rabbit to fluoresce green under ultraviolet light. The claimed work came to be known as the \"GFP bunny\", and which Kac called \"Alba\". This claim by Kac has been disputed by the scientists at the lab who noted that they had performed the exact same experiment (i.e., the insertion of the jellyfish GFP protein-coding gene) on numerous other animals (cats, dogs, etc.) previously and did not create \"Alba\" (known to the researchers only as \"Rabbit Number 5256\") under the direction of Kac. The laboratory consequently kept possession of the transgenic rabbit which it had created and funded and the \"transgenic art\" was never exhibited at the Digital Avignon festival [2000] as intended. Kac -- claiming that his rabbit was the first GFP bunny created in the name of Art -- used this dispute to popularize the issue as one of disguised censorship by launching a \"Free Alba\" campaign. A doctored photo of the artist holding a day-glow-green tinted rabbit appears on his website. The members of the Critical Art Ensemble have written books and staged multimedia performance interventions around this issue, including \"The Flesh Machine\" (focusing on in vitro fertilisation, surveillance of the body, and liberal eugenics) and \"Cult of the New Eve\" (In order to analyze how, in their words, \"Science is the institution of authority regarding the production of knowledge, and tends to replace this particular social function of conventional Christianity in the west\").\n\nHeather Dewey-Hagborg is an information artist and biohacker who uses genomic DNA left behind by people as a starting point for creating lifelike, computer-generated, 3-D portraits.\n\nBiohacking experiences many of the same criticisms as synthetic biology and genetic engineering already receive, plus other concerns relating to the distributed and non-institutional nature of the work, involving potential hazards with lack of oversight by professionals or governments. Concerns about biohackers creating pathogens in unmonitored garage laboratories led the Federal Bureau of Investigation (FBI) to begin sending its representatives to DIYbio conferences in 2009. The arrest and prosecution of some members for their work with harmless microbes, such as artivist Steve Kurtz, has been denounced as political repression by critics who argue the U.S. government has used post-9/11 anti-terrorism powers to intimidate artists and others who use their art to criticize society.\n\nExisting regulations are not specific to this field, so that the possibility of pathological organisms being created and released unintentionally or intentionally by biohackers has become a matter of concern, for example, in the spirit of the re-creation of the 1917 flu virus by Armed Forces Institute of Pathology researchers in 2005. In the US the FBI Weapons of Mass Destruction Directorate has worked with the American Association for the Advancement of Science's National Science Advisory Board for Biosecurity to convene a series of meetings to discuss biosecurity, which have included discussions of amateur biologists and ways to manage the risks to society it poses. At the National Institutes of Health, National Science Advisory Board for Biosecurity leads efforts to educate the public on \"dual use research of concern\", for example with websites like \"Science Safety Security\". In 2011, DIYbio organized conferences to attempt to create codes of ethics for biohackers.\n\nPat Mooney, executive director of ETC Group, is a critic of biohacking who argues that—using a laptop computer, published gene sequence information, and mail-order synthetic DNA—just about anyone has the potential to construct genes or entire genomes from scratch (including those of the lethal pathogens) in the near-future. A 2007 ETC Group report warns that the danger of this development is not just bio-terror, but \"bio-error\".\n\nWhile no DIYbio project to date has involved harmful agents, the fear remains in the minds of both regulators and laypersons. However, it is often pointed out that DIYbio is at too early a stage to consider such advanced projects feasible, as few successful transformative genetics projects have been undertaken yet. It is also worth noting that, while an individual could conceivably do harm with sufficient skill and intent, there exist biology labs throughout the world with greater access to the technology, skill and funding to accomplish a bioweapons project.\n\nWhile detractors argue that do-it-yourself biologists need some sort of supervision, enthusiasts argue that uniform supervision is impossible and the best way to prevent accidents or malevolence is to encourage a culture of transparency, where, in essence, do-it-yourself biologists would be peer reviewed by other biohackers. Enthusiasts argue that fear of potential hazards should be met with increased research and education rather than closing the door on the profound positive impacts that distributed biological technology will have on human health, the environment, and the standard of living around the world. Due to the lack of precedent regarding such a business model, the DIYbio founders see this as an opportunity to be innovators in regulatory and safety policy.\n\n\n"}
{"id": "52081281", "url": "https://en.wikipedia.org/wiki?curid=52081281", "title": "Donor principle", "text": "Donor principle\n\nIn linguistics, the donor principle refers primarily to the observance of the original spelling of a loanword from the original (\"donor\") language. This principle applies in particular to the standardization in the receiver language of exonyms when they are used in publications.\n\nThe term donor principle is sometimes also used for the particular spelling of names of specific products, brands, institutions etc. chosen by their owner, founder, designer, etc., when it clashes with the official spelling rules. This often pertains to the use of capital letters. (e.g. \"YouTube\"), for example.\n"}
{"id": "14342476", "url": "https://en.wikipedia.org/wiki?curid=14342476", "title": "Encyclopedia Africana", "text": "Encyclopedia Africana\n\nAfricana: The Encyclopedia of the African and African-American Experience edited by Henry Louis Gates and \nAnthony Appiah (Basic Civitas Books 1999, 2nd ed. Oxford University Press, 2005, ) is a compendium of Africana studies including African studies and the \"Pan-African diaspora\" inspired by W. E. B. Du Bois' project of an \"Encyclopedia Africana\". Du Bois envisioned \"an \"Encyclopedia Africana\",\" which was to be \"unashamedly Afro-Centric but not indifferent to the impact of the outside world.\"\n\nThe first edition appeared in a single volume, of which about a third each was dedicated to North American African-American studies, to Afro-Latin American topics of Latin America and the Caribbean and to Africa proper. The second edition was published by Oxford University Press in five volumes, including more than 3500 entries on 3960 pages.\n\nDaniel Alexander Payne Murray was one of the first Afro-Americans to work as a librarian at the Library of Congress in 1871. In 1899 Murray organized an exhibit at the 1900 Paris Exposition on Negro authors. Under his direction, his award-winning exhibit became the core of the Library of Congress's Colored Author Collection. Murray planned to expand his collection and create an encyclopedia of African-American achievement. Although he never completed the project, the idea of an encyclopedia that explored the black experience was revived and expanded by W. E. B. Du Bois. In 1901 Du Bois widened the scope of the project to encompass the entire African diaspora. He suggested that the encyclopedia be called the \"Encyclopedia Africana\" in a similar fashion to the \"Encyclopædia Britannica\". Du Bois envisioned a scientific and comprehensive work on Africa and peoples of African descent that would refute the Enlightenment notion of blacks as devoid of civilization and the hallmarks of humanity. Due to lack of support from the established philanthropies, the project died.\n\n\n\n"}
{"id": "954420", "url": "https://en.wikipedia.org/wiki?curid=954420", "title": "Generation Jones", "text": "Generation Jones\n\nGeneration Jones is a term coined by the author Jonathan Pontell to describe those born from approximately 1954 to 1964, while other sources place the start point at 1956 or 1957. This group is essentially the latter half of the baby boomers to the first years of Generation X. Unlike older baby boomers, most of Generation Jones did not grow up with World War II veterans as fathers, and for them there was no compulsory military service and no defining political cause, as opposition to United States involvement in the Vietnam War had been for older boomers. \n\nThe name \"Generation Jones\" has several connotations, including a large anonymous generation, a \"keeping up with the Joneses\" competitiveness and the slang word \"jones\" or \"jonesing\", meaning a yearning or craving. It is said that Jonesers were given huge expectations as children in the 1960s, and then confronted with a different reality as they came of age during a long period of mass unemployment and when de-industrialization arrived full force in the mid-late 1970s and 1980s, leaving them with a certain unrequited \"jonesing\" quality for the more prosperous days of the past. \n\nThe generation is noted for coming of age after a huge swath of their older brothers and sisters in the earlier portion of the baby boomer population had come immediately preceding them; thus, many Generation Jones members complain that there was a paucity of resources and privileges available to them that were seemingly abundant to those older boomers born earlier. Therefore, there is a certain level of bitterness about and a \"jonesing\" for the level of freedom and affluence granted to older boomers but denied to their generation.\n\nThe term has enjoyed some currency in political and cultural commentary, including during the 2008 United States presidential election, where Generation Jonesers Barack Obama and Sarah Palin were on presidential tickets.\n\nGeneration Jones has been covered and discussed in newspapers and magazines and on TV and radio shows. Pontell has appeared on TV networks such as CNN, MSNBC, and BBC, discussing the cultural, political, and economic implications of this generation's emergence.\n\nIn the business world, Generation Jones has become a part of the strategic planning of many companies and industries, particularly in the context of targeting Jonesers through marketing efforts. Carat UK, a European media buying agency, has done extensive research into Generation Jones consumers.\n\nPolitically, Generation Jones has emerged as a crucial voting segment in Western elections. In the U.S. 2006 congressional and 2004 presidential elections, and the 2005 U.K. elections, Generation Jones's electoral role was widely described as pivotal by the media and political pollsters. In the 2008 U.S. Presidential election, Generation Jones was again seen as a key electoral segment because of the high degree to which its members were swing voters during the election cycle. Influential journalists, like Clarence Page and Peter Fenn, singled out Generation Jones voters as crucial in the final weeks of the campaign.\nNumerous studies have been done by political pollsters and publications analyzing the voting behavior of GenJonesers.\n\nThe election to the presidency of Barack Obama, born in 1961, plus Republican vice presidential candidate Sarah Palin, born 1964, focused more attention on Generation Jones. Many journalists, publications, and experts — including Jonathan Alter (\"Newsweek\"), David Brooks (\"The New York Times\") and Karen Tumulty (\"Time\") — have characterized Obama as a member of Generation Jones.\n\nKey characteristics assigned to members are pessimism, distrust of government, and general cynicism.\n\n\n"}
{"id": "11020549", "url": "https://en.wikipedia.org/wiki?curid=11020549", "title": "Germanische Altertumskunde Online", "text": "Germanische Altertumskunde Online\n\nGermanische Altertumskunde Online, formerly called Reallexikon der Germanischen Altertumskunde, is a German encyclopedia of the study of Germanic history and cultures, as well as the cultures that were in close contact with them.\n\nThe first edition of the \"Reallexikon der Germanischen Altertumskunde\" appeared in four volumes between 1911 and 1919, edited by Johannes Hoops. The second edition, under the auspices of the Göttingen Academy of Sciences and Humanities, was edited by Heinrich Beck (from vol 1, 1968/72), Heiko Steuer (from vol. 8, 1991/94), Rosemarie Müller (from 1992), and Dieter Geuenich (from vol. 13, 1999), and was published by Walter de Gruyter between 1969 and 2008.\n\nIn 2010, the most recent version was published, now renamed \"Germanische Altertumskunde Online\". Edited by Heinrich Beck, Sebastian Brather, Dieter Geuenich, Wilhelm Heizmann, Steffen Patzold, and Heiko Steuer, it is published online by De Gruyter, accessible via subscription.\n\n"}
{"id": "26950608", "url": "https://en.wikipedia.org/wiki?curid=26950608", "title": "Gimjang", "text": "Gimjang\n\nGimjang (), also spelled kimjang, is the traditional process of preparation and preservation of kimchi, the spicy Korean fermented vegetable dish, in the wintertime. During the summer months, Kimchi is made fresh, from seasonal vegetables. For one month, starting from the tenth moon of the year, people prepare large quantities of kimchi, to provide nutrition throughout winter.\n\nGimjang was listed as an UNESCO Intangible Cultural Heritage in December 2013.\n\nKimchi can be eaten as an accompaniment to almost any meal, and is an important part of Korean culture. Recipes date back to at least the 13th century, when it was made from vegetables, pickles and either salt or a mixture of alcohol and salt. Red pepper was added to the ingredients in the 17th century. Modern day kimchi is typically made from napa cabbage and white radish, although there are hundreds of variations; it may also contain turnip, leek, carrots, and garlic.\n\nIn the cooler weather of November, there are lots of crops in the fields and market-places, and the Gimjang process begins. The labour-intensive task is shared by families, relatives and neighbours. Groups of Korean people gather to cut the vegetables, wash them, and add salt to cure the food and begin the fermentation process. The nature of kimchi means that it is challenging to store for long periods; if it is too cold, it will freeze, and if it is too warm, it will over ferment, and may turn sour. The traditional solution prior to effective modern refrigeration is to store kimchi in earthenware jars in the ground, buried up to the neck level of the jar to prevent the contents from freezing. As the temperature falls below 0 °C, fermentation is halted and the food is preserved; it begins again as the temperature increases in spring time.\n\nThe strong odors of kimchi can taint other products in a refrigerator, and despite modern advances in refrigeration, the custom of gimjang continues to be passed down the generations. It is common in cities for people to store large jars of fermenting kimchi on balconies. It is also increasingly common to own and use secondary refrigerators designed specifically for storing kimchi.\n\nIn an attempt to combat the increasing popularity of mass-produced kimchi, which is convenient for modern life, Seoul has created the world's only kimchi museum, where tourists and local people can sample different types of the fermented dish, and learn about the traditional gimjang process. Although consumption figures have fallen, Koreans still consume of Kimchi per head each year.\n\n"}
{"id": "19728383", "url": "https://en.wikipedia.org/wiki?curid=19728383", "title": "Glass delusion", "text": "Glass delusion\n\nThe glass delusion is an external manifestation of a psychiatric disorder recorded in Europe mainly in the late Middle Ages and early modern period (fifteenth to seventeenth centuries). People feared that they were made of glass \"and therefore likely to shatter into pieces\". One famous early sufferer was King Charles VI of France who refused to allow people to touch him, and wore reinforced clothing to protect himself from accidental \"shattering\".\n\nConcentration of the glass delusion among the wealthy and educated classes allowed modern scholars to associate it with a wider and better described disorder of scholar's melancholy.\n\nRobert Burton's \"The Anatomy of Melancholy\" (1621) touches on the subject in the commentary as one of many related manifestations of the same anxiety: \"Fear of devils, death, that they shall be so sick, of some such or such disease, ready to tremble at every object, they shall die themselves forthwith, or that some of their dear friends or near allies are certainly dead; imminent danger, loss, disgrace still torment others; that they are all glass, and therefore will suffer no man to come near them; that they are all cork, as light as feathers; others as heavy as lead; some are afraid their heads will fall off their shoulders, that they have frogs in their bellies, Etc.\"\n\nMiguel de Cervantes based one of his short \"Exemplary Novels\", \"The Glass Graduate\" (, 1613), on the delusion of the title subject, an aspiring young lawyer. Thomas Rodaja fell into a grave depression after being bedridden for six months subsequent to being poisoned with a purportedly aphrodisiac potion. He claimed that, being of glass, his perceptions are clearer than those of men of flesh and demonstrated by offering witty comments. After two years of illness, Rodaja was cured by a monk; no details of the cure are provided except that the monk was allegedly a miracle-maker.\n\nDutch poet Constantijn Huygens wrote a \"Costly Folly\" (1622) centered on a subject who \"fears everything that moves in his vicinity... the chair will be the death for him, he trembles at the bed, fearful that one will break his bum, the other smash his head\".\n\nFrench philosopher René Descartes wrote \"Meditations on First Philosophy\" (1641), using the glass delusion as an example of an insane person whose perceived knowledge of the world differs from the majority.\n\nIn modern times, the glass delusion has not completely disappeared. There are still isolated cases today. \"Surveys of modern psychiatric institutions have only revealed two specific (uncorroborated) cases of the glass delusion. Foulché-Delbosc reports finding one Glass Man in a Paris asylum, and a woman who thought she was a potsherd was recorded at an asylum in Merenberg.\" Andy Lameijn, a psychiatrist from the Netherlands, reports that he has a male patient suffering from the delusion in Leiden.\n\nThe neurotic behavior of the nineteenth-century Russian composer Peter Ilyich Tchaikovsky seems reminiscent of the glass delusion, centering as it did around his difficulties caused by his belief that his head would fall off while conducting if he did not hold his chin. While the legend may be exaggerated, it seems to have some basis in fact:\n\n"}
{"id": "4263254", "url": "https://en.wikipedia.org/wiki?curid=4263254", "title": "Glass house effect", "text": "Glass house effect\n\nThe Glass House Effect (or GHE) is the resulting phenomenon brought on by an awareness that one is subject to ubiquitous surveillance. In corporate environments, the transparency is considered a good idea, as it is believed this discourages corporate crime and other misfeasance.\n\nThe Glass House Effect can induce an overwhelming sense of hopelessness brought on those subject to such uncontrolled observation. In such circumstances, solitude is conspicuously absent, and privacy is considered a \"thoughtcrime\". The messages conveyed to the subject in such an environment usually involve some variation on the notion of Catch-22, such as\n\n\n"}
{"id": "1139545", "url": "https://en.wikipedia.org/wiki?curid=1139545", "title": "History of the chair", "text": "History of the chair\n\nThe history of chairs started in ancient Egypt. These chairs appear to have been of great richness and splendour. Fashioned of ebony and ivory, or of carved and gilded, wood, they were covered with costly materials and supported upon representations of the legs of beasts or the figures of captives.\nEgyptians believed that the chairs need to represent natural forms to avoid creating chaos in the universe, by creating an artificial object. This tendency is seen all over Egyptian art and manufacture. \nAn arm-chair in fine preservation found in a tomb in the Valley of the Kings is astonishingly similar, even in small details, to that \"Empire\" style which followed Napoleon’s campaign in Egypt. The earliest monuments of Nineveh represent a chair without a back but with tastefully carved legs ending in lions' claws or bulls' hoofs. Others are supported by figures in the nature of caryatides or by animals.\n\nThe earliest known form of Greek chair dates back to six or seven centuries BCE. On the frieze of the Parthenon, Zeus occupies a square seat with a bar-back and thick turned legs; it is ornamented with winged sphinxes and the feet of beasts. The characteristic Roman chairs were of marble, also adorned with sphinxes. The curule chair was originally very similar in form to the modern folding chair, but eventually received a good deal of ornament.\nThe most famous of the very few chairs which have come down from a remote antiquity is the reputed Chair of Saint Peter in St Peter's Basilica at Rome. The wooden portions are much decayed, but it would appear to be Byzantine work of the 6th century, and to be really an ancient sedia gestatoria. It has ivory carvings representing the labours of Hercules. A few pieces of an earlier oaken chair have been let in; the existing one, Gregorovius says, is of acacia wood. The legend that this was the curile chair of the senator Pudens is necessarily apocryphal. It is not, as is popularly supposed, enclosed in Gian Lorenzo Bernini's bronze chair, but is kept under triple lock and exhibited only once in a century. Byzantium, like Greece and Rome, affected the curule form of chair, and in addition to lions’ heads and winged figures of Victory (or Nike) and dolphin-shaped arms used also the lyre-back which has been made familiar by the pseudo-classical revival of the end of the 18th century.\n\nOne type of chair in ancient Mexico is called the icpalli and is mentioned by Jacques Soustelle. The icpalli can be seen in Diego Rivera's mural of the Aztec market of Tlatelolco, Palacio Nacional, Mexico City. The icpalli is also featured in the Codex Telleriano-Remensis; dignitaries and emperors are depicted sitting in them.\n\nThe chair of Maximian in the cathedral of Ravenna is believed to date from the middle of the 6th century. It is of marble, round, with a high back, and is carved in high relief with figures of saints and scenes from the Gospels—the Annunciation, the Adoration of the Magi, the flight into Egypt and the baptism of Christ. The smaller spaces are filled with carvings of animals, birds, flowers and foliated ornament. The Chair of St. Augustine, dating from at least the early thirteenth century is one of the oldest cathedrae is not in use.\n\nAnother very ancient seat is the so-called \"Chair of Dagobert\" in the Louvre. It is of cast bronze, sharpened with the chisel and partially gilt; it is of the curule or faldstool type and supported upon legs terminating in the heads and feet of animals. The seat, which was probably of leather, has disappeared. Its attribution depends entirely upon the statement of Suger, abbot of St Denis in the 12th century, who added a back and arms. Its age has been much discussed, but Viollet-le-Duc dated it to early Merovingian times, and it may in any case be taken as the oldest faldstool in existence.\n\nTo the same generic type belongs the famous abbots’ chair of Glastonbury; such chairs might readily be taken to pieces when their owners travelled. The faldisterium in time acquired arms and a back, while retaining its folding shape. The most famous, as well as the most, ancient, English chair is that made at the end of the 13th century for Edward I, in which most subsequent monarchs have been crowned. It is of an architectural type and of oak, and was covered with gilded gesso which long since disappeared.\n\nPassing from these historic examples we find the chair monopolized by the ruler, lay or ecclesiastical, to a comparatively late date. As the seat of authority it stood at the head of the lord’s table, on his dais, by the side of his bed. The seigneurial chair, more common in France and the Netherlands than in England, is a very interesting type, approximating in many respects to the episcopal or abbatial throne or stall. It early acquired a very high back and sometimes had a canopy. Arms were invariable, and the lower part was closed in with panelled or carved front and sides—the seat, indeed, was often hinged and sometimes closed with a key.\n\nThat we are still said to sit \"in\" an arm-chair and \"on\" other kinds of chairs is a reminiscence of the time when the lord or seigneur sat \"in his chair.\" These throne-like seats were always architectural in character, and as Gothic feeling waned took the distinctive characteristics of Renaissance work. The furniture makers also covered their crude work with gold which is called gilding.\n\nBefore the Tang Dynasty (618–907 AD), the predominant sitting positions in the Han Chinese culture and neighboring cultures such as the Japanese Culture, Korean Culture, Turkic Culture in Central Asia and Tai Kadai Cultures to the southwest were the seiza and lotus position on the floor or sitting mats. The earliest images of chairs in China are from sixth-century Buddhist murals and stele, but the practice of sitting in chairs at that time was rare. It was not until the twelfth century that chairs became widespread in China. Scholars disagree on the reasons for the adoption of the chair. The most common theories are that the chair was an outgrowth of indigenous Chinese furniture, that it evolved from a camp stool imported from Central Asia, that it was introduced to China by Nestorian missionaries in the seventh century, and that the chair came to China from India as a form of Buddhist monastic furniture. In modern China, unlike Korea or Japan, it is not common to sit at floor level.\n\nIn Europe, it was owing in great measure to the Renaissance that the chair ceased to be a mark of high office, and became the customary companion of whoever could afford to buy it. Once the idea of privilege faded the chair speedily came into general use. We find almost at once began to reflect the fashions of the hour. No piece of furniture has ever been so close an index to sumptuary changes. It has varied in size, shape and sturdiness with the fashion not only of women’s dress but of men’s also. Thus the chair which was not, even with its arms purposely suppressed, too ample during the several reigns of some form or other of hoops and farthingale, became monstrous when these protuberances disappeared. Again, the costly laced coats of the dandy of the 18th and early 19th centuries were so threatened by the ordinary form of seat that a “conversation chair” was devised, which enabled the buck and the ruffler to sit with his face to the back, his valuable tails hanging unimpeded over the front. The early chair almost invariably had arms, and it was not until towards the close of the 16th century that the smaller form grew common.\n\nThe majority of the chairs of all countries until the middle of the 17th century were of timber (the commonest survival is oak) without upholstery, and when it became customary to cushion them, leather was sometimes employed; subsequently velvet and silk were extensively used, and at a later period cheaper and often more durable materials. . In Abraham Bosse's engraving (\"illustration, left\"), a stylish Parisian musical party of about 1630 have pulled their low chairs (called \"backstools\" in contemporary England) away from the tapestry-hung walls where they were normally lined up. The padded back panels were covered with needlework panels to suit the tapestries, or in other settings with leather, plain or tooled. Plain cloth across the back hid the wooden framing. Stools with column legs complement the set, but aren't \"en suite\". In seventeenth century France the bergere chair became fashionable among the nobility and was often made of walnut.\n\nLeather was not infrequently used even for the costly and elaborate chairs of the faldstool form—occasionally sheathed in thin plates of silver—which Venice sent all over Europe. To this day, indeed, leather is one of the most frequently employed materials for chair covering. The outstanding characteristic of most chairs until the middle of the 17th century was massiveness and solidity. Being usually made of oak, they were of considerable weight, and it was not until the introduction of the handsome Louis XIII chairs with cane backs and seats that either weight or solidity was reduced.\n\nAlthough English furniture derives so extensively from foreign and especially French and Italian models, the earlier forms of English chairs owed but little to exotic influences. This was especially the case down to the end of the Tudor period, after which France began to set her mark upon the British chair. The squat variety, with heavy and sombre back, carved like a piece of panelling, gave place to a taller, more slender, and more elegant form, in which the framework only was carved, and attempts were made at ornament in new directions. The stretcher especially offered opportunities which were not lost upon the cabinet-makers of the Restoration. From a mere uncompromising cross-bar intended to strengthen the construction it blossomed, almost suddenly, into an elaborate scroll-work or an exceedingly graceful semicircular ornament connecting all four legs, with a vase-shaped knob in the centre. The arms and legs of chairs of this period were scrolled, the splats of the back often showing a rich arrangement of spirals and scrolls. This most decorative of all types appears to have been popularized in England by the cavaliers who had been in exile with Charles II, and had become familiar with it in the north-western parts of the European continent. During the reign of William III and Mary II these charming forms degenerated into something much stiffer and more rectangular, with a solid, more or less fiddle-shaped splat and a cabriole leg with pad feet. The more ornamental examples had cane seats and ill-proportioned cane backs. From these forms was gradually developed the Chippendale chair, with its elaborately interlaced back, its graceful arms and square or cabriole legs, the latter terminating in the claw and ball or the pad foot. George Hepplewhite, Thomas Sheraton and Robert Adam all aimed at lightening the chair, which, even in the master hands of Thomas Chippendale, remained comparatively heavy. The endeavour succeeded, and the modern chair is everywhere comparatively slight.\n\nInformal, \"galante\" manners and a new half-reclining posture that replaced the former bolt-upright demeanor of court and aristocracy in the age of Louis XIV went hand-in-hand with new commodious seat furniture, developed in Paris about 1720 (\"illustration, right\"). The new Rococo chairs were upholstered \"à chassis\", on removable frames secured by clips, so that changes from winter to summer furniture could be effected without recourse to the \"menuisier\". Off-season upholstered frames were stored in the \"garde-meuble\". These early Louis XV chairs have backs upholstered à la reine, with the back in a flat panel that was ordinarily placed squared to the wall, so that the top-rails' curves complemented those of the \"boiserie\" panels behind them.\n\nIn the illustration, the symmetrical cusped and scrolling seatrails that flow into stubby cabriole legs of these comfortable low armchairs (\"chauffeuses\") have their direct origins in Chinese lacquer tables (not chairs).\nFrench fashions in chairs, as with everything else, radiated from Paris. From the late 1720s, fashionable \"Louis XV\" French chairs were constructed without stretchers, which interfered with the unified flow of curved seatrails into cabriole legs that generally ended in scroll feet. According to strict guild regulations in force until the Revolution, French chairmaking was the business of the \"menuisier\" alone, whose craft was conjoined with that of the upholsterer (\"huissier\"), both of whom specialized in seat-furniture-making in Paris. A range of specialised seats were developed and given fanciful names, of which the comfortable \"bergère\" (\"shepherdess\") is the most familiar. Walnut and beech were the characteristics woods employed; finishes were painted in clear light tones en suite with wall panelling, gilded (sometimes \"rechampi en blanc\") or left in the natural color (\"á la capuchine\"), in which case walnut was the timber used. Fruitwoods were popular for chairmaking in the provinces, where the menuisier might also be called upon to provide carved and moulded \"boiseries\" for rooms. Lyon, Bordeaux and Liège all produced characteristic variations on Paris models between ca. 1725 and 1780.\n\nIn the late 1760s in Paris the first Parisian neoclassical chairs were made, even before the accession of Louis XVI, whose name is attached to the first phases of the style. Straight tapering fluted legs joined by a block at the seat rail and architectural mouldings, characterize the style, in which each element is a discrete entity. Louis Delanois, Jean-Claude Sené and Georges Jacob were three leading chairmakers in the 1770s and 80s.\n\nThe 18th century was indeed the golden age of the chair, especially in France and England (including Colonial America), between which there was considerable give and take of ideas. Even Diderot could not refrain from writing of them in his Encyclopédie. The typical Louis Seize chair, oval-backed and ample of seat, with descending arms and round-reeded legs, covered in Beauvais or some such gay tapestry woven with Boucher or Watteau-like scenes, is a very gracious object, in which the period reached its high-water mark. The Empire brought in squat and squabby shapes, comfortable enough no doubt, but entirely destitute of inspiration. English Empire chairs were often heavier and more sombre than those of French design.\n\nThough some stories attribute its invention to Benjamin Franklin, historians trace the rocking chair's origins to North America during the early 18th century. It arrived in England shortly after its development, although work continued in America. The production of wicker rocking chairs reached its peak in America during the middle of the 18th century.\n\nThe art nouveau school produced chairs of simplicity. The Arts and Crafts movement produced heavy, straight lined, minimally ornamented chairs.\nThe most famous being the Michael Thonet Bendwood chair or the 'bistro chair' created in 1859 which has revolutionized the industry and is still being produced today.\n\nThe 20th century saw an increasing use of technology in chair construction with such things as all-metal folding chairs, metal-legged chairs, the Slumber Chair, moulded plastic chairs and ergonomic chairs, recliner chairs (easy chair), butterfly chair, beanbag chairs, the egg or pod chair, plywood and laminate wood chairs, and massage chairs. Architects such as Frank Lloyd Wright and Eero Saarinen also designed chairs to match the design of their buildings.\n\n\n"}
{"id": "1430935", "url": "https://en.wikipedia.org/wiki?curid=1430935", "title": "Hysteron proteron", "text": "Hysteron proteron\n\nThe hysteron proteron (from the , \"hýsteron próteron\", \"later earlier\") is a rhetorical device. It occurs when the first key word of the idea refers to something that happens temporally later than the second key word. The goal is to call attention to the more important idea by placing it first.\n\nThe standard example comes from the \"Aeneid\" of Virgil: \"Moriamur, et in media arma ruamus\" (\"Let us die, and charge into the thick of the fight\"; ii. 353). An example of hysteron proteron encountered in everyday life is the common reference to putting on one's \"shoes and socks\", rather than \"socks and shoes\".\n\nBy this deliberate reversal, hysteron proteron draws attention to the important point, so giving it primacy.\nHysteron proteron is a form of hyperbaton, which describes general rearrangements of the sentence.\n\nIt can also be defined as a figure of speech consisting of the reversal of a natural or rational order (as in \"then came the thunder and the lightning\").\n\nAn example from the Quran that demonstrates hysteron proteron, verse (aya) number 89–90 from Sura Number 21 from the Quran says that God granted Zechariah's prayer for a son, even though Zechariah was very old and his wife was sterile:\n\n\"We granted his prayer and gave him John, and we made his wife fertile for him.\" Quran (89–90, 21)\n\nThe sequence, one feels, should have been: We granted his prayer; we made his wife fertile for him; and [having done so] we gave him John. The reversal of the expected sequence (hysteron proteron) in the verse suggests immediacy: Zechariah's prayer was granted without any delay at all, so much so that the detail itself, \"We made his wife fertile for him,\" was not allowed to intervene between the prayer and its acceptance.\n"}
{"id": "5575456", "url": "https://en.wikipedia.org/wiki?curid=5575456", "title": "ISO 639 macrolanguage", "text": "ISO 639 macrolanguage\n\nISO 639-3 is an international standard for language codes. In defining some of its language codes, some are classified as macrolanguages, which include other individual languages in the standard. This category exists to assist mapping between another set of languages codes, ISO 639-2, and ISO 639-3. ISO 639-3 is curated by SIL International, ISO 639-2 is curated by the Library of Congress (USA).\n\nThe mapping often has the implication that it covers borderline cases where two language varieties may be considered strongly divergent dialects of the same language or very closely related languages (dialect continuums). It may also encompass situations when there are language varieties that are sometimes considered to be varieties of the same language and sometimes different languages for ethnic or political rather than linguistic reasons. However, this is not its primary function and the classification is not evenly applied. For example, \"Chinese\" is a macrolanguage encompassing many languages that are not mutually intelligible, but the languages \"Standard German\", \"Bavarian German\", and other closely related languages do \"not\" form a macrolanguage despite being more mutually intelligible. Other examples include Tajiki not being part of the Persian macrolanguage despite sharing much lexicon, and Urdu and Hindi not forming a macrolanguage. Even all dialects of Hindi are considered as separate languages. Basically, ISO 639-2 and ISO 639-3 use different criteria for dividing language varieties into languages, 639-2 uses shared writing systems and literature more whereas 639-3 focuses on mutual intelligibility and shared lexicon. The macrolanguages exist within the ISO 639-3 code set to make mapping between the two sets easier.\n\nThere are fifty-six language codes in ISO 639-2 that are considered to be macrolanguages in ISO 639-3. The use of this category of macrolanguage was applied in \"Ethnologue\", starting in the 16th edition.\n\nSome of the macrolanguages had no individual language (as defined by 639-3) in ISO 639-2, e.g. \"ara\" (Arabic), but ISO 639-3 recognizes different varieties of Arabic as separate languages under some circumstances. Others, like \"nor\" (Norwegian) had their two individual parts (nno Nynorsk, nob Bokmål) already in 639-2. That means some languages (e.g. \"arb\" Standard Arabic) that were considered by ISO 639-2 to be dialects of one language (\"ara\") are now in ISO 639-3 in certain contexts considered to be individual languages themselves. This is an attempt to deal with varieties that may be linguistically distinct from each other, but are treated by their speakers as forms of the same language, e.g. in cases of diglossia. For example,\n\n\nISO 639-2 also includes codes for collections of languages; these are not the same as macrolanguages. These collections of languages are excluded from ISO 639-3, because they never refer to individual languages. Most such codes are included in ISO 639-5.\n\n\nThis list only includes official data from http://www.sil.org/iso639-3.\n is the ISO 639-3 language code for Akan. Its ISO 639-1 code is ak. There are two individual language codes assigned:\n\n is the ISO 639-3 language code for Arabic language. Its ISO 639-1 code is ar. There are 30 individual language codes assigned.\n\n is the ISO 639-3 language code for Aymara. Its ISO 639-1 code is ay. There are two individual language codes assigned:\n\n is the ISO 639-3 language code for Azerbaijani. Its ISO 639-1 code is az. There are two individual language codes assigned:\n\n is the ISO 639-3 language code for Baluchi. There are three individual language codes assigned:\n\n is the ISO 639-3 language code for Bikol. There are eight individual language codes assigned:\n\n is the ISO 639-3 language code for Bontok. There are five individual language codes assigned:\n\n\n is the ISO 639-3 language code for Buriat. There are three individual language codes assigned:\n\n is the ISO 639-3 language code for Mari, a language located in Russia. There are two individual language codes assigned:\n\n is the ISO 639-3 language code for Cree. Its ISO 639-1 code is cr. There are six individual language codes assigned:\n\nIn addition, there are six closely associated individual codes.\n\nIn addition, there is 1 other language without individual codes closely associated, but not part of, this macrolanguage code.\n\n is the ISO 639-3 language code for Delaware. There are two individual language codes assigned:\n\n is the ISO 639-3 language code for Slave. There are two individual language codes assigned:\n\n is the ISO 639-3 language code for Dinka. There are five individual language codes assigned:\n\n is the ISO 639-3 language code for Dogri. There are two individual language codes assigned:\n\n is the ISO 639-3 language code for Estonian. Its ISO 639-1 code is et. There are two individual language codes assigned:\n\n is the ISO 639-3 language code for Persian. Its ISO 639-1 code is fa. There are two individual language codes assigned:\n\n is the ISO 639-2 and ISO 639-3 language code for Fulah (also spelled Fula). Its ISO 639-1 code is ff. There are nine individual language codes assigned for varieties of Fulah:\n\n is the ISO 639-3 language code for Gbaya located in the Central African Republic. There are six to seven individual language codes assigned:\n\n is the ISO 639-3 language code for Gondi. There are two individual language codes assigned:\n\n is the ISO 639-3 language code for Grebo. There are five individual language codes assigned:\n\n is the ISO 639-3 language code for Guarani. Its ISO 639-1 code is gn. There are five individual language codes assigned:\n\n is the ISO 639-3 language code for Haida. There are two individual language codes assigned:\n\n is the ISO 639-3 language code for Serbo-Croatian. There are three individual language codes assigned:\n\n is the ISO 639-3 language code for Hmong. As of February 2007, 24 individual language codes are included:\n\n is the ISO 639-3 language code for Inuktitut. Its ISO 639-1 code is iu. There are two individual language codes assigned:\n\n is the ISO 639-3 language code for Inupiaq. Its ISO 639-1 code is ik. There are two individual language codes assigned:\n\n is the ISO 639-3 language code for Judeo-Arabic. There are five individual language codes assigned:\n\n is the ISO 639-2 and ISO 639-3 language code for the Kanuri language. Its ISO 639-1 code is kr. There are three individual language codes assigned in ISO 639-3 for varieties of Kanuri:\n\nThere are 2 other related languages that are not considered part of the macrolanguage under ISO 639:\n\n is the ISO 639-3 language code for Kalenjin language. With effective from January 14, 2008, there are nine individual language codes assigned:\n\n is the ISO 639-3 language code for Konkani macrolanguage. There are two individual language codes assigned.\n\nBoth languages are referred to as Konkani by their respective speakers.\n\n is the ISO 639-3 language code for Komi. Its ISO 639-1 code is kv. There are two individual language codes assigned:\n\n is the ISO 639-3 language code for Kongo. Its ISO 639-1 code is kg. There are three individual language codes assigned:\n\n is the ISO 639-3 language code for Kpelle language. There are two individual language codes assigned.\n\n is the ISO 639-3 language code for Kurdish. Its ISO 639-1 code is ku. There are three individual language codes assigned:\n\n is the ISO 639-3 language code for Lahnda language. There are eight individual language codes assigned.\nNote that lah does \"not\" include Panjabi/Punjabi (pan).\n\n is the ISO 639-3 language code for Latvian. Its ISO 639-1 code is lv. There are two individual language codes assigned:\n\n\n is the ISO 639-3 language code for Luhya language. With effective from January 14, 2008, there are 14 individual language codes assigned:\n\n is the ISO 639-3 language code for Mandingo language. There are seven individual language codes assigned.\n\n is the ISO 639-3 language code for Malagasy. Its ISO 639-1 code is mg. There are eleven to twelve individual language codes assigned:\n\n is the ISO 639-3 language code for Mongolian. Its ISO 639-1 code is mn. There are two individual language codes assigned:\n\n is the ISO 639-3 language code for Malay. Its ISO 639-1 code is ms. There are 13 individual language codes assigned:\n\n is the ISO 639-3 language code for Marwari language. There are six individual language codes assigned.\n\n is the ISO 639-3 language code for Norwegian. Its ISO 639-1 code is no. There are two individual language codes assigned:\n\n is the ISO 639-3 language code for the Anishinaabe languages, commonly called the Ojibwe language group. Its ISO 639-1 code is oj. There are seven individual language codes assigned:\n\nIn addition, there are three closely associated individual codes.\n\nIn addition, there are two other languages without individual codes closely associated, but not part of, this macrolanguage code.\n\n is the ISO 639-3 language code for Oromo language. Its ISO 639-1 code is om. There are four individual language codes assigned:\n\n is the ISO 639-3 language code for Pushto language. Its ISO 639-1 code is ps. There are three individual language codes assigned.\n\n is the ISO 639-3 language code for Quechua languages. Its ISO 639-1 code is qu. As of April 2007 there are 44 individual language codes assigned for Quechua varieties.\n\n is the ISO 639-3 language code for Rajasthani language. There are six individual language codes assigned.\n\n is the ISO 639-3 language code for Romany language. There are seven individual language codes assigned.\n\nIn addition, there are eight individual codes not part of this macrolanguage but they are categorized as mixed languages.\n\nIn addition, there is a language without an individual code assigned, which it is not part of this macrolanguage.\n\n is the ISO 639-3 language code for Albanian. Its ISO 639-1 code is sq. As of June 2006 there are four individual language codes assigned for Albanian languages:\n\n is the ISO 639-3 language code for Sardinian language. Its ISO 639-1 code is sc. There are four individual language codes assigned.\n\n is the ISO 639-3 language code for Swahili. Its ISO 639-1 code is sw. There are two individual language codes assigned:\n\n is the ISO 639-3 language code for Syriac language. There are two individual language codes assigned.\n\n is the ISO 639-3 language code for Tamashek language. There are four individual language codes assigned.\n\n is the ISO 639-3 language code for Uzbek language. Its ISO 639-1 code is uz. There are two individual language codes assigned.\n\n is the ISO 639-3 language code for Yiddish language. Its ISO 639-1 code is yi. There are two individual language codes assigned.\n\n is the ISO 639-3 language code for Zapotec language. There are 57 individual language codes assigned.\n\nIn addition, there is an individual code not part of this macrolanguage because it is categorized as a historical language.\n\n is the ISO 639-3 language code for Zhuang languages. Its ISO 639-1 code is za. There are 16 individual language codes assigned.\n\n is the ISO 639-3 language code for Chinese. Its ISO 639-1 code is zh. There are 13 individual language codes assigned, some with their own dialects:\n\nAlthough the Dungan language () is considered most closely related to Mandarin, it is not listed under Chinese in ISO 639-3 due to separate historical and cultural development.\n\nISO 639 also lists codes for Old Chinese (), Late Middle Chinese (), and Classical Chinese (). They are not listed under Chinese in ISO 639-3 because they are categorized as ancient and historical languages, respectively.\n\n is the ISO 639-3 language code for Zaza language. There are two individual language codes assigned.\n\n\n"}
{"id": "674787", "url": "https://en.wikipedia.org/wiki?curid=674787", "title": "In medias res", "text": "In medias res\n\nA narrative work beginning in medias res (, lit. \"into the middle of things\") opens in the midst of the plot (cf. \"ab ovo\", \"ab initio\"). Often, exposition is bypassed and filled in gradually, either through dialogue, flashbacks or description of past events. For example, \"Hamlet\" begins after the death of Hamlet's father. Characters make reference to King Hamlet's death without the plot's first establishment of said fact. Since the play focuses on Hamlet and the revenge itself more so than the motivation, Shakespeare utilizes \"in medias res\" to bypass superfluous exposition.\n\nWorks that employ \"in medias res\" often, though not always, will subsequently use flashback and nonlinear narrative for exposition of earlier events in order to fill in the backstory. For example, in Homer's \"Odyssey\", we first learn about Odysseus's journey when he is held captive on Calypso's island. We then find out, in Books IX through XII, that the greater part of Odysseus's journey precedes that moment in the narrative. On the other hand, Homer's \"Iliad\" has relatively few flashbacks, although it opens in the thick of the Trojan War.\n\nThe Roman lyric poet and satirist Horace (65–8 BC) first used the terms ab ōvō (\"from the egg\") and in mediās rēs (\"into the middle of things\") in his \"Ars poetica\" (\"Poetic Arts\", c. 13 BC), wherein lines 147–149 describe the ideal epic poet:\nThe \"egg\" reference is to the mythological origin of the Trojan War in the birth of Helen and Clytemnestra from the double egg laid by Leda following her seduction by Zeus in the guise of a swan.\n\nProbably originated in oral tradition, the narrative technique of beginning a story \"in medias res\" is a stylistic convention of epic poetry, the exemplars in Western literature being the \"Iliad\" and the \"Odyssey\" (both 7th century BC), by Homer. Likewise, the technique features in the Indian \"Mahābhārata\" (c. 8th century BC – c. 4th century AD). \n\nThe classical-era poet Virgil (Publius Vergilius Maro, 70–19 BC) continued this literary narrative technique in the \"Aeneid\", which is part of the Greek literary tradition of imitating Homer. Later works featuring \"in medias res\" include the stories \"Sinbad the Sailor\" and \"The Three Apples\" from the \"One Thousand and One Nights\" (c. 9th century), the German \"Nibelungenlied\" (12th century), the Spanish \"Cantar de Mio Cid\" (c. 14th century), the Italian \"Divine Comedy\" (1320) by Dante Alighieri, the Portuguese \"The Lusiads\" (1572) by Luís Vaz de Camões, \"Jerusalem Delivered\" (1581) by Torquato Tasso, \"Paradise Lost\" (1667) by John Milton, and generally in Modernist literature.\n\nModern novelists known to extensively employ \"in medias res\" in conjunction with flashbacks include William Faulkner and Toni Morrison.\n\nEdgar Allan Poe’s The Tell-Tale Heart is written in medias res.\n\nIt is typical for film noir to begin \"in medias res\"; for example, a private detective will enter the plot already in progress. \"Crossfire\" (1947) opens with the murder of Joseph Samuels. As the police investigate the crime, the story behind the murder is told via flashbacks. \"Dead Reckoning\" (1947) opens with Humphrey Bogart as Rip Murdock on the run and attempting to hide in a Catholic church. Inside, the backstory is told in flashback as Murdock explains his situation to a priest.\n\nThe technique has been used across genres, including dramas such as \"Through a Glass Darkly\" (1961), \"8½\" (1963), \"Raging Bull\" (1980), and \"City of God\" (2002); crime thrillers such as \"No Way Out\" (1987), \"Grievous Bodily Harm\" (1988), \"The Usual Suspects\" (1995), and \"Kill Bill Volume 2\" (2004); horror films such as \"Firestarter\" (1984); action films such as many in the James Bond franchise; and comedies such as \"Dr. Strangelove\" (1964).\n\nMany war films, such as \"The Thin Red Line\" (1998), also begin \"in medias res\", with the protagonists already actively in combat and no prior domestic scenes leading up to the film's events.\n\nOccasionally, adaptations of source material may employ \"in medias res\" while the original version did not. For example, the film adaptation of the stage musical \"Camelot\" employed \"in medias res\" while the original Broadway version did not (although revivals of the musical have). Stanley Kubrick's 1962 film adaptation of \"Lolita\" begins \"in medias res\" although the novel does not. Herman Wouk's stage adaptation of his own novel \"The Caine Mutiny\" begins \"in medias res\" as it opens with the court-martial that occupies the final section of the novel, telling the earlier part of the story through flashbacks in court-room testimony.\n\n"}
{"id": "4886629", "url": "https://en.wikipedia.org/wiki?curid=4886629", "title": "Jake the Alligator Man", "text": "Jake the Alligator Man\n\nJake the Alligator Man is an alleged half-man, half-alligator creature on display in apparently mummified condition at Marsh's Free Museum, a tourist trap located at 409 South Pacific Avenue in Long Beach, Washington. He was acquired by the Marshes for $750 in 1967 from an antique store.\n\nA postcard image was used by the \"Weekly World News\" on November 9, 1993 for front-page article, \"Half-human, half-alligator discovered in Florida swamp.\" The periodical subsequently reported on his escape from captivity, killing of a Miami man, and giving birth.\n\nJake has acquired a cult following in Northwestern popular culture. His 75th birthday party is held annually in early August on the peninsula, and features events such as a bachelor party, car show, bridal contest, and live music. Bumper stickers featuring the oddity can be commonly seen throughout Washington and Oregon.\n\n\n"}
{"id": "18552", "url": "https://en.wikipedia.org/wiki?curid=18552", "title": "Larousse Gastronomique", "text": "Larousse Gastronomique\n\nLarousse Gastronomique () is an encyclopedia of gastronomy. The majority of the book is about French cuisine, and contains recipes for French dishes and cooking techniques. The first edition included few non-French dishes and ingredients; later editions include many more. The book was originally published by Éditions Larousse, founded by Pierre Larousse.\n\nThe first edition (1938) was edited by Prosper Montagné, with prefaces by Georges Auguste Escoffier and Philéas Gilbert. Gilbert was a collaborator in the creation of this book as well as \"Le Guide Culinaire\" with Escoffier, leading to some cross-over with the two books. It caused Escoffier to note when he was asked to write the preface that he could \"see with my own eyes,\" and \"Montagné cannot hide from me the fact that he has used \"Le Guide\" as a basis for his new book, and certainly used numerous recipes.\"\n\nThe third English edition (2001), which runs to approximately 1350 pages has been modernized and includes additional material on other cuisines. It is also available in a concise edition (2003). A new, updated and revised edition was released on 13 October 2009 published by Hamlyn in the UK.\n\n\n"}
{"id": "47135293", "url": "https://en.wikipedia.org/wiki?curid=47135293", "title": "List of monuments damaged by conflict in the Middle East during the 21st century", "text": "List of monuments damaged by conflict in the Middle East during the 21st century\n\nThis is a list of monuments suffering damage from conflict in the Middle East during the 21st century. It is sorted by country.\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "24186322", "url": "https://en.wikipedia.org/wiki?curid=24186322", "title": "Makapansgat pebble", "text": "Makapansgat pebble\n\nThe Makapansgat pebble (ca. 3,000,000 BP) is a 260-gram reddish-brown jasperite cobble with natural chipping and wear patterns that make it look like a crude rendition of a human face. \n\nThe pebble is interesting in that it was found some distance from any possible natural source, associated with the bones of \"Australopithecus africanus\" in a cave in Makapansgat, South Africa. Though it is definitely not a manufactured object, it has been suggested that some australopithecine might have recognized it as a symbolic face, in possibly the earliest example of symbolic thinking or aesthetic sense in the human heritage, and brought the pebble back to the cave. This would make it a candidate for the oldest known manuport.\n\nThe teacher Wilfred I. Eizman found it in the Makapansgat, a dolerite cave in the Makapan Valley north of Mokopane, Limpopo, South Africa in 1925. Almost 50 years later, Raymond Dart was the first to describe it in 1974.\n\nThe Makapansgat pebble cannot be seen as art if a usual definition of the term is used, as the object was found and not made. Nevertheless that an Australopithecus may have recognized a face would reveal that the early hominid had some sort of capacity for symbolic thinking, necessary for the development of art and language. If the early hominid has seen this object really as a face, or had magical speculations towards this object or just enjoyed the pebble remains unclear.\n\n\n"}
{"id": "220122", "url": "https://en.wikipedia.org/wiki?curid=220122", "title": "Moral rights", "text": "Moral rights\n\nMoral rights are rights of creators of copyrighted works generally recognized in civil law jurisdictions and, to a lesser extent, in some common law jurisdictions. They include the right of attribution, the right to have a work published anonymously or pseudonymously, and the right to the integrity of the work. The preserving of the integrity of the work allows the author to object to alteration, distortion, or mutilation of the work that is \"prejudicial to the author's honor or reputation\". Anything else that may detract from the artist's relationship with the work even after it leaves the artist's possession or ownership may bring these moral rights into play. Moral rights are distinct from any economic rights tied to copyrights. Even if an artist has assigned his or her copyright rights to a work to a third party, he or she still maintains the moral rights to the work.\n\nMoral rights were first recognized in France and Germany, before they were included in the \"Berne Convention for the Protection of Literary and Artistic Works\" in 1928. Canada recognizes moral rights (\"droits moraux\") in its \"Copyright Act\" (\"Loi sur le droit d'auteur\"). The United States became a signatory to the convention in 1989, and incorporated a version of moral rights under its copyright law under Title 17 of the U.S. Code.\n\nSome jurisdictions allow for the waiver of moral rights. In the United States, the \"Visual Artists Rights Act of 1990 (VARA)\" recognizes moral rights, but applies only to a narrow subset of works of visual art.\n\nSome jurisdictions like Austria differentiate between narrow and wide moral rights. Whilst the former is about integrity of the work, the latter limits usages, which may harm the author's integrity. Some copyright timestamp services allow an author to publish allowed and disallowed usage intentions to prevent a violation of such wider moral rights.\n\nThrough the Rome Revision of the Berne Convention in 1928, the Berne Convention accepted two forms of moral rights; paternity and integrity. These rights are included in Article 6bis of the \"Berne Convention\" as follows:\n\nIndependent of the author's economic rights, and even after the transfer of the said rights, the author shall have the right to claim authorship of the work and to object to any distortion, modification of, or other derogatory action in relation to the said work, which would be prejudicial to the author's honor or reputation.\n\nLegend:\n\nIn most of Europe, it is not possible for authors to assign or even waive their moral rights. This is following a tradition in European copyright itself, which is regarded as an item of property which cannot be sold, but only licensed. Parties certainly can agree not to enforce them (and such terms are very common in contracts in Europe). There may also be a requirement for the author to 'assert' these moral rights before they can be enforced. In many books, for example, this is done on a page near the beginning, in and amongst the British Library/Library of Congress data.\n\nSection 14.1 of Canada's Copyright Act protects the moral rights of authors. The moral rights cannot be assigned, but can be waived contractually. Many publishing contracts in Canada now contain a standard moral right waiver.\n\nMoral rights in Canada were famously exercised in the case of \"Snow v. The Eaton Centre Ltd.\" In this case Toronto Eaton Centre, a large shopping mall, had commissioned the artist Michael Snow for a sculpture of Canada Geese. Snow successfully stopped Eaton's from decorating the geese with bows at Christmas.\n\nArticle 20 of the provides unlimited term of protection of the rights of authorship, alteration, and integrity of an author. As Article 55 of the same Law provides retroactive protection of unexpired term on the date of entry into force of this Law, the Chinese perpetual moral rights are retroactive as well. The version retains this provision and the original Article 55 becomes Article 59.\n\nArt. 18, Copyright Act, 2005 provides perpetual moral rights. The moral rights in Art. 6 are for proper attribution and against any distortion, mutilation or other modification of the work where that act would be or is prejudicial to the reputation of the author or where the work is discredited by the act.\n\nMoral Rights is specified under Copyright Ordinance (Chapter 528) Division IV, starting from section 89. Author of computer program does not have Moral Rights (section 91). Moral Rights cannot be transferred unless on the death of moral rights holder (section 105 and 106).\n\nMoral rights are recognised under section 57 of India copyright act. Section 57 of India Copyright act refers to Author's Special rights. It states:\n\nThe issue of moral rights was discussed in Amar Nath Sehgal V Union of India & Ors.(Amar Nath Sehgal V Union of India & Ors CS/OS/No.2074/1992 decided on 21st Feb 2005. Court of Mr. Justice Pradeep Nandrajog). The case pertained to a mural that was commissioned in 1957 by Government of India during construction of Vigyan Bhavan at New Delhi. The mural in question was made of bronze had span of 140 feet sweep of 40 feet. The mural remained on display and was much appreciated till pulled down in 1979 and then consigned to storerooms of Union of India. Delhi High Court specifically referred to Berne Convention in delivering judgement. Court also awarded damages Rs. 500000 (half million) and also decreed in favor of the Amar Nath Sehgal that he would have an absolute right to recreate the mural at any place and right to sale the same.\n\nThe Court accepted existence of moral rights despite the work being commissioned work and copyright had passed over to union of India and suit being brought 13years after the said act(defense of limitations as pleaded by Government was rejected by the court).\n\nArticle 41 of the Decree-Law_n.o_43/99/M provides inalienable, unrenounceable and imprescriptible author’s personal rights.\n\nIn Taiwan, the Copyright Act has provided authors' perpetual moral rights with regard of attribution and protection against alteration in bad faith, even if the works are in the public domain, as follows:\n\nMoral rights have had a less robust tradition in the United States. Copyright law in the United States emphasizes protection of financial reward over protection of creative attribution. The exclusive rights tradition in the United States is inconsistent with the notion of moral rights as it was constituted in the Civil Code tradition stemming from post-Revolutionary France. When the United States acceded to the Berne Convention, it stipulated that the Convention's \"moral rights\" provisions were addressed sufficiently by other statutes, such as laws covering slander and libel.\n\nSome individual states have moral rights laws, particularly pertaining to visual art and artists (\"See\", \"e.g.\" California Art Preservation Act, Artists Authorship Rights Act (New York)). However, it is unclear if these laws, or portions thereof, are preempted by federal laws, such as the Visual Artists Rights Act.\n\nIn \"Gilliam v. American Broadcasting\", the Monty Python comedy troupe made a claim of \"mutilation\" (akin to a moral rights claim) in 1975 in legal proceedings against American TV network ABC for airing re-edited versions of \"Monty Python's Flying Circus\". However, the case was primarily decided on the basis of whether the BBC was licensed in such a way as to allow ABC to edit the videos (paragraph 20).\n\nThe Visual Artists Rights Act of 1990 grants authors of a \"work of visual art\" - e.g. photographs, paintings, sculptures, etc. - the non-transferable right to\n\n\nThese rights are distinct from any rights of copyright and ownership of a copy of the work.\n\nCopyright holders have the right to control adaptations, or the preparation of \"derivative works\". This right is given under copyright law. \"See\" 17 U.S.C. § 106.\n\nSection 43 of the Lanham Act governs false and misleading advertising, and can apply in some instances to attribution of protected works. However, it cannot be used to create moral rights for works outside of the Act. \"See\" \"Dastar v. Twentieth Century Fox\".\n\nAuthors occasionally wish to distance themselves from work they've been involved with, some to the point of not wishing to be recognized as the work's author. One way they may do this is by signing the work under a pseudonym. Alan Smithee was a traditional, collective pseudonym used between 1968 and 1999 by discontented Hollywood film directors who no longer wanted to be credited. This courtesy was not always extended, however. The director of \"\", Russell Mulcahy, wanted his name removed after the completion bond company took over film production, but he was contractually obliged not to impugn the film and he was told that using a pseudonym would impugn it.\n\nIf the work was unfinished, sometimes the original author will choose a pseudonym as permission for the copyright holder to do whatever they wish to finish and market the unwanted work, cutting ties from the product.\n\n\n\n"}
{"id": "19262812", "url": "https://en.wikipedia.org/wiki?curid=19262812", "title": "Nisei", "text": "Nisei\n\nAlthough the earliest organized group of Japanese emigrants left Japan centuries ago, and a later group settled in Mexico in 1897, the four largest populations of Japanese immigrants and their descendants live in Brazil, Canada, Peru, and the United States.\n\nSome US \"Nisei\" were born after the end of World War II during the baby boom. Most \"Nisei\", however, who were living in the western United States during World War II, were forcibly interned with their parents (\"Issei\") after Executive Order 9066 was promulgated to exclude everyone of Japanese descent from large parts of the Western states. It has been argued that some \"Nisei\" feel caught in a dilemma between their Nisei parents and other Americans. The Nisei of Hawaii had a somewhat different experience.\n\nIn the United States, two representative \"Nisei\" were Daniel Inouye and Fred Korematsu. Hawaiian-born was one of many young Nisei men who volunteered to fight in the nation's military when restrictions against Japanese-American enlistment were removed in 1943. Inouye later went on to become a U.S. Senator from Hawaii after it achieved statehood.\n\nThe overwhelming majority of Japanese Americans had reacted to the internment by acquiescing to the government's order, hoping to prove their loyalty as Americans. To them, Korematsu's opposition was treacherous to both his country and his community. Across the span of decades, he was seen as a traitor, a test case, an embarrassment and, finally, a hero.\n\nBrazil is home to the largest Japanese population outside Japan, estimated to number more than 1.5 million (including those of mixed-race or mixed-ethnicity), more than that of the 1.2 million in the United States. The \"Nisei\" Japanese Brazilians are an important part of the ethnic minority in that South American nation.\n\nWithin Japanese-Canadian communities across Canada, three distinct subgroups developed, each with different sociocultural referents, generational identity, and wartime experiences.\n\nAmong the approximately 80,000 Peruvians of Japanese descent, the \"Nisei\" Japanese Peruvians comprise the largest element. Former Peruvian President Alberto Fujimori was the \"Nisei\" son of \"Issei\" emigrants from Kumamoto, Japan.\n\nJapanese Americans and Japanese Canadians have special names for each of their generations in North America. These are formed by combining one of the Japanese numbers corresponding to the generation with the Japanese word for generation (\"sei\" 世). The Japanese-American and Japanese-Canadian communities have themselves distinguished their members with terms like \"Issei\", \"Nisei,\" and \"Sansei\" which describe the first, second and third generation of immigrants. The fourth generation is called \"Yonsei\" (四世) and the fifth is called \"Gosei\" (五世). The \"Issei,\" \"Nisei\" and \"Sansei\" generations reflect distinctly different attitudes to authority, gender, non-Japanese involvement, and religious belief and practice, and other matters. The age when individuals faced the wartime evacuation and internment is the single, most significant factor which explains these variations in their experiences, attitudes and behaviour patterns.\n\nThe term \"Nikkei\" (日系) was coined by a multinational group of sociologists and encompasses all of the world's Japanese immigrants across generations. The collective memory of the \"Issei\" and older \"Nisei\" was an image of Meiji Japan from 1870 through 1911, which contrasted sharply with the Japan that newer immigrants had more recently left. These differing attitudes, social values and associations with Japan were often incompatible with each other. In this context, the significant differences in post-war experiences and opportunities did nothing to mitigate the gaps which separated generational perspectives.\n\nIn North America since the redress victory in 1988, a significant evolutionary change has occurred. The Nisei, their parents and their children are changing the way they look at themselves as individuals of Japanese descent in their respective nations of Canada, the United States and Mexico.\n\nThere are currently just over one hundred thousand British Japanese, mostly in London; but unlike other \"Nikkei terms used centered from Japan to distinguish the distance from Japanese nationality elsewhere in the world, these Britons do not conventionally parse their communities in generational terms as \"Issei,\" \"Nisei,\" or \"Sansei.\"\n\nThe second generation of immigrants, born in Canada or the United States to parents not born in Canada or the United States, is called \"Nisei\" (二世). The \"Nisei\" have become part of the general immigrant experience in the United States and Canada to become part of the greater \"melting pot\" of Americans and Canadians. Some \"Nisei\" have resisted being absorbed into the majority society, largely because of their tendency to maintain Japanese interpersonal styles of relationships. -- \n\nMost \"Nisei\" were educated in Canadian or American school systems where they were taught Canadian or American national values as national citizens of those countries of individualism and citizenship. When these were taken away in the early 1940s, the \"Nisei\" confronted great difficulty in accepting or coming to terms with internment and forced resettlement. Older \"Nisei\" tended to identify more closely with the \"Issei,\" sharing similar economic and social characteristics. Older \"Nisei\" who had been employed in small businesses, in farming, in fishing or in semi-skilled occupations, tended to remain in blue-collar work. In contrast, the younger \"Nisei\" attended university and college and entered various professions and white-collar employment after the war. This sharp division in post-war experiences and opportunities exacerbated the gaps between these \"Nisei.\"\n\nThe \"kanreki\" (還暦), a traditional, pre-modern Japanese rite of passage to old age at 60, was sometimes celebrated by the \"Issei\" and is now being celebrated by increasing numbers of \"Nisei.\" Rituals are enactments of shared meanings, norms, and values; and this Japanese rite of passage highlights a collective response among the Nisei to the conventional dilemmas of growing older.\nAging is affecting the demographics of the Nisei. According to a 2011 columnist in \"The Rafu Shimpo\" of Los Angeles, the obituaries showing the number of Japanese Americans in their 80s and 90s — Nisei, in a word — who are passing is staggering\"\n\nThe Japanese-born \"Issei\" learned Japanese as their mother tongue, and their success in learning English as a second language was varied. Most \"Nisei\" speak Japanese to some extent, learned from \"Issei\" parents, Japanese school, and living in a Japanese community or in the internment camps. A majority of English-speaking \"Nisei\" have retained knowledge of the Japanese language, at least in its spoken form. Most \"Sansei\" speak English as their first language and most marry people of non-Japanese ancestry.\n\nAn illustrative point-of-view, as revealed in the poetry of an \"Issei\" woman:\n\nThere was relatively little inter-marriage during the Nisei generation, mainly because the relocation and the war intervened\nexactly at a time when the group was of marrying age. Identification of them with the enemy by the American public, made them\nunpopular and unlikely candidates for inter-racial marriage. Beside this, they were thrown, en masse, into camps with others of\nthe same ethnicity, causing the majority of Nisei to marry other Nisei. This is why third generation Sansei are mostly still of\nthe same racial appearance as the Issei, who first immigrated to the U.S. \nThe Sansei generation has widely inter-married in the post WWII years, with estimates of such unions at over 60 percent.\n\nWhen the Canadian and American governments interned West Coast Japanese in 1942, neither distinguished between those who were citizens (\"Nisei\") and their non-citizen parents (\"Issei\").\n\nIn 1978, the Japanese American Citizens League actively began demanding be taken as redress for harms endured by Japanese Americans during World War II.\n\nIn 1980, Congress established the Commission on Wartime Relocation and Internment of Civilians (CWRIC) The commission report, \"Personal Justice Denied,\" condemned the internment as \"unjust and motivated by racism rather than real military necessity\".\n\nIn 1988, U.S. President Ronald Reagan signed the Civil Liberties Act of 1988, which provided for a formal apology and payments of $20,000 for each survivor. The legislation stated that government actions were based on \"race prejudice, war hysteria, and a failure of political leadership\". The Civil Liberties Act Amendments of 1992, appropriating an additional $400 million in order to ensure that all remaining internees received their $20,000 redress payments, was signed into law by President George H. W. Bush, who also issued another formal apology from the U.S. government.\n\nJapanese and Japanese Americans who were relocated during WWII were compensated for direct property losses in 1948. These payments were awarded to 82,210 Japanese Americans or their heirs at a cost of $1.6 billion; the program's final disbursement occurred in 1999.\n\nIn 1983, the National Association of Japanese Canadians (NAJC) mounted a campaign demanding redress for injustices during the war years. NAJC hired Price Waterhouse to estimate the economic losses to Japanese Canadians resulting from property confiscations and loss of wages due to internment. On the basis of detailed records maintained by the Custodian of Alien Property, it was determined that the total loss totalled $443 million (in 1986 dollars).\n\nIn 1988, Prime Minister Brian Mulroney gave that long-awaited formal apology and the Canadian government began to make good on a compensation package—including $21,000 to all surviving internees, and the re-instatement of Canadian citizenship to those who were deported to Japan.\n\nThe number of \"nisei\" who have earned some degree of public recognition has continued to increase over time; but the quiet lives of those whose names are known only to family and friends are no less important in understanding the broader narrative of the \"nikkei.\" Although the names highlighted here are over-represented by \"issei\" from North America, the Latin American member countries of the Pan American Nikkei Association (PANA) include Argentina, Bolivia, Brazil, Chile, Colombia, Mexico, Paraguay, Peru and Uruguay, in addition to the English-speaking United States and Canada.\n\n\n\n\n"}
{"id": "33524705", "url": "https://en.wikipedia.org/wiki?curid=33524705", "title": "Origins of society", "text": "Origins of society\n\nThe origins of society — the evolutionary emergence of distinctively human social organization — is an important topic within evolutionary biology, anthropology, prehistory and palaeolithic archaeology. While little is known for certain, debates since Hobbes and Rousseau have returned again and again to the philosophical, moral and evolutionary questions posed.\n\nArguably the most influential theory of human social origins is that of Thomas Hobbes, who in his \"Leviathan\" argued that without strong government, society would collapse into \"Bellum omnium contra omnes\" — \"the war of all against all\":\n\nIf Hobbes' idea is accepted, it follows that society could not have emerged prior to the state. This school of thought has remained influential to this day. Prominent in this respect is British archaeologist Colin Renfrew (Baron Renfrew of Kaimsthorn), who points out that the state did not emerge until long after the evolution of \"Homo sapiens\". The earliest representatives of our species, according to Renfrew, may well have been \"anatomically\" modern, but they were not yet \"cognitively\" or \"behaviourally\" modern. For example, they lacked political leadership, large-scale cooperation, food production, organised religion, law or symbolic artefacts. Humans were simply hunter-gatherers, who — much like extant apes — ate whatever food they could find in the vicinity. Renfrew controversially suggests that hunter-gatherers to this day think and socialise along lines not radically different from those of their nonhuman primate counterparts. In particular, he says that they do not \"ascribe symbolic meaning to material objects\" and for that reason \"lack fully developed 'mind.'\"\n\nHowever, hunter-gatherer ethnographers emphasise that extant foraging peoples certainly do have social institutions — notably institutionalised rights and duties codified in formal systems of kinship. Elaborate rituals such as initiation ceremonies serve to cement contracts and commitments, quite independently of the state. Other scholars would add that insofar as we can speak of \"human revolutions\" — \"major transitions\" in human evolution — the first was not the Neolithic Revolution but the rise of symbolic culture that occurred toward the end of the Middle Stone Age.\n\nArguing the exact opposite of Hobbes's position, anarchist anthropologist Pierre Clastres views the state and society as mutually incompatible: genuine society is always struggling to survive \"against\" the state.\n\nLike Hobbes, Jean-Jacques Rousseau argued that society was born in a social contract. In Rousseau's case, however, sovereignty is vested in the entire populace, who enter into the contract directly with one another. \"The problem\", he explained, \"is to find a form of association which will defend and protect with the whole common force the person and goods of each associate, and in which each, while uniting himself with all, may still obey himself alone, and remain as free as before.\" This is the fundamental problem of which the Social Contract provides the solution. The contract's clauses, Rousseau continued, may be reduced to one — \"the total alienation of each associate, together with all his rights, to the whole community. Each man, in giving himself to all, gives himself to nobody; and as there is no associate over whom he does not acquire the same right as he yields others over himself, he gains an equivalent for everything he loses, and an increase of force for the preservation of what he has\". In other words: \"Each of us puts his person and all his power in common under the supreme direction of the general will, and, in our corporate capacity, we receive each member as an indivisible part of the whole.\" At once, in place of the individual personality of each contracting party, this act of association creates a moral and collective body, composed of as many members as the assembly contains votes, and receiving from this act its unity, its common identity, its life and its will. By this means, each member of the community acquires not only the capacities of the whole but also, for the first time, rational mentality:\n\nIn his influential book, \"Ancient Law\" (1861), Maine argued that in early times, the basic unit of human social organisation was the patriarchal family:\n\nHostile to French revolutionary and other radical social ideas, Maine's motives were partly political. He sought to undermine the legacy of Rousseau and other advocates of man’s natural rights by asserting that originally, no one had any rights at all – ‘every man, living during the greater part of his life under the patriarchal despotism, was practically controlled in all his actions by a regimen not of law but of caprice’. Not only were the patriarch’s children subject to what Maine calls his ‘despotism’: his wife and his slaves were equally affected. The very notion of kinship, according to Maine, was simply a way of categorizing those who were forcibly subjected to the despot’s arbitrary rule. Maine later added a Darwinian strand to this argument. In his \"The Descent of Man,\" Darwin had cited reports that a wild-living male gorilla would monopolise for itself as large a harem of females as it could violently defend. Maine endorsed Darwin’s speculation that ‘primeval man’ probably 'lived in small communities, each with as many wives as he could support and obtain, whom he would have jealously guarded against all other men’. Under pressure to spell out exactly what he meant by the term 'patriarchy', Maine clarified that ‘sexual jealousy, indulged through power, might serve as a definition of the Patriarchal Family’.\n\nIn his influential book, \"Ancient Society\" (1877), its title echoing Maine's \"Ancient Law,\" Lewis Henry Morgan proposed a very different theory. Morgan insisted that throughout the earlier periods of human history, neither the state nor the family existed.\n\nFrederick Engels built on Morgan's ideas in his 1884 essay, \"The Origin of the Family, Private Property and the State in the light of the researches of Lewis Henry Morgan.\" His primary interest was the position of women in early society, and — in particular — Morgan's insistence that the matrilineal clan preceded the family as society's fundamental unit. 'The mother-right gens', wrote Engels in his survey of contemporary historical materialist scholarship, 'has become the pivot around which the entire science turns...' Engels argued that the matrilineal clan represented a principle of self-organization so vibrant and effective that it allowed no room for patriarchal dominance or the territorial state.\n\nEmile Durkheim considered that in order to exist, any human social system must counteract the natural tendency for the sexes to promiscuously conjoin. He argued that social order presupposes sexual morality, which is expressed in prohibitions against sex with certain people or during certain periods — in traditional societies particularly during menstruation.\n\nThe incest taboo, wrote Durkheim in 1898, is no more than a particular example of something more basic and universal - the ritualistic setting apart of 'the sacred' from 'the profane'. This begins as the segregation of the sexes, each of which - at least on important occasions - is 'sacred' or 'set apart' from the other. 'The two sexes', as Durkheim explains, 'must avoid each other with the same care as the profane flees from the sacred and the sacred from the profane.' Women as sisters act out the role of 'sacred' beings invested 'with an isolating power of some sort, a power which holds the masculine population at a distance.' Their menstrual blood in particular sets them in a category apart, exercising a 'type of repulsing action which keeps the other sex far from them'. In this way, the earliest ritual structure emerges — establishing morally regulated 'society' for the first time.\n\nCharles Darwin pictured early human society as resembling that of apes, with one or more dominant males jealously guarding a harem of females. In his myth of the 'Primal Horde', Sigmund Freud later took all this as his starting point but then postulated an insurrection mounted by the tyrant's own sons: Following this, the band of brothers were about to take sexual possession of their mothers and sisters when suddenly they were overcome with remorse. In their contradictory emotional state, their dead father now became stronger than the living one had been. In memory of him, the brothers revoked their deed by forbidding the killing and eating of the 'totem' (as their father had now become) and renouncing their claim to the women who had just been set free. In this way, the two fundamental taboos of primitive society – not to eat the totem and not to marry one's sisters – were established for the first time.\n\nA related but less dramatic version of Freud's 'sexual revolution' idea was proposed in 1960 by American social anthropologist Marshall Sahlins. Somehow, he writes, the world of primate brute competition and sexual dominance was turned upside-down: \n\nIf we accept Rousseau's line of reasoning, no single dominant individual is needed to embody society, to guarantee security or to enforce social contracts. The people themselves can do these things, combining to enforce the general will. A modern origins theory along these lines is that of evolutionary anthropologist Christopher Boehm. Boehm argues that ape social organisation tends to be despotic, typically with one or more dominant males monopolising access to the locally available females. But wherever there is dominance, we can also expect resistance. In the human case, resistance to being personally dominated intensified as humans used their social intelligence to form coalitions. Eventually, a point was reached when the costs of attempting to impose dominance became so high that the strategy was no longer evolutionarily stable, whereupon social life tipped over into 'reverse dominance' — defined as a situation in which only the entire community, on guard against primate-style individual dominance, is permitted to use force to suppress deviant behaviour.\n\nHuman beings, writes social anthropologist Ernest Gellner, are not genetically programmed to be members of this or that social order. You can take a human infant and place it into any kind of social order and it will function acceptably. What makes human society so distinctive is the fabulous range of quite different forms it takes across the world. Yet in any given society, the range of permitted behaviours is quite narrowly constrained. This is not owing to the existence of any externally imposed system of rewards and punishments. The constraints come from within — from certain compulsive moral concepts which members of the social order have internalised. The society installs these concepts in each individual's psyche in the manner first identified by Emile Durkheim, namely, by means of collective rituals such as initiation rites. Therefore, the problem of the origins of society boils down to the problem of the origins of collective ritual.\n\nFeminist scholars — among them palaeoanthropologists Leslie Aiello and Camilla Power — take similar arguments a step further, arguing that any reform or revolution which overthrew male dominance must surely have been led by women. Evolving human females, Power and Aiello suggest, actively separated themselves from males on a periodic basis, using their own blood (and/or pigments such as red ochre) to mark themselves as fertile and defiant: In similar vein, anthropologist Chris Knight argues that Boehm's idea of a 'coalition of everyone' is hard to envisage, unless — along the lines of a modern industrial picket line — it was formed to co-ordinate 'sex-strike' action against badly behaving males: In virtually all hunter-gatherer ethnographies, according to Knight, a persistent theme is that 'women like meat', and that they determinedly use their collective bargaining power to motivate men to hunt for them and bring home their kills — on pain of exclusion from sex. Arguments about women's crucial role in domesticating males — motivating them to cooperate — have also been advanced by anthropologists Kristen Hawkes, Sarah Hrdy and Bruce Knauft among others. Meanwhile, other evolutionary scientists continue to envisage uninterrupted male dominance, continuity with primate social systems and the emergence of society on a gradualist basis without revolutionary leaps.\n\nIn his 1985 book, \"Social Evolution\", Robert Trivers outlines the theoretical framework used today by most evolutionary biologists to understand how and why societies are established. Trivers sets out from the fundamental fact that genes survive beyond the death of the bodies they inhabit, because copies of the same gene may be replicated in multiple different bodies. From this, it follows that a creature should behave altruistically to the extent that those benefiting carry the same genes — 'inclusive fitness', as this source of cooperation in nature is termed. Where animals are unrelated, cooperation should be limited to 'reciprocal altruism' or 'tit-for-tat'.\nWhere previously, biologists took parent-offspring cooperation for granted, Trivers predicted on theoretical grounds both cooperation and conflict — as when a mother needs to wean an existing baby (even against its will) in order to make way for another. Previously, biologists had interpreted male infanticidal behaviour as aberrant and inexplicable or, alternatively, as a necessary strategy for culling excess population. Trivers was able to show that such behaviour was a logical strategy by males to enhance their own reproductive success at the expense of conspecifics including rival males. Ape or monkey females whose babies are threatened have directly opposed interests, often forming coalitions to defend themselves and their offspring against infanticidal males.\nHuman society, according to Trivers, is unusual in that it involves the male of the species investing parental care in his own offspring — a rare pattern for a primate. Where such cooperation occurs, it's not enough to take it for granted: in Trivers' view we need to \"explain\" it using an overarching theoretical framework applicable to humans and nonhumans alike.\n\nRobin Dunbar originally studied gelada baboons in the wild in Ethiopia, and has done much to synthesise modern primatological knowledge with Darwinian theory into a comprehensive overall picture. The components of primate social systems 'are essentially alliances of a political nature aimed at enabling the animals concerned to achieve more effective solutions to particular problems of survival and reproduction'. Primate societies are in essence 'multi-layered sets of coalitions'. Although physical fights are ultimately decisive, the social mobilisation of allies usually decides matters and requires skills that go beyond mere fighting ability. The manipulation and use of coalitions demands sophisticated social — more precisely \"political\" — intelligence.\nUsually but not always, males exercise dominance over females. Even where male despotism prevails, females typically gang up with one another to pursue agendas of their own. When a male gelada baboon attacks a previously dominant rival so as to take over his harem, the females concerned may insist on their own say in the outcome. At various stages during the fighting, the females may 'vote' among themselves on whether to accept the provisional outcome. Rejection is signalled by refusing to groom the challenger; acceptance is signalled by going up to him and grooming him. According to Dunbar, the ultimate outcome of an inter-male 'sexual fight' always depends on the female 'vote'.\nDunbar points out that in a primate social system, lower-ranking females will typically suffer the most intense harassment. Consequently, they will be the first to form coalitions in self-defence. But maintaining commitment from coalition allies involves much time-consuming manual grooming, putting pressure on time-budgets. In the case of evolving humans, who were living in increasingly large groups, the costs would soon have outweighed the benefits — unless some more efficient way of maintaining relationships could be found. Dunbar argues that 'vocal grooming' — using the voice to signal commitment — was the time-saving solution adopted, and that this led eventually to speech. Dunbar goes on to suggest (citing evolutionary anthropologist Chris Knight) that \"distinctively human\" society may have been evolved under pressure from female ritual and 'gossiping' coalitions established to dissuade males from fighting one another and instead cooperate in hunting for the benefit of the whole camp: Dunbar stresses that this is currently a minority theory among specialists in human origins — most still support the 'bison-down-at-the-lake' theory attributing early language and cooperation to the imperatives of men's activities such as hunting. Despite this, he argues that 'female bonding may have been a more powerful force in human evolution than is sometimes supposed'. Although still controversial, the idea that female coalitions may have played a decisive role has subsequently received strong support from a number of anthropologists including Sarah Hrdy, Camilla Power, Ian Watts. and Jerome Lewis. It is also consistent with recent studies by population geneticists (see Verdu et al. 2013 for Central African Pygmies; Schlebusch 2010 for Khoisan) showing a deep-time tendency to matrilocality among African hunter-gatherers.\n\n\n"}
{"id": "46673516", "url": "https://en.wikipedia.org/wiki?curid=46673516", "title": "Page 99 test", "text": "Page 99 test\n\nThe page 99 test is a method of evalutating a work of fiction suggested by literary critic Ford Madox Ford. Ford suggested that prospective readers open a book and read page 99 to gain a sense of how well written the work is while avoiding any back-cover synopsis or the first few pages, as these are typically given extra attention during editing and may not reflect the quality of the book as a whole.\n\n"}
{"id": "36713338", "url": "https://en.wikipedia.org/wiki?curid=36713338", "title": "Physical cultural studies", "text": "Physical cultural studies\n\nPhysical Cultural Studies (PCS) encompasses the diversely focused field of scholarly work which is united by a commitment toward engaging varied dimensions or expressions of (in)active bodies or physical culture (Andrews & Silk, 2011). In this physical culture is understood as “cultural practices in which the physical body – the way it moves, is represented, has meanings assigned to it, and is imbued with power – is central” (Vertinsky, quoted in Silk & Andrews, 2011)\nPhysical Cultural Studies is closely related to the fields of sport sociology, cultural studies, sociology of the body, body culture studies, queer studies and disability studies. \n\nPCS is predominantly concerned with studying the active body. The aim of such a focus is to problematise the taken-for-granted aspects of human movement and embodiment in such a way that makes social divisions (class, gender, ethnicity, ability, generation, sex, nation, race), and the processes that produce, reproduce and contest these divisions become visible and changeable. In this respect, we can see that the 'physical' is of central importance to PCS. Indeed, it is this empirical focus ( and subsequent breadth) that separates PCS from fields such as the sociology of sport. This is because PCS scholars take as their subjects of study - all the many and varied, more or less 'legitimate', popular and emerging, work or leisure related - forms of physical culture. areas of study include: exercise, health, dance, recreation, leisure, fitness, daily living, and work related activities.\n\nIn the analysis of these activities PCS considers context and contextualisation to be vital. Indeed, how can one understand a cultural practice without reference to all the surrounding factors, flows, processes, actors and institutions with which it is articulated? For example, PCS researchers identify and seek to understand the complex political, economic, social and technological relationships in which the event occurs in order to understand physical culture as relational.\n\nThose in the field of physical cultural studies believe that research into, or understanding of, physical culture is of little importance if it does not make a difference in the world. Therefore, the idea of 'value free' research is not accepted in PCS. Instead, Partisanship is the dominant ideal. Such a perspective is related to many aspects of PCS study that vary from 'mainstream' academia. For example, PCS is concerned with care and community in which public education is of central importance. In addition, PCS aims to be political, empowering and reflexive. Finally PCS researchers attempt to question their presupposed hierarchy over the researched.\n\nSee also praxis\n\nPCS incorporates many methods of gathering data, oftentimes implementing a variety of methods together to create rich, contextual and multi-perspective analyses of physical culture. Such methods include ethnography, auto ethnography, contextual analysis, media analysis, discourse analysis and participant observation.\n\nNewman, J., James, J., Driscoll, M., Stokes, G., (2012) Center for Physical Cultural Studies (CPCS). The Florida State University: College of Education – Department of Sport Management\n\nAndrews, D., & Silk, M., (2011). Physical Cultural Studies: Engendering a Productive Dialogue. Sociology of Sport Journal 28: 1-3\n\nSilk, M., & Andrews, D., (2011). Toward a Physical Cultural Studies. Sociology of Sport Journal 28: 1-3\n\nResearch: Physical Cultural Studies (2012) University of Maryland: Kinesiology. Retrieved 08/10/12 from: http://www.sph.umd.edu/KNES/research/sportstud.html\n\nPCS at Bath (2012) University of Bath: Department of Education. Retrieved 08/10/12 from: http://www.bath.ac.uk/education/research/programmes/pcs/bath.html\n\nCentre for sport policy studies (2012) university of Toronto: Faculty of Kinesiology and Physical Education. Retrieved 08/10/12 from: http://www.physical.utoronto.ca/Centre_for_Sport_Policy_Studies.aspx\n\nThe H.J. Lutcher Stark Center for Physical Cultural Studies. Retrieved 08/10/12 from: http://www.starkcenter.org/\n\nBody, Movement and Culture Research Group (2012). University of Alberta: Faculty of Physical Education and Recreation. Retrieved 08/10/12 from: http://www.physedandrec.ualberta.ca/Research/LaboratoriesandResearchWorksho/BodyMovementandCultureResearch.aspx\n"}
{"id": "983079", "url": "https://en.wikipedia.org/wiki?curid=983079", "title": "Pitch (filmmaking)", "text": "Pitch (filmmaking)\n\nA pitch is a concise verbal (and sometimes visual) presentation of an idea for a film or TV series generally made by a screenwriter or film director to a film producer or studio executive in the hope of attracting development finance to pay for the writing of a screenplay.\n\n\"Pitch\" is a contraction of the phrase \"sales pitch\". A pitch is used throughout different stages of production, such as casting and distribution, as well as to urge film producers to further fund a project. Filmmakers who devise a pitch tend to manufacture a production package, which is handed out to each potential investor during the pitch. The package contains the basic information for the filmmaker's project, such as a plot synopsis and budgeting values. Sometimes, filmmakers will produce an independent pitch trailer as a part of the package to help potential financiers better visualize the project and the filmmaker's vision.\n\nThough pitches are usually made on the basis of a full script or teleplay, animated productions for both film and television are often pitched on the basis of storyboards alone. For example, the animated television show \"Phineas and Ferb\" was pitched from a storyboard. Co-founders of the project, Dan Povenmire and Jeff \"Swampy\" Marsh, needed to convince overseas executives for The Walt Disney Company to greenlight the series, so they drew a storyboard and recorded it as a reel. They then mixed it and dubbed it over with sound effects, voices, and narrative, then sent the recording to the executives, who accepted it.\n\nTelevision pitches can also be devised by the network or company that produces the program. Certain networks are pitched the idea of including a character in a series in order to boost ratings. Such pitches have been used with \"Oliver\" in \"The Brady Bunch\" and \"Luke\" on \"Growing Pains\". Networks also try to force their ideas on series' producers through their pitches, though their approach is business-oriented and their ideas are generally not favored by writers and viewers. In 1992, the crew of the animated series \"Rugrats\" was approached by Nickelodeon, which pitched the idea of a \"Rugrats\" Hanukkah special. Paul Germain, co-creator of the series, responded by suggesting a passover special, which he dubbed a \"funny idea.\" After they closed production for that special, they began considering the Hanukkah special and eventually created it in 1996 as the episode \"A Rugrats Chanukah.\"\n\n"}
{"id": "4692651", "url": "https://en.wikipedia.org/wiki?curid=4692651", "title": "Portrait (literature)", "text": "Portrait (literature)\n\nThe portrait is a literary genre derived from pictorial portraiture.\n\nThe imitation of painting is apparent in the name of the genre itself, which is a painting term. Historians of antiquity recognised the task of the portrait as representation; we find the beginnings of the narrative portrait in Livy and Tacitus. However, the portrait began to emerge from the need to describe oneself (self-portrait) or one's contemporaries, as in the \"Essays\" of Montaigne. This latter work develops a line of questioning around the movement of the representation of the individual (or of a society) from the pictorial mode to the discursive mode.\n\nThe portrait can be realised in prose or in verse. Its objectives vary according to context: sociocultural, sociopolitical, historical, or again according to the subjectivity of the portraitist (the writer). Thus one can speak of a fictional portrait (corresponding to the characters who populate the fictional universe of each author) as much as a realist one (representing real-life people).\n\nThe portrait oscillates between reality and fiction, between eulogy and satire, between one portrait which imitates its original and another which moves away from it (such as the caricatures found in newspapers or in Molière). Nevertheless, the objective portrait which describes the flaws and qualities of the individual represented (or equally the object or the idea) is quite widespread. The literary portrait evolved through the centuries and its development has been shaped by writers as well as literary critics and theorists.\n\nIt is from the 1650s that the portrait began to be defined as a literary genre. It is through the social innovations of the \"précieuses\" - such as La Grande Mademoiselle who, influenced by the portrait-laden works of Madeleine de Scudéry, gathered around her (as a \"salonnière\" or ‘salon hostess’) men of letters - that the portrait was transformed into a ‘diversion of society’.\n\nThe literary portrait held to the essential aesthetic rules of the pictorial mode - that is, it had to describe the individual (model) faithfully in order to disguinguish it as a type apart. Nevertheless, it was not to be inferred from the recognition of the individual represented, but rather from the portraitist's style. This narrative representation had the function of highlighting fixed and timeless physical and mental features, as one sees in the works of Molière or in the \"Caractères\" by Jean de La Bruyère. It had to be achieved through layers of successive description - as in painting - which were only distinct phrases describing the real model's features.\n\nThe Age of Enlightenment heralded a new phase in the development of the literary portrait. It invaded literature and even contaminated music. Mozart and Beethoven excelled in this genre. Nevertheless, the portrait carried more of the psychology of the model represented than his or her physical appearance.\n\nIn Denis Diderot, it is precisely the pictorial portrait that is the occasion of a narrative self-portrait effected in the form of an artistic critique of the paintings and statues which were made of him. Thus he did not like the painting by Louis Michel van Loo portraying him:\nThe philosopher blamed the painter's wife for having prevented him from being himself: “It is this madwoman, madame Van Loo, who had come to gossip with him while he was being painted, who gave him that air, and who spoiled everything.” Diderot took to imagining what his portrait would have been like: \n\nAfter criticizing the portrait that portrays him, he writes:\n\nHe informs them, “My children, I tell you that it is not me,” and undertakes to trace in writing the real portrait of himself:\n\nAccording to Diderot, only one painter managed to make a pictorial portrait of him in which he recognizes himself and that is Jean-Baptiste Garand: by an apparent irony of fate, this success was the result of chance: \n\nMoreover, the semi-private sphere of correspondence also allowed the sketching of portraits in principle intended solely for the use of the recipient of the letter. Thus, Marie Du Deffand, taking the thermal waters at Forges-les-Eaux, was able to draw a sharp and cheerful portrait of Madame de Pecquigny, the companion that fate had assigned her during her treatment: \n\nHowever, it is not so much her spirit - or the way she uses it - that irritates Marie Du Deffand as the woman's quirks:\n\nMarie Du Deffand completes this portrait of an eccentric by linking her to her interlocutor: “I am sorry that you have in common with her the impossibility of staying a minute at rest.” After which she concludes, in accordance with the philosophy of resignation and disinterest she defends, the temporary nature of that which she will have to endure on this “holiday meeting”: \nThe evolution of the narrative portrait did not stop at the nineteenth century but, on the contrary, it became more refined and took on nuances through the intervention of Sainte-Beuve in the works or the critiques of such literary portraits.\n\nIn fact, the portrait found a true place in the novel where it represented not only real-life individuals but also fictional individuals (who could also be symbolic). It is in this way that the portrait became a predominant and recurring theme in the work of Balzac.\n\nThe portrait continued its journey throughout the twentieth century with the modern novel. In Nathalie Sarraute (in the Portrait d'un inconnu) the features are not fixed, the temporality plays its role in the genre of the moving portrait, progressive, fragmented, as in the life of a human.\n"}
{"id": "10751250", "url": "https://en.wikipedia.org/wiki?curid=10751250", "title": "Redistribution (cultural anthropology)", "text": "Redistribution (cultural anthropology)\n\nIn cultural anthropology and sociology, redistribution refers to a system of economic exchange involving the centralized collection of goods from members of a group followed by the redivision of those goods among those members. It is a form of reciprocity. Redistribution differs from simple reciprocity, which is a dyadic back-and-forth exchange between two parties. Redistribution, in contrast, consists of pooling, a system of reciprocities. It is a \"within\" group relationship, whereas reciprocity is a \"between\" relationship. Pooling establishes a centre, whereas reciprocity inevitably establishes two distinct parties with their own interests. While the most basic form of pooling is that of food within the family, it is also the basis for sustained community efforts under a political leader.\n\nSahlins argues that generalized reciprocity within families by elders may be a \"starting mechanism\" for more general hierarchy, by placing many in the giver's debt. This leads to the question, \"when does reciprocity give way to redistribution.\" Sahlins argues that chiefly redistribution is not different in principle and nothing but a highly organized form of kinship-rank reciprocity. Others, such as French Marxist anthropologist Claude Meillassoux, used the development of ranked kin redistribution from generalized reciprocity as the basis for a lineage mode of production found in western African chiefdoms and kingdoms.\nAn elaborate example of this in a non-market society is the potlatch, where large amounts of personal resources are ceremonially given away to others in the community according to social status, with the tacit expectation that other members of the community would themselves give away large amounts of their own property in the future.\n\nBähre argued that redistribution is a central mechanism in capitalist economies. In South Africa, many find themselves in a post-Fordist economy that is characterised by redistribution through the state (development aid, welfare), through markets (for example commercial insurance) and through religious institutions (neo-Pentecostal churches).\n\nIn modern mixed market economies, the central form of redistribution is facilitated through taxation by the state. Redistribution of property therefore occurs where properties are allocated back to individuals or groups within society either through the provision of public services or directly through welfare benefits.\n\n"}
{"id": "57976514", "url": "https://en.wikipedia.org/wiki?curid=57976514", "title": "Resignation syndrome", "text": "Resignation syndrome\n\nResignation syndrome (in Swedish \"Uppgivenhetssyndrom\") is a dissociative syndrome that induces a catatonic state. This disorder mainly affects young people who have suffered psychological trauma. Depicted as a culture-bound syndrome, it has chiefly been observed in Sweden among children of asylum seekers from former Soviet and Yugoslav countries. It has also recently been observed in refugee children on Nauru, an Australian immigration detention center.\n"}
{"id": "8625075", "url": "https://en.wikipedia.org/wiki?curid=8625075", "title": "Sanseki", "text": "Sanseki\n\nThe term \"Sanseki\" (三跡) or \"three [brush] traces\" is used in Japanese to refer to a group of three famous Heian period calligraphers:\n\n\n"}
{"id": "35291011", "url": "https://en.wikipedia.org/wiki?curid=35291011", "title": "Semiotics of culture", "text": "Semiotics of culture\n\nSemiotics of culture is a research field within semiotics that attempts to define culture from semiotic perspective and as a type of human symbolic activity, creation of signs and a way of giving meaning to everything around. Therefore, here culture is understood as a system of symbols or meaningful signs. Because the main sign system is the linguistic system, the field is usually referred to as semiotics of culture and language. Under this field of study symbols are analyzed and categorized in certain class within the hierarchal system. With postmodernity, metanarratives are no longer as pervasive and thus categorizing these symbols in this postmodern age is more difficult and rather critical.\n\nThe research field was of particular interest for the Tartu–Moscow Semiotic School (USSR). Linguists and semioticians by the Tartu School viewed culture as a hierarchical semiotic system consisting of set of functions correlated to it, and linguistic codes that are used by social groups to maintain coherence. These codes are viewed as superstructures based on natural language, and here the ability of humans to symbolize is central.\n\nThe study received a research ground also in Japan where the idea that culture and nature should not be contrasted and contradicted but rather harmonized was developed.\n\n"}
{"id": "9343775", "url": "https://en.wikipedia.org/wiki?curid=9343775", "title": "Seven Great Singing Stars", "text": "Seven Great Singing Stars\n\nThe Seven Great Singing Stars () were the seven most renowned singers of China in the 1940s.\n\nSeveral of the stars acted in films, and their music played a prominent role in developing the Cinema of China. They dominated the Chinese pop music industry in the 1930s and 1940s, which was centered in Shanghai, and often performed in a genre known as Shidaiqu (時代曲). Amongst the earliest of the stars to emerge in the 1930s were Zhou Xuan, Gong Qiuxia, Yao Lee, and Bai Hong. In the '40s, Bai Guang, Li Xianglan, and Wu Yingyin also became popular, and these seven were grouped as the seven great singing stars of the period.\n\nShanghai was occupied by the Japanese starting from 1937 to 1945. Li Xianglan, who was Japanese, came to prominence in this period although her Japanese ancestry was not revealed at that time. After the Communist victory in 1949, there began a large migration of people from Shanghai to Hong Kong, and the Communist Party of China also denounced Shanghai popular music as Yellow Music (黃色歌曲), a form of pornography, which effectively ended this period in Shanghai. The film and music industry had already begun to shift to Hong Kong in the '40s, and by the 1950s Hong Kong had become the center of the entertainment industry. While some of the seven continued to perform for many years, Zhou Xuan died in 1957, Li Xianglan retired from entertainment in 1958, and Bai Guang stopped recording in 1959.\n\n"}
{"id": "36100844", "url": "https://en.wikipedia.org/wiki?curid=36100844", "title": "Sixtiers", "text": "Sixtiers\n\nThe Sixtiers (Russian: Шестидесятники) were representatives of а new generation of the Soviet Intelligentsia, most of whom were born between 1925 and 1945, and entered the culture and politics of the USSR during the late 1950s and 1960s — after the Khrushchev Thaw. Their worldviews were formed by years of Stalin's repressions and purges, which affected many of the Sixtiers' immediate families; and World War II, where many of them had volunteered to fight.\n\nSixtiers were distinguished by their liberal and anti-totalitarian views, and romanticism that found vivid expressions in music and visual arts. Although most of the Sixtiers believed in Communist ideals, they had come to be strongly disappointed with Stalin's regime and its repression of basic civil liberties.\n\nMany of the Sixtiers were intellectuals of roughly two strains: the \"physicists\" (those involved in the technical sciences) and the \"lyricists\" (writers, theater and film professionals, and otherwise liberal arts representatives). Bard (singer-songwriter) culture, poetry, disillusionment in politics, and love for camping trips to the farther regions of the Soviet Union were some of the common attributes and pastimes of the Sixtiers.\n\nThe Sixtiers had some parallels to the New Left and hippie movements in the West but had more in common with the more intellectual-oriented Beat Generation.\n\n\n"}
{"id": "2744606", "url": "https://en.wikipedia.org/wiki?curid=2744606", "title": "Social criticism", "text": "Social criticism\n\nThe term social criticism often refers to a mode of criticism that locates the reasons for malicious conditions in a society considered to be in a flawed social structure. It may also refer to people adhering to a social critic's aims at practical solutions by way of specific measures either for consensual reform or powerful revolution.\n\nReligious persecution was common in Europe and was the reason for many physical and mental exoduses within the continent. Through such experiences, one of the first documents of social criticism was born: the \"Testament\" of Jean Meslier.\n\nRepression experienced by a minority often leads to protest. Without sufficient resolution of the dispute, a social criticism can be formulated, often covered by political groups (political monopoly). For protesting people \"within\" a social movement, it is often frustrating to experience failure of the movement and its own agenda.\n\nThe positivism dispute between critical rationalism, e.g. between Karl Popper and the Frankfurt School, is the academic form of the same discrepancy. This dispute deals with the question of whether research in the social sciences should be \"neutral\" or consciously adopt a partisan view.\n\nAcademic works of social criticism can belong to social philosophy, political economy, sociology, social psychology, psychoanalysis but also cultural studies and other disciplines or reject academic forms of discourse.\n\nSocial criticism can also be expressed in a fictional form, e.g. in a revolutionary novel like \"The Iron Heel\" by Jack London or in dystopian novels like Aldous Huxley's \"Brave New World\" (1932) or George Orwell's \"Nineteen Eighty-Four\" (1949) or Ray Bradbury's \"Fahrenheit 451\" (1953), or Rafael Grugman's \"Nontraditional Love\" (2008), children's books or films.\n\nFictional literature can have a significant social impact. For example, the 1852 novel \"Uncle Tom's Cabin\", by Harriet Beecher Stowe furthered the anti-slavery movement in the United States, and the 1885 novel \"Ramona\", by Helen Hunt Jackson, brought about changes in laws regarding Native Americans. Similarly, Upton Sinclair's 1906 novel \"The Jungle\" helped create new laws related to public health and food handling, and Arthur Morrison's 1896 novel \"A Child of the Jago\" caused England to change its housing laws. George Orwell and Charles Dickens wrote \"Animal Farm\" and \"A Tale of Two Cities\", respectively, to express their disillusionment with society and human nature. \"Animal Farm\", written in 1944, is a book that tells the animal fable of a farm in which the farm animals revolt against their human masters. It is an example of social criticism in literature in which Orwell satirized the events in Russia after the Bolshevik Revolution. He anthropomorphises the animals, and alludes each one to a counterpart in Russian history. \"A Tale of Two Cities\" also typifies this kind of literature. Besides the central theme of love, is another prevalent theme, that of a revolution gone bad. He shows us that, unfortunately, human nature causes us to be vengeful and, for some of us, overly ambitious. Both these books are similar in that both describe how, even with the best of intentions, our ambitions get the best of us. Both authors also demonstrate that violence and the Machiavellian attitude of \"the ends justifying the means\" are deplorable. They also express their authors' disenchantment with the state of evolution of human nature.\n\nAccording to Frederick Douglass, \"Where justice is denied, where poverty is enforced, where ignorance prevails, and where any one class is made to feel that society is an organized conspiracy to oppress, rob and degrade them, neither persons nor property will be safe.\"\n\nThe authors imply, that even if we begin with honourable intentions, there will be some who will let their basic instincts take control. \"Animal Farm\" portrays this nature through parodying events in real history. Given the right conditions, these events could happen anywhere. Take for example, a leader becoming overly ambitious, to the point of harming his people for more power.\n\nIn \"A Tale of Two Cities\", Dickens examines the inner soul, and shares with us how people are driven to the valley of human emotions, where desperation and anger reign, and what could happen afterwards if we let these emotions build up inside. Every human being is capable of becoming a ruthless, opportunistic being like Napoleon or Madame Defarge, if placed in the right place, at the right time.\n\nSocial criticism is certainly present in opera (The Cradle Will Rock, Trouble in Tahiti) and other types of classical music, such as the Symphony No.13, called \"Babi Yar\", of Dmitri Shostakovich. Other musical expressions of social criticism are frequent in punk and rap music, examples being \"Pretty Vacant\" by Sex Pistols and \"Brenda's Got a Baby\" by 2Pac. Heavy metal bands such as Black Sabbath, Metallica and Megadeth also use social criticism extensively, particularly in their earlier works.\n"}
{"id": "37235", "url": "https://en.wikipedia.org/wiki?curid=37235", "title": "Society", "text": "Society\n\nA society is a group of individuals involved in persistent social interaction, or a large social group sharing the same geographical or social territory, typically subject to the same political authority and dominant cultural expectations. Societies are characterized by patterns of relationships (social relations) between individuals who share a distinctive culture and institutions; a given society may be described as the sum total of such relationships among its constituent of members. In the social sciences, a larger society often exhibits stratification or dominance patterns in subgroups.\n\nInsofar as it is collaborative, a society can enable its members to benefit in ways that would not otherwise be possible on an individual basis; both individual and social (common) benefits can thus be distinguished, or in many cases found to overlap. A society can also consist of like-minded people governed by their own norms and values within a dominant, larger society. This is sometimes referred to as a subculture, a term used extensively within criminology.\n\nMore broadly, and especially within structuralist thought, a society may be illustrated as an economic, social, industrial or cultural infrastructure, made up of, yet distinct from, a varied collection of individuals. In this regard society can mean the objective relationships people have with the material world and with other people, rather than \"other people\" beyond the individual and their familiar social environment.\n\nThe term \"society\" came from the Latin word \"\", which in turn was derived from the noun \"socius\" (\"comrade, friend, ally\"; adjectival form \"socialis\") used to describe a bond or interaction between parties that are friendly, or at least civil. Without an article, the term can refer to the entirety of humanity (also: \"society in general\", \"society at large\", etc.), although those who are unfriendly or uncivil to the remainder of society in this sense may be deemed to be \"antisocial\". However, the Scottish economist, Adam Smith taught instead that a society \"may subsist among different men, as among different merchants, from a sense of its utility without any mutual love or affection, if only they refrain from doing injury to each other.\"\n\nUsed in the sense of an association, a society is a body of individuals outlined by the bounds of functional interdependence, possibly comprising characteristics such as national or cultural identity, social solidarity, language, or hierarchical structure.\n\nSociety, in general, addresses the fact that an individual has rather limited means as an autonomous unit. The great apes have always been more (\"Bonobo\", \"Homo\", \"Pan\") or less (\"Gorilla\", \"Pongo\") social animals, so Robinson Crusoe-like situations are either fictions or unusual corner cases to the ubiquity of social context for humans, who fall between presocial and eusocial in the spectrum of animal ethology.\n\nCultural relativism as a widespread approach or ethic has largely replaced notions of \"primitive\", better/worse, or \"progress\" in relation to cultures (including their material culture/technology and social organization).\n\nAccording to anthropologist Maurice Godelier, one critical novelty in society, in contrast to humanity's closest biological relatives (chimpanzees and bonobos), is the parental role assumed by the males, which supposedly would be absent in our nearest relatives for whom paternity is not generally determinable.\n\nSocieties may also be structured politically. In order of increasing size and complexity, there are bands, tribes, chiefdoms, and state societies. These structures may have varying degrees of political power, depending on the cultural, geographical, and historical environments that these societies must contend with. Thus, a more isolated society with the same level of technology and culture as other societies is more likely to survive than one in closer proximity to others that may encroach on their resources. A society that is unable to offer an effective response to other societies it competes with will usually be subsumed into the culture of the competing society.\n\nSociologist Peter L. Berger defines society as \"...a human product, and nothing but a human product, that yet continuously acts upon its producers.\" According to him, society was created by humans but this creation turns back and creates or molds humans every day. \n\nSociologist Gerhard Lenski differentiates societies based on their level of technology, communication, and economy: (1) hunters and gatherers, (2) simple agricultural, (3) advanced agricultural, (4) industrial, and (5) special (e.g. fishing societies or maritime societies). This is similar to the system earlier developed by anthropologists Morton H. Fried, a conflict theorist, and Elman Service, an integration theorist, who have produced a system of classification for societies in all human cultures based on the evolution of social inequality and the role of the state. This system of classification contains four categories:\n\nIn addition to this there are:\n\nOver time, some cultures have progressed toward more complex forms of organization and control. This cultural evolution has a profound effect on patterns of community. Hunter-gatherer tribes settled around seasonal food stocks to become agrarian villages. Villages grew to become towns and cities. Cities turned into city-states and nation-states.\n\nMany societies distribute largess at the behest of some individual or some larger group of people. This type of generosity can be seen in all known cultures; typically, prestige accrues to the generous individual or group. Conversely, members of a society may also shun or scapegoat members of the society who violate its norms. Mechanisms such as gift-giving, joking relationships and scapegoating, which may be seen in various types of human groupings, tend to be institutionalized within a society. Social evolution as a phenomenon carries with it certain elements that could be detrimental to the population it serves.\n\nSome societies bestow status on an individual or group of people when that individual or group performs an admired or desired action. This type of recognition is bestowed in the form of a name, title, manner of dress, or monetary reward. In many societies, adult male or female status is subject to a ritual or process of this type. Altruistic action in the interests of the larger group is seen in virtually all societies. The phenomena of community action, shunning, scapegoating, generosity, shared risk, and reward are common to many forms of society.\n\nSocieties are social groups that differ according to subsistence strategies, the ways that humans use technology to provide needs for themselves. Although humans have established many types of societies throughout history, anthropologists tend to classify different societies according to the degree to which different groups within a society have unequal access to advantages such as resources, prestige, or power. Virtually all societies have developed some degree of inequality among their people through the process of social stratification, the division of members of a society into levels with unequal wealth, prestige, or power. Sociologists place societies in three broad categories: pre-industrial, industrial, and postindustrial.\n\nIn a pre-industrial society, food production, which is carried out through the use of human and animal labor, is the main economic activity. These societies can be subdivided according to their level of technology and their method of producing food. These subdivisions are hunting and gathering, pastoral, horticultural, agricultural, and feudal.\n\nThe main form of food production in such societies is the daily collection of wild plants and the hunting of wild animals. Hunter-gatherers move around constantly in search of food. As a result, they do not build permanent villages or create a wide variety of artifacts, and usually only form small groups such as bands and tribes. However, some hunting and gathering societies in areas with abundant resources (such as people of tlingit) lived in larger groups and formed complex hierarchical social structures such as chiefdom. The need for mobility also limits the size of these societies. They generally consist of fewer than 60 people and rarely exceed 100. Statuses within the tribe are relatively equal, and decisions are reached through general agreement. The ties that bind the tribe are more complex than those of the bands. Leadership is personal—charismatic—and used for special purposes only in tribal society. There are no political offices containing real power, and a chief is merely a person of influence, a sort of adviser; therefore, tribal consolidations for collective action are not governmental. The family forms the main social unit, with most members being related by birth or marriage. This type of organization requires the family to carry out most social functions, including production and education.\n\nPastoralism is a slightly more efficient form of subsistence. Rather than searching for food on a daily basis, members of a pastoral society rely on domesticated herd animals to meet their food needs. Pastoralists live a nomadic life, moving their herds from one pasture to another. Because their food supply is far more reliable, pastoral societies can support larger populations. Since there are food surpluses, fewer people are needed to produce food. As a result, the division of labor (the specialization by individuals or groups in the performance of specific economic activities) becomes more complex. For example, some people become craftworkers, producing tools, weapons, and jewelry. The production of goods encourages trade. This trade helps to create inequality, as some families acquire more goods than others do. These families often gain power through their increased wealth. The passing on of property from one generation to another helps to centralize wealth and power. Over time emerge hereditary chieftainships, the typical form of government in pastoral societies.\n\nFruits and vegetables grown in garden plots that have been cleared from the jungle or forest provide the main source of food in a horticultural society. These societies have a level of technology and complexity similar to pastoral societies. Some horticultural groups use the slash-and-burn method to raise crops. The wild vegetation is cut and burned, and ashes are used as fertilizers. Horticulturists use human labor and simple tools to cultivate the land for one or more seasons. When the land becomes barren, horticulturists clear a new plot and leave the old plot to revert to its natural state. They may return to the original land several years later and begin the process again. By rotating their garden plots, horticulturists can stay in one area for a fairly long period of time. This allows them to build semipermanent or permanent villages. The size of a village's population depends on the amount of land available for farming; thus villages can range from as few as 30 people to as many as 2000.\n\nAs with pastoral societies, surplus food leads to a more complex division of labor. Specialized roles in horticultural societies include craftspeople, shamans (religious leaders), and traders. This role specialization allows people to create a wide variety of artifacts. As in pastoral societies, surplus food can lead to inequalities in wealth and power within horticultural political systems, developed because of the settled nature of horticultural life.\n\nAgrarian societies use agricultural technological advances to cultivate crops over a large area. Sociologists use the phrase agricultural revolution to refer to the technological changes that occurred as long as 8,500 years ago that led to cultivating crops and raising farm animals. Increases in food supplies then led to larger populations than in earlier communities. This meant a greater surplus, which resulted in towns that became centers of trade supporting various rulers, educators, craftspeople, merchants, and religious leaders who did not have to worry about locating nourishment.\n\nGreater degrees of social stratification appeared in agrarian societies. For example, women previously had higher social status because they shared labor more equally with men. In hunting and gathering societies, women even gathered more food than men. However, as food stores improved and women took on lesser roles in providing food for the family, they increasingly became subordinate to men. As villages and towns expanded into neighboring areas, conflicts with other communities inevitably occurred. Farmers provided warriors with food in exchange for protection against invasion by enemies. A system of rulers with high social status also appeared. This nobility organized warriors to protect the society from invasion. In this way, the nobility managed to extract goods from “lesser” members of society.\n\nFeudalism was a form of society based on ownership of land. Unlike today's farmers, vassals under feudalism were bound to cultivating their lord's land. In exchange for military protection, the lords exploited the peasants into providing food, crops, crafts, homage, and other services to the landowner. The estates of the realm system of feudalism was often multigenerational; the families of peasants may have cultivated their lord's land for generations.\n\nBetween the 15th and 16th centuries, a new economic system emerged that began to replace feudalism. Capitalism is marked by open competition in a free market, in which the means of production are privately owned. Europe's exploration of the Americas served as one impetus for the development of capitalism. The introduction of foreign metals, silks, and spices stimulated great commercial activity in European societies.\n\nIndustrial societies rely heavily on machines powered by fuels for the production of goods. This produced further dramatic increases in efficiency. The increased efficiency of production of the industrial revolution produced an even greater surplus than before. Now the surplus was not just agricultural goods, but also manufactured goods. This larger surplus caused all of the changes discussed earlier in the domestication revolution to become even more pronounced.\n\nOnce again, the population boomed. Increased productivity made more goods available to everyone. However, inequality became even greater than before. The breakup of agricultural-based feudal societies caused many people to leave the land and seek employment in cities. This created a great surplus of labor and gave capitalists plenty of laborers who could be hired for extremely low wages.\n\nPost-industrial societies are societies dominated by information, services, and high technology more than the production of goods. Advanced industrial societies are now seeing a shift toward an increase in service sectors over manufacturing and production. The United States is the first country to have over half of its work force employed in service industries. Service industries include government, research, education, health, sales, law, and banking.\n\nThe term \"society\" is currently used to cover both a number of political and scientific connotations as well as a variety of associations.\n\nThe development of the Western world has brought with it the emerging concepts of Western culture, politics, and ideas, often referred to simply as \"Western society\". Geographically, it covers at the very least the countries of Western Europe, North America, Australia, and New Zealand. It sometimes also includes Eastern Europe, South America, and Israel.\n\nThe cultures and lifestyles of all of these stem from Western Europe. They all enjoy relatively strong economies and stable governments, allow freedom of religion, have chosen democracy as a form of governance, favor capitalism and international trade, are heavily influenced by Judeo-Christian values, and have some form of political and military alliance or cooperation.\n\nAlthough the concept of information society has been under discussion since the 1930s, in the modern world it is almost always applied to the manner in which information technologies have impacted society and culture. It therefore covers the effects of computers and telecommunications on the home, the workplace, schools, government, and various communities and organizations, as well as the emergence of new social forms in cyberspace.\n\nOne of the European Union's areas of interest is the information society. Here policies are directed towards promoting an open and competitive digital economy, research into information and communication technologies, as well as their application to improve social inclusion, public services, and quality of life.\n\nThe International Telecommunications Union's World Summit on the Information Society in Geneva and Tunis (2003 and 2005) has led to a number of policy and application areas where action is envisaged.\n\nAs access to electronic information resources increased at the beginning of the 21st century, special attention was extended from the information society to the knowledge society. An analysis by the Irish government stated, \"The capacity to manipulate, store and transmit large quantities of information cheaply has increased at a staggering rate over recent years. The digitisation of information and the associated pervasiveness of the Internet are facilitating a new intensity in the application of knowledge to economic activity, to the extent that it has become the predominant factor in the creation of wealth. As much as 70 to 80 percent of economic growth is now said to be due to new and better knowledge.\"\n\nThe Second World Summit on the Knowledge Society, held in Chania, Crete, in September 2009, gave special attention to the following topics:\n\nPeople of many nations united by common political and cultural traditions, beliefs, or values are sometimes also said to form a society (such as Judeo-Christian, Eastern, and Western). When used in this context, the term is employed as a means of contrasting two or more \"societies\" whose members represent alternative conflicting and competing worldviews.\n\nSome academic, professional, and scientific associations describe themselves as \"societies\" (for example, the American Mathematical Society, the American Society of Civil Engineers, or the Royal Society).\n\nIn some countries, e.g. the United States, France, and Latin America, the term \"society' is used in commerce to denote a partnership between investors or the start of a business. In the United Kingdom, partnerships are not called societies, but co-operatives or mutuals are often known as societies (such as friendly societies and building societies).\n\n\n"}
{"id": "379153", "url": "https://en.wikipedia.org/wiki?curid=379153", "title": "Subplot", "text": "Subplot\n\nIn fiction, a subplot is a secondary strand of the plot that is a supporting side story for any story or the main plot. Subplots may connect to main plots, in either time and place or in thematic significance. Subplots often involve supporting characters, those besides the protagonist or antagonist. Subplots may also intertwine with the main plot at some point in a story.\n\nSubplots are distinguished from the main plot by taking up less of the action, having fewer significant events occur, with less impact on the \"world\" of the work, and occurring to less important characters. \n\nIn screenwriting, a subplot is referred to as a \"B story\" or a \"C story,\" etc.\n"}
{"id": "18945331", "url": "https://en.wikipedia.org/wiki?curid=18945331", "title": "Three-act structure", "text": "Three-act structure\n\nThe three-act structure is a model used in narrative fiction that divides a story into three parts (acts), often called the Setup, the Confrontation and the Resolution.\n\nThe first act is usually used for exposition, to establish the main characters, their relationships and the world they live in. Later in the first act, a dynamic, on-screen incident occurs, known as the \"inciting incident\", or \"catalyst\", that confronts the main character (the protagonist), and whose attempts to deal with this incident lead to a second and more dramatic situation, known as the first plot point, which (a) signals the end of the first act, (b) ensures life will never be the same again for the protagonist and (c) raises a dramatic question that will be answered in the climax of the film. The dramatic question should be framed in terms of the protagonist's call to action, (Will X recover the diamond? Will Y get the girl? Will Z capture the killer?).\n\nThe second act, also referred to as \"rising action\", typically depicts the protagonist's attempt to resolve the problem initiated by the first turning point, only to find themselves in ever worsening situations. Part of the reason protagonists seem unable to resolve their problems is because they do not yet have the skills to deal with the forces of antagonism that confront them. They must not only learn new skills but arrive at a higher sense of awareness of who they are and what they are capable of, in order to deal with their predicament, which in turn changes who they are. This is referred to as \"character development\" or a \"character arc\". This cannot be achieved alone and they are usually aided and abetted by mentors and co-protagonists.\n\nThe third act features the resolution of the story and its subplots. The climax is the scene or sequence in which the main tensions of the story are brought to their most intense point and the dramatic question answered, leaving the protagonist and other characters with a new sense of who they really are.\n\n\n"}
{"id": "59096005", "url": "https://en.wikipedia.org/wiki?curid=59096005", "title": "Transformative arts", "text": "Transformative arts\n\nTransformative arts is the use of artistic activities, such as story-telling, painting, and music-making, to precipitate constructive individual and social change.\n\nThe individual changes effected through transformative arts are commonly cognitive and emotional. This results from the way participation in a creative process and pursuit of an artistic practice can promote a critical re-evaluation of previously held beliefs, accompanied by unfamiliar feelings, which alters perception of the world, oneself, and others.\n\nThe social changes effected through transformative arts occurs when this altered perception manifests in new ways of interacting with others.\n\nAlthough engagement in artistic activities has been integral to the means by which individuals and communities have sought personal comfort, self-reflection, and group cohesion for thousands of years, the origin of transformative arts as a modern formal concept is commonly attributed to the work of John Dewey.\n\nDewey espoused four main ideas around which transformative arts pivot. Firstly, art is not an object but an experience, in which one or more persons participate. Secondly, every individual is potentially an artist by way of his or her capacity to participate in this experience, through any artistic activity. Thirdly, such participation inevitably precipitates some kind of transformative change to how the participants think, feel, and behave. Fourthly, art is therefore both psychological and social, transforming not only individual intrapersonal processes, but also interpersonal relationships.\n\nAccordingly, transformative arts are facilitated by artists with the psychological purpose of promoting individual introspection, and with the social purpose of promoting inclusion, reciprocity, and justice.\n\n"}
{"id": "286347", "url": "https://en.wikipedia.org/wiki?curid=286347", "title": "Turkology", "text": "Turkology\n\nTurkology (or Turcology) is a complex of humanities sciences studying languages, history, literature, folklore, culture, and ethnology of people speaking Turkic languages and Turkic peoples in chronological and comparative context. This includes ethnic groups from the Sakha in East Siberia to the Balkan Turks and Gagauz in Moldova.\n\nEthnological information on Turkic tribes for the first time was systemized by the 11th-century Turkic philologist Mahmud al-Kashgari in the \"Dīwān ul-Lughat it-Turk\" (Dictionary of Turkic language). Multi-lingual dictionaries were compiled from the late 13th century for the practical application of participants in international trade and political life: Kipchak (Cuman)-Persian-Latin-German \"Codex Cumanicus\", \"Armenian-Kipchak\", and \"Russian-Kipchak\" dictionaries. By the Middle Ages the Turkology was centred around Byzantine/Greek historians, ambassadors and travelers, and geographers. In the 15th-17th centuries the main subject of Turkology was the study of the Ottoman Empire and the Turkish language, and the Turkic languages of Eastern Europe and Western Asia. In 1533 a first hand-written primer appeared, and by 1612 a printed grammar by Jerome Megizer was published, followed by F. Mesgnien-Meninski's 4-volume \"Thesaurus Linguarum Orientalium\" published in 1680.\n\nP. S. Pallas initiated a more scientific approach to Turkology with his \"Comparative dictionaries of all languages and dialects\" (1787) which included lexical materials from Tatar, Mishar, Nogai, Bashkir, and other Türkic languages. In the 19th century, Turkology was further developed by M. A. Kazembek's \"Grammar of the Turkish-Tatar language\" (1839), O. N. Betlingk \"Grammar of the Yakut language\" (1851). A major achievement was the deciphering at the end of the 19th century of the Early Middle Age Orkhon inscriptions by V. Thomsen and W. W. Radloff (1895). By the end of the 19th century, Turkology developed into a complex discipline that included linguistics, history, ethnology, archeology, arts and literature. In the 20th century the Turkology complex included physical anthropology, numismatics, genetics, ancient Turkic alphabetic scripts, typology, genesis, and etymology, onomastics and toponymy. The appearance of \"Türkische Bibliothek\" (1905–27) inaugurated specialised periodicals, followed by \"Mitteilungen zur Osmanischen Geschichte\" (1921–26). Scientific developments allowed calibrated dating, dendrochronology, metallurgy, chemistry, textile, and other specialized disciplines which contributed to the development of the Turkological studies. Deeper study of the ancient sources allowed better understanding of economical, social, mythological and cultural forces of the sedentary and nomadic societies. Linguistic studies uncovered pre-literate symbioses and mutual influences between different peoples.\n\nOn 9 August 1944 the Central Committee VKP(b), the ruling party of the USSR, published an edict prohibiting \"ancientization\" of Turkic history. The edict was followed by a consecutive wave of mass arrests, imprisoning and killing of the intelligentsia, massive creation of replacement \"scientists\", and re-writing of history pages on an industrial scale. Combined with the concurrent wholesale deportation of indigenous populations to remote areas in Middle Asia and Siberia, the wipe-out of the science was nearly complete, and the impact of the action subsided only partially in the newly independent countries after the collapse of the USSR. In the two decades after the Bolshevik's assuming power, the tradition of Turkological studies in Russia and dependent countries was practically wiped out.\n\nOn the other hand, this edict brought unintended benefits to Turkology. One was the nearly immediate linguistic development of an alternate lexicon which replaced the nouns and adjectives containing the word \"Türk\" by a wealth of euphemisms: \"nomads, Siberians, Paleosiberians, Middle Asians, Scythians, Altaians, Tuvians\", etc. that filled scientific publications. The other was \"writing into a drawer\", when results of the years of fruitful work were written down for future publication. When the bonds relaxed, the publications exploded. Another was a flight of scientists from European Russia into remote areas, which brought first class scientists to many intellectually starved outlying areas of Middle Asia. Another one was connected with the statewide efforts to re-invent the history, when a wealth of Turkological facts were found in the process of search for \"correct\" history. And another one was a built-up of the public interest for the forbidden subjects, that resulted that no print size could satisfy the demand. L.N.Gumilev and O.Suleimenov inflamed a surge in the new generation of Turkology scholars.\n\nWith the physical culling of the scholars from the society, concurrently was also organized a total extermination of all their published and unpublished works, their books were removed from the libraries and destroyed from private collections by intimidated population, articles and publications were culled, published photographs were retouched, private photographs were destroyed, published scientific references were erased, or publications with undesired references were destroyed. Very few of the early 20th century expedition diaries, ethnographical notes, reports and drafts for publications were ever recovered.\n\n\n\nA selection of English-language periodicals studying Turkology\n\n\n"}
{"id": "30695401", "url": "https://en.wikipedia.org/wiki?curid=30695401", "title": "Variantology", "text": "Variantology\n\nVariantology has been conceived as an international research project with the aim of developing a critical appraisal of the established concepts of “media”. The concept of a medium is thus opened up to approaches and disciplines that up to now have remained outside the contemporary discourse on media, such as theology, various musicology, aspects of natural sciences, fine arts or classical philology. Furthermore, it is opened up to cultures of knowledge that have long been excluded from the western discourse, like the oriental and Arabic-Islamic culture. Variantology also attempts to explore how reciprocally these disciplines then become open to thinking in categories and terms of media and communication. Consequently, the network of research that constitutes the Variantology project involves scholars based in academic institutions as well as artists, musicians and authors.\n\nTo come to a different understanding of media, a central part of research is the development of a network of scientists, artists and scholars who are engaged with the \"deep time relations“ between arts, sciences, and technologies. The term \"deep time relations“ refers to the notion of being a plurality of traversals through the genealogy of what we call media today. The underlying theoretical center is Michel Foucault’s concept of genealogy, which he developed from Friedrich Nietzsche’s thinking about morality as a historical- and social-generated construction. Foucault's approach in this connection was to comprehend history as a constitution of knowledge, of discourses, of objectification and so on, detached from an idea of historical subjects and previously unquestioned categories of western (Eurocentric) culture and power.\n\nAn integral part of the project is the annual international workshop. The first three Variantology workshops were held at Academy of Media Arts Cologne, the fourth one at UdK in Berlin, and the 5th at Biblioteca Nazionale Vittorio Emanuele III in Naples, Italy.\n"}
{"id": "31642536", "url": "https://en.wikipedia.org/wiki?curid=31642536", "title": "Vitaly Lazarenko", "text": "Vitaly Lazarenko\n\nVitaly Lazarenko (1890–1939) was a Russian/Soviet acrobat know best for his acrobatic skills and use of political satire during events.\n\nHe performed in the clown duo Bim Bom.\n"}
{"id": "50186794", "url": "https://en.wikipedia.org/wiki?curid=50186794", "title": "White Privilege Conference", "text": "White Privilege Conference\n\nThe White Privilege Conference is a yearly conference held to discuss the issue of white privilege.\n\nThe conference features several workshops and groups for students and adults about racism, race, perceived white privilege, sexism, black oppression, racial injustice, as well as discussions of lesbian, gay and transgender rights, as well as Islam and Islamophobia.\n\nThe White Privilege Conference was founded in 2000 by Eddie Moore Jr., a former diversity director at Brooklyn Friends. \n\nAs of 2016, many New York private schools had students and faculty attending the conference.\n\nAt the 2016 White Privilege Conference attendees complained that the conference was \"too white\". Inspired by the 2015 Twitter #OscarsSoWhite campaign, Twitter users adopted the hashtag #WPCSoWhite and claimed the conference that was supposed to fight white privilege instead entrenched it.\n\nThe Twitter tag appeared to have been started by Aeriel Ashlee, an Asian American education consultant who attended the 2016 conference and objected to many sections of a keynote address delivered by white historian James W. Loewen, including his use of the N-word.\n\nThe conference has been criticized by some in the media as nothing more than white guilt.\n\n"}
{"id": "10507902", "url": "https://en.wikipedia.org/wiki?curid=10507902", "title": "Yaylak", "text": "Yaylak\n\nYaylag () is a Turkic term, meaning summer highland pasture (from \"yay\", meaning summer, and \"-lagh\" or \"-lağ\", a deverbal plus denominal suffix in Turkic languages). The converse term is gishlag (also spelled as \"kışlak\" or \"qhishloq\"), a winter pasture (from \"kış\", \"qish\" or \"gish\", a Turkic word for winter). The latter one gave rise to the term \"kishlak\" for rural settlements in Central Asia. Transcriptions of the term include yaylak (), yaylaq (), یایلاق (), ailoq, jaylaw (), or jayloo (), and yeilâq (Persian).\n\nAn authority on the subject of nomadism, Anatoly Khazanov, notes: \"The specific significance of pastoralism is usually at its most apparent in the specialized mountain variant of herdsman husbandry; in Soviet anthropology this is often referred to as \"yaylag pastoralism\"...\" In Western anthropology \"yaylag\" pastoralism more or less corresponds to the notion of \"transhumance\" (\"Transhumanz\")\n\nAccording to Karl H. Menges, who studied and witnessed the nomadic lifestyle of the Turkic Qashqai tribe in Iran, \"[t]ribes in their summer encampments (jajłaγ), and not on the move (köç). They live, during the months May-August, in the region as designated above, and begin to move southward to the winter encampments (qyšłaγ) about the end of August.\"\n\nThere are different variants of \"yaylag pastoralism\", some of which are similar to semi-nomadic pastoralism, although most are similar to herdsman husbandry (such as in mountainous areas of Europe and the Caucasus). However, in the Eurasian steppes, the Middle East and North Africa \"yaylag\" pastoralism often co-exists with semi-nomadic pastoralism and pastoral nomadism.\n\nIn the description of another Western specialist on nomads and pastoralism, Khazanov's classification system is the most modern approach, \"classifying nomadic forms according to a society’s extent of migratory mobility, the primacy of specific animals in producing their subsistence products, and the level of symbiosis between nomadic and settled agricultural societies. He categorizes pastoralists into five types, ranging from “pure pastoral nomadism” to “semi-nomadic pastoralism,” “semi-sedentary pastoralism,” and finally to “distant-pastures husbandry” and “seasonal transhumance” (Khazanov’s yaylag – Khazanov 1994, 19-23)\".\n\n\"Yaylag pastoralism\" enables people occupied with agriculture in specific ecological zones to use other areas as seasonal pastures when they are at their most productive. During one part of the year the livestock is kept in mountain pastures and during the other parts is driven to lower zones.\n\nAnother explanation of yaylag's importance and position in today's agriculture is given by recent research: \"Because it is semiarid, large parts of the Middle East traditionally have been given over to a mode of livelihood that combines the extensive cultivation of crops such as wheat and barley with sheep and goat herding. Herds are usually moved in fixed patterns between adjacent ecological zones in the course of a year and graze on the stubble of cultivated fields after harvest. Such movement is called \"transhumant pastoralism\" or seminomadism, and it differs from the movement of nomadic groups who follow their herds (pastoral nomadism). Seminomadic pastoralists and pastoral nomads form a significant but declining minority in such countries as Saudi Arabia (probably less than 3 percent), Iran (4 percent), and Afghanistan (no more than 10 percent). They comprise less than 2 percent of the population in the countries of North Africa, with the exception of Libya and Mauritania.\" \n\nVariation in mobile pastoral systems is commonly linked to both the ecology of herding and socio-political negotiations. These factors can contribute to significant changes in the way pastoralists manage territory and lay claim on locations in their landscape (e.g., pastures and campgrounds). In light of the environmental variability in pasture quality from year to year, however, ownership and control of particular locations and resources such as summer and winter pastures (\"ailoq\" and \"qhishloq\") and seasonal cisterns (\"yekhdon\") brought about various forms of social interactions, such as trading of resources, political alliances, and land rental, to meet the needs of domesticated herds.\n\nAnother source provides additional background on yaylag pastoralism in Iran and Caucasus: \"The seminomads live in a valley or on a plain in winter and in the highlands during the summer. Their \"seasonal home\" can mark the beginning of their transition from seminomadic pastoralism to a settled village life. Another example of this way of life from another part of the Northern Tier is the Bakhtiari tribes of Iran. All along the Zagros mountain range from Azerbaijan to the Arabian Sea, pastoral tribes move back and forth with their herds every year between their home in the valley and the one in the foothills.\"\n\nA number of scholars have suggested that \"yaylag pastoralism\" has ancient roots in Neolithic Western Asia, alleging that already in the seventh millennium B.C. the pastoralism of the inhabitants of the Zagros Mountains had taken on a \"yaylag\" form, and that besides their permanent settlements these people also had seasonal camps in the mountains. Flannery, 1965: 1254-5, Narr, 1959: 85, Masson 1976: 39. Although, \"recent research has demonstrated, however, that \"yaylag pastoralism\" in the Zagros Mountains can be dated no earlier than the second half of the fourth millennium B.C. (Mortensen, 1975: 23f., 32-3). However, as yet there is insufficient data for this question to be finally resolved.\"\n"}
