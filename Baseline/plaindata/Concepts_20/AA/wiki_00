{"id": "509995", "url": "https://en.wikipedia.org/wiki?curid=509995", "title": "Abstract and concrete", "text": "Abstract and concrete\n\nAbstract and concrete are classifications that denote whether the object that a term describes has physical referents. Abstract objects have no physical referents, whereas concrete objects do. They are most commonly used in philosophy and semantics. Abstract objects are sometimes called abstracta (sing. abstractum) and concrete objects are sometimes called \"concreta\" (sing. \"concretum\"). An abstract object is an object that does not exist at any particular time or place, but rather exists as a type of thing—i.e., an idea, or abstraction. The term \"abstract object\" is said to have been coined by Willard Van Orman Quine. The study of abstract objects is called abstract object theory.\n\nThe type–token distinction identifies physical objects that are tokens of a particular type of thing. The \"type\" of which it is a part is in itself an abstract object. The abstract-concrete distinction is often introduced and initially understood in terms of paradigmatic examples of objects of each kind:\n\nAbstract objects have often garnered the interest of philosophers because they raise problems for popular theories. In ontology, abstract objects are considered problematic for physicalism and some forms of naturalism. Historically, the most important ontological dispute about abstract objects has been the problem of universals. In epistemology, abstract objects are considered problematic for empiricism. If abstracta lack causal powers or spatial location, how do we know about them? It is hard to say how they can affect our sensory experiences, and yet we seem to agree on a wide range of claims about them. \n\nSome, such as Edward Zalta and arguably, Plato in his Theory of Forms, have held that abstract objects constitute the defining subject matter of metaphysics or philosophical inquiry more broadly. To the extent that philosophy is independent of empirical research, and to the extent that empirical questions do not inform questions about abstracta, philosophy would seem especially suited to answering these latter questions. \n\nIn modern philosophy, the distinction between abstract and concrete was explored by Immanuel Kant and G. W. F. Hegel.\n\nGottlob Frege said that abstract objects, such as numbers, were members of a third realm, different from the external world or from internal consciousness. \n\nAnother popular proposal for drawing the abstract-concrete distinction contends that an object is abstract if it lacks any causal powers. A causal power has the ability to affect something causally. Thus, the empty set is abstract because it cannot act on other objects. One problem for this view is that it is not clear exactly what it is to have a causal power. For a more detailed exploration of the abstract-concrete distinction, follow the link below to the \"Stanford Encyclopedia\" article.\n\nJean Piaget uses the terms \"concrete\" and \"formal\" to describe the different types of learning. Concrete thinking involves facts and descriptions about everyday, tangible objects, while abstract (formal operational) thinking involves a mental process.\nRecently, there has been some philosophical interest in the development of a third category of objects known as the quasi-abstract. Quasi-abstract objects have drawn particular attention in the area of social ontology and documentality. Some argue that the over-adherence to the platonist duality of the concrete and the abstract has led to a large category of social objects having been overlooked or rejected as nonexisting because they exhibit characteristics that the traditional duality between concrete and abstract regards as incompatible. Specially, the ability to have temporal location, but not spatial location, and have causal agency (if only by acting through representatives). These characteristics are exhibited by a number of social objects, including states of the international legal system.\n\n"}
{"id": "55063170", "url": "https://en.wikipedia.org/wiki?curid=55063170", "title": "Afro-pessimism", "text": "Afro-pessimism\n\nAfro-pessimism is a framework and critical idiom that describes the ongoing effects of racism, colonialism, and historical processes of enslavement including the Trans-Atlantic slave trade, and their impact on structural conditions as well as personal, subjective, and lived experience, and embodied reality. \n\nThe term was first coined in 1990 in an article in \"Jeune Afrique Economie\" by Francophone Cameroonian author Sony Lab'ou Tansi. Writer and intellectual Frank B. Wilderson III developed the term in his political memoir about his time spent teaching and participating in the African National Congress in South Africa during apartheid. \n\nAccording to Tansi, \"Afro-pessimism [is] a terrible word used to conceal the greatest mess of all time,\" which is the \"tragedy\" that Africa's position \"dooms us to construct and build garbage economies in the depths of the most cruel, unbearable, and inhuman form of indignity that humans can swallow\" (as translated by John Conteh-Morgan). According to Wilderson, afro-pessimism theorizes blackness as a position of \"accumulation and fungibility\" (Saidiya Hartman); that is, as condition—or relation—of ontological death, as opposed to a cultural identity or human subjectivity.\n\nWilderson, along with Hortense Spillers, Saidiya Hartman, Achille Mbembe, Jared Sexton, and others who have contributed to afro-pessimist thought, cite the Martinician psychiatrist, philosopher, and writer Frantz Fanon as a foundational figure in the tradition of Afro-pessimism. \n\nAfro-pessimism has been constructed in many ways and with different aims. But Afro-pessimism is chiefly approached a transcendent position, not as a negative or disaffected political attitude in the sense that pessimism might seemingly connote. The Black radical tradition has drawn upon the term as a way to acknowledge the power, depth, and vitality of the resilience and radical imagination of people of African descent. Within this same critique, some have used Afro-pessimism to articulate the subject-position of renunciation, refusal, distancing, dread, doubt and abjection in response to the multitude and ongoing effects and historical traumas of colonialism. This includes the view that dismantling white supremacy would mean dismantling much of the social and political institutions of the modern world.\n\nDiscussions of Afro-pessimism have manifest in an online context, and have continued in Afro-pessimist approaches to art, poetics, and computing.\n\nAfro-pessimist ideas have been part of ongoing conversations about pan-African identity, as an inclusionary concept of blackness among all people of African descent. Pan-African thought has drawn attention to the shared racial identity and also the particulars of the expression of African identity among the African Diaspora and peoples on the African continent. Pan-African thought has analyzed the ongoing struggles of African peoples, and the power of Afrocentricity as a move away from the colonialism and violence of Eurocentricity. The writings of Frantz Fanon, a Martinican psychiatrist, intellectual, and revolutionary, reflect pan-African and Afro-pessimistic approaches to decolonization and black liberation. \n\nThe Pan-African movement négritude represents pessimism as a kind of realist recognition of the historical traumas of colonialism, from an existentialist position. A key figure in the movement, Aimé Césaire, uses pessimism to consider transcendence and a recognition of the breadth of the cultural imagination and perseverance of people of African descent.\n\nAfro-pessimism has also been employed as a term describing a narrative in Western media and International relations theory that portrays post-colonial Africa as unlikely to achieve economic growth and democratic governance. This use of Afro-pessimism has nothing to with Wilderson's definition. This form of Afro-pessimism has been criticized as a Western construct regarding the ongoing portrayal of Africa and African people in Western media, overwhelmingly in terms of tragedy, doom, victimization, and victim-hood. Scholar Toussaint Nothias has characterized these discussions by the components, \"essentialism, racialization, selectivity, ranking framework, and prediction.\" From this Afro-pessimistic perspective, news media that portray Africa and African people by the trope of victimhood, mirror the Eurocentric and ethnocentric of the Western media, language, images, and rhetoric. In this ways the media tends to victimize and exoticize Africa for its going struggles with poverty, health-crisis, famine, and lack of modern development. The victimization is then visible in the humanitarian and development projects, which sometimes use the language of \"saving\" African people from such \"humanitarian disasters\".\n\n\n"}
{"id": "10000937", "url": "https://en.wikipedia.org/wiki?curid=10000937", "title": "Category (Kant)", "text": "Category (Kant)\n\nIn Kant's philosophy, a category ( in the original or \"Kategorie\" in modern German) is a pure concept of the understanding (\"Verstand\"). A Kantian category is a characteristic of the appearance of any object in general, before it has been experienced. Kant wrote that \"They are concepts of an object in general….\" Kant also wrote that, \"…pure cоncepts [Categories] of the undеrstanding which apply to objects of intuition in general….\" Such a category is not a classificatory division, as the word is commonly used. It is, instead, the condition of the possibility of objects in general, that is, objects as such, any and all objects, not specific objects in particular.\n\nThe word comes from the Greek κατηγορία, \"katēgoria\", meaning \"that which can be said, predicated, or publicly declared and asserted, about something.\" A category is an attribute, property, quality, or characteristic that can be predicated of a thing. \"…I remark concerning the categories…that their logical employment consists in their use as predicates of objects.\" Kant called them \"ontological predicates.\"\n\nA category is that which can be said of everything in general, that is, of anything that is an object. John Stuart Mill wrote: \"The Categories, or Predicaments — the former a Greek word, the latter its literal translation in the Latin language — were believed to be an enumeration of all things capable of being named, an enumeration by the \"summa genera\" (highest kind), i.e., the most extensive classes into which things could be distributed, which, therefore, were so many highest Predicates, one or other of which was supposed capable of being affirmed with truth of every nameable thing whatsoever.\"\n\nAristotle had claimed that the following ten predicates or categories could be asserted of anything in general: substance, quantity, quality, relation, action, affection (passivity), place, time (date), position, and state. These are supposed to be the qualities or attributes that can be affirmed of each and every thing in experience. Any particular object that exists in thought must have been able to have the Categories attributed to it as possible predicates because the Categories are the properties, qualities, or characteristics of any possible object in general. The Categories of Aristotle and Kant are the general properties that belong to all things without expressing the peculiar nature of any particular thing. Kant appreciated Aristotle's effort, but said that his table was imperfect because \" … as he had no guiding principle, he merely picked them up as they occurred to him...\"\n\nThe Categories do not provide knowledge of individual, particular objects. Any object, however, must have Categories as its characteristics if it is to be an object of experience. It is presupposed or assumed that anything that is a specific object must possess Categories as its properties because Categories are predicates of an object in general. An object in general does not have all of the Categories as predicates at one time. For example, a general object cannot have the qualitative Categories of reality and negation at the same time. Similarly, an object in general cannot have both unity and plurality as quantitative predicates at once. The Categories of Modality exclude each other. Therefore, a general object cannot simultaneously have the Categories of possibility/impossibility and existence/non–existence as qualities.\n\nSince the Categories are a list of that which can be said of every object, they are related only to human language. In making a verbal statement about an object, a speaker makes a judgment. A general object, that is, every object, has attributes that are contained in Kant's list of Categories. In a judgment, or verbal statement, the Categories are the predicates that can be asserted of every object and all objects.\n\nKant believed that the ability of the human understanding (German: \"Verstand\", Greek: \"dianoia\" \"διάνοια\", Latin: \"ratio\") to think about and know an object is the same as the making of a spoken or written judgment about an object. According to him, \"Our ability to judge is equivalent to our ability to think.\"\nA judgment is the thought that a thing is known to have a certain quality or attribute. For example, the sentence \"The rose is red\" is a judgment. Kant created a table of the forms of such judgments as they relate to all objects in general.\n\nThis table of judgments was used by Kant as a model for the table of categories. Taken together, these twelvefold tables constitute the formal structure for Kant's architectonic conception of his philosophical system.\n\nCategories are entirely different from the appearances of objects. According to Kant, in order to relate to specific phenomena, categories must be \"applied\" through time. The way that this is done is called a schema.\n\nArthur Schopenhauer, in his criticism of the Kantian philosophy, found many errors in Kant's use of the Categories of Quality, Quantity, Relation, and Modality. Schopenhauer also noted that in accordance with Kant's claim, non-human animals would not be able to know objects. Animals would only know impressions on their sense organs, which Kant mistakenly calls perception.\n\n\n"}
{"id": "5370", "url": "https://en.wikipedia.org/wiki?curid=5370", "title": "Category of being", "text": "Category of being\n\nIn ontology, the different kinds or ways of being are called categories of being; or simply categories. To investigate the categories of being is to determine the most fundamental and the broadest classes of entities. A distinction between such categories, in making the categories or applying them, is called an ontological distinction.\n\nThe process of abstraction required to discover the number and names of the categories has been undertaken by many philosophers since Aristotle and involves the careful inspection of each concept to ensure that there is no higher category or categories under which that concept could be subsumed. The scholars of the twelfth and thirteenth centuries developed Aristotle's ideas, firstly, for example by Gilbert of Poitiers, dividing Aristotle's ten categories into two sets, primary and secondary, according to whether they inhere in the subject or not:\nSecondly, following Porphyry’s likening of the classificatory hierarchy to a tree, they concluded that the major classes could be subdivided to form subclasses, for example, Substance could be divided into Genus and Species, and Quality could be subdivided into Property and Accident, depending on whether the property was necessary or contingent. An alternative line of development was taken by Plotinus in the second century who by a process of abstraction reduced Aristotle’s list of ten categories to five: Substance, Relation, Quantity, Motion and Quality. Plotinus further suggested that the latter three categories of his list, namely Quantity, Motion and Quality correspond to three different kinds of relation and that these three categories could therefore be subsumed under the category of Relation. This was to lead to the supposition that there were only two categories at the top of the hierarchical tree, namely Substance and Relation, and if relations only exist in the mind as many supposed, to the two highest categories, Mind and Matter, reflected most clearly in the dualism of René Descartes.\n\nAn alternative conclusion however began to be formulated in the eighteenth century by Immanuel Kant who realised that we can say nothing about Substance except through the relation of the subject to other things. In the sentence \"This is a house\" the substantive subject \"house\" only gains meaning in relation to human use patterns or to other similar houses. The category of Substance disappears from Kant's tables, and under the heading of Relation, Kant lists \"inter alia\" the three relationship types of Disjunction, Causality and Inherence. The three older concepts of Quantity, Motion and Quality, as Peirce discovered, could be subsumed under these three broader headings in that Quantity relates to the subject through the relation of Disjunction; Motion relates to the subject through the relation of Causality; and Quality relates to the subject through the relation of Inherence. Sets of three continued to play an important part in the nineteenth century development of the categories, most notably in G.W.F. Hegel's extensive tabulation of categories, and in C.S. Peirce's categories set out in his work on the logic of relations. One of Peirce's contributions was to call the three primary categories Firstness, Secondness and Thirdness which both emphasises their general nature, and avoids the confusion of having the same name for both the category itself and for a concept within that category.\n\nIn a separate development, and building on the notion of primary and secondary categories introduced by the Scholastics, Kant introduced the idea that secondary or \"derivative\" categories could be derived from the primary categories through the combination of one primary category with another. This would result in the formation of three secondary categories: the first, \"Community\" was an example that Kant gave of such a derivative category; the second, \"Modality\", introduced by Kant, was a term which Hegel, in developing Kant's dialectical method, showed could also be seen as a derivative category; and the third, \"Spirit\" or \"Will\" were terms that Hegel and Schopenhauer were developing separately for use in their own systems. Karl Jaspers in the twentieth century, in his development of existential categories, brought the three together, allowing for differences in terminology, as Substantiality, Communication and Will. This pattern of three primary and three secondary categories was used most notably in the nineteenth century by Peter Mark Roget to form the six headings of his Thesaurus of English Words and Phrases. The headings used were the three objective categories of Abstract Relation, Space (including Motion) and Matter and the three subjective categories of Intellect, Feeling and Volition, and he found that under these six headings all the words of the English language, and hence any possible predicate, could be assembled.\n\nIn the twentieth century the primacy of the division between the subjective and the objective, or between mind and matter, was disputed by, among others, Bertrand Russell and Gilbert Ryle. Philosophy began to move away from the metaphysics of categorisation towards the linguistic problem of trying to differentiate between, and define, the words being used. Ludwig Wittgenstein’s conclusion was that there were no clear definitions which we can give to words and categories but only a \"halo\" or \"corona\" of related meanings radiating around each term. Gilbert Ryle thought the problem could be seen in terms of dealing with \"a galaxy of ideas\" rather than a single idea, and suggested that category mistakes are made when a concept (e.g. \"university\"), understood as falling under one category (e.g. abstract idea), is used as though it falls under another (e.g. physical object). With regard to the visual analogies being used, Peirce and Lewis, just like Plotinus earlier, likened the terms of propositions to points, and the relations between the terms to lines. Peirce, taking this further, talked of univalent, bivalent and trivalent relations linking predicates to their subject and it is just the number and types of relation linking subject and predicate that determine the category into which a predicate might fall. Primary categories contain concepts where there is one dominant kind of relation to the subject. Secondary categories contain concepts where there are two dominant kinds of relation. Examples of the latter were given by Heidegger in his two propositions \"the house is on the creek\" where the two dominant relations are spatial location (Disjunction) and cultural association (Inherence), and \"the house is eighteenth century\" where the two relations are temporal location (Causality) and cultural quality (Inherence). A third example may be inferred from Kant in the proposition \"the house is impressive or sublime\" where the two relations are spatial or mathematical disposition (Disjunction) and dynamic or motive power (Causality). Both Peirce and Wittgenstein introduced the analogy of colour theory in order to illustrate the shades of meanings of words. Primary categories, like primary colours, are analytical representing the furthest we can go in terms of analysis and abstraction and include Quantity, Motion and Quality. Secondary categories, like secondary colours, are synthetic and include concepts such as Substance, Community and Spirit.\n\nOne of Aristotle’s early interests lay in the classification of the natural world, how for example the genus \"animal\" could be first divided into \"two-footed animal\" and then into \"wingless, two-footed animal\". He realised that the distinctions were being made according to the qualities the animal possesses, the quantity of its parts and the kind of motion that it exhibits. To fully complete the proposition \"this animal is…\" Aristotle stated in his work on the Categories that there were ten kinds of predicate where...\n\n\"…each signifies either substance or quantity or quality or relation or where or when or being-in-a-position or having or acting or being acted upon\".\n\nHe realised that predicates could be simple or complex. The simple kinds consist of a subject and a predicate linked together by the \"categorical\" or inherent type of relation. For Aristotle the more complex kinds were limited to propositions where the predicate is compounded of two of the above categories for example \"this is a horse running\". More complex kinds of proposition were only discovered after Aristotle by the Stoic, Chrysippus, who developed the \"hypothetical\" and \"disjunctive\" types of syllogism and these were terms which were to be developed through the Middle Ages and were to reappear in Kant's system of categories.\n\n\"Category\" came into use with Aristotle's essay \"Categories\", in which he discussed univocal and equivocal terms, predication, and ten categories:\n\nPlotinus in writing his \"Enneads\" around AD 250 recorded that \"philosophy at a very early age investigated the number and character of the existents… some found ten, others less…. to some the genera were the first principles, to others only a generic classification of existents\". He realised that some categories were reducible to others saying \"why are not Beauty, Goodness and the virtues, Knowledge and Intelligence included among the primary genera?\" He concluded that such transcendental categories and even the categories of Aristotle were in some way posterior to the three Eleatic categories first recorded in Plato's dialogue \"Parmenides\" and which comprised the following three coupled terms: \n\nPlotinus called these \"the hearth of reality\" deriving from them not only the three categories of Quantity, Motion and Quality but also what came to be known as \"the three moments of the Neoplatonic world process\":\n\nPlotinus likened the three to the centre, the radii and the circumference of a circle, and clearly thought that the principles underlying the categories were the first principles of creation. \"From a single root all being multiplies\". Similar ideas were to be introduced into Early Christian thought by, for example, Gregory of Nazianzus who summed it up saying \"Therefore Unity, having from all eternity arrived by motion at duality, came to rest in trinity\".\n\nIn the \"Critique of Pure Reason\" (1781), Immanuel Kant argued that the categories are part of our own mental structure and consist of a set of \"a priori\" concepts through which we interpret the world around us. These concepts correspond to twelve logical functions of the understanding which we use to make judgements and there are therefore two tables given in the \"Critique\", one of the Judgements and a corresponding one for the Categories. To give an example, the logical function behind our reasoning from ground to consequence (based on the Hypothetical relation) underlies our understanding of the world in terms of cause and effect (the Causal relation). In each table the number twelve arises from, firstly, an initial division into two: the Mathematical and the Dynamical; a second division of each of these headings into a further two: Quantity and Quality, and Relation and Modality respectively; and, thirdly, each of these then divides into a further three subheadings as follows.\nTable of Judgements\n\nMathematical\nDynamical\n\nTable of Categories\n\nMathematical\nDynamical\n\nCriticism of Kant's system followed, firstly, by Arthur Schopenhauer, who amongst other things was unhappy with the term \"Community\", and declared that the tables \"do open violence to truth, treating it as nature was treated by old-fashioned gardeners\", and secondly, by W.T.Stace who in his book \"The Philosophy of Hegel\" suggested that in order to make Kant's structure completely symmetrical a third category would need to be added to the Mathematical and the Dynamical. This, he said, Hegel was to do with his category of Notion.\n\nG.W.F. Hegel in his \"Science of Logic\" (1812) attempted to provide a more comprehensive system of categories than Kant and developed a structure that was almost entirely triadic. So important were the categories to Hegel that he claimed \"the first principle of the world, the Absolute, is a system of categories… the categories must be the reason of which the world is a consequent\".\n\nUsing his own logical method of combination, later to be called the Hegelian dialectic, of arguing from thesis through antithesis to synthesis, he arrived, as shown in W.T.Stace's work cited, at a hierarchy of some 270 categories. The three very highest categories were Logic, Nature and Spirit. The three highest categories of Logic, however, he called Being, Essence and Notion which he explained as follows:\nSchopenhauer's category that corresponded with Notion was that of Idea, which in his \"Four-Fold Root of Sufficient Reason\" he complemented with the category of the Will. The title of his major work was \"The World as Will and Idea\". The two other complementary categories, reflecting one of Hegel's initial divisions, were those of Being and Becoming. At around the same time, Goethe was developing his colour theories in the \"Farbenlehre\" of 1810, and introduced similar principles of combination and complementation, symbolising, for Goethe, \"the primordial relations which belong both to nature and vision\". Hegel in his \"Science of Logic\" accordingly asks us to see his system not as a tree but as a circle.\n\nCharles Sanders Peirce, who had read Kant and Hegel closely, and who also had some knowledge of Aristotle, proposed a system of merely three phenomenological categories: Firstness, Secondness, and Thirdness, which he repeatedly invoked in his subsequent writings. Like Hegel, C.S.Peirce attempted to develop a system of categories from a single indisputable principle, in Peirce's case the notion that in the first instance he could only be aware of his own ideas. \n\nAlthough Peirce's three categories correspond to the three concepts of relation given in Kant's tables, the sequence is now reversed and follows that given by Hegel, and indeed before Hegel of the three moments of the world-process given by Plotinus. Later, Peirce gave a mathematical reason for there being three categories in that although monadic, dyadic and triadic nodes are irreducible, every node of a higher valency is reducible to a \"compound of triadic relations\". Ferdinand de Saussure, who was developing \"semiology\" in France just as Peirce was developing \"semiotics\" in the US, likened each term of a proposition to \"the centre of a constellation, the point where other coordinate terms, the sum of which is indefinite, converge\".\n\nEdmund Husserl (1962, 2000) wrote extensively about categorial systems as part of his phenomenology.\n\nFor Gilbert Ryle (1949), a category (in particular a \"category mistake\") is an important semantic concept, but one having only loose affinities to an ontological category.\n\nContemporary systems of categories have been proposed by John G. Bennett (The Dramatic Universe, 4 vols., 1956–65), Wilfrid Sellars (1974), Reinhardt Grossmann (1983, 1992), Johansson (1989), Hoffman and Rosenkrantz (1994), Roderick Chisholm (1996), Barry Smith (ontologist) (2003), and Jonathan Lowe (2006).\n\n\n\n"}
{"id": "29358535", "url": "https://en.wikipedia.org/wiki?curid=29358535", "title": "Comply or explain", "text": "Comply or explain\n\nComply or explain is a regulatory approach used in the United Kingdom, Germany, the Netherlands and other countries in the field of corporate governance and financial supervision. Rather than setting out binding laws, government regulators (in the UK, the Financial Reporting Council, in Germany, under the Aktiengesetz) set out a code, which listed companies may either comply with, or if they do not comply, explain publicly why they do not. The UK Corporate Governance Code, the German Corporate Governance Code (or Deutscher Corporate Governance Kodex) and the Dutch Corporate Governance Code 'Code Tabaksblat' () use this approach in setting minimum standards for companies in their audit committees, remuneration committees and recommendations for how good companies should divide authority on their boards.\n\nThe purpose of \"comply or explain\" is to \"let the market decide\" whether a set of standards is appropriate for individual companies. Since a company may deviate from the standard, this approach rejects the view that \"one size fits all\", but because of the requirement of disclosure of explanations to market investors, anticipates that if investors do not accept a company's explanations, then investors will sell their shares, hence creating a \"market sanction\", rather than a legal one. The concept was first introduced after the recommendations of the Cadbury Report of 1992.\n\n"}
{"id": "6978", "url": "https://en.wikipedia.org/wiki?curid=6978", "title": "Concept", "text": "Concept\n\nConcepts are mental representations, abstract objects or abilities that make up the fundamental building blocks of thoughts and beliefs. They play an important role in all aspects of cognition.\n\nIn contemporary philosophy, there are at least three prevailing ways to understand what a concept is:\n\n\nConcepts can be organized into a hierarchy, higher levels of which are termed \"superordinate\" and lower levels termed \"subordinate\". Additionally, there is the \"basic\" or \"middle\" level at which people will most readily categorize a concept. For example, a basic-level concept would be \"chair\", with its superordinate, \"furniture\", and its subordinate, \"easy chair\".\n\nA concept is instantiated (reified) by all of its actual or potential instances, whether these are things in the real world or other ideas.\n\nConcepts are studied as components of human cognition in the cognitive science disciplines of linguistics, psychology and philosophy, where an ongoing debate asks whether all cognition must occur through concepts. Concepts are used as formal tools or models in mathematics, computer science, databases and artificial intelligence where they are sometimes called classes, schema or categories. In informal use the word \"concept\" often just means any idea.\n\nWithin the framework of the representational theory of mind, the structural position of concepts can be understood as follows: Concepts serve as the building blocks of what are called \"mental representations\" (colloquially understood as \"ideas in the mind\"). Mental representations, in turn, are the building blocks of what are called \"propositional attitudes\" (colloquially understood as the stances or perspectives we take towards ideas, be it \"believing\", \"doubting\", \"wondering\", \"accepting\", etc.). And these propositional attitudes, in turn, are the building blocks of our understanding of thoughts that populate everyday life, as well as folk psychology. In this way, we have an analysis that ties our common everyday understanding of thoughts down to the scientific and philosophical understanding of concepts.\n\nA central question in the study of concepts is the question of what concepts \"are\". Philosophers construe this question as one about the ontology of concepts – what they are really like. The ontology of concepts determines the answer to other questions, such as how to integrate concepts into a wider theory of the mind, what functions are allowed or disallowed by a concept's ontology, etc. There are two main views of the ontology of concepts: (1) Concepts are abstract objects, and (2) concepts are mental representations.\n\nPlatonist views of the mind construe concepts as abstract objects,\n\nThere is debate as to the relationship between concepts and natural language. However, it is necessary at least to begin by understanding that the concept \"dog\" is philosophically distinct from the things in the world grouped by this concept – or the reference class or extension. Concepts that can be equated to a single word are called \"lexical concepts\".\n\nStudy of concepts and conceptual structure falls into the disciplines of linguistics, philosophy, psychology, and cognitive science.\n\nIn the simplest terms, a concept is a name or label that regards or treats an abstraction as if it had concrete or material existence, such as a person, a place, or a thing. It may represent a natural object that exists in the real world like a tree, an animal, a stone, etc. It may also name an artificial (man-made) object like a chair, computer, house, etc. Abstract ideas and knowledge domains such as freedom, equality, science, happiness, etc., are also symbolized by concepts. It is important to realize that a concept is merely a symbol, a representation of the abstraction. The word is not to be mistaken for the thing. For example, the word \"moon\" (a concept) is not the large, bright, shape-changing object up in the sky, but only \"represents\" that celestial object. Concepts are created (named) to describe, explain and capture reality as it is known and understood.\n\nKant declared that human minds possess pure or \"a priori\" concepts. Instead of being abstracted from individual perceptions, like empirical concepts, they originate in the mind itself. He called these concepts categories, in the sense of the word that means predicate, attribute, characteristic, or quality. But these pure categories are predicates of things \"in general\", not of a particular thing. According to Kant, there are twelve categories that constitute the understanding of phenomenal objects. Each category is that one predicate which is common to multiple empirical concepts. In order to explain how an \"a priori\" concept can relate to individual phenomena, in a manner analogous to an \"a posteriori\" concept, Kant employed the technical concept of the schema. He held that the account of the concept as an abstraction of experience is only partly correct. He called those concepts that result from abstraction \"a posteriori concepts\" (meaning concepts that arise out of experience). An empirical or an \"a posteriori\" concept is a general representation (\"Vorstellung\") or non-specific thought of that which is common to several specific perceived objects (Logic, I, 1., §1, Note 1)\n\nA concept is a common feature or characteristic. Kant investigated the way that empirical \"a posteriori\" concepts are created.\nIn cognitive linguistics, abstract concepts are transformations of concrete concepts derived from embodied experience. The mechanism of transformation is structural mapping, in which properties of two or more source domains are selectively mapped onto a blended space (Fauconnier & Turner, 1995; see conceptual blending). A common class of blends are metaphors. This theory contrasts with the rationalist view that concepts are perceptions (or \"recollections\", in Plato's term) of an independently existing world of ideas, in that it denies the existence of any such realm. It also contrasts with the empiricist view that concepts are abstract generalizations of individual experiences, because the contingent and bodily experience is preserved in a concept, and not abstracted away. While the perspective is compatible with Jamesian pragmatism, the notion of the transformation of embodied concepts through structural mapping makes a distinct contribution to the problem of concept formation.\n\nPlato was the starkest proponent of the realist thesis of universal concepts. By his view, concepts (and ideas in general) are innate ideas that were instantiations of a transcendental world of pure forms that lay behind the veil of the physical world. In this way, universals were explained as transcendent objects. Needless to say this form of realism was tied deeply with Plato's ontological projects. This remark on Plato is not of merely historical interest. For example, the view that numbers are Platonic objects was revived by Kurt Gödel as a result of certain puzzles that he took to arise from the phenomenological accounts.\n\nGottlob Frege, founder of the analytic tradition in philosophy, famously argued for the analysis of language in terms of sense and reference. For him, the sense of an expression in language describes a certain state of affairs in the world, namely, the way that some object is presented. Since many commentators view the notion of sense as identical to the notion of concept, and Frege regards senses as the linguistic representations of states of affairs in the world, it seems to follow that we may understand concepts as the manner in which we grasp the world. Accordingly, concepts (as senses) have an ontological status (Morgolis:7).\n\nAccording to Carl Benjamin Boyer, in the introduction to his \"The History of the Calculus and its Conceptual Development\", concepts in calculus do not refer to perceptions. As long as the concepts are useful and mutually compatible, they are accepted on their own. For example, the concepts of the derivative and the integral are not considered to refer to spatial or temporal perceptions of the external world of experience. Neither are they related in any way to mysterious limits in which quantities are on the verge of nascence or evanescence, that is, coming into or going out of existence. The abstract concepts are now considered to be totally autonomous, even though they originated from the process of abstracting or taking away qualities from perceptions until only the common, essential attributes remained.\n\nIn a physicalist theory of mind, a concept is a mental representation, which the brain uses to denote a class of things in the world. This is to say that it is literally, a symbol or group of symbols together made from the physical material of the brain. Concepts are mental representations that allow us to draw appropriate inferences about the type of entities we encounter in our everyday lives. Concepts do not encompass all mental representations, but are merely a subset of them. The use of concepts is necessary to cognitive processes such as categorization, memory, decision making, learning, and inference.\n\nConcepts are thought to be stored in long term cortical memory, in contrast to episodic memory of the particular objects and events which they abstract, which are stored in hippocampus. Evidence for this separation comes from hippocampal damaged patients such as patient HM. The abstraction from the day's hippocampal events and objects into cortical concepts is often considered to be the computation underlying (some stages of) sleep and dreaming. Many people (beginning with Aristotle) report memories of dreams which appear to mix the day's events with analogous or related historical concepts and memories, and suggest that they were being sorted or organised into more abstract concepts. (\"Sort\" is itself another word for concept, and \"sorting\" thus means to organise into concepts.)\n\nThe classical theory of concepts, also referred to as the empiricist theory of concepts, is the oldest theory about the structure of concepts (it can be traced back to Aristotle), and was prominently held until the 1970s. The classical theory of concepts says that concepts have a definitional structure. Adequate definitions of the kind required by this theory usually take the form of a list of features. These features must have two important qualities to provide a comprehensive definition. Features entailed by the definition of a concept must be both \"necessary\" and \"sufficient\" for membership in the class of things covered by a particular concept. A feature is considered necessary if every member of the denoted class has that feature. A feature is considered sufficient if something has all the parts required by the definition. For example, the classic example \"bachelor\" is said to be defined by \"unmarried\" and \"man\". An entity is a bachelor (by this definition) if and only if it is both unmarried and a man. To check whether something is a member of the class, you compare its qualities to the features in the definition. Another key part of this theory is that it obeys the \"law of the excluded middle\", which means that there are no partial members of a class, you are either in or out.\n\nThe classical theory persisted for so long unquestioned because it seemed intuitively correct and has great explanatory power. It can explain how concepts would be acquired, how we use them to categorize and how we use the structure of a concept to determine its referent class. In fact, for many years it was one of the major activities in philosophy – concept analysis. Concept analysis is the act of trying to articulate the necessary and sufficient conditions for the membership in the referent class of a concept. For example, Shoemaker's classic \"Time Without Change\" explored whether the concept of the flow of time can include flows where no changes take place, though change is usually taken as a definition of time.\n\nGiven that most later theories of concepts were born out of the rejection of some or all of the classical theory, it seems appropriate to give an account of what might be wrong with this theory. In the 20th century, philosophers such as Wittgenstein and Rosch argued against the classical theory. There are six primary arguments summarized as follows:\n\nPrototype theory came out of problems with the classical view of conceptual structure. Prototype theory says that concepts specify properties that members of a class tend to possess, rather than must possess. Wittgenstein, Rosch, Mervis, Berlin, Anglin, and Posner are a few of the key proponents and creators of this theory. Wittgenstein describes the relationship between members of a class as \"family resemblances\". There are not necessarily any necessary conditions for membership, a dog can still be a dog with only three legs. This view is particularly supported by psychological experimental evidence for prototypicality effects. Participants willingly and consistently rate objects in categories like 'vegetable' or 'furniture' as more or less typical of that class. It seems that our categories are fuzzy psychologically, and so this structure has explanatory power. We can judge an item's membership to the referent class of a concept by comparing it to the typical member – the most central member of the concept. If it is similar enough in the relevant ways, it will be cognitively admitted as a member of the relevant class of entities. Rosch suggests that every category is represented by a central exemplar which embodies all or the maximum possible number of features of a given category. According to Lech, Gunturkun, and Suchan explain that categorization involves many areas of the brain, some of these are; visual association areas, prefrontal cortex, basal ganglia, and temporal lobe.\n\nTheory-theory is a reaction to the previous two theories and develops them further. This theory postulates that categorization by concepts is something like scientific theorizing. Concepts are not learned in isolation, but rather are learned as a part of our experiences with the world around us. In this sense, concepts' structure relies on their relationships to other concepts as mandated by a particular mental theory about the state of the world. How this is supposed to work is a little less clear than in the previous two theories, but is still a prominent and notable theory. This is supposed to explain some of the issues of ignorance and error that come up in prototype and classical theories as concepts that are structured around each other seem to account for errors such as whale as a fish (this misconception came from an incorrect theory about what a whale is like, combining with our theory of what a fish is). When we learn that a whale is not a fish, we are recognizing that whales don't in fact fit the theory we had about what makes something a fish. In this sense, the Theory–Theory of concepts is responding to some of the issues of prototype theory and classic theory.\n\nAccording to the theory of ideasthesia (or \"sensing concepts\"), activation of a concept may be the main mechanism responsible for creation of phenomenal experiences. Therefore, understanding how the brain processes concepts may be central to solving the mystery of how conscious experiences (or qualia) emerge within a physical system e.g., the sourness of the sour taste of lemon. This question is also known as the hard problem of consciousness. Research on ideasthesia emerged from research on synesthesia where it was noted that a synesthetic experience requires first an activation of a concept of the inducer. Later research expanded these results into everyday perception.\n\nThere is a lot of discussion on the most effective theory in concepts. Another theory is semantic pointers, which use perceptual and motor representations and these representations are like symbols.\n\nThe term \"concept\" is traced back to 1554–60 (Latin \"\" – \"something conceived\").\n\n"}
{"id": "38191512", "url": "https://en.wikipedia.org/wiki?curid=38191512", "title": "Concept-driven strategy", "text": "Concept-driven strategy\n\nA concept-driven strategy is a process for formulating strategy that draws on the explanation of how humans inquire provided by linguistic pragmatic philosophy. This argues that thinking starts by selecting (explicitly or implicitly) a set of concepts (frames, patterns, lens, principles, etc.) gained from our past experiences. These are used to reflect on whatever happens, or is done, in the future.\n\nConcept-driven strategy therefore starts from agreeing and enacting a set of strategic concepts (organizing principles) that \"works best\" for an organisation. For example, a hospital might set its strategy as intending to be Caring, World Class, Local, Evidence Based, and Team Based. A University might set its strategy as intending to be Ranked, Problem Solving, Online, Equis, and Offering Pathways. A commercial corporation might set its strategy as intending to be Innovative, Global, Have Visible Supply Chains, Agile and Market Share Dominant. These strategic concepts make up its \"Statement of Intent\" (or Purpose).\n\nMuch of the strategic management literature mutates Peter Drucker's call for corporations to start the strategic management process by producing a statement of purpose, mission and objectives. This has been mutated into a call to start with a vision, mission and objectives statement. There is an alternative approach which focuses on the Statement of Purpose or Intent. Drucker's example for this statement for a commercial corporation was to state that the corporation's purpose was to create customers. That is, it was going to use the concept of 'customer creation' to coordinate and organise the cognition or mindset of those that worked for the organisation. This was why the corporation existed. Having one concept is now thought to be insufficient. George Armitage Miller's modified The Magical Number Seven, Plus or Minus Two and dialectic suggests a handful of concepts under tension would be preferable.\n\nThe Statement of Purpose, Statement of Intent or concept-driven approach to strategy formulation therefore focuses on setting and enacting a set strategic concepts. If a participatory approach is being used these concepts will be acquired through a process of collaboration with stakeholders. Once agreed the strategic concepts can be used to coordinate activities and act as a set of decision making criteria. The set of concepts that make up the Statement of Intent is then used to make sense of an unpredictable future across an organisation in a co-ordinated manner.\n\nLinguistic pragmatism argues that our prior conceptions interpret our perception (sensory inputs). These conceptions are represented by concepts like running, smiling, justice, reasoning and agility. They are patterns of activity, experienced in our past and remembered. They can be named by those with language and so shared.\n\nBagginni explains pragmatic concepts using the classic example of whether the earth is flat or round.\n\nAnother example would be that we can think of the war in Iraqi differently by reflecting off the concepts of oil security, Imperialism, aggressive capitalism, liberation or democracy. \nThe concept-driven approach to strategy formulation involves setting and using a set of linguistic pragmatic concepts.\n\nThe steps to formulating a participatory concept-driven strategy are:\n\n\nConcept-driven strategy is the name given to a number of similar strategic thinking approaches.\n\nGenerally, the term 'concept-driven' is used to encourage a focus on the 'concepts' being used. See Concept learning or Management Concepts.\n\nSome organisations produce a 'statement of intent' with little thought as to the concepts it contains. However, if it is a short list of concepts, high level objectives, principles, priorities or frames, then concept-driven strategy offers a philosophical basis for these statements.\n\nSome organisations produce a 'strategic principles' statement which again is similar to a statement of intent and the same applies about the concepts approach offering a philosophical basis. The term 'strategic priorities' or 'strategic values' are often used in the same way as strategic principles.\n\nThe literature about 'corporate purpose' is also similar to that of strategic intent. Sometimes, purpose refers to present actions and intent to future ones. If purpose is expressed as a set of concepts, then the concepts approach again provides some philosophical basis.\n\nThere is a connection between 'systems thinking' and concept-driven strategy. The Churchman/Ackoff stream of systems thinking was interested in a developing generic system of concepts for thinking about problems. Rather than a generic set of concepts, the concept-driven approach uses whatever concepts stakeholders think work best for the future of their organisation.\n\nThere is a military planning approach called 'concept-led'. The military-like leadership seems to have moved the concepts from being drivers to be leaders. There seems to be very little difference otherwise.\n\nIn turbulent environments, concepts are thought 'more flexible than objectives' (goals, targets) as they provide why certain actions are preferable. The purpose and intent literature likes to distinguish itself from the objectives literature by saying purpose and intent provide the reasons for (why change), the driver for change. Objectives are where you end up. In complex dynamic situations, there may be many acceptable end points, many of which cannot be anticipated by planners. Arguably the only objective is to survive. How is explained in the statement of intent.\n\nPerhaps strangely, there is a connection between 'metaphor', metaphoric criticism, or conceptual metaphor and concept-driven strategy. Pragmatic concepts are not images but most concepts relate to metaphors. For example, to say an organisation is like a machine, with cogs, or like an adaptive organism, is to use the concepts of machine and organism to reflect on organisations. Much of what has been written about the usefulness of metaphors in planning applies to concepts.\n\nThe term 'strategic frames' is not common given the extensive literature on frame analysis but frames and pragmatic concepts seem to be very similar. Amos Tversky defines a frame as a conception of outcomes.\n\nThe system of strategic concepts listed in a statement of intent, purpose, principles, frames or conceptual metaphor are organizing principle(s).\n\nAlso, as Karl Weick explains sensemaking as the process of conceptualising problems, concept-driven strategy might be thought of as a pragmatic means of sensemaking a strategy.\n\n\n"}
{"id": "698226", "url": "https://en.wikipedia.org/wiki?curid=698226", "title": "Concept map", "text": "Concept map\n\nA concept map or conceptual diagram is a diagram that depicts suggested relationships between concepts. It is a graphical tool that instructional designers, engineers, technical writers, and others use to organize and structure knowledge.\n\nA concept map typically represents ideas and information as boxes or circles, which it connects with labeled arrows in a downward-branching hierarchical structure. The relationship between concepts can be articulated in linking phrases such as \"causes\", \"requires\", or \"contributes to\".\n\nThe technique for visualizing these relationships among different concepts is called \"concept mapping\". Concept maps have been used to define the ontology of computer systems, for example with the object-role modeling or Unified Modeling Language formalism.\n\nA concept map is a way of representing relationships between ideas, images, or words in the same way that a sentence diagram represents the grammar of a sentence, a road map represents the locations of highways and towns, and a circuit diagram represents the workings of an electrical appliance. In a concept map, each word or phrase connects to another, and links back to the original idea, word, or phrase. Concept maps are a way to develop logical thinking and study skills by revealing connections and helping students see how individual ideas form a larger whole. An example of the use of concept maps is provided in the context of learning about types of fuel.\n\nConcept maps were developed to enhance meaningful learning in the sciences. A well-made concept map grows within a \"context frame\" defined by an explicit \"focus question\", while a mind map often has only branches radiating out from a central picture. Some research evidence suggests that the brain stores knowledge as productions (situation-response conditionals) that act on declarative memory content, which is also referred to as chunks or propositions. Because concept maps are constructed to reflect organization of the declarative memory system, they facilitate sense-making and meaningful learning on the part of individuals who make concept maps and those who use them.\n\n\nConcept mapping was developed by Joseph D. Novak and his research team at Cornell University in the 1970s as a means of representing the emerging science knowledge of students. It has subsequently been used as a tool to increase meaningful learning in the sciences and other subjects as well as to represent the expert knowledge of individuals and teams in education, government and business. Concept maps have their origin in the learning movement called constructivism. In particular, constructivists hold that learners actively construct knowledge.\n\nNovak's work is based on the cognitive theories of David Ausubel, who stressed the importance of prior knowledge in being able to learn (or \"assimilate\") new concepts: \"The most important single factor influencing learning is what the learner already knows. Ascertain this and teach accordingly.\" Novak taught students as young as six years old to make concept maps to represent their response to focus questions such as \"What is water?\" \"What causes the seasons?\" In his book \"Learning How to Learn\", Novak states that a \"meaningful learning involves the assimilation of new concepts and propositions into existing cognitive structures.\"\n\nVarious attempts have been made to conceptualize the process of creating concept maps. Ray McAleese, in a series of articles, has suggested that mapping is a process of \"off-loading\". In this 1998 paper, McAleese draws on the work of Sowa and a paper by Sweller & Chandler. In essence, McAleese suggests that the process of making knowledge explicit, using \"nodes\" and \"relationships\", allows the individual to become aware of what they know and as a result to be able to modify what they know. Maria Birbili applies that same idea to helping young children learn to think about what they know. The concept of the \"knowledge arena\" is suggestive of a virtual space where learners may explore what they know and what they do not know.\n\nConcept maps are used to stimulate the generation of ideas, and are believed to aid creativity. Concept mapping is also sometimes used for brain-storming. Although they are often personalized and idiosyncratic, concept maps can be used to communicate complex ideas.\n\nFormalized concept maps are used in software design, where a common usage is Unified Modeling Language diagramming amongst similar conventions and development methodologies.\n\nConcept mapping can also be seen as a first step in ontology-building, and can also be used flexibly to represent formal argument — similar to argument maps.\n\nConcept maps are widely used in education and business. Uses include:\n\n"}
{"id": "42415226", "url": "https://en.wikipedia.org/wiki?curid=42415226", "title": "Conceptual combination", "text": "Conceptual combination\n\nConceptual combination is a fundamental cognitive process by which two or more existing basic concepts are mentally synthesized to generate a composite, higher-order concept. The products of this process are sometimes referred to as \"complex concepts.\" Combining concepts allows individuals to use a finite number of concepts which they already understand to construct a potentially limitless quantity of new, related concepts. It is an essential component of many abilities, such as perception, language, synthetic reasoning, creative thought and abstraction.\n\nConceptual combination is an important concept in the fields of cognitive psychology and cognitive science.\n\nThe mechanism by which conceptual combination occurs is debatable, both on cognitive and neurological levels. As such, multiple models have been developed or applied to better define how the process occurs.\n\nCognitive models attempt to functionally outline the mental computation involved in conceptual combination. \n\nConstraint theory stipulates that the concept that results from an attempt at conceptual combination is controlled by three constraints known as diagnosticity, plausibility and informativeness. \"Diagnosticity\" refers to the a complex concept's possession of the defining properties of its component simple concepts. Because such properties are diagnostic of the component concepts, at least some of them should be diagnostic of the higher-order representations constructed from those concepts. \"Plausibility\" refers to consistency with existing knowledge and prior experience. It is based on the assumption that a complex concept should be reasonably relevant to the context in which it is used. This assumption makes the most sense in a practical, linguistic context, particularly when a speaker is catering to the understanding of the listener. \"Informativeness\" is the property of having more meaning or properties than any individual component. If a complex concept were not distinguishable from any given component, it would be identical to that component. Because nothing can logically be both a component of something and the totality of something simultaneously, a complex concept must at least be the sum of its parts. Many argue that the interaction among component concepts should allow a complex concept to be greater than that sum. If multiple possible ways to structure or interpret a complex concept exist, the one which best satisfies or most satisfies these constraints is the one which will be used. The paradigm upon which constraint theory is based is computational, and therefore views the mind as a processor which operates on the basis of standard problem-solving protocols (i.e. algorithms and heuristics).\n\nThe spreading activation model is a model in connectionist theory sometimes designed to represent how concepts are activated in relation to one another. Though it is typically applied to information search processes like recognition, brainstorming, and recall, it can be used to explain how concepts are combined as well as connected.\n\nSpreading activation models represent memory and knowledge as a network of interlinked concepts. Every concept manifests as a node within this network, with related nodes/concepts linked to one another with connections. Concepts that are more strongly associated with one another either in terms of content or an individual's past experience are correspondingly more strongly linked.\n\nWhen one concept is employed in working memory, the corresponding node is also activated. This activation spreads through the node's links, making it easier to activate nodes to which the activated node is connected. This spreading activation stimulates the linked nodes, pressuring them to activate to an extent proportional to the strength of the connection between the stimulating node and the stimulated node. If sufficient net stimulation is accrued through a stimulated node's links, it will also activate. Thus, being connected to an activated node makes it easier for an inactive node to become active as well; concepts become more readily accessed when individuals are stimulated with related concepts first. This increase in ease of access is known as \"priming.\"\n\nSpreading activation models tend to imply that processing concepts occurs in series; that is, each concept is processed one-at-a-time, one after the other. As such, individuals tend to combine concepts more readily, easily, and quickly if they are more closely linked within the network of concepts. This implication, however, has caused spreading activation to come under a great deal of criticism, particularly with respect to how the concept is employed in feature theories.\n\nThe features and properties of complex concepts are generally assumed to be derived from the simple concepts that compose them. One popularly discussed model involves a two-stage serial process. In the initial stage, features from each of the component simple concepts are retrieved from memory through spreading activation. This allows a complex concept to accrue features with existing relationships with its component simple concepts. During this stage, the basic definition of what the complex concept is and/or means is generates. In the second stage, knowledge and reasoning are employed upon the features accrued in the previous stage to generate further features. For example, one might reason that the complex concept \"white jacket,\" if worn in a blizzard, would make one difficult to see; it would follow that one should ascribe the property of \"good for winter camouflage,\" despite the fact that this property is not closely attached to the component concepts \"white\" nor \"jacket.\" This stage is especially useful when properties of complex concepts contradict those of their component concepts, such as the different colours of milk and chocolate milk.\n\nThis model, however, has come under criticism due to its inconsistency with empirical studies. If conceptual combination employed serial spreading activation, for instance, it should take longer to verify the properties of complex concepts, as they necessarily possess more concepts than their component simple concepts. Research has nonetheless shown that it takes less time to confirm complex concepts' properties than their components and about equal time to reject false properties for both. This occurred even when the properties of the complex concept contradicted those of the simple concepts. Likewise, when experiment participants are exposed to a set of features first, and then asked to verify whether or not they correspond to simple or complex concepts, the participants tend to provide correct verification answers for the complex concepts more quickly.\n\nThe neurological basis of conceptual combination has received considerably less attention than its cognitive basis. Nevertheless, research has revealed several specific brain regions that are intimately involved if not entirely responsible for neural processing involved in conceptual combination.\n\nOf particular relevance is the left anterior temporal lobe. Studies have previously demonstrated an additive effect for stimulation in this subsection of neural cortex tissue. When experiment participants were verbally presented with certain simple concepts, the processing of the information causes electrical stimulation in the region. When the same participants were verbally presented with a single complex concept formed from the combination of the aforementioned simple concepts, the stimulation recorded was equivalent to the sum of the stimulation that resulted from each individual component simple concept. In other words, the stimulation caused by a complex concept is equivalent to the total stimulation caused by its component concepts. More recent data contradicts those results by indicating a multiplicative effect in which the activation caused by a complex concept is the product of the activation levels caused by its component concepts, rather than the sum.\n\nFurther support for the role of the left anterior temporal lobe has been previously established through neuropsychological studies. Semantic dementia is a disorder in which conceptual manipulation, including conceptual combination, is hindered. These indicate that the neural damage associated with semantic dementia occurs within this brain region. Unfortunately, neuropsychological studies that attempt to replicate this pattern have failed, leading uncertainty as to whether initial results were valid.\n\nAs language is the means by which concepts are communicated and expressed, the processed involved in linguistic expression and interpretation are heavily intertwined with combined concepts. Many theories of concept combination mechanisms, including constraint theory were developed within the context of language, and therefore make more sense when applied in a linguistic context. Study into the linguistic aspects of concept combination as has generally been focused on the interpretation mechanism.\n\nA concept that can be expressed using a single word is called a \"lexical concept.\" A lexical concept is usually treated as a basic concept, although it can just as easily be a complex concept.\n\nTwo lexical concepts are often used together as phrases to represent a combined concept of greater specificity. This is most readily seen in the use of adjectives to modify nouns and the use of adverbs to modify verbs and adjectives. Consider, for example, phrases such as \"burnt toast,\" \"eat roughly,\" and \"readily loved.\" Multiple noun lexical concepts can also be used together in order to represent combined concepts. Through this process, a limited pool of nouns can be used to produce an exponentially larger pool of phrases such as \"sound wave,\" \"video game,\" and \"sleeping pill.\"\n\nIn addition to constraint theory, there are two principal theories surrounding the mechanism by which noun-noun combinations are interpreted. The first of these is \"dual-process theory.\" Dual-process theory proposed that there are two means by which people interpreted noun-noun phrases. \"Relational interpretation\" attempts to establish a relationship between the nouns and interprets the combined phrase in terms of that relationship. For example, one might relationally interpret the phrase \"snake mouse\" to refer to a mouse meant to be eaten by snakes, as the two concepts have a predatory relationship. \"Property interpretation\" identifies properties associated with the first noun and then applies them onto the second noun. In this case the phrase \"snake mouse\" might be interpreted as a mouse with poisonous fangs or an elongated body.\n\nThe second principal theory is known as the \"Competition in Relations among Nominals\" theory. It states that the assumed modification effect of a noun on its partner in a novel noun-noun combination is the one which it has been seen to employ most often in the past. For example, \"chocolate cat\" is usually interpreted as \"a cat made of chocolate\" rather than \"a chocolate-eating cat\" simply because the \"made of\" modifier is heavily conditioned to be associated with \"chocolate.\"\n\nExplanations of linguistic expression of complex concepts have been linked to spreading activation models. When an individual identifies a lexical concept through vision or hearing, the corresponding node in that individual's cognitive network is said to activate. This makes it easier for lexical concepts linked to the activated concept to be comprehended, as they are primed. This is consistent with current empirical data, which shows that when individuals are interpreting sentences, they process the linguistic content more quickly when several related words follow one another. In turn, it becomes easier for people to combine these related concepts together and understand them as a relationship, rather than two distinct entities. For example, consider the example, \"John spread butter on a bagel.\" In this sentence, the lexical concepts \"spread,\" \"butter,\" and \"bagel\" are associated with one another and easy to combine into a mental representation of a breakfast scenario. Conversely, consider the example, \"John baked a computer.\" Because \"baked\" and \"computer\" are not related lexical concepts, it takes more effort and time to build a mental representation of this unusual scenario.\n\nHowever, spreading activation models of conceptual combination have been criticized in light of how humans have been observed to combined languages. Those who claim that the theory provides an insufficient account of linguistic conceptual combination refer to the ability of humans to readily understand lexical concept combinations with seemingly no apparent connection with one another. One example of this would be the sentence \"John saw an elephant cloud.\" \"Elephant\" and \"cloud\" do not shared a close association, but it takes little effort to comprehend that the term \"elephant cloud\" refers to a cloud shaped like an elephant. This has led some to conclude that the combination of lexical concepts does not wholly rely on the simultaneous activation of linked lexical concepts alone. Rather, they claim that the process involves the use of existing nodes to generate entirely new concepts independent of their parent concepts.\n\nAlthough many theories of novel noun-noun combination interpretation ignore the effect of social environment, some theorists have attempted to account for any contingencies social context may cause.\n\nWhen lexical concept combinations are interpreted without the influence of social context, the interpretation carried out is termed \"sense generation.\" This includes all processes that would normally occur excepting those dependent on a conversation partner. The \"generation hypothesis\" accordingly states that the interpretation mechanism of a noun-noun combination is essentially the same regardless of context. This does not rule out the possibility that social context can affect sense generation in some way, but it does assert that the basic structure of the process is unaffected. As seen above, debate as to what sense generation entails and how many sub-processes into which it should be divided is a contentious matter in cognitive science.\n\nThe \"anaphor resolution hypothesis\" instead asserts that before sense generation occurs, interpreters first search their memory of recent communication to see if the combination refers to something previously discussed. This process is termed \"anaphor resolution'.' If a referent is identified, interpretation occurs without sense generation in light of that referent. Even if an explicit referent does not exist, anaphor resolution can help facilitate sense generation by providing more information that might hint at the combination's intended meaning.\n\nThe \"dual-process hypothesis\" not to be confused with dual-process theory, states that sense generation and anaphor resolution occur in parallel. Both processes begin to work once the noun-noun combination is presented. Proponents of this hypothesis disagree as to how the interpretation is eventually resolves. Some believe that whichever process reaches a conclusion first provides the answer. Others believe that both provide continuous input to a third, mediating process that eventually makes a decision based on input from both.\n\nCreativity necessitates the employment of existing concepts in novel ways, and therefore requires conceptual combination. Surprisingly, this contribution seems to be limited. Conceptual combination is a significant contributor to convergent thinking, but not divergent thinking. For example, practice with generating new concepts through combination does not improve brainstorming. It does, however, assist in devising creative problem solving methods.\n\nThe psychological community's growing understanding of how concepts are manipulated has allowed educators to teach new concepts more effectively. Tools that are developed based on conceptual combination theory attempt to teach individual tasks, and then challenge students to exercise them together in order to promote both base subject skills and the critical thinking needed to apply them simultaneously to solve new problems. Máder & Vajda, for instance, developed a three-dimensional grid with cells of adjustable height which has been successfully used in numerous activities capable of improving the effectiveness of high school mathematics education.\n"}
{"id": "2381958", "url": "https://en.wikipedia.org/wiki?curid=2381958", "title": "Conceptual model", "text": "Conceptual model\n\nA conceptual model is a representation of a system, made of the composition of concepts which are used to help people know, understand, or simulate a subject the model represents. It is also a set of concepts. Some models are physical objects; for example, a toy model which may be assembled, and may be made to work like the object it represents.\n\nThe term \"conceptual model\" may be used to refer to models which are formed after a conceptualization or generalization process. Conceptual models are often abstractions of things in the real world whether physical or social. Semantic studies are relevant to various stages of concept formation. Semantics is basically about concepts, the meaning that thinking beings give to various elements of their experience.\n\nThe term \"conceptual model\" is normal. It could mean \"a model of concept\" or it could mean \"a model that is conceptual.\" A distinction can be made between \"what models are\" and \"what models are made of\". With the exception of iconic models, such as a scale model of Winchester Cathedral, most models are concepts. But they are, mostly, intended to be models of real world states of affairs. The value of a model is usually directly proportional to how well it corresponds to a past, present, future, actual or potential state of affairs. A model of a concept is quite different because in order to be a good model it need not have this real world correspondence. In artificial intelligence conceptual models and conceptual graphs are used for building expert systems and knowledge-based systems; here the analysts are concerned to represent expert opinion on what is true not their own ideas on what is true.\n\nConceptual models (models that are conceptual) range in type from the more concrete, such as the mental image of a familiar physical object, to the formal generality and abstractness of mathematical models which do not appear to the mind as an image. Conceptual models also range in terms of the scope of the subject matter that they are taken to represent. A model may, for instance, represent a single thing (e.g. the \"Statue of Liberty\"), whole classes of things (e.g. \"the electron\"), and even very vast domains of subject matter such as \"the physical universe.\" The variety and scope of conceptual models is due to then variety of purposes had by the people using them.\nConceptual modeling is the activity of formally describing some aspects of the physical and social world around us for the purposes of understanding and communication.\"\n\nA conceptual model's primary objective is to convey the fundamental principles and basic functionality of the system which it represents. Also, a conceptual model must be developed in such a way as to provide an easily understood system interpretation for the models users. A conceptual model, when implemented properly, should satisfy four fundamental objectives.\n\n\nThe conceptual model plays an important role in the overall system development life cycle. Figure 1 below, depicts the role of the conceptual model in a typical system development scheme. It is clear that if the conceptual model is not fully developed, the execution of fundamental system properties may not be implemented properly, giving way to future problems or system shortfalls. These failures do occur in the industry and have been linked to; lack of user input, incomplete or unclear requirements, and changing requirements. Those weak links in the system design and development process can be traced to improper execution of the fundamental objectives of conceptual modeling. The importance of conceptual modeling is evident when such systemic failures are mitigated by thorough system development and adherence to proven development objectives/techniques.\n\nAs systems have become increasingly complex, the role of conceptual modelling has dramatically expanded. With that expanded presence, the effectiveness of conceptual modeling at capturing the fundamentals of a system is being realized. Building on that realization, numerous conceptual modeling techniques have been created. These techniques can be applied across multiple disciplines to increase the users understanding of the system to be modeled. A few techniques are briefly described in the following text, however, many more exist or are being developed. Some commonly used conceptual modeling techniques and methods include: workflow modeling, workforce modeling, rapid application development, object-role modeling, and the Unified Modeling Language (UML).\n\nData flow modeling (DFM) is a basic conceptual modeling technique that graphically represents elements of a system. DFM is a fairly simple technique, however, like many conceptual modeling techniques, it is possible to construct higher and lower level representative diagrams. The data flow diagram usually does not convey complex system details such as parallel development considerations or timing information, but rather works to bring the major system functions into context. Data flow modeling is a central technique used in systems development that utilizes the structured systems analysis and design method (SSADM).\n\nEntity-relationship modeling (ERM) is a conceptual modeling technique used primarily for software system representation. Entity-relationship diagrams, which are a product of executing the ERM technique, are normally used to represent database models and information systems. The main components of the diagram are the entities and relationships. The entities can represent independent functions, objects, or events. The relationships are responsible for relating the entities to one another. To form a system process, the relationships are combined with the entities and any attributes needed to further describe the process. Multiple diagramming conventions exist for this technique; IDEF1X, Bachman, and EXPRESS, to name a few. These conventions are just different ways of viewing and organizing the data to represent different system aspects.\n\nThe event-driven process chain (EPC) is a conceptual modeling technique which is mainly used to systematically improve business process flows. Like most conceptual modeling techniques, the event driven process chain consists of entities/elements and functions that allow relationships to be developed and processed. More specifically, the EPC is made up of events which define what state a process is in or the rules by which it operates. In order to progress through events, a function/ active event must be executed. Depending on the process flow, the function has the ability to transform event states or link to other event driven process chains. Other elements exist within an EPC, all of which work together to define how and by what rules the system operates. The EPC technique can be applied to business practices such as resource planning, process improvement, and logistics.\n\nThe dynamic systems development method uses a specific process called JEFFF to conceptually model a systems life cycle. JEFFF is intended to focus more on the higher level development planning that precedes a projects initialization. The JAD process calls for a series of workshops in which the participants work to identify, define, and generally map a successful project from conception to completion. This method has been found to not work well for large scale applications, however smaller applications usually report some net gain in efficiency.\n\nAlso known as Petri nets, this conceptual modeling technique allows a system to be constructed with elements that can be described by direct mathematical means. The petri net, because of its nondeterministic execution properties and well defined mathematical theory, is a useful technique for modeling concurrent system behavior, i.e. simultaneous process executions.\n\nState transition modeling makes use of state transition diagrams to describe system behavior. These state transition diagrams use distinct states to define system behavior and changes. Most current modeling tools contain some kind of ability to represent state transition modeling. The use of state transition models can be most easily recognized as logic state diagrams and directed graphs for finite-state machines.\n\nBecause the conceptual modeling method can sometimes be purposefully vague to account for a broad area of use, the actual application of concept modeling can become difficult. To alleviate this issue, and shed some light on what to consider when selecting an appropriate conceptual modeling technique, the framework proposed by Gemino and Wand will be discussed in the following text. However, before evaluating the effectiveness of a conceptual modeling technique for a particular application, an important concept must be understood; Comparing conceptual models by way of specifically focusing on their graphical or top level representations is shortsighted. Gemino and Wand make a good point when arguing that the emphasis should be placed on a conceptual modeling language when choosing an appropriate technique. In general, a conceptual model is developed using some form of conceptual modeling technique. That technique will utilize a conceptual modeling language that determines the rules for how the model is arrived at. Understanding the capabilities of the specific language used is inherent to properly evaluating a conceptual modeling technique, as the language reflects the techniques descriptive ability. Also, the conceptual modeling language will directly influence the depth at which the system is capable of being represented, whether it be complex or simple.\n\nBuilding on some of their earlier work, Gemino and Wand acknowledge some main points to consider when studying the affecting factors: the content that the conceptual model must represent, the method in which the model will be presented, the characteristics of the models users, and the conceptual model languages specific task. The conceptual models content should be considered in order to select a technique that would allow relevant information to be presented. The presentation method for selection purposes would focus on the techniques ability to represent the model at the intended level of depth and detail. The characteristics of the models users or participants is an important aspect to consider. A participant's background and experience should coincide with the conceptual models complexity, else misrepresentation of the system or misunderstanding of key system concepts could lead to problems in that systems realization. The conceptual model language task will further allow an appropriate technique to be chosen. The difference between creating a system conceptual model to convey system functionality and creating a system conceptual model to interpret that functionality could involve to completely different types of conceptual modeling languages.\n\nGemino and Wand go on to expand the affected variable content of their proposed framework by considering the focus of observation and the criterion for comparison. The focus of observation considers whether the conceptual modeling technique will create a \"new product\", or whether the technique will only bring about a more intimate understanding of the system being modeled. The criterion for comparison would weigh the ability of the conceptual modeling technique to be efficient or effective. A conceptual modeling technique that allows for development of a system model which takes all system variables into account at a high level may make the process of understanding the system functionality more efficient, but the technique lacks the necessary information to explain the internal processes, rendering the model less effective.\n\nWhen deciding which conceptual technique to use, the recommendations of Gemino and Wand can be applied in order to properly evaluate the scope of the conceptual model in question. Understanding the conceptual models scope will lead to a more informed selection of a technique that properly addresses that particular model. In summary, when deciding between modeling techniques, answering the following questions would allow one to address some important conceptual modeling considerations.\n\n\nAnother function of the simulation conceptual model is to provide a rational and factual basis for assessment of simulation application appropriateness.\n\nIn cognitive psychology and philosophy of mind, a mental model is a representation of something in the mind, but a mental model may also refer to a nonphysical external model of the mind itself.\n\nA metaphysical model is a type of conceptual model which is distinguished from other conceptual models by its proposed scope; a metaphysical model intends to represent reality in the broadest possible way. This is to say that it explains the answers to fundamental questions such as whether matter and mind are one or two substances; or whether or not humans have free will.\n\nAn epistemological model is a type of conceptual model whose proposed scope is the known and the knowable, and the believed and the believable.\n\nIn logic, a model is a type of interpretation under which a particular statement is true. Logical models can be broadly divided into ones which only attempt to represent concepts, such as mathematical models; and ones which attempt to represent physical objects, and factual relationships, among which are scientific models.\n\nModel theory is the study of (classes of) mathematical structures such as groups, fields, graphs, or even universes of set theory, using tools from mathematical logic. A system that gives meaning to the sentences of a formal language is called a model for the language. If a model for a language moreover satisfies a particular sentence or theory (set of sentences), it is called a model of the sentence or theory. Model theory has close ties to algebra and universal algebra.\n\nMathematical models can take many forms, including but not limited to dynamical systems, statistical models, differential equations, or game theoretic models. These and other types of models can overlap, with a given model involving a variety of abstract structures.\n\nA more comprehensive type of mathematical model uses a linguistic version of category theory to model a given situation. Akin to entity-relationship models, custom categories or sketches can be directly translated into database schemas. The difference is that logic is replaced by category theory, which brings powerful theorems to bear on the subject of modeling, especially useful for translating between disparate models (as functors between categories).\n\nA scientific model is a simplified abstract view of a complex reality. A scientific model represents empirical objects, phenomena, and physical processes in a logical way. Attempts to formalize the principles of the empirical sciences use an interpretation to model reality, in the same way logicians axiomatize the principles of logic. The aim of these attempts is to construct a formal system for which reality is the only interpretation. The world is an interpretation (or model) of these sciences, only insofar as these sciences are true.\n\nA statistical model is a probability distribution function proposed as generating data. In a parametric model, the probability distribution function has variable parameters, such as the mean and variance in a normal distribution, or the coefficients for the various exponents of the independent variable in linear regression. A nonparametric model has a distribution function without parameters, such as in bootstrapping, and is only loosely confined by assumptions. Model selection is a statistical method for selecting a distribution function within a class of them; e.g., in linear regression where the dependent variable is a polynomial of the independent variable with parametric coefficients, model selection is selecting the highest exponent, and may be done with nonparametric means, such as with cross validation.\n\nIn statistics there can be models of mental events as well as models of physical events. For example, a statistical model of customer behavior is a model that is conceptual (because behavior is physical), but a statistical model of customer satisfaction is a model of a concept (because satisfaction is a mental not a physical event).\n\nIn economics, a model is a theoretical construct that represents economic processes by a set of variables and a set of logical and/or quantitative relationships between them. The economic model is a simplified framework designed to illustrate complex processes, often but not always using mathematical techniques. Frequently, economic models use structural parameters. Structural parameters are underlying parameters in a model or class of models. A model may have various parameters and those parameters may change to create various properties.\n\nA system model is the conceptual model that describes and represents the structure, behavior, and more views of a system. A system model can represent multiple views of a system by using two different approaches. The first one is the non-architectural approach and the second one is the architectural approach. The non-architectural approach respectively picks a model for each view. The architectural approach, also known as system architecture, instead of picking many heterogeneous and unrelated models, will use only one integrated architectural model.\n\nIn business process modelling the enterprise process model is often referred to as the \"business process model\". Process models are core concepts in the discipline of process engineering. Process models are:\nThe same process model is used repeatedly for the development of many applications and thus, has many instantiations.\n\nOne possible use of a process model is to prescribe how things must/should/could be done in contrast to the process itself which is really what happens. A process model is roughly an anticipation of what the process will look like. What the process shall be will be determined during actual system development.\n\nConceptual models of human activity systems are used in soft systems methodology (SSM), which is a method of systems analysis concerned with the structuring of problems in management. These models are models of concepts; the authors specifically state that they are not intended to represent a state of affairs in the physical world. They are also used in information requirements analysis (IRA) which is a variant of SSM developed for information system design and software engineering.\n\nLogico-linguistic modeling is another variant of SSM that uses conceptual models. However, this method combines models of concepts with models of putative real world objects and events. It is a graphical representation of modal logic in which modal operators are used to distinguish statement about concepts from statements about real world objects and events.\n\nIn software engineering, an entity-relationship model (ERM) is an abstract and conceptual representation of data. Entity-relationship modeling is a database modeling method, used to produce a type of conceptual schema or semantic data model of a system, often a relational database, and its requirements in a top-down fashion. Diagrams created by this process are called entity-relationship diagrams, ER diagrams, or ERDs.\n\nEntity-relationship models have had wide application in the building of information systems intended to support activities involving objects and events in the real world. In these cases they are models that are conceptual. However, this modeling method can be used to build computer games or a family tree of the Greek Gods, in these cases it would be used to model concepts.\n\nA domain model is a type of conceptual model used to depict the structural elements and their conceptual constraints within a domain of interest (sometimes called the problem domain). A domain model includes the various entities, their attributes and relationships, plus the constraints governing the conceptual integrity of the structural model elements comprising that problem domain. A domain model may also include a number of conceptual views, where each view is pertinent to a particular subject area of the domain or to a particular subset of the domain model which is of interest to a stakeholder of the domain model.\n\nLike entity-relationship models, domain models can be used to model concepts or to model real world objects and events.\n\n\n"}
{"id": "17306829", "url": "https://en.wikipedia.org/wiki?curid=17306829", "title": "Conceptual necessity", "text": "Conceptual necessity\n\nConceptual necessity is a property of the certainty with which a state of affairs, as presented by a certain description, occurs: it occurs by conceptual necessity if and only if it occurs just by virtue of the meaning of the description. If someone is a bachelor, for instance, then he is bound to be unmarried by conceptual necessity, because the meaning of the word \"bachelor\" determines that he is.\n\nAlternatively, there is metaphysical necessity, which is a certainty determined, not by the meaning of a description, but instead by facts in the world described.\n\nHistorically, Baruch Spinoza was a subscriber to this belief.\n\n"}
{"id": "58267", "url": "https://en.wikipedia.org/wiki?curid=58267", "title": "Conceptual schema", "text": "Conceptual schema\n\nA 'conceptual schema' is a high-level description of a business's informational needs. It typically includes only the main concepts and the main relationships among them. Typically this is a first-cut model, with insufficient detail to build an actual database. This level describes the structure of the whole database for a group of users. The conceptual model is also known as the data model that can be used to describe the conceptual schema when a database system is implemented. It hides the internal details of physical storage and targets on describing entities, datatype, relationships and constraints.\n\nA conceptual schema or conceptual data model is a map of concepts and their relationships used for databases. This describes the semantics of an organization and represents a series of assertions about its nature. Specifically, it describes the things of significance to an organization (\"entity classes\"), about which it is inclined to collect information, and characteristics of (\"attributes\") and associations between pairs of those things of significance (\"relationships\").\n\nBecause a conceptual schema represents the semantics of an organization, and not a database design, it may exist on various levels of abstraction. The original ANSI four-schema architecture began with the set of \"external schema\" that each represent one person's view of the world around him or her. These are consolidated into a single \"conceptual schema\" that is the superset of all of those external views. A data model can be as concrete as each person's perspective, but this tends to make it inflexible. If that person's world changes, the model must change. Conceptual data models take a more abstract perspective, identifying the fundamental things, of which the things an individual deals with are just examples.\n\nThe model does allow for what is called inheritance in object oriented terms. The set of instances of an entity class may be subdivided into entity classes in their own right. Thus, each instance of a \"sub-type\" entity class is also an instance of the entity class's \"super-type\". Each instance of the super-type entity class, then is also an instance of one of the sub-type entity classes.\n\nSuper-type/sub-type relationships may be \"exclusive\" or not. A methodology may require that each instance of a super-type may \"only\" be an instance of \"one\" sub-type. Similarly, a super-type/sub-type relationship may be \"exhaustive\" or not. It is exhaustive if the methodology requires that each instance of a super-type \"must be\" an instance of a sub-type. A sub-type named other is often necessary.\n\n\nA data structure diagram (DSD) is a data model or diagram used to describe conceptual data models by providing graphical notations which document entities and their relationships, and the constraints that bind them.\n\n\n\n"}
{"id": "47792266", "url": "https://en.wikipedia.org/wiki?curid=47792266", "title": "Construction of Concept Map", "text": "Construction of Concept Map\n\nConcept is usually perceived as a regularity in events or objects or in their records. While constructing a concept map, it is essential to keep in mind that the concept be built with reference to a focus question. Hence, initially, the focus question to which we seek to answer is carefully chosen because learners usually tend to deviate from this question relating only to domains and thus, fails to answer the question.\n\nWith the selected domain and the focus question, the next step is to identify the key concepts which apply to this domain.About 15 to 25 concepts is sufficient which is usually ordered in a rank ordered list. Such list should be established from the most general and inclusive concept for the particular chosen problem. This list will assist in at least in the beginning of the construction of the concept map. The list is referred to as Parking Lot since the list is constantly shuffled to build up the required network of the concept. Two or more concepts are connected to each other using linking words or phrases which can only then complete a meaningful sentence.Another important characteristics of a concept map is the cross-links. This cross link acts as the relationship between two different domains used in the concept map.This helps in a clear representation of the knowledge contained in the concept and also gives a clear background with specific examples. \n"}
{"id": "26167139", "url": "https://en.wikipedia.org/wiki?curid=26167139", "title": "Definitionism", "text": "Definitionism\n\nDefinitionism (also called the classical theory of concepts) is the school of thought in which it is believed that a proper explanation of a theory consists of all the concepts used by that theory being well-defined. This approach has been criticized for its dismissal of the importance of ostensive definitions.\n"}
{"id": "1973470", "url": "https://en.wikipedia.org/wiki?curid=1973470", "title": "Fuzzy concept", "text": "Fuzzy concept\n\nA fuzzy concept is a concept of which the boundaries of application can vary considerably according to context or conditions, instead of being fixed once and for all. This means the concept is vague in some way, lacking a fixed, precise meaning, without however being unclear or meaningless altogether. It has a definite meaning, which can be made more precise only through further elaboration and specification - including a closer definition of the context in which the concept is used. The study of the characteristics of fuzzy concepts and fuzzy language is called \"fuzzy semantics\". The inverse of a \"fuzzy concept\" is a \"crisp concept\" (i.e. a precise concept). \n\nA fuzzy concept is understood by scientists as a concept which is \"to an extent applicable\" in a situation. That means the concept has \"gradations\" of significance or \"unsharp\" (variable) boundaries of application. A fuzzy statement is a statement which is true \"to some extent\", and that extent can often be represented by a scaled value. The best known example of a fuzzy concept around the world is an amber traffic light, and indeed fuzzy concepts are widely used in traffic control systems. The term is also used these days in a more general, popular sense - in contrast to its technical meaning - to refer to a concept which is \"rather vague\" for any kind of reason.\n\nIn the past, the very idea of reasoning with fuzzy concepts faced considerable resistance from academic elites. They did not want to endorse the use of imprecise concepts in research or argumentation. Yet although people might not be aware of it, the use of fuzzy concepts has risen gigantically in all walks of life from the 1970s onward. That is mainly due to advances in electronic engineering, fuzzy mathematics and digital computer programming. The new technology allows very complex inferences about \"variations on a theme\" to be anticipated and fixed in a program. \n\nThe new neuro-fuzzy computational methods make it possible, to identify, to measure and respond to fine gradations of significance, with great precision. It means that practically useful concepts can be coded and applied to all kinds of tasks, even if, ordinarily, these concepts are never precisely defined. Nowadays engineers, statisticians and programmers often represent fuzzy concepts mathematically, using fuzzy logic, fuzzy values, fuzzy variables and fuzzy sets.\n\nProblems of vagueness and fuzziness have probably always existed in human experience. The boundary between different things can appear blurry. Sometimes people have to think, when they are not in the best frame of mind to do it, or, they have to talk about something out there, which just isn't sharply defined. Across time, however, philosophers and scientists began to reflect about those kinds of problems, in much more systematic ways.\n\nThe ancient Sorites paradox first raised the logical problem of how we could exactly define the threshold at which a change in quantitative gradation turns into a qualitative or categorical difference. With some physical processes this threshold is relatively easy to identify. For example, water turns into steam at 100 °C or 212 °F (the boiling point depends partly on atmospheric pressure, which decreases at higher altitudes). \n\nWith many other processes and gradations, however, the point of change is much more difficult to locate, and remains somewhat vague. Thus, the boundaries between qualitatively different things may be \"unsharp\": we know that there are boundaries, but we cannot define them exactly. \n\nAccording to the modern idea of the continuum fallacy, the fact that a statement is to an extent vague, does not automatically mean that it is invalid. The problem then becomes one of how we could ascertain the kind of validity that the statement does have.\n\nThe Nordic myth of Loki's wager suggested that concepts that lack precise meanings or precise boundaries of application cannot be usefully discussed at all. However, the 20th century idea of \"fuzzy concepts\" proposes that \"somewhat vague terms\" can be operated with, since we can explicate and define the variability of their application, by assigning numbers to gradations of applicability. This idea sounds simple enough, but it had large implications.\n\nThe intellectual origins of the species of fuzzy concepts as a logical category have been traced back to a diversity of famous and less well-known thinkers, including (among many others) Eubulides, Plato, Cicero, Georg Wilhelm Friedrich Hegel, Karl Marx and Friedrich Engels, Friedrich Nietzsche, Hugh MacColl, Charles S. Peirce, Max Black, Jan Łukasiewicz, Emil Leon Post, Alfred Tarski, Georg Cantor, Nicolai A. Vasiliev, Kurt Gödel, Stanisław Jaśkowski and Donald Knuth. \n\nAcross at least two and a half millennia, all of them had something to say about graded concepts with unsharp boundaries. This suggests at least that the awareness of the existence of concepts with \"fuzzy\" characteristics, in one form or another, has a very long history in human thought. Quite a few logicians and philosophers have also tried to \"analyze\" the characteristics of fuzzy concepts as a recognized species, sometimes with the aid of some kind of many-valued logic or substructural logic.\n\nAn early attempt in the post-WW2 era to create a theory of sets where set membership is a matter of degree was made by Abraham Kaplan and Hermann Schott in 1951. They intended to apply the idea to empirical research. Kaplan and Schott measured the degree of membership of empirical classes using real numbers between 0 and 1, and they defined corresponding notions of intersection, union, complementation and subset. However, at the time, their idea \"fell on stony ground\". J. Barkley Rosser Sr. published a treatise on many-valued logics in 1952, anticipating \"many-valued sets\". Another treatise was published in 1963 by Aleksandr A. Zinov'ev and others\n\nIn 1964, the American philosopher William Alston introduced the term \"degree vagueness\" to describe vagueness in an idea that results from the absence of a definite cut-off point along an implied scale (in contrast to \"combinatory vagueness\" caused by a term that has a number of logically independent conditions of application). \n\nThe German mathematician Dieter Klaua published a German-language paper on fuzzy sets in 1965, but he used a different terminology (he referred to \"many-valued sets\", not \"fuzzy sets\").\n\nTwo popular introductions to many-valued logic in the late 1960s were by Robert J. Ackermann and Nicholas Rescher respectively. Rescher’s book includes a bibliography on fuzzy theory up to 1965, which was extended by Robert Wolf for 1966-1974. Haack provides references to significant works after 1974. Bergmann provides a more recent (2008) introduction to fuzzy reasoning.\n\nUsually the Iranian-born American computer scientist Lotfi A. Zadeh (1921-2017) is credited with inventing the specific idea of a \"fuzzy concept\" in his seminal 1965 paper on fuzzy sets, because he gave a formal mathematical presentation of the phenomenon that was widely accepted by scholars.<ref>Lotfi A. Zadeh, \"Fuzzy sets\". In: \"Information and Control\", Vol. 8, June 1965, pp. 338–353.\n\n"}
{"id": "166213", "url": "https://en.wikipedia.org/wiki?curid=166213", "title": "Human condition", "text": "Human condition\n\nThe human condition is \"the characteristics, key events, and situations which compose the essentials of human existence, such as birth, growth, emotionality, aspiration, conflict, and mortality\". This is a very broad topic which has been and continues to be pondered and analyzed from many perspectives, including those of religion, philosophy, history, art, literature, anthropology, psychology, and biology.\n\nAs a literary term, \"the human condition\" is typically used in the context of ambiguous subjects such as the meaning of life or moral concerns.\n\nEach major religion has definitive beliefs regarding the human condition. For example, Buddhism teaches that life is a perpetual cycle of suffering, death, and rebirth from which humans can be liberated via the Noble Eightfold Path. Meanwhile, Christianity teaches that humans are born in a sinful condition and are doomed in the afterlife unless they receive salvation through Jesus Christ.\n\nPhilosophers have provided many perspectives. An influential ancient view was that of the \"Republic\" in which Plato explored the question \"what is justice?\" and postulated that it is not primarily a matter among individuals but of society as a whole, prompting him to devise a utopia. Two thousand years later René Descartes declared \"I think, therefore I am\" because he believed the human mind, particularly its faculty of reason, to be the primary determiner of truth; for this he is often credited as the father of modern philosophy. One such modern school, existentialism, attempts to reconcile an individual's sense of disorientation and confusion in a universe believed to be absurd.\n\nMany works of literature provide perspective on the human condition. One famous example is Shakespeare's monologue \"All the world's a stage\" that pensively summarizes seven phases of human life.\n\nPsychology has many theories, such as Maslow's hierarchy of needs and the notion of identity crisis. It also has various methods, e.g. the logotherapy developed by Holocaust survivor Viktor Frankl to discover and affirm human meaning. Another method, cognitive behavioral therapy, has become a widespread treatment for clinical depression.\n\nEver since 1859, when Charles Darwin published \"On the Origin of Species\", the biological theory of evolution has been significant. The theory posits that the human species is related to all others, living and extinct, and that natural selection is the primary survival factor. This has provided a basis for new beliefs, e.g. social Darwinism, and for new technology, e.g. antibiotics.\n\nNotable uses of the term \"the human condition\" include André Malraux's novel \"Man's Fate\", René Magritte's painting \"La Condition Humaine\", Hannah Arendt's political philosophy, and Masaki Kobayashi's film trilogy.\n\n"}
{"id": "161999", "url": "https://en.wikipedia.org/wiki?curid=161999", "title": "Idea", "text": "Idea\n\nIn philosophy, ideas are usually taken as mental representational images of some object. Ideas can also be abstract concepts that do not present as mental images. Many philosophers have considered ideas to be a fundamental ontological category of being. The capacity to create and understand the meaning of ideas is considered to be an essential and defining feature of human beings. In a popular sense, an idea arises in a reflexive, spontaneous manner, even without thinking or serious reflection, for example, when we talk about the \"idea\" of a person or a place. A new or original idea can often lead to innovation.\n\nThe word \"idea\" comes from Greek ἰδέα \"idea\" \"form, pattern,\" from the root of ἰδεῖν \"idein\", \"to see.\" \n\nOne view on the nature of ideas is that there exist some ideas (called \"innate ideas\") which are so general and abstract that they could not have arisen as a representation of an object of our perception but rather were in some sense always present. These are distinguished from \"adventitious ideas\" which are images or concepts which are accompanied by the judgment that they are caused or occasioned by an external object.\n\nAnother view holds that we only discover ideas in the same way that we discover the real world, from personal experiences. The view that humans acquire all or almost all their behavioral traits from nurture (life experiences) is known as \"tabula rasa\" (\"blank slate\"). Most of the confusions in the way ideas arise is at least in part due to the use of the term \"idea\" to cover both the representation perceptics and the object of conceptual thought. This can be always illustrated in terms of the scientific doctrines of innate ideas, \"concrete ideas versus abstract ideas\", as well as \"simple ideas versus complex ideas\".\n\nPlato in Ancient Greece was one of the earliest philosophers to provide a detailed discussion of ideas and of the thinking process (it must be noted that in Plato's Greek the word \"idea\" carries a rather different sense from our modern English term). Plato argued in dialogues such as the \"Phaedo\", \"Symposium\", \"Republic\", and \"Timaeus\" that there is a realm of ideas or forms (\"eidei\"), which exist independently of anyone who may have thoughts on these ideas, and it is the ideas which distinguish mere opinion from knowledge, for unlike material things which are transient and liable to contrary properties, ideas are unchanging and nothing but just what they are. Consequently, Plato seems to assert forcefully that material things can only be the objects of opinion; real knowledge can only be had of unchanging ideas. Furthermore, ideas for Plato appear to serve as universals; consider the following passage from the \"Republic\":\nDescartes often wrote of the meaning of \"idea\" as an image or representation, often but not necessarily \"in the mind\", which was well known in the vernacular. Despite that Descartes is usually credited with the invention of the non-Platonic use of the term, he at first followed this vernacular use. In his \"Meditations on First Philosophy\" he says, \"Some of my thoughts are like images of things, and it is to these alone that the name 'idea' properly belongs.\" He sometimes maintained that ideas were innate and uses of the term \"idea\" diverge from the original primary scholastic use. He provides multiple non-equivalent definitions of the term, uses it to refer to as many as six distinct kinds of entities, and divides \"ideas\" inconsistently into various genetic categories. For him knowledge took the form of ideas and philosophical investigation is the deep consideration of these entities.\n\nIn striking contrast to Plato's use of idea is that of John Locke. In his Introduction to An Essay Concerning Human Understanding, Locke defines \"idea\" as \"that term which, I think, serves best to stand for whatsoever is the object of the understanding when a man thinks, I have used it to express whatever is meant by phantasm, notion, species, or whatever it is which the mind can be employed about in thinking; and I could not avoid frequently using it.\" He said he regarded the book necessary to examine our own abilities and see what objects our understandings were, or were not, fitted to deal with. In his philosophy other outstanding figures followed in his footsteps — Hume and Kant in the 18th century, Arthur Schopenhauer in the 19th century, and Bertrand Russell, Ludwig Wittgenstein, and Karl Popper in the 20th century. Locke always believed in \"good sense\" — not pushing things to extremes and on taking fully into account the plain facts of the matter. He considered his common-sense ideas \"good-tempered, moderate, and down-to-earth.\"\n\nAs John Locke studied humans in his work “An Essay Concerning Human Understanding” he continually referenced Descartes for ideas as he asked this fundamental question: “When we are concerned with something about which we have no certain knowledge, what rules or standards should guide how confident we allow ourselves to be that our opinions are right?” A simpler way of putting it is how do humans know ideas, and what are the different types of ideas. An idea to Locke “can simply mean some sort of brute experience.” He shows that there are “No innate principles in the mind.”. Thus, he concludes that “our ideas are all experiential in nature.” An experience can either be a sensation or a reflection: “consider whether there are any innate ideas in the mind before any are brought in by the impression from sensation or reflection.” Therefore, an idea was an experience in which the human mind apprehended something.\n\nIn a Lockean view, there are really two types of ideas: complex and simple. Simple ideas are the building blocks for much more complex ideas, and “While the mind is wholly passive in the reception of simple ideas, it is very active in the building of complex ideas…” Complex ideas, therefore, can either be modes, substances, or relations. Modes are when ideas are combined in order to convey new information. For instance, David Banach gives the example of beauty as a mode. He says that it is the combination of color and form. Substances, however, is different. Substances are certain objects, that can either be dogs, cats, or tables. And relations represent the relationship between two or more ideas. In this way, Locke did, in fact, answer his own questions about ideas and humans.\n\nHume differs from Locke by limiting \"idea\" to the more or less vague mental reconstructions of perceptions, the perceptual process being described as an \"impression.\" Hume shared with Locke the basic empiricist premise that it is only from life experiences (whether their own or others') that humans' knowledge of the existence of anything outside of themselves can be ultimately derived, that they shall carry on doing what they are prompted to do by their emotional drives of varying kinds. In choosing the means to those ends, they shall follow their accustomed associations of ideas. Hume has contended and defended the notion that \"reason alone is merely the 'slave of the passions'.\" \n\nImmanuel Kant defines an \"idea\" as opposed to a \"concept\". \"Regulative ideas\" are ideals that one must tend towards, but by definition may not be completely realized. Liberty, according to Kant, is an idea. The autonomy of the rational and universal subject is opposed to the determinism of the empirical subject. Kant felt that it is precisely in knowing its limits that philosophy exists. The business of philosophy he thought was not to give rules, but to analyze the private judgements of good common sense.\n\nWhereas Kant declares limits to knowledge (\"we can never know the thing in itself\"), in his epistemological work, Rudolf Steiner sees \"ideas\" as \"objects of experience\" which the mind apprehends, much as the eye apprehends light. In \"Goethean Science\" (1883), he declares, \"Thinking ... is no more and no less an organ of perception than the eye or ear. Just as the eye perceives colors and the ear sounds, so thinking perceives ideas.\" He holds this to be the premise upon which Goethe made his natural-scientific observations.\n\nWundt widens the term from Kant's usage to include \"conscious representation of some object or process of the external world\". In so doing, he includes not only ideas of memory and imagination, but also perceptual processes, whereas other psychologists confine the term to the first two groups. One of Wundt's main concerns was to investigate conscious processes in their own context by experiment and introspection. He regarded both of these as \"exact methods\", interrelated in that experimentation created optimal conditions for introspection. Where the experimental method failed, he turned to other \"objectively valuable aids\", specifically to \"those products of cultural communal life which lead one to infer particular mental motives. Outstanding among these are speech, myth, and social custom.\" Wundt designed the basic mental activity apperception — a unifying function which should be understood as an activity of the will. Many aspects of his empirical physiological psychology are used today. One is his principles of mutually enhanced contrasts and of assimilation and dissimilation (i.e. in color and form perception and his advocacy of \"objective\" methods of expression and of recording results, especially in language. Another is the principle of heterogony of ends — that multiply motivated acts lead to unintended side effects which in turn become motives for new actions.\n\nC. S. Peirce published the first full statement of pragmatism in his important works \"\" (1878) and \"\" (1877). In \"How to Make Our Ideas Clear\" he proposed that a \"clear idea\" (in his study he uses concept and \"idea\" as synonymic) is defined as one, when it is apprehended such as it will be recognized wherever it is met, and no other will be mistaken for it. If it fails of this clearness, it is said to be obscure. He argued that to understand an idea clearly we should ask ourselves what difference its application would make to our evaluation of a proposed solution to the problem at hand. Pragmatism (a term he appropriated for use in this context), he defended, was a method for ascertaining the meaning of terms (as a theory of meaning). The originality of his ideas is in their rejection of what was accepted as a view and understanding of knowledge by scientists for some 250 years, i.e. that, he pointed, knowledge was an impersonal fact. Peirce contended that we acquire knowledge as \"participants\", not as \"spectators\". He felt \"the real\", sooner or later, is information acquired through ideas and knowledge with the application of logical reasoning would finally result in. He also published many papers on logic in relation to \"ideas\".\n\nG. F. Stout and J. M. Baldwin, in the \"Dictionary of Philosophy and Psychology\", define \"idea\" as \"the reproduction with a more or less adequate image, of an object not actually present to the senses.\" They point out that an idea and a perception are by various authorities contrasted in various ways. \"Difference in degree of intensity\", \"comparative absence of bodily movement on the part of the subject\", \"comparative dependence on mental activity\", are suggested by psychologists as characteristic of an idea as compared with a perception.\n\nIt should be observed that an idea, in the narrower and generally accepted sense of a mental reproduction, is frequently composite. That is, as in the example given above of the idea of a chair, a great many objects, differing materially in detail, all call a single idea. When a man, for example, has obtained an idea of chairs in general by comparison with which he can say \"This is a chair, that is a stool\", he has what is known as an \"abstract idea\" distinct from the reproduction in his mind of any particular chair (see abstraction). Furthermore, a complex idea may not have any corresponding physical object, though its particular constituent elements may severally be the reproductions of actual perceptions. Thus the idea of a centaur is a complex mental picture composed of the ideas of man and horse, that of a mermaid of a woman and a fish.\n\nDiffusion studies explore the spread of ideas from culture to culture. Some anthropological theories hold that all cultures imitate ideas from one or a few original cultures, the Adam of the Bible, or several cultural circles that overlap. Evolutionary diffusion theory holds that cultures are influenced by one another but that similar ideas can be developed in isolation.\n\nIn the mid-20th century, social scientists began to study how and why ideas spread from one person or culture to another. Everett Rogers pioneered diffusion of innovations studies, using research to prove factors in adoption and profiles of adopters of ideas. In 1976, in his book \"The Selfish Gene\", Richard Dawkins suggested applying biological evolutionary theories to the spread of ideas. He coined the term \"meme\" to describe an abstract unit of selection, equivalent to the gene in evolutionary biology.\n\nJames Boswell recorded Samuel Johnson's opinion about ideas. Johnson claimed that they are mental images or internal visual pictures. As such, they have no relation to words or the concepts which are designated by verbal names.\n\nTo protect the cause of invention and innovation, the legal constructions of Copyrights and Patents were established. Patent law regulates various aspects related to the functional manifestation of inventions based on new ideas or incremental improvements to existing ones. Thus, patents have a direct relationship to ideas.\n\nIn some cases, authors can be granted limited legal monopolies on the manner in which certain works are expressed. This is known colloquially as copyright, although the term intellectual property is used mistakenly in place of \"copyright\". Copyright law regulating the aforementioned monopolies generally does not cover the actual ideas. The law does not bestow the legal status of property upon ideas per se. Instead, laws purport to regulate events related to the usage, copying, production, sale and other forms of exploitation of the fundamental expression of a work, that may or may not carry ideas. Copyright law is fundamentally different from patent law in this respect: patents do grant monopolies on ideas (more on this below).\n\nA copyright is meant to regulate some aspects of the usage of expressions of a work, \"not\" an idea. Thus, copyrights have a negative relationship to ideas.\n\nWork means a tangible medium of expression. It may be an original or derivative work of art, be it literary, dramatic, musical recitation, artistic, related to sound recording, etc. In (at least) countries adhering to the Berne Convention, copyright automatically starts covering the work upon the original creation and fixation thereof, without any extra steps. While creation usually involves an idea, the idea in itself does not suffice for the purposes of claiming copyright. \nConfidentiality and nondisclosure agreements are legal instruments that assist corporations and individuals in keeping ideas from escaping to the general public. Generally, these instruments are covered by contract law.\n\n\n"}
{"id": "34644725", "url": "https://en.wikipedia.org/wiki?curid=34644725", "title": "Jurisprudence of concepts", "text": "Jurisprudence of concepts\n\nThe jurisprudence of concepts was the first \"sub-school\" of legal positivism, according to which, the written law must reflect concepts, when interpreted. Its main representatives were Ihering, Savigny and Puchta.\n\nThis school was, thus, the preceding trigger of the idea that law comes from a dogmatic source, imposition from man over man and not a \"natural\" consequence of other sciences or of metaphysical faith.\n\nAmong the main characters of the \"jurisprudence of concepts\" are:\n\nSo, according to this school, law should have prevailing sources based upon the legislative process, although needing to be proven by more inclusive ideas of a social sense.\n\n"}
{"id": "25200737", "url": "https://en.wikipedia.org/wiki?curid=25200737", "title": "Knowledge arena", "text": "Knowledge arena\n\nA knowledge arena is a virtual space where individuals can manipulate concepts and relationships to form a concept map. Individuals using a computer with appropriate software can represent concepts and the relationships between concepts in a node-relationship-node formalism. The process of thinking about the concepts and making associations between them has been called \"off-loading\" by McAleese.\n\nThe concept map is a form of a semantic network or semantic graph. It is formally based on graph theory. In the concept map, concepts are represented by nodes. The relationship between nodes are represented by \"typed links\" or \"edges\". (See Graph theory.) In creating a map or graphic representation of what is known an individual intentionally interacts with the graphical interface or map and through a reflective process adds nodes (concepts) and /or adds relationships (edges or typed links) or modifies existing node-relationship-node instances. It is likely that the process of engaging with concepts and relationships between concepts brings about the creation of understandings as well as making the understandings explicit.\n\nMany different claims have been made for the utility of the concept map. The interactive and reflective nature of map creation is highlighted by the use of the description Knowledge Arena. Although maps may represent what an individual knows at a point in time; it is likely that by interacting with the concepts and relationships in the knowledge arena individual continues to create and modify what that individual \"knows\".\n\nSee also \n"}
{"id": "599917", "url": "https://en.wikipedia.org/wiki?curid=599917", "title": "Mental image", "text": "Mental image\n\nA mental image or mental picture is the representation in a person's mind of the physical world outside that person. It is an experience that, on most occasions, significantly resembles the experience of perceiving some object, event, or scene, but occurs when the relevant object, event, or scene is not actually present to the senses. There are sometimes episodes, particularly on falling asleep (hypnagogic imagery) and waking up (hypnopompic), when the mental imagery, being of a rapid, phantasmagoric and involuntary character, defies perception, presenting a kaleidoscopic field, in which no distinct object can be discerned. Mental imagery can sometimes produce the same effects as would be produced by the behavior or experience imagined.\n\nThe nature of these experiences, what makes them possible, and their function (if any) have long been subjects of research and controversy in philosophy, psychology, cognitive science, and, more recently, neuroscience. As contemporary researchers use the expression, mental images or imagery can comprise information from any source of sensory input; one may experience auditory images, olfactory images, and so forth. However, the majority of philosophical and scientific investigations of the topic focus upon \"visual\" mental imagery. It has sometimes been assumed that, like humans, some types of animals are capable of experiencing mental images. Due to the fundamentally introspective nature of the phenomenon, there is little to no evidence either for or against this view.\n\nPhilosophers such as George Berkeley and David Hume, and early experimental psychologists such as Wilhelm Wundt and William James, understood ideas in general to be mental images. Today it is very widely believed that much imagery functions as mental representations (or mental models), playing an important role in memory and thinking. William Brant (2013, p. 12) traces the scientific use of the phrase \"mental images\" back to John Tyndall's 1870 speech called the \"Scientific Use of the Imagination\". Some have gone so far as to suggest that images are best understood to be, by definition, a form of inner, mental or neural representation; in the case of hypnagogic and hypnapompic imagery, it is not representational at all. Others reject the view that the image experience may be identical with (or directly caused by) any such representation in the mind or the brain, but do not take account of the non-representational forms of imagery.\n\nIn 2010, IBM applied for a patent on a method to extract mental images of human faces from the human brain. It uses a feedback loop based on brain measurements of the fusiform face area in the brain that activates proportionate with degree of facial recognition. It was issued in 2015.\n\nThe notion of a \"mind's eye\" goes back at least to Cicero's reference to mentis oculi during his discussion of the orator's appropriate use of simile.\n\nIn this discussion, Cicero observed that allusions to \"the Syrtis of his patrimony\" and \"the Charybdis of his possessions\" involved similes that were \"too far-fetched\"; and he advised the orator to, instead, just speak of \"the rock\" and \"the gulf\" (respectively)—on the grounds that \"the eyes of the mind are more easily directed to those objects which we have seen, than to those which we have only heard\".\n\nThe concept of \"the mind's eye\" first appeared in English in Chaucer's (c. 1387) Man of Law's Tale in his \"Canterbury Tales\", where he tells us that one of the three men dwelling in a castle was blind, and could only see with \"the eyes of his mind\"; namely, those eyes \"with which all men see after they have become blind\".\n\nThe biological foundation of the mind's eye is not fully understood. Studies using fMRI have shown that the lateral geniculate nucleus and the V1 area of the visual cortex are activated during mental imagery tasks. Ratey writes:\nThe visual pathway is not a one-way street. Higher areas of the brain can also send visual input back to neurons in lower areas of the visual cortex. [...] As humans, we have the ability to see with the mind's eye – to have a perceptual experience in the absence of visual input. For example, PET scans have shown that when subjects, seated in a room, imagine they are at their front door starting to walk either to the left or right, activation begins in the visual association cortex, the parietal cortex, and the prefrontal cortex - all higher cognitive processing centers of the brain.\n\nThe rudiments of a biological basis for the mind's eye is found in the deeper portions of the brain below the neocortex, or where the center of perception exists. The thalamus has been found to be discrete to other components in that it processes all forms of perceptional data relayed from both lower and higher components of the brain. Damage to this component can produce permanent perceptual damage, however when damage is inflicted upon the cerebral cortex, the brain adapts to neuroplasticity to amend any occlusions for perception. It can be thought that the neocortex is a sophisticated memory storage warehouse in which data received as an input from sensory systems are compartmentalized via the cerebral cortex. This would essentially allow for shapes to be identified, although given the lack of filtering input produced internally, one may as a consequence, hallucinate - essentially seeing something that isn't received as an input externally but rather internal (i.e. an error in the filtering of segmented sensory data from the cerebral cortex may result in one seeing, feeling, hearing or experiencing something that is inconsistent with reality).\n\nNot all people have the same internal perceptual ability. For many, when the eyes are closed, the perception of darkness prevails. However, some people are able to perceive colorful, dynamic imagery. The use of hallucinogenic drugs increases the subject's ability to consciously access visual (and auditory, and other sense) percepts.\n\nFurthermore, the pineal gland is a hypothetical candidate for producing a mind's eye; Rick Strassman and others have postulated that during near-death experiences (NDEs) and dreaming, the gland might secrete a hallucinogenic chemical \"N\",\"N\"-Dimethyltryptamine (DMT) to produce internal visuals when external sensory data is occluded. However, this hypothesis has yet to be fully supported with neurochemical evidence and plausible mechanism for DMT production.\n\nThe hypothesized condition where a person lacks a mind's eye is called aphantasia. The term was first suggested in a 2015 study.\n\nCommon examples of mental images include daydreaming and the mental visualization that occurs while reading a book. Another is of the pictures summoned by athletes during training or before a competition, outlining each step they will take to accomplish their goal. When a musician hears a song, he or she can sometimes \"see\" the song notes in their head, as well as hear them with all their tonal qualities. This is considered different from an after-effect, such as an after-image. Calling up an image in our minds can be a voluntary act, so it can be characterized as being under various degrees of conscious control.\n\nAccording to psychologist and cognitive scientist Steven Pinker, our experiences of the world are represented in our minds as mental images. These mental images can then be associated and compared with others, and can be used to synthesize completely new images. In this view, mental images allow us to form useful theories of how the world works by formulating likely sequences of mental images in our heads without having to directly experience that outcome. Whether other creatures have this capability is debatable.\n\nThere are several theories as to how mental images are formed in the mind. These include the dual-code theory, the propositional theory, and the functional-equivalency hypothesis. The dual-code theory, created by Allan Paivio in 1971, is the theory that we use two separate codes to represent information in our brains: image codes and verbal codes. Image codes are things like thinking of a picture of a dog when you are thinking of a dog, whereas a verbal code would be to think of the word \"dog\". Another example is the difference between thinking of abstract words such as \"justice\" or \"love\" and thinking of concrete words like \"elephant\" or \"chair.\" When abstract words are thought of, it is easier to think of them in terms of verbal codes—finding words that define them or describe them. With concrete words, it is often easier to use image codes and bring up a picture of a \"human\" or \"chair\" in your mind rather than words associated or descriptive of them.\n\nThe propositional theory involves storing images in the form of a generic propositional code that stores the meaning of the concept not the image itself. The propositional codes can either be descriptive of the image or symbolic. They are then transferred back into verbal and visual code to form the mental image.\n\nThe functional-equivalency hypothesis is that mental images are \"internal representations\" that work in the same way as the actual perception of physical objects. In other words, the picture of a dog brought to mind when the word \"dog\" is read is interpreted in the same way as if the person looking at an actual dog before them.\n\nResearch has occurred to designate a specific neural correlate of imagery; however, studies show a multitude of results. Most studies published before 2001 suggest neural correlates of visual imagery occur in brodmann area 17. Auditory performance imagery have been observed in the premotor areas, precunes, and medial brodmann area 40. Auditory imagery in general occurs across participants in the temporal voice area (TVA), which allows top-down imaging manipulations, processing, and storage of audition functions. Olfactory imagery research shows activation in the anterior piriform cortex and the posterior piriform cortex; experts in olfactory imagery have larger gray matter associated to olfactory areas. Tactile imagery is found to occur in the dorsolateral prefrontal area, inferior frontal gyrus, frontal gyrus, insula, precentral gyrus, and the medial frontal gyrus with basil ganglia activation in the ventral posteriomedial nucleus and putamen (hemisphere activation corresponds to the location of the imagined tactile stimulus). Research in gustatory imagery reveals activation in the anterior insular cortex, frontal operculum, and prefrontal cortex. Novices of a specific form of mental imagery show less gray matter than experts of mental imagery congruent to that form. A meta-analysis of neuroimagery studies revealed significant activation of the bilateral dorsal parietal, interior insula, and left inferior frontal regions of the brain.\n\nImagery has been thought to cooccur with perception; however, participants with damaged sense-modality receptors can sometimes perform imagery of said modality receptors. Neuroscience with imagery has been used to communicate with seemingly unconscious individuals through fMRI activation of different neural correlates of imagery, demanding further study into low quality consciousness. A study on one patient with one occipital lobe removed found the horizontal area of their visual mental image was reduced.\n\nVisual imagery is the ability to create mental representations of things, people, and places that are absent from an individual’s visual field. This ability is crucial to problem-solving tasks, memory, and spatial reasoning. Neuroscientists have found that imagery and perception share many of the same neural substrates, or areas of the brain that function similarly during both imagery and perception, such as the visual cortex and higher visual areas. Kosslyn and colleagues (1999) showed that the early visual cortex, Area 17 and Area 18/19, is activated during visual imagery. They found that inhibition of these areas through repetitive transcranial magnetic stimulation (rTMS) resulted in impaired visual perception and imagery. Furthermore, research conducted with lesioned patients has revealed that visual imagery and visual perception have the same representational organization. This has been concluded from patients in which impaired perception also experience visual imagery deficits at the same level of the mental representation.\n\nBehrmann and colleagues (1992) describe a patient C.K., who provided evidence challenging the view that visual imagery and visual perception rely on the same representational system. C.K. was a 33-year old man with visual object agnosia acquired after a vehicular accident. This deficit prevented him from being able to recognize objects and copy objects fluidly. Surprisingly, his ability to draw accurate objects from memory indicated his visual imagery was intact and normal. Furthermore, C.K. successfully performed other tasks requiring visual imagery for judgment of size, shape, color, and composition. These findings conflict with previous research as they suggest there is a partial dissociation between visual imagery and visual perception. C.K. exhibited a perceptual deficit that was not associated with a corresponding deficit in visual imagery, indicating that these two processes have systems for mental representations that may not be mediated entirely by the same neural substrates. \n\nSchlegel and colleagues (2013) conducted a functional MRI analysis of regions activated during manipulation of visual imagery. They identified 11 bilateral cortical and subcortical regions that exhibited increased activation when manipulating a visual image compared to when the visual image was just maintained. These regions included the occipital lobe and ventral stream areas, two parietal lobe regions, the posterior parietal cortex and the precuneus lobule, and three frontal lobe regions, the frontal eye fields, dorsolateral prefrontal cortex, and the prefrontal cortex. Due to their suspected involvement in working memory and attention, the authors propose that these parietal and prefrontal regions, and occipital regions, are part of a network involved in mediating the manipulation of visual imagery. These results suggest a top-down activation of visual areas in visual imagery.\n\nUsing Dynamic Causal Modeling (DCM) to determine the connectivity of cortical networks, Ishai et al. (2010) demonstrated that activation of the network mediating visual imagery is initiated by prefrontal cortex and posterior parietal cortex activity. Generation of objects from memory resulted in initial activation of the prefrontal and the posterior parietal areas, which then activate earlier visual areas through backward connectivity. Activation of the prefrontal cortex and posterior parietal cortex has also been found to be involved in retrieval of object representations from long-term memory, their maintenance in working memory, and attention during visual imagery. Thus, Ishai et al. suggest that the network mediating visual imagery is composed of attentional mechanisms arising from the posterior parietal cortex and the prefrontal cortex.\n\nVividness of visual imagery is a crucial component of an individual’s ability to perform cognitive tasks requiring imagery. Vividness of visual imagery varies not only between individuals but also within individuals. Dijkstra and colleagues (2017) found that the variation in vividness of visual imagery is dependent on the degree to which the neural substrates of visual imagery overlap with those of visual perception. They found that overlap between imagery and perception in the entire visual cortex, the parietal precuneus lobule, the right parietal cortex, and the medial frontal cortex predicted the vividness of a mental representation. The activated regions beyond the visual areas are believed to drive the imagery-specific processes rather than the visual processes shared with perception. It has been suggested that the precuneus contributes to vividness by selecting important details for imagery. The medial frontal cortex is suspected to be involved in the retrieval and integration of information from the parietal and visual areas during working memory and visual imagery. The right parietal cortex appears to be important in attention, visual inspection, and stabilization of mental representations. Thus, the neural substrates of visual imagery and perception overlap in areas beyond the visual cortex and the degree of this overlap in these areas correlates with the vividness of mental representations during imagery.\n\nMental images are an important topic in classical and modern philosophy, as they are central to the study of knowledge. In the \"Republic\", Book VII, Plato has Socrates present the Allegory of the Cave: a prisoner, bound and unable to move, sits with his back to a fire watching the shadows cast on the cave wall in front of him by people carrying objects behind his back. These people and the objects they carry are representations of real things in the world. Unenlightened man is like the prisoner, explains Socrates, a human being making mental images from the sense data that he experiences.\n\nThe eighteenth-century philosopher Bishop George Berkeley proposed similar ideas in his theory of idealism. Berkeley stated that reality is equivalent to mental images—our mental images are not a copy of another material reality but that reality itself. Berkeley, however, sharply distinguished between the images that he considered to constitute the external world, and the images of individual imagination. According to Berkeley, only the latter are considered \"mental imagery\" in the contemporary sense of the term.\n\nThe eighteenth century British writer Dr. Samuel Johnson criticized idealism. When asked what he thought about idealism, he is alleged to have replied \"I refute it thus!\" as he kicked a large rock and his leg rebounded. His point was that the idea that the rock is just another mental image and has no material existence of its own is a poor explanation of the painful sense data he had just experienced.\n\nDavid Deutsch addresses Johnson's objection to idealism in \"The Fabric of Reality\" when he states that, if we judge the value of our mental images of the world by the quality and quantity of the sense data that they can explain, then the most valuable mental image—or theory—that we currently have is that the world has a real independent existence and that humans have successfully evolved by building up and adapting patterns of mental images to explain it. This is an important idea in scientific thought.\n\nCritics of scientific realism ask how the inner perception of mental images actually occurs. This is sometimes called the \"homunculus problem\" (see also the mind's eye). The problem is similar to asking how the images you see on a computer screen exist in the memory of the computer. To scientific materialism, mental images and the perception of them must be brain-states. According to critics, scientific realists cannot explain where the images and their perceiver exist in the brain. To use the analogy of the computer screen, these critics argue that cognitive science and psychology have been unsuccessful in identifying either the component in the brain (i.e., \"hardware\") or the mental processes that store these images (i.e. \"software\").\n\nCognitive psychologists and (later) cognitive neuroscientists have empirically tested some of the philosophical questions related to whether and how the human brain uses mental imagery in cognition.\n\nOne theory of the mind that was examined in these experiments was the \"brain as serial computer\" philosophical metaphor of the 1970s. Psychologist Zenon Pylyshyn theorized that the human mind processes mental images by decomposing them into an underlying mathematical proposition. Roger Shepard and Jacqueline Metzler challenged that view by presenting subjects with 2D line drawings of groups of 3D block \"objects\" and asking them to determine whether that \"object\" is the same as a second figure, some of which rotations of the first \"object\". Shepard and Metzler proposed that if we decomposed and then mentally re-imaged the objects into basic mathematical propositions, as the then-dominant view of cognition \"as a serial digital computer\" assumed, then it would be expected that the time it took to determine whether the object is the same or not would be independent of how much the object had been rotated. Shepard and Metzler found the opposite: a linear relationship between the degree of rotation in the mental imagery task and the time it took participants to reach their answer.\n\nThis mental rotation finding implied that the human mind—and the human brain—maintains and manipulates mental images as topographic and topological wholes, an implication that was quickly put to test by psychologists. Stephen Kosslyn and colleagues showed in a series of neuroimaging experiments that the mental image of objects like the letter \"F\" are mapped, maintained and rotated as an image-like whole in areas of the human visual cortex. Moreover, Kosslyn's work showed that there are considerable similarities between the neural mappings for imagined stimuli and perceived stimuli. The authors of these studies concluded that, while the neural processes they studied rely on mathematical and computational underpinnings, the brain also seems optimized to handle the sort of mathematics that constantly computes a series of topologically-based images rather than calculating a mathematical model of an object.\n\nRecent studies in neurology and neuropsychology on mental imagery have further questioned the \"mind as serial computer\" theory, arguing instead that human mental imagery manifests both visually and kinesthetically. For example, several studies have provided evidence that people are slower at rotating line drawings of objects such as hands in directions incompatible with the joints of the human body, and that patients with painful, injured arms are slower at mentally rotating line drawings of the hand from the side of the injured arm.\n\nSome psychologists, including Kosslyn, have argued that such results occur because of interference in the brain between distinct systems in the brain that process the visual and motor mental imagery. Subsequent neuroimaging studies showed that the interference between the motor and visual imagery system could be induced by having participants physically handle actual 3D blocks glued together to form objects similar to those depicted in the line-drawings. Amorim et al. have shown that, when a cylindrical \"head\" was added to Shepard and Metzler's line drawings of 3D block figures, participants were quicker and more accurate at solving mental rotation problems. They argue that motoric embodiment is not just \"interference\" that inhibits visual mental imagery but is capable of facilitating mental imagery.\n\nAs cognitive neuroscience approaches to mental imagery continued, research expanded beyond questions of serial versus parallel or topographic processing to questions of the relationship between mental images and perceptual representations. Both brain imaging (fMRI and ERP) and studies of neuropsychological patients have been used to test the hypothesis that a mental image is the reactivation, from memory, of brain representations normally activated during the perception of an external stimulus. In other words, if perceiving an apple activates contour and location and shape and color representations in the brain’s visual system, then imagining an apple activates some or all of these same representations using information stored in memory. Early evidence for this idea came from neuropsychology. Patients with brain damage that impairs perception in specific ways, for example by damaging shape or color representations, seem to generally to have impaired mental imagery in similar ways. Studies of brain function in normal human brains support this same conclusion, showing activity in the brain’s visual areas while subjects imagined visual objects and scenes.\n\nThe previously mentioned and numerous related studies have led to a relative consensus within cognitive science, psychology, neuroscience, and philosophy on the neural status of mental images. In general, researchers agree that, while there is no homunculus inside the head viewing these mental images, our brains do form and maintain mental images as image-like wholes. The problem of exactly how these images are stored and manipulated within the human brain, in particular within language and communication, remains a fertile area of study.\n\nOne of the longest-running research topics on the mental image has basis on the fact that people report large individual differences in the vividness of their images. Special questionnaires have been developed to assess such differences, including the Vividness of Visual Imagery Questionnaire (VVIQ) developed by David Marks. Laboratory studies have suggested that the subjectively reported variations in imagery vividness are associated with different neural states within the brain and also different cognitive competences such as the ability to accurately recall information presented in pictures Rodway, Gillies and Schepman used a novel long-term change detection task to determine whether participants with low and high vividness scores on the VVIQ2 showed any performance differences. Rodway et al. found that high vividness participants were significantly more accurate at detecting salient changes to pictures compared to low-vividness participants. This replicated an earlier study.\n\nRecent studies have found that individual differences in VVIQ scores can be used to predict changes in a person's brain while visualizing different activities. Functional magnetic resonance imaging (fMRI) was used to study the association between early visual cortex activity relative to the whole brain while participants visualized themselves or another person bench pressing or stair climbing. Reported image vividness correlates significantly with the relative fMRI signal in the visual cortex. Thus, individual differences in the vividness of visual imagery can be measured objectively.\n\nLogie, Pernet, Buonocore and Della Sala (2011) used behavioural and fMRI data for mental rotation from individuals reporting vivid and poor imagery on the VVIQ. Groups differed in brain activation patterns suggesting that the groups performed the same tasks in different ways. These findings help to explain the lack of association previously reported between VVIQ scores and mental rotation performance.\n\nSome educational theorists have drawn from the idea of mental imagery in their studies of learning styles. Proponents of these theories state that people often have learning processes that emphasize visual, auditory, and kinesthetic systems of experience. According to these theorists, teaching in multiple overlapping sensory systems benefits learning, and they encourage teachers to use content and media that integrates well with the visual, auditory, and kinesthetic systems whenever possible.\n\nEducational researchers have examined whether the experience of mental imagery affects the degree of learning. For example, imagining playing a 5-finger piano exercise (mental practice) resulted in a significant improvement in performance over no mental practice—though not as significant as that produced by physical practice. The authors of the study stated that \"mental practice alone seems to be sufficient to promote the modulation of neural circuits involved in the early stages of motor skill learning\".\n\nIn general, Vajrayana Buddhism, Bön, and Tantra utilize sophisticated visualization or \"imaginal\" (in the language of Jean Houston of Transpersonal Psychology) processes in the thoughtform construction of the yidam sadhana, kye-rim, and dzog-rim modes of meditation and in the yantra, thangka, and mandala traditions, where holding the fully realized form in the mind is a prerequisite prior to creating an 'authentic' new art work that will provide a sacred support or foundation for deity.\n\nMental imagery can act as a substitute for the imagined experience: Imagining an experience can evoke similar cognitive, physiological, and/or behavioral consequences as having the corresponding experience in reality. At least four classes of such effects have been documented.\n\n"}
