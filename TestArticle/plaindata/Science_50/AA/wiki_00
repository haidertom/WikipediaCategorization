{"id": "18547138", "url": "https://en.wikipedia.org/wiki?curid=18547138", "title": "Ancient Aliens", "text": "Ancient Aliens\n\nAncient Aliens is an American television series that premiered on April 20, 2010, on the History channel. Produced by Prometheus Entertainment in a documentary style, the program presents hypotheses of ancient astronauts and proposes that historical texts, archaeology, and legends contain evidence of past human-extraterrestrial contact. The show has been widely criticized by historians, cosmologists and other scientific circles for presenting and promoting pseudoscience and pseudohistory.\n\nThe series started with a TV special of the same name that aired on March 8, 2009, on the History channel. Seasons 1–3 aired on the same channel until 2011. From season 4 to the middle of season 7, the series aired on H2. On April 10, 2015, episode premieres returned to History.\n\nSeason 13 premiered on April 27, 2018 with a two-hour special.\n\nThe executive producer of \"Ancient Aliens\" is Kevin Burns, who also directed and wrote the pilot episode. Giorgio A. Tsoukalos serves as consulting producer and appeared on screen in the pilot. Erich von Däniken appeared in the pilot episode, and UFO researcher C. Scott Littleton served as an expert consultant for the show until his death in 2010.\n\nRadio talk show host George Noory speaks in five episodes, including the pilot. Reverend Barry Downing, known for describing angels in the Bible as ancient astronauts, offered his viewpoints in the pilot episode. Psychologist Jonathan Young, who brings a mythological perspective, appears on screen in every episode but the first pilot. Alternate history author David Hatcher Childress speaks frequently in most episodes.\n\nThe program had 1.676 million viewers in late October 2010, in mid-December (for the \"Unexplained Structures\" episode) and in late January 2011 it had \n\nReviewers have characterized the show as \"far-fetched\", \"hugely speculative\", and \"...expound[ing] wildly on theories suggesting that astronauts wandered the Earth freely in ancient times.\" Most of the ideas presented in the show are not accepted by the scientific community, and have been criticized as pseudoscience and pseudohistory. History professor Ronald H. Fritze observed that pseudoscience as offered by von Däniken and the \"Ancient Aliens\" program has a periodic popularity in the US: \"In a pop culture with a short memory and a voracious appetite, aliens and pyramids and lost civilizations are recycled like fashions.\"\n\nForbes.com contributor Brad Lockwood criticized \"Ancient Aliens\" as an example of the History Channel's addition of \"programs devoted to monsters, aliens, and conspiracies\", commenting that, \"\"Ancient Aliens\" defies all ability to suspend disbelief for the sake of entertainment.\" Forbes.com staff writer Alex Knapp also criticized the series and cited archaeologist Keith Fitzpatrick-Matthews' rebuke of the History Channel for \"treating (\"Ancient Aliens\") nonsense as though it were fact.\"\n\nSmithsonian.com science writer Brian Switek was extremely critical of the series, particularly an episode that suggested \"aliens exterminated dinosaurs to make way for our species.\" He characterized the show as \"some of the most noxious sludge in television’s bottomless chum bucket.\" Switek wrote that the show employs the Gish gallop technique to overwhelm the viewer with many \"fictions and distortions\".\n\nOthers have called attention to a paucity of opposing viewpoints. Kenneth Feder, Professor of Archaeology at Central Connecticut State University and author of \"Frauds, Myths, and Mysteries: Science and Pseudoscience in Archaeology\", has said that he was approached by \"Ancient Aliens\" producers regarding his potential participation. \"My response was, I’d be happy to be on your show, but you should know that I think that the ancient astronaut hypothesis is execrable bullshit,\" he said, in an interview. \"I haven’t heard back from them, rather remarkably. So, I guess maybe they’re not interested in the other point of view.\"\n\n\"South Park\" parodied the show in an episode entitled \"A History Channel Thanksgiving\" (November 11, 2011, episode 15.13). Reviewer Ramsey Isler commented, \"The aim is placed squarely on \"Ancient Aliens\" specifically,\" and described the animation as \"a perfect satire of all the ridiculousness of this series, including the black and white art with aliens photoshopped in, and interviews with people of dubious authority.\"\n\nViceland premiered \"\" (also known as \"Action Bronson Watches Ancient Aliens\") with a special on April 20, 2016 followed by a ten-episode series beginning in July. The series features rapper Action Bronson, who praises \"Ancient Aliens\" as \"the best thing that was ever created by man,\" commenting over the History series while smoking cannabis with celebrity guests. According to producers Jordan Kinley and Hannah Gregg, the show was conceived as a way to address disgruntled viewers of H2, the network that formerly aired \"Ancient Aliens\" before being replaced by Viceland on cable carriers in the United States.\n\n\n\n"}
{"id": "34663672", "url": "https://en.wikipedia.org/wiki?curid=34663672", "title": "Annals of Philosophy", "text": "Annals of Philosophy\n\nAnnals of Philosophy was a learned journal founded in 1813 by the Scottish chemist Thomas Thomson. It shortly became a leader in its field of commercial scientific periodicals. Contributors included John George Children, Edward Daniel Clarke, Philip Crampton, Alexander Crichton, James Cumming, John Herapath, William George Horner, Thomas Dick Lauder, John Miers, Matthew Paul Moyle, Robert Porrett, James Thomson, and Charles Wheatstone.\n\nThomson edited it until 1821, when he was succeeded in 1821 by Richard Phillips. The journal was bought by Richard Taylor in 1827, and closed down for the benefit of the \"Philosophical Magazine\".\n\nThe \"Annals of Philosophy\" were issued monthly following a standard pattern. Often the first article was a biographical article (10 pages) on a living or recently deceased scientist. This was then followed by a series of extended pieces (5-10 pages) on particular topics, sometimes by eminent authors. Then there were shorter news items and correspondence. Summaries followed: first of the proceedings of learned bodies (Royal Society, Linnean, French Institute -if available: the Napoleonic Wars made communications with the continent difficult at first, etc.), then of patents, and finally of new books. The last section was a meteorological journal. Every six months a title page, index, and preface were issued which could be bound before the six monthly issues to make a half-yearly volume. Including front matter, volumes were just under 500 pages each.\n\n\n"}
{"id": "20860737", "url": "https://en.wikipedia.org/wiki?curid=20860737", "title": "Antiquarian science books", "text": "Antiquarian science books\n\nAntiquarian science books are original historical works (e.g., books or technical papers) concerning science, mathematics and sometimes engineering. \nThese books are important primary references for the study of the history of science and technology, they can provide valuable insights into the historical development of the various fields of scientific inquiry (History of science, History of mathematics, etc.)\n\nThe landmark are significant first (or early) editions typically worth hundreds or thousands of dollars (prices may vary widely based on condition, etc.). \nReprints of these books are often available, for example from Great Books of the Western World, Dover Publications or Google Books.\n\nIncunabula are extremely rare and valuable, but as the \"scientific revolution\" is only taken to have started around the 1540s, such works of Renaissance literature (including alchemy, Renaissance magic, etc.) are not usually included under the notion of \"scientific\" literature. Printed originals of the beginning scientific revolution thus date to the 1540s or later, notably beginning with the original publication of Copernican heliocentrism. Nicolaus Copernicus' \"De revolutionibus orbium coelestium\" of 1543 sold for more than US$2 million at auctions.\n\n\n\n\n\n\n"}
{"id": "51409385", "url": "https://en.wikipedia.org/wiki?curid=51409385", "title": "Apollo's Arrow", "text": "Apollo's Arrow\n\nApollo’s Arrow: The Science of Prediction and the Future of Everything is a non-fiction book about prediction written by Canadian author and mathematician David Orrell. The book was initially published in Canada by HarperCollins in 2007, and was a national bestseller. It was published in the United States as \"The Future of Everything: The Science of Prediction\", and translated versions were also published in Japan, South Korea and China.\n\nThe book was taught as part of a university course in “Forecasting via Mathematical Modeling” at Gustavus Adolphus College in 2009.\n\nIn this book, Orrell explains the science of prediction to a general audience. The book begins with a general history of prediction from the Delphic oracle to the present day. The next part considers three different areas of prediction in detail: weather, health and economics. It argues that these are all examples of complex systems that cannot be reduced to equations. As mathematical models become more refined, the number of unknown parameters tends to explode. At the same time, networks of interlocking feedback loops make the models unstable. According to Orrell, the resulting model error (rather than e.g. the butterfly effect) is the main reason why forecasts go wrong.\n\nIn the final part, the book turns to predictions for the future, including the long-term effects of climate change. It concludes with some thoughts for the future, as well as a reminder that all such forecasts are unreliable.\n\nThe title of the book is a reference to a mythical arrow that once belonged to the god Apollo. According to legend, the arrow was gifted by a priest to Pythagoras, allowing him to dart through space and time.\n"}
{"id": "42277", "url": "https://en.wikipedia.org/wiki?curid=42277", "title": "Aryan race", "text": "Aryan race\n\nThe Aryan race is a racial grouping that emerged in the period of the late 19th century and mid-20th century to describe people of Indo-European heritage.\n\nIt derives from the idea that the original speakers of the Indo-European languages and their descendants up to the present day constitute a distinctive race or subrace of the Caucasian race.\n\nThe term \"Aryan\" has generally been used to describe the Proto-Indo-Iranian language root *arya which was the ethnonym the Indo-Iranians adopted to describe Aryans. Its cognate in Sanskrit is the word \"ārya\" (Devanāgarī: आर्य), in origin an ethnic self-designation, in Classical Sanskrit meaning \"honourable, respectable, noble\". The Old Persian cognate \"ariya-\" (Old Persian cuneiform: 𐎠𐎼𐎡𐎹) is the ancestor of the modern name of Iran and ethnonym for the Iranian people.\n\nIn the 18th century, the most ancient known Indo-European languages were those of the ancient Indo-Iranians. The word \"Aryan\" was therefore adopted to refer not only to the Indo-Iranian peoples, but also to native Indo-European speakers as a whole, including the Romans, Greeks, and the Germans. It was soon recognised that Balts, Celts, and Slavs also belonged to the same group. It was argued that all of these languages originated from a common root – now known as Proto-Indo-European – spoken by an ancient people who were thought of as ancestors of the European, Iranian, and Indo-Aryan peoples.\n\nThis usage was common among knowledgeable authors writing in the late 19th and early 20th century. An example of this usage appears in \"The Outline of History\", a bestselling 1920 work by H. G. Wells. In that influential volume, Wells used the term in the plural (\"the Aryan peoples\"), but he was a staunch opponent of the racist and politically motivated exploitation of the singular term (\"the Aryan people\") by earlier authors like Houston Stewart Chamberlain (see below) and was careful either to avoid the generic singular, though he did refer now and again in the singular to some specific \"Aryan people\" (e.g., the Scythians). In 1922, in \"A Short History of the World\", Wells depicted a highly diverse group of various \"Aryan peoples\" learning \"methods of civilization\" and then, by means of different uncoordinated movements that Wells believed were part of a larger dialectical rhythm of conflict between settled civilizations and nomadic invaders that also encompassed Aegean and Mongol peoples \"inter alia\", \"subjugat[ing]\" – \"in form\" but not in \"ideas and methods\" – \"the whole ancient world, Semitic, Aegean and Egyptian alike\".\n\nHowever, in a climate of burgeoning racism it proved difficult to maintain such nuanced distinctions. Even Max Mueller, a linguist who wrote in 1888 that \"an ethnologist who speaks of Aryan race, Aryan blood, Aryan eyes and hair, is as great a sinner as a linguist who speaks of a dolichocephalic dictionary or a brachycephalic grammar\", was on occasion guilty of using the term \"Aryan race\".\n\nIn the 1944 edition of Rand McNally's \"World Atlas\", the Aryan race is depicted as one of the ten major racial groupings of mankind. The science fiction author Poul Anderson, an anti-racist libertarian of Scandinavian ancestry, in his many works, consistently used the term \"Aryan\" as a synonym for \"Indo-Europeans\".\n\nThe use of \"Aryan\" as a synonym for Indo -European may occasionally appear in material that is based on historic scholarship. Thus, a 1989 article in \"Scientific American\", Colin Renfrew uses the term \"Aryan\" as a synonym for \"Indo-European\".\n\nThe term Indo-Aryan is still commonly used to describe the Indic half of the Indo-Iranian languages, i.e., the family that includes Sanskrit and modern languages such as Hindi-Urdu, Bengali, Punjabi, Gujarati, Romani, Kashmiri, Sinhalese and Marathi.\n\nIn the context of 19th-century physical anthropology and scientific racism, the term \"Aryan race\" has been misapplied to all people descended from the Proto-Indo-Europeans – a subgroup of the Europidor \"Caucasian\" race, in addition to the Indo-Iranians (who are the only people known to have used \"Arya\" as an endonym in ancient times). This usage was considered to include most modern inhabitants of Australasia, the Caucasus, Central Asia, Europe, Latin America, North America, Siberia, South Asia, Southern Africa, and West Asia. Such claims became increasingly common during the early 19th century, when it was commonly believed that the Aryans originated in the south-west Eurasian steppes (present-day Russia and Ukraine).\n\nMax Müller is often identified as the first writer to mention an \"Aryan race\" in English. In his \"Lectures on the Science of Language\" (1861), Muller referred to Aryans as a \"race of people\". At the time, the term race had the meaning of \"a group of tribes or peoples, an ethnic group\". Müller's concept of Aryan was later construed to imply a biologically distinct sub-group of humanity, by writers such as Arthur de Gobineau, who argued that the Aryans represented a superior branch of humanity. Müller objected to the mixing of linguistics and anthropology. \"The Science of Language and the Science of Man cannot be kept too much asunder ... I must repeat what I have said many times before, it would be wrong to speak of Aryan blood as of dolichocephalic grammar\". He restated his opposition to this method in 1888 in his essay \"Biographies of words and the home of the Aryas\".\nBy the late 19th century the steppe theory of Indo-European origins was challenged by a view that the Indo-Europeans originated in ancient Germany or Scandinavia – or at least that in those countries the original Indo-European ethnicity had been preserved. The word Aryan was consequently used even more restrictively – and even less in keeping with its Indo-Iranian origins – to mean \"Germanic\", \"Nordic\" or Northern Europeans. This implied division of Caucasoids into Aryans, Semites and Hamites was also based on linguistics, rather than based on physical anthropology; it paralleled an archaic tripartite division in anthropology between \"Nordic\", \"Alpine\" and \"Mediterranean\" races.\n\nA number of later writers, such as the French anthropologist Vacher de Lapouge in his book \"L'Aryen\", argued that this superior branch could be identified biologically by using the cephalic index (a measure of head shape) and other indicators. He argued that the long-headed \"dolichocephalic-blond\" Europeans, characteristically found in northern Europe, were natural leaders, destined to rule over more \"brachiocephalic\" (short headed) peoples.\n\nThe German origin of the Aryans was especially promoted by the archaeologist Gustaf Kossinna, who claimed that the Proto-Indo-European peoples were identical to the Corded Ware culture of Neolithic Germany. This idea was widely circulated in both intellectual and popular culture by the early twentieth century, and is reflected in the concept of \"Corded-Nordics\" in Carleton S. Coon's 1939 \"The Races of Europe\".\n\nOther anthropologists contested such claims. In Germany, Rudolf Virchow launched a study of craniometry, which prompted him to denounce \"Nordic mysticism\" in the 1885 Anthropology Congress in Karlsruhe, while Josef Kollmann, a collaborator of Virchow, stated in the same congress that the people of Europe, be they English, German, French, and Spaniard belonged to a \"mixture of various races,\" furthermore declaring that the \"results of craniology...[are] against any theory concerning the superiority of this or that European race\" to others.\n\nVirchow's contribution to the debate sparked a controversy. Houston Stewart Chamberlain, a strong supporter of the theory of a superior Aryan race or Germanic race, attacked Josef Kollmann arguments in detail. While the \"Aryan race\" theory remained popular, particularly in Germany, some authors defended Virchow's perspective, in particular Otto Schrader, Rudolph von Jhering and the ethnologist Robert Hartmann (1831–1893), who proposed to ban the notion of \"Aryan\" from anthropology.\n\nThe Theosophical movement, founded by Helena Blavatsky and Henry Olcott at the end of the nineteenth century, took inspiration from Indian culture, in this case, perhaps, from the Hindu reform movement the Arya Samaj founded by Swami Dayananda.\nBlavatsky argued that humanity had descended from a series of \"root races\", naming the fifth root race (out of seven) the Aryan race. She thought that the Aryans originally came from Atlantis and described the Aryan races with the following words:\n\nBlavatsky used \"Root Race\" as a technical term to describe human evolution over the large time periods in her cosmology. However, she also claimed that there were modern non-Aryan peoples who were inferior to Aryans. She regularly contrasts \"Aryan\" with \"Semitic\" culture, to the detriment of the latter, asserting that Semitic peoples are an offshoot of Aryans who have become \"degenerate in spirituality and perfected in materiality.\" She also states that some peoples are \"semi-animal creatures\". These latter include \"the Tasmanians, a portion of the Australians and a mountain tribe in China\". There are also \"considerable numbers of the mixed Lemuro-Atlantean peoples produced by various crossings with such semi-human stocks – e.g., the wild men of Borneo, the Veddhas of Ceylon, most of the remaining Australians, Bushmen, Negritos, Andaman Islanders, etc.\"\n\nDespite this, Blavatsky's admirers claim that her thinking was not connected to fascist or racialist ideas, asserting that she believed in a Universal Brotherhood of humanity and wrote that \"all men have spiritually and physically the same origin\" and that \"mankind is essentially of one and the same essence\". On the other hand, in \"The Secret Doctrine\", Blavatsky states: \"Verily mankind is 'of one blood,' but not of the same essence.\"\n\nBlavatsky connects physical race with spiritual attributes constantly throughout her works:\nThe intellectual difference between the Aryan and other civilized nations and such savages as the South Sea Islanders, is inexplicable on any other grounds. No amount of culture, nor generations of training amid civilization, could raise such human specimens as the Bushmen, the Veddhas of Ceylon, and some African tribes, to the same intellectual level as the Aryans, the Semites, and the Turanians so called. The 'sacred spark' is missing in them and it is they who are the only inferior races on the globe, now happily – owing to the wise adjustment of nature which ever works in that direction – fast dying out. Verily mankind is 'of one blood,' but not of the same essence. We are the hot-house, artificially quickened plants in nature, having in us a spark, which in them is latent.\" ... Esoteric history teaches that idols and their worship died out with the Fourth Race, until the survivors of the hybrid races of the latter (Chinamen, African Negroes, &c.) gradually brought the worship back. The Vedas countenance no idols; all the modern Hindu writings do.\n\nAccording to Blavatsky, \"the MONADS of the lowest specimens of humanity (the \"narrow-brained\" savage South-Sea Islander, the African, the Australian) had no Karma to work out when first born as men, as their more favoured brethren in intelligence had\".\n\nShe also prophesies of the destruction of the racial \"failures of nature\" as the future \"higher race\" ascends:\nThus will mankind, race after race, perform its appointed cycle-pilgrimage. Climates will, and have already begun, to change, each tropical year after the other dropping one sub-race, but only to beget another higher race on the ascending cycle; while a series of other less favoured groups – the failures of nature – will, like some individual men, vanish from the human family without even leaving a trace behind.\n\nThe second subrace of the Fifth or Aryan root race, the Arabian, is regarded by Theosophists as one of the Aryan subraces. It is believed by Theosophists that the Arabians, although asserted in traditional Theosophy to be of Aryan (i.e., Indo-European) ancestry, adopted the Semitic language of the people around them who had migrated earlier from Atlantis (the fifth or (original) Semite subrace of the Atlantean root race). Theosophists assert that the Jews originated as an offshoot of the Arabian subrace in what is now Yemen about 30,000 BC. They migrated first to Somalia and then later to Egypt, where they lived until the time of Moses. Thus, according to the teachings of Theosophy, the Jews are part of the Aryan race.\n\nGuido von List (and his followers such as Lanz von Liebenfels) later took up some of Blavatsky's ideas, mixing her ideology with nationalistic and fascist ideas; this system of thought became known as Ariosophy. It was believed in Ariosophy that the Teutonics were superior to all other peoples because according to Theosophy the Teutonics or Nordics were the most recent subrace of the Aryan root race to have evolved. Such views also fed into the development of Nazi ideology. Theosophical publications such as \"The Aryan Path\" were strongly opposed to the Nazi usage, attacking racialism.\n\nThe ideology of Nazism was based upon the conception of the ancient Aryan race being a superior race, holding the highest position in the racial hierarchy and that the Germanic peoples were the most racially pure existing peoples of Aryan stock. The Nazi conception of the Aryan race arose from earlier proponents of a supremacist conception of the race as described by racial theorist figures such as Arthur de Gobineau and Houston Stewart Chamberlain.\n\nNazi racial theorist Hans F. K. Günther identified the European race as having five subtype races: Nordic, Mediterranean, Dinaric, Alpine, and East Baltic. Günther applied a Nordicist conception that Nordics were the highest in the racial hierarchy amongst these five European subtype races. In his book \"Rassenkunde des deutschen Volkes\" (1922) (\"Racial Science of the German People\"), Günther recognized Germans as being composed of all five European subtypes, but emphasized the strong Nordic heritage amongst Germans. Günther believed Slavic people to be of \"Eastern race\", one that was separate from Germans and Nordics, and warned about mixing \"German blood\" with Slavic one. He defined each racial subtype according to general physical appearance and their psychological qualities including their \"racial soul\" - referring to their emotional traits and religious beliefs, and provided detailed information on their hair, eye, and skin colours, facial structure. He provided photographs of Germans identified as Nordic in places like Baden, Stuttgart, Salzburg, and Schwaben; and provided photographs of Germans he identified as Alpine and Mediterranean types, especially in Vorarlberg, Bavaria, and the Black Forest region of Baden. Adolf Hitler read \"Rassenkunde des deutschen Volkes,\" which influenced his racial policy and resulted in Günther's Nazi-backed attainment of a position in the anthropology department at the University of Jena in 1932 where Hitler attended Günther's inaugural lecture.\n\nGünther distinguished Aryans from Jews, and identified Jews as descending from non-European races, particularly from what he classified as the Near Asian race (\"Vorderasiatische\") more commonly known as the Armenoid race, and said that such origins rendered Jews fundamentally different from and incompatible with Germans and most Europeans. This association of Jews with the Armenoid type had been utilized by Zionist Jews who claimed that Jews were a group within that type. He claimed that the Near Eastern race descended from the Caucasus in the fifth and fourth millennia BC, and that it had expanded into Asia Minor and Mesopotamia and eventually to the west coast of the Eastern Mediterranean Sea. Aside from ascribing Armenians and Jews as having Near Eastern characteristics, he ascribed them to several other contemporary peoples, including: Greeks, Turks, Syrians, and Iranians. In his work \"Racial Characteristics of the Jewish People\", he defined the racial soul of the Near Eastern race as emphasizing a \"commercial spirit\" (\"Handelgeist\"), and described them as \"artful traders\" - a term that Gunther ascribed as being used by Jewish racial theorist Samuel Weissenberg to describe contemporary Armenians, Greeks, and Jews. Günther added to that description of the Near Eastern type as being composed primarily of commercially spirited and artful traders, by claiming that the type held strong psychological manipulation skills that aided them in trade. He claimed that the Near Eastern race had been \"bred not so much for the conquest and exploitation of nature as it was for the conquest and exploitation of people\".\n\nHitler's conception of the Aryan \"Herrenvolk\" (\"master race\") explicitly excluded the vast majority of Slavs, regarding the Slavs as having dangerous Jewish and Asiatic influences. Because of this, the Nazis declared Slavs to be \"Untermenschen\" (subhumans). Exceptions were made for a small percentage of Slavs who were seen by the Nazis to be descended from German settlers and therefore fit to be Germanised to be considered part of the Aryan folk or nation. Hitler described Slavs as \"a mass of born slaves who feel the need of a master\". Hitler declared that because Slavs were subhumans that the Geneva Conventions were not applicable to them, and German soldiers in World War II were thus permitted to ignore the Geneva Conventions in regards to Slavs. Hitler called Slavs \"a rabbit family\" meaning they were intrinsically idle and disorganized. Nazi Germany's propaganda minister Joseph Goebbels had media speak of Slavs as primitive animals who were from the Siberian tundra who were like a \"dark wave of filth\". The Nazi notion of Slavs being inferior non-Aryans was part of the agenda for creating Lebensraum (\"living space\") for Germans and other Germanic people in eastern Europe that was initiated during World War II under \"Generalplan Ost\": millions of Germans and other Germanic settlers would be moved into conquered territories of Eastern Europe, while the original Slavic inhabitants were to be annihilated, removed, or enslaved. Nazi Germany's ally the Independent State of Croatia rejected the common conception that Croats were primarily a Slavic people and claimed that Croats were primarily the descendants of the Germanic Goths. However the Nazi regime continued to classify Croats as a\"subhuman\" in spite of the alliance. Nazi Germany's policy changed towards Slavs in response to military manpower shortages, in which it accepted Slavs to serve in its armed forces within occupied territories, in spite of them being considered subhuman, as a pragmatic means to resolve such manpower shortages.\n\nShortly after the Nazis came to power in 1933 they passed the Law for the Restoration of the Professional Civil Service law which required all civil servants to provide proof of their Aryan ancestry and defined \"non-Aryan\" as a person with one Jewish grandparent. In 1933, the German Interior Ministry official Albert Gorter drafted an official definition of the \"Aryan race\" for the new law which included all non-Jewish Europeans, this definition was unacceptable by the Nazis. However, Achim Gerke revised Gorter's draft of the Civil Service Law classifying Aryans as people \"tribally\" related to \"German blood\" The Nuremberg race laws of 1935 classified as \"racially acceptable\" people with \"German or related blood\".\n\nHitler often doubted whether Czechs were Aryan or not, he said in his table talk \"It is enough for a Czech to grow a moustache for anyone to see, from the way the thing droops, that his origin is Mongolian.\" The question of whether Italians were Aryan enough was questioned by the Nazi racial theorists. Hitler viewed northern Italians as strongly Aryan, but not southern Italians. The Nazis viewed the downfall of the Roman Empire as being the result of the pollution of blood from racial intermixing, claiming that Italians were a hybrid of races, including black African races. Hitler even mentioned his view of the presence of Negroid blood in the Mediterranean peoples during his first meeting with Mussolini in 1934. The definition of \"Aryan\" remained in constant flux to such an extent that the Nazis questioned whether European ethnic groups such as Finns or Hungarians were to be classified as \"Aryans\". Hungarians were classified as \"tribally alien\" but not necessarily \"blood alien\", in 1934 the Nazis published a pamphlet which declared Magyars (which it did not define) as Aryans. The following year, an article published by the Nazis admitted that there were disputes over the racial status of Hungarians. As late as 1943, there were disputes over whether Hungarians were to be classified as Aryan.\nIn 1942, Hitler declared that the Finns were \"racially related Germanic neighboring peoples\", although there is no evidence to suggest that this was based on anything racial.\n\nThe idea of the Northern origins of the Aryans was particularly influential in Germany. It was widely believed that the \"Vedic Aryans\" were ethnically identical to the Goths, Vandals and other ancient Germanic peoples of the \"Völkerwanderung\". This idea was often intertwined with antisemitic ideas. The distinctions between the \"Aryan\" and \"Semitic\" peoples were based on the aforementioned linguistic and ethnic history. A complete, highly speculative theory of Aryan and anti-Semitic history can be found in Alfred Rosenberg's major work, \"The Myth of the Twentieth Century\".\nSemitic peoples came to be seen as a foreign presence within Aryan societies, and the Semitic peoples were often pointed to as the cause of conversion and destruction of social order and values leading to culture and civilization's downfall by proto-Nazi theorists such as Houston Stewart Chamberlain.\n\nThese and other ideas evolved into the Nazi use of the term \"Aryan race\" to refer to what they saw as being a superior race, which was narrowly defined by the Nazis as being identical with the Nordic race, followed by other sub-races of the Aryan race and excluding Slavs as non-Aryan. They worked to maintain the purity of this race through eugenics programs (including anti-miscegenation legislation, compulsory sterilization of the mentally ill and the mentally deficient, the execution of the institutionalized mentally ill as part of a euthanasia program).\n\nHeinrich Himmler (the \"Reichsführer\" of the SS), the person ordered by Adolf Hitler to implement the Final Solution, or the Holocaust, told his personal masseur Felix Kersten that he always carried with him a copy of the ancient Aryan scripture, the Bhagavad Gita because it relieved him of guilt about what he was doing – he felt that like the warrior Arjuna, he was simply doing his duty without attachment to his actions.\n\nIn a 1921 speech in Bologna, Mussolini stated that \"Fascism was born... out of a profound, perennial need of this our Aryan and Mediterranean race\". In this speech Mussolini was referring to Italians as being the Mediterranean branch of the Aryan race, Aryan in the meaning of people of an Indo-European language and culture. Italian Fascism emphasized that race was bound by spiritual and cultural foundations, and identified a racial hierarchy based on spiritual and cultural factors. While Italian Fascism based its conception of race on spiritual and cultural factors, Mussolini explicitly rejected notions that biologically \"pure\" races existed though biology was still considered a relevant factor in race.\n\nItalian Fascism strongly rejected the common Nordicist conception of the Aryan race that idealized \"pure\" Aryans as having certain physical traits that were defined as Nordic such as blond hair and blue eyes. The antipathy by Mussolini and other Italian Fascists to Nordicism was over the existence of what they viewed as the Mediterranean inferiority complex that they claimed had been instilled into Mediterraneans by the propagation of such theories by German and Anglo-Saxon Nordicists who viewed Mediterranean peoples as racially degenerate and thus in their view inferior. Mussolini refused to allow Italy to return again to this inferiority complex, initially rejecting Nordicism. However traditional Nordicist claims of Mediterraneans being degenerate due to having a darker colour of skin than Nordics had long been rebuked in anthropology through the depigmentation theory that claimed that lighter-skinned peoples had been depigmented from a darker skin, this theory has since become a widely accepted view in anthropology. Anthropologist Carleton S. Coon in his work \"The races of Europe\" (1939) subscribed to depigmentation theory that claimed that the Nordic race's light-coloured skin was the result of depigmentation from their ancestors of the Mediterranean race.\n\nIn the early 1930s, with the rise to power of the Nazi Party in Germany with \"Führer\" Adolf Hitler's emphasis on a Nordicist conception of the Aryan race, strong tensions arose between the Fascists and the Nazis over racial issues. In 1934, in the aftermath of Austrian Nazis killing Austrian Chancellor Engelbert Dollfuss, an ally of Italy, Mussolini became enraged and responded by angrily denouncing Nazism. Mussolini rebuked Nazism's Nordicism, claiming that the Nazis' emphasizing of a common Nordic \"Germanic race\" was absurd, saying \"a Germanic race does not exist. ... We repeat. Does not exist. Scientists say so. Hitler says so.\" The fact that Germans were not purely Nordic was indeed acknowledged by prominent Nazi racial theorist Hans F. K. Günther in his book \"Rassenkunde des deutschen Volkes\" (1922) (\"Racial Science of the German People\"), where Günther recognized Germans as being composed of five Aryan subtype races: Nordic, Mediterranean, Dinaric, Alpine, and East Baltic while asserting that the Nordics were the highest in a racial hierarchy of the five subtypes.\n\nBy 1936, the tensions between Fascist Italy and Nazi Germany reduced and relations became more amicable. In 1936, Mussolini decided to launch a racial programme in Italy, and was interested in the racial studies being conducted by Giulio Cogni. Cogni was a Nordicist but did not equate Nordic identity with Germanic identity as was commonly done by German Nordicists. Cogni had travelled to Germany where he had become impressed by Nazi racial theory and sought to create his own version of racial theory. On 11 September 1936, Cogni sent Mussolini a copy of his newly published book \"Il Razzismo\" (1936). Cogni declared the racial affinity of the Mediterranean and Nordic racial subtypes of the Aryan race and claimed that the intermixing of Nordic Aryans and Mediterranean Aryans in Italy produced a superior synthesis of Aryan Italians. Cogni addressed the issue of racial differences between northern and southern Italians, declaring southern Italians were mixed between Aryan and non-Aryan races, that he claimed was most likely due to infiltration by Asiatic peoples in Roman times and later Arab invasions. As such, Cogni viewed Southern Italian Mediterraneans as being polluted with orientalizing tendencies. He would later change his idea and claim that Nordics and Southern Italians were closely related groups both racially and spiritually. His opinion was that they were generally responsible for what is the best in European civilization. Initially Mussolini was not impressed with Cogni's work, however Cogni's ideas entered into the official Fascist racial policy several years later.\n\nIn 1938 Mussolini was concerned that if Italian Fascism did not recognize Nordic heritage within Italians, that the Mediterranean inferiority complex would return to Italian society. Therefore, in summer 1938, the Fascist government officially recognized Italians as having Nordic heritage and being of Nordic-Mediterranean descent and in a meeting with PNF members, and in June 1938 in a meeting with PNF members, Mussolini identified himself as Nordic and declared that previous policy of focus on Mediterraneanism was to be replaced by a focus on Aryanism.\n\nThe Fascist regime began publication of the racialist magazine \"La Difesa della Razza\" in 1938. The Nordicist racial theorist Guido Landra took a major role in the early work of \"La Difesa\", and published the \"Manifesto of Racial Scientists\" in the magazine in 1938. The \"Manifesto\" received substantial criticism, including its assertion of Italians being a \"pure race\", as it was viewed as absurd. \"La Difesa\" published other theories that described long-term Nordic Aryan amongst Italians, such as the theory that in the Eneolithic age Nordic Aryans arrived to Italy. Many of the writers took up the traditional Nordicist claim that the decline and fall of the Roman Empire was due to the arrival of Semitic immigrants. \"La Difesa\"'s writers were divided on their claims that described how Italians extricated themselves from Semitic influence.\n\nThe Nordicist direction of Fascist racial policy was challenged in 1938 by a resurgence of the Mediterraneanist faction in the PNF. By 1939, the Mediterraneanists' advocacy of a nativist racial theory that rejected ascribing the achievements of the Italian people to Nordic peoples. This nativist racial policy was prominently promoted by Ugo Rellini. Rellini rejected the notion of large-scale invasions of Italy by Nordic Aryans in the Eneolithic age, and claimed that Italians were an indigenous people descended from the Cro-Magnons. Rellini claimed that Mediterranean and Nordic peoples arrived later and peacefully intermixed in small numbers with the indigenous Italian population.\n\nIn 1941 the PNF's Mediterraneanists through the influence of Giacomo Acerbo put forward a comprehensive definition of the Italian race. However these efforts were challenged by Mussolini's endorsement of Nordicist figures with the appointment of staunch spiritual Nordicist Alberto Luchini as head of Italy's Racial Office in May 1941, as well as with Mussolini becoming interested in Julius Evola's spiritual Nordicism in late 1941. Acerbo and the Mediterraneanists in his High Council on Demography and Race sought to bring the regime back to supporting Mediterraneanism by thoroughly denouncing the pro-Nordicist \"Manifesto of the Racial Scientists\". The Council recognized Aryans as being a linguistic-based group, and condemned the \"Manifesto\" for denying the influence of pre-Aryan civilization on modern Italy, saying that the \"Manifesto\" \"constitutes an unjustifiable and undemonstrable negation of the anthropological, ethnological, and archaeological discoveries that have occurred and are occurring in our country\". Furthermore, the Council denounced the \"Manifesto\" for \"implicitly\" crediting Germanic invaders of Italy in the guise of the Lombards for having \"a formative influence on the Italian race in a disproportional degree to the number of invaders and to their biological predominance\". The Council claimed that the obvious superiority of the ancient Greeks and Romans in comparison with the ancient Germanic tribes made it inconceivable that Italian culture owed a debt to ancient Aryan Germans. The Council denounced the \"Manifesto\"'s Nordicist attitude towards Mediterraneans that it claimed was \"considering them as slaves\" and was \"a repudiation of the entire Italian civilization\".\n\nSince the military defeat of Nazi Germany by the Allies in 1945, some neo-Nazis have developed a more inclusive definition of \"Aryan\", claiming that the peoples of Western Europe are the closest descendants of the ancient Aryans, with Nordic and Germanic peoples being the most \"racially pure.\"\n\nAccording to Nicholas Goodrick-Clarke, many neo-Nazis want to establish an autocratic state modeled after Nazi Germany to be called the \"Western Imperium\". It is believed that this proposed state would be able to attain world domination by combining the nuclear arsenals of the four major Aryan world powers, the United States, the United Kingdom, France, and Russia under a single military command.\n\nThis proposed state would be led by a \"Führer\"-like figure called the \"Vindex\", and would include all areas inhabited by the \"Aryan race\", as conceived by Neo-Nazis. Only those of the Aryan race would be full citizens of the state. The \"Western Imperium\" would embark on a vigorous and dynamic program of space exploration, followed by the creation by genetic engineering of a super race called Homo Galactica. The concept of the \"Western Imperium\" as outlined in the previous three sentences is based on the original concept of the \"Imperium\" as outlined in the 1947 book \"Imperium: The Philosophy of History and Politics\" by Francis Parker Yockey as further updated, extended and refined in the early 1990s in pamphlets published by David Myatt.\n\n\n\n\nNotes\nBibliography\n\nFurther reading\n\n"}
{"id": "6090423", "url": "https://en.wikipedia.org/wiki?curid=6090423", "title": "BDORT", "text": "BDORT\n\nThe Bi-Digital O-Ring Test (BDORT), characterized as a form of applied kinesiology, is a patented alternative medicine diagnostic procedure in which a patient forms an 'O' with his or her fingers, and the diagnostician subjectively evaluates the patient's health according to the patient's finger strength as the diagnostician tries to pry them apart.\n\nBDORT has been cited and characterized at length by the American Institute for Technology and Science Education as a specific and noteworthy example of pseudoscientific quackery.\n\nBDORT was invented by Yoshiaki Omura, along with several other related alternative medicine techniques. They are featured in Omura's self-published \"Acupuncture & Electro-Therapeutics Research, The International Journal,\" of which Omura is founder and editor-in-chief, as well as in seminars presented by Omura and his colleagues.\n\nOmura is registered to practice acupuncture in New York State.\n\nIn the only known full, formal independent evaluation of BDORT or of any other BDORT-related treatment and technique by a mainstream scientific or medical body, the Medical Practitioners Disciplinary Tribunal of New Zealand ruled, in two separate cases brought before it in 2003, that Richard Warwick Gorringe, MB, ChB of Hamilton, New Zealand, who used BDORT (which he also called \"Peak Muscle Resistance Testing\", or \"PMRT\") to the exclusion of conventional diagnoses on his patients, was guilty of malpractice. In the first case, the Tribunal found it \"is not a plausible, reliable, or scientific technique for making medical decisions\" and \"there is no plausible evidence that PMRT has any scientific validity\".\nIn the second case the Tribunal ruled Gorringe again relied on BDORT to the exclusion of traditional diagnoses, which ultimately led to the death of a patient. As a result of these findings and conclusions, Gorringe was fined and stripped of his license to practice medicine.\n\n is president and founder of the \"International College of Acupuncture & Electro-Therapeutics,\" president and founder of the \"International Bi-Digital O-Ring Test Medical Association,\" and medical research director of the \"Heart Disease Research Foundation.\"\n\nThe test is a subjective evaluation of a patient's opposing muscle strength in which a diagnostician employs the thumb and forefinger of each hand, formed in the shape of an O, to attempt to force apart an O shape formed by the patient who places the fingertips of their thumb and one of their remaining fingers together. At the same time, the patient holds a slide of organ tissue, a sample of medication, potential allergen, etc., in their free hand, or is otherwise 'probed' at an appropriate acupuncture point by the use of a metal rod or laser pointer. The diagnostician then uses their perception of the strength required to force apart the patient's 'O-Ring' of thumb and one of the remaining fingers to assess the patient's health.\n\nThe United States Patent and Trademark Office (USPTO) rejected the initial BDORT patent application as 'too unbelievable to be true'. The application was then resubmitted in 1987, and the USPTO again rejected it. After receiving expert testimony from Omura's \"associates in clinical fields and basic sciences, both in Japan and the United States\" regarding BDORT, the USPTO issued in 1993.\n\nThe fact that a patent was granted to the BDORT has been cited as an example of 'high weirdness' by one firm of patent attorneys.\n\nThe BDORT is capable, according to its proponents, of a wide range of applications in the diagnosis, prescription of treatment, and evaluation of efficacy of treatment of, amongst others: heart conditions, cancers, 'pre-cancers', allergic reactions, viral and bacterial infections, a range of organic and/or environmental stresses, as well as the precise location of acupuncture points and meridians previously unknown or inappropriately identified.\n\nOther than the New Zealand Medical Practitioners Disciplinary Tribunal's reports, there is no known independent mainstream scientific or medical evaluation or validation of any of the BDORT or BDORT-related claims, including the following BDORT variants:\n\n\n\n\n\n\nThe New Zealand Medical Practitioners Disciplinary Tribunal, ruled on two separate malpractice cases against Richard Warwick Gorringe, MB, ChB, of Hamilton, New Zealand.\nIn the first, held in Wellington in 2003, where BDORT was also referred to as 'PMRT' ('Peak Muscle Resistance Testing') by Gorringe, the tribunal examined and dismissed any claims of scientific validity of BDORT, offering the following summary statement of findings:\n\nAs a result of these findings and conclusions, Gorringe was fined and stripped of his license to practice medicine.\n\nIn separate hearings the Medical Practitioners Disciplinary Tribunal held in December 2003 and ruled upon in May 2004 in Auckland, found Gorringe guilty of malpractice in the death of an earlier patient, and concluded that Gorringe's reliance on BDORT to the exclusion of conventional diagnoses led to the patient's death.\n\nSeveral expert witnesses provided testimony about BDORT at the MPDT Wellington hearings, with which the tribunal concurred:\n\nIn the first New Zealand MPDT report from Wellington in 2003, the tribunal defines the terms PMRT and BDORT as equivalent:\n\nLater in the same report, the tribunal again equates PMRT and BDORT, but states that the technique used by Gorringe is different from Dr. Omura's:\n\nThe tribunal uses the terms BDORT and PMRT interchangeably throughout the Wellington report from 2003.\n\nIn the second MPDT report from Auckland in 2004, the tribunal does not mention PMRT at all, and refers to Gorringe's technique exclusively as 'BDORT'.\n\nThe Quackwatch article reviewing these two New Zealand MPDT reports also equates PMRT and BDORT, stating:\n\nBDORT-related seminars, given by Omura, are conducted monthly in New York. The University of the State of New York Education Department allows these seminars to count towards course credit for physicians and dentists seeking certification for the application of acupuncture in the course of their practice.\n\nIn a Decision of 15 May 2007 the Victorian Civil and Administrative Tribunal, in Victoria, Australia, in an appeal against a decision by the Chinese Medical Registration Board of Victoria refusing registration to practice as an acupuncturist, found that attendance and participation in Yoshiaki Omura's \"Annual International Symposium on Acupuncture & Electro-Therapeutics\" as accredited by the University of the State of New York Education Department, in addition to \"clinical experience ... with these subjects in respect of real patients\" did not meet the Chinese Medicine Board's requirement of \"competencies substantially equivalent to\" those taught in a Board certified acupuncture class. Given this, the Tribunal ruled that the Board was not required to certify the applicant as a practitioner of Chinese medicine.\n\n"}
{"id": "151107", "url": "https://en.wikipedia.org/wiki?curid=151107", "title": "Body Worlds", "text": "Body Worlds\n\nBody Worlds (German title: Körperwelten) is a traveling exposition of dissected human bodies, animals, and other anatomical structures of the body that have been preserved through the process of plastination. Gunther von Hagens developed the preservation process which \"unite[s] subtle anatomy and modern polymer chemistry\", in the late 1970s.\n\nA series of \"Body Worlds\" anatomical exhibitions has toured many countries worldwide, sometimes raising controversies about the sourcing and display of actual human corpses and body parts. Nevertheless, Von Hagens maintains that all human specimens were obtained with full knowledge and consent of the donors before they died, and his organization keeps extensive documentation of this permission. Von Hagens emphasizes both educational and artistic aspects of his complex and innovative dissections, and offers online teaching guides for educators. He also tries to distinguish his efforts from those of competitors who may have been less thorough in obtaining advance permission from their specimen sources.\n\nThe exhibit states that its purpose and mission is the education of laymen about the human body, leading to better health awareness. All the human plastinates are from people who donated their bodies for plastination via a body donation program. Each Body Worlds exhibition contains approximately 25 full-body plastinates with expanded or selective organs shown in positions that enhance the role of certain systems.\n\nTo produce specimens for \"Body Worlds\", von Hagens employs 340 people at five laboratories in three countries, China, Germany and Kyrgyzstan. Each laboratory is categorized by specialty, with the China laboratory focusing on animal specimens. One of the most difficult specimens to create was the giraffe that appears in \"Body Worlds & The Cycle of Life\". The specimen took three years to complete – ten times longer than it takes to prepare a human body. Ten people are required to move the giraffe, because its final weight (like all specimens after plastination) is equal to the original animal.\n\nMore than 200 specimens of real human organs and organ systems are displayed in glass cases, some showing various medical conditions. Some of the specimens, such as the Tai Chi Man, demonstrate interventions, and include prosthetics such as artificial hip joints or heart valves. Also featured is a liver with cirrhosis and the lungs of a smoker and non-smoker are placed side by side. A prenatal display features fetuses and embryos, some with congenital disorders.\n\nBody Worlds exhibitions have received more than 37 million visitors, making them the world's most popular touring attraction. \"Body Worlds\" was first presented in Tokyo in 1995. Body Worlds exhibitions have since been hosted by more than 50 museums and venues in North America, Europe and Asia. \"Body Worlds 2 & The Brain – Our Three Pound Gem\" (concerning the brain and nervous system) opened in 2005 at the California Science Center in Los Angeles. it is showing at the Telus World of Science in Vancouver. Several Body Worlds exhibits (as well as Von Hagens himself) were featured in the 2006 film \"Casino Royale\". Among the plastinates featured were the \"Poker Playing Trio\" (which plays a key role in one scene) and \"Rearing Horse and Rider\".\n\n\"Body Worlds 3 & The Story of the Heart\" (concerning the cardiovascular system) opened on 25 February 2006, at the Houston Museum of Natural Science. On 9 July 2009 this show appeared at the Buffalo Museum of Science in Buffalo, New York. , it is showing at the Denver Museum of Nature and Science in Denver, Colorado. \"Body Worlds 4\" debuted 22 February 2008 at the Museum of Science and Industry in Manchester in England and was in the Cureghem Cellars in Brussels until March 2009. \"Body Worlds & The Mirror of Time\" (featuring human development and aging) debuted at The O in London in October 2008. \"Körperwelten & Der Zyklus Des Lebens (The cycle of life)\" opened in Heidelberg in January 2009. \"Body Worlds Vital\" was inaugurated at the Universum museum of the National Autonomous University of Mexico in 2012.\n\nIn July 2008, the Czech Senate passed a law to address illegal trading in human tissue and ban \"advertising of donation of human cells and tissues for money or similar advantages\".\n\nOn Tuesday 21 April 2009, a French judge ruled concerning the Paris exhibition of \"Our Body: The Universe Within\", that exhibiting dead bodies for profit was a \"violation of the respect owed to them\". \"Under the law, the proper place for corpses is in the cemetery\", said Judge Louis-Marie Raingeard. Raingeard ordered the exhibition to close within 24 hours or face a fine of 20,000 euro (over 26,000 dollars) for each day it stayed open. The judge also ordered authorities to seize the 17 bodies on display and all of the organs on display from an unknown number of people for proper burial. Gunther Von Hagens issued a press statement denying any connection between the closed Chinese exhibition and his Body Worlds franchise. Similar exhibitions had already been successfully staged in Lyon and Marseille.\n\nThe UK Parliament created legislation for exhibits of human remains, including plastinated bodies and body parts, in England and Wales under the Human Tissue Act 2004. This requires a licence to be granted by the Human Tissue Authority. The Human Tissue Act superseded the Anatomy Act 1832, which had been found by an independent commission (The Redfern Report) to be inadequate on contemporary collection and use of human tissues, following the Alder Hey organs scandal. In March 2008, the Manchester Museum of Science and Industry was granted such a licence to hold \"Body Worlds 4\" and a further licence was granted to the exhibition in the O2, London, in 2008.\n\nThe Human Tissue (Scotland) Act 2006 – which amended the Anatomy Act 1984 – covers Scotland. Under the terms of this Act, licences for the handling of human remains, including display, must be granted directly by the Scottish Ministry.\n\nVarious organizations gave evidence to the Scottish Executive during the consultation process, including the Royal College of Surgeons of Edinburgh, the Wellcome Trust, and the Museums Association.\n\nVarious legislation has been proposed and enacted in different American states. Most proposals concentrate on issues regarding the sale of human remains and the consent of the donors.\n\nNational legislation on consent and tissue donation issues is expressed in the Uniform Anatomical Gift Act (2006) passed by the National Conference of Commissioners on Uniform State Laws which states that \"an anatomical gift of a donor's body or part may be made during the life of the donor for the purpose of transplantation, therapy, research, or education\" and prohibits trafficking in donated human organs for profit.\n\nIn early 2008, former U.S. Republican Representative W. Todd Akin proposed an amendment to the Smoot-Hawley Tariff Act of 1930 to \"make it unlawful for a person to import plastinated human remains into the United States.\" The President of the American Association of Anatomists has expressed concern that the scope of the act is \"too broad\" and that \"Preventing importation of all plastinated specimens could severely restrict their use for medical education.\". The bill of amendment was not enacted during the 2007–2008 Congressional session.\n\nCalifornia's proposed bill AB1519 (Ma), sponsored by Assemblywoman Fiona Ma, tried to \"require exhibitors to get a county permit; to do so, they would have to prove to county health officials that the people whose cadavers were on display — or their next of kin — had consented\".\n\nAssembly Bill 1519 would have made California the first state to require such proof. It was vetoed by Governor Arnold Schwarzenegger on 26 September 2008.\n\nThe state of Florida prohibits the sale or purchase of human remains and \"Authorizes certain science centers located in this state to transport plastinated bodies into, within, or out of this state and exhibit such bodies for the purpose of public education without the consent of this state's anatomical board if the science center notifies the board of any such transportation or exhibition, as well as the location and duration of any exhibition, at least 30 days before such transportation or exhibition\".\n\nIn January 2009, Rep. Marcus Oshiro introduced two bills prompted by presentation of the BODIES Exhibition in that state.\n\nHB28 Relating to Dead Human Bodies would add to the prohibition against buying dead human bodies, the selling of dead human bodies and defines the term \"dead human body\" to include plastinated bodies and body parts. It would increase the fine for buying or selling a dead human body to up to $5,000.\n\nHB29 Relating to Dead Human Bodies. Would prohibit the commercial display of dead human bodies without a permit from the Department of Health.\n\nIn June 2008, New York State Senate passed legislation regulating body exhibits. A bill that was sponsored by Senator Jim Alesi requires anyone showing an exhibit that uses real human bodies in New York museums to produce a permit detailing their origin.\n\nRepresentative Mike Fleck's proposed bill would require evidence of informed consent from the decedent or relatives of all humans whose remains are put on display.\n\nThe state of Washington considered a bill that would \"require written authorization to display human remains for a commercial purpose\".\n\nReligious groups, including representatives of the Catholic Church and some Jewish rabbis have objected to the display of human remains, stating that it is inconsistent with reverence towards the human body.\n\nIn 2003, while promoting a display in the Hamburg Museum of Erotica, von Hagens announced his intention to create a sex plastinate. In May 2009 he unveiled a plastinate of a couple having sex, intended for a Berlin exhibition.\n\nIn 2007, the Bishop of Manchester launched a campaign to coincide with the opening of Body Worlds in that city, accusing the exhibitors of being \"body snatchers\" and \"robbing the NHS\", arguing that donation of bodies for plastination would deprive the National Health Service of organs for transplant. The site included a government petition calling for \"a review of the law regarding the policies and practices of touring shows involving corpses\".\n\nConsent is a primary focus of discussion. In January 2004, the German news magazine \"Der Spiegel\" reported that von Hagens had acquired corpses of executed prisoners in China; von Hagens countered that he did not know the origin of the bodies, and returned seven disputed cadavers to China. In 2004, von Hagens obtained an injunction against \"Der Spiegel\" for making the claims. Paul Harris, director of North Carolina's State Board of Funeral Services, has stated, \"Somebody at some level of government ought to be able to look at a death certificate, a statement from an embalmer, donation documents... That's a reasonable standard to apply.\" Assemblywoman Fiona Ma (D-San Francisco) said, \"These displays do have important educational benefits, but using bodies against a person's will is unacceptable\".\n\nQuestions raised regarding deceased hospital patients from Kyrgyzstan and executed prisoners from China – were categorically stated to have never been used in a Body Worlds exhibition, according to BodyWorlds. \"Five years ago, customs officers intercepted 56 bodies and hundreds of brain samples sent from the Novosibirsk Medical Academy to von Hagens' lab in Heidelberg, Germany. The cadavers were traced to a Russian medical examiner who was convicted last year of illegally selling the bodies of homeless people, prisoners and indigent hospital patients. Von Hagens was not charged with any wrongdoing, and says his cadavers are obtained only through proper legal and ethical channels.\n\nAn Ethical Commission set up by the California Science Center in Los Angeles in 2004 had the following members: \nReverend Richard Benson, Assistant Prof of Moral Theology and Academic Dean, \nSt. John's Seminar, Roman Catholic Archdiocese of Los Angeles;\nDavid C. Blake, PhD, JD, VP, Mission and Ethics,\nSaint John's Health Center;\nRabbi Morley Feinstein,\nSenior Rabbi, University Synagogue;\nReverend Leonard Jackson,\nAssociate Minister,\nFirst African Methodist Episcopal Church (First AME). \nThey determined that \n\"All the bodies need to be properly donated. Advisors felt that this is the most controversial aspect of the project. Proper body donation should be verified to the Science Center's satisfaction, and involves several components. Several advisors reviewed the Body Donor and felt it should be reviewed to ensure that it meets an adequate standard of disclosure and informed consent. They recommended that the form should be clear to make sure the bodies in the exhibit consented to public display. The source of donated bodies should be verifiable; Ask an independent party to review donor forms, verifying that all bodies are donated properly.; Communicate to guests, near the entrance of the exhibit, that the bodies are donated.\"\nAs an ethical concern, consent is not regulated worldwide according to the same ethics. \"That paperwork is then separated from the bodies, which can be used for displays or sold in pieces to medical schools. No one will know for sure, because each plastinated corpse is made anonymous to protect its privacy.\" Hans Martin Sass, a philosophy professor with a speciality in ethics, was hired by the California Science Center to investigate Body Worlds before the show's U.S. debut in 2004. He matched over 200 donation forms to death certificates, but he did not match the paperwork to specific bodies von Hagens has on display.\n\nInternational trade experts have objected to the way in which bodies for commercial display are imported, because the way their categorization codes (as \"art collections\") do not require Centers for Disease Control stamps or death certificates, both of which are required for medical cadavers. In most countries plastinated human specimens are classified under Customs Classification Code 97050000.48 \"items in anatomical collections\". This customs code encompasses \"zoological, botanical, mineralogical or anatomical collections or items in such collections.\"\n\nIn an ethical analysis, Thomas Hibbs, professor of ethics and culture at Baylor University, a private Baptist-affiliated institution, compared cadaver displays to pornography, in that they reduce the subject to \"the manipulation of body parts stripped of any larger human significance.\"\n\nIn a 2006 lecture entitled \"Plasti-Nation: How America was Won\", Lucia Tanassi, professor of medical ethics and anthropology at Vanderbilt University Medical Center, explored questions for ethicists regarding this new scientific frontier. Tanassi called it provocative that ethics committees have contributed to the popularization of the exhibits without setting forth any process of a line of inquiry, pointing to an ethics report from the California Science Center. As part of that review, bioethicist Hans Martin Sass was sent to Heidelberg to match donor consents with death certificates.\n\nConcerns have been expressed about the educational aspects, especially the inclusion of these displays for school field trips. St. Louis Diocese Archbishop Raymond Burke strongly suggested that Catholic Schools avoid scheduling field trips, stating that parents, and not children, should retain the freedom of deciding whether or not their children will view the exhibit. Concerned with how \"some kids process\" these \"graphic\" images, Des McKay, school superintendent in Abbotsford, British Columbia (near Greater Vancouver), barred field trips to exhibits of plasticized human beings. In an editorial to the Abbotsford News, Rev. Christoph Reiners questions what effect the exhibits will have on the values of children attending for school field trips. Others—such as the Catholic Schools Office of Phoenix—acknowledge the educational content of Body Worlds. Reporting on the exhibition at the O2 bubble in 2008/2009, Melanie Reid of The Times stated \"(Body Worlds) should be compulsory viewing for every child of 10 or over\"\n\nVon Hagens maintains copyright control over pictures of his exhibits. Visitors are not allowed to take pictures, and press photographers are required to sign agreements permitting only a single publication in a defined context, followed by a return of the copyright to Von Hagens. Because of a similar agreement applied to sound bites (O-Töne, in German) a German press organization suggested that the press refrain from reporting about the exhibition in Munich in 2003 .\n\nThe Body Worlds website offers plastinated pieces for sale. There are a wide range of products from plastinated fruit jewelry to entire humans. Although some of the pieces require purchasers to be a qualified user—those intending to use the pieces for \"research, educational, medical or therapeutic purposes\"—many pieces, including animal testicles and baby chicks, require no authorization. There are also extremely realistic plastinate impressions of human hearts and slices (including one slice of copulating humans) for sale to the general public.\n\nThe success of Body Worlds has given rise to several similar shows featuring plastinated cadavers, including \"BODIES... The Exhibition\" and \"Our Body: The Universe Within\" in the United States, \"Bodies Revealed\" in the United Kingdom, \"Body Exploration\" in the Republic of China, \"Mysteries of the Human Body\" in South Korea, \"Jintai Plastomic: Mysteries of the Human Body\" in Japan, \"Cuerpos Entrañables\" in Spain.\n\nSome of these contain exhibits very similar to von Hagens' plastinates; Von Hagens has asserted copyright protection, and has sued \"Body Exploration\" and \"Bodies Revealed\".\nThe suits were based on a presumed copyright of certain positions of the bodies, but the counterparty asserts that the human body in its diversity cannot be copyrighted.\n\nSuch lawsuits have not stopped the competition. While the Korean police in Seoul confiscated a few exhibits from \"Bodies Revealed\", the exhibition went on successfully.\n\nSeveral of the competing exhibitions have been organized by the publicly traded US company Premier Exhibitions. They started their first \"Bodies Revealed\" exhibition in Blackpool, England which ran from August through October 2004. In 2005 and 2006 the company opened their \"Bodies Revealed\" and \"BODIES... The Exhibition\" exhibitions in Seoul, Tampa, Miami, New York City, and Seattle. Other exhibition sites in 2006 are Mexico City, Atlanta (GA), London, Great Britain and Las Vegas (Nevada).\n\nUnlike Body Worlds, none of the competing exhibitions or their suppliers have a body donation programme. Dr. Roy Glover, a spokesperson for \"BODIES... The Exhibition\" said all their exhibits use unclaimed cadavers, deposited at the University of Dalian by Chinese authorities. In May 2008, a settlement with the attorney general of New York obliged Premier Exhibitions to offer refunds to visitors when it could not prove consent for the use of the bodies in its exhibitions. New York Attorney General Andrew Cuomo commented: \"Despite repeated denials, we now know that Premier itself cannot demonstrate the circumstances that led to the death of the individuals. Nor is Premier able to establish that these people consented to their remains being used in this manner.\"\n\n\n\n"}
{"id": "6738308", "url": "https://en.wikipedia.org/wiki?curid=6738308", "title": "Borderless selling", "text": "Borderless selling\n\nBorderless selling is the process of selling services to clients outside the country of origin of services through modern methods which eliminate the actions specifically designed to hinder international trade. International trade through \"borderless selling\" is a new phenomenon born in the current \"globalization\" era.\n\nBorderless selling is defined as the process of performing sales transaction between two or more parties from different countries (an exporter and an importer) which is free from actions specifically designed to hinder international trade, such as tariff barriers, currency restrictions, and import quotas.\n\nInternational trade which is the exchange of goods and services across international borders has been present throughout much of history of economics, society and politics. \n\nIt is assumed that offshore outsourcing gave birth to \"borderless selling\". The selling of services by offshore outsourcing service providers to foreign clients is free from actions specifically designed to hinder international trade, such as tariff barriers, currency restrictions, and import quotas. This is largely because most of the services are sold or delivered electronically from the offshore service provider to the foreign client. This phenomenon gave birth to borderless selling.\n\nThere is a high correlation between outsourcing and exporting activity. However, borderless selling is different from free international trade or selling. Under the belief in Mercantilism, most nations had high tariffs and many restrictions on international trade for centuries. In the 19th century, a belief in free trade became paramount in west, especially in Britain and this outlook has since then dominated the thinking of western nations. Traditionally international trade was possible between only those countries which regulated international trade through bilateral treaties. Borderless selling is possible between any two countries of the world because services can be exported using modern telecommunication networks without the need to regulate trade.\n\nThe \"borderless selling\" term was originated as part of the research carried out by team led by Paramjeev Singh Sethi.\n\n\n\nMany services can be sold through borderless selling, popularly including:\n\nDifferent means used for borderless selling:\n\n"}
{"id": "48582204", "url": "https://en.wikipedia.org/wiki?curid=48582204", "title": "BrainCraft", "text": "BrainCraft\n\nBrainCraft is an educational video series on YouTube created by Australian science communicator Vanessa Hill. Hill's videos use stop motion and paper craft animation to explain neuroscience, psychology and human behavior. \"BrainCraft\" is part of the PBS Digital Studios network.\n\n\"BrainCraft\" videos are about science, with many episodes discussing phenomena related to sleep, memory, brain hacks and the science of food. \"BrainCraft\" launched on 23 November 2013 with the video, \"Is Google Killing Your Memory?\" In its first few months on YouTube, \"BrainCraft\" joined PBS Digital Studios. As of February 26, 2018, \"BrainCraft\" has 413,088 subscribers and 24,156,875 views.\n\nHill has collaborated with many well-known YouTubers such as Vsauce, Mike Rugnetta (PBS Idea Channel, Know Your Meme), Jake Roper (Vsauce3), Dianna Cowern (PBS Physics Girl), and more.\n\n\"BrainCraft\" videos have been featured in Scientific American, Huffington Post, Gizmodo and MTV.\n\n"}
{"id": "2526670", "url": "https://en.wikipedia.org/wiki?curid=2526670", "title": "Bully for Brontosaurus", "text": "Bully for Brontosaurus\n\nBully for Brontosaurus (1991) is the fifth volume of collected essays by the Harvard paleontologist Stephen Jay Gould. The essays were culled from his monthly column \"This View of Life\" in \"Natural History\" magazine, to which Gould contributed for 27 years. The book deals, in typically discursive fashion, with themes familiar to Gould's writing: evolution and its teaching, science biography, and probabilities.\n\nThe title essay, \"Bully for Brontosaurus\", discusses the theory and history of taxonomy by examining the debate over whether \"Brontosaurus\" should be labelled \"Apatosaurus\". In \"Justice Scalia's Misunderstanding\", Gould dissects and decisively rejects Antonin Scalia's dissent in the United States Supreme Court case \"Edwards v. Aguillard\" that overturned the last creationist statute in the country. Gould claimed his favourite essay to be \"In a Jumbled Drawer\" which discusses the debate between Nathaniel Shaler and William James over whether the improbability of our having evolved necessitates divine intervention (Gould, like James, argues no); the essay includes a letter from former President Jimmy Carter as a postscript, which discusses the issue.\n\nThe essay \"Male Nipples and Clitoral Ripples\" dealt with the issue of adaptive arguments. It derives from some work by Elisabeth Lloyd, whose subsequent 2005 book was dedicated to Gould (and her parents), and uses the case of the female orgasm to expand on the subject of adaptiveness in both depth and breadth.\n\n"}
{"id": "57896735", "url": "https://en.wikipedia.org/wiki?curid=57896735", "title": "CEASE therapy", "text": "CEASE therapy\n\nCEASE (Complete Elimination of Autistic Spectrum Expression) therapy is used by naturopaths (particularly homeopaths) who claim, without evidence, that it can treat or even cure people with autism. It involves a mixture of supplements, high-dose vitamin C, 'orthomolecular support', dietary restrictions and homeopathy and was developed by the late Tinus Smits - a Dutch doctor. Smits claimed to have used it to treat over 300 children with autism. The therapy became more notable in 2017/2018 because of regulatory action taken by professional bodies in The Netherlands, UK and Canada following a series of complaints about unfounded claims. \n\nSmits in the book \"Autism Beyond Despair - CEASE Therapy\" stated that autistic children should never be vaccinated. \n\nIn October 2017 the Dutch Advertising Code Foundation (Stichting Reclame Code) found that the official website for CEASE therapy was in breach of advertising regulations.\n\nIn the United Kingdom, the Professional Standards Authority (PSA) placed some requirements on the Society of Homeopaths (SoH) when they reaccredited their members' register under their Accredited Register scheme, due to concerns about the way in which members marketed CEASE therapy. The PSA asked the SoH to confirm \"what action it will take to ensure children are safe as a condition of its re-accreditation\". In June 2018 the Society of Homeopaths published a position statement advising their members not to imply any cure of autism when marketing CEASE therapy. It has been estimated that more than 120 homeopaths are offering CEASE in the UK though not all are SoH members. In July 2015 the UK's Advertising Standards Authority (ASA) found Teddington Homeopathy's marketing of CEASE therapy in breach of the Advertising Standards Code. The following month the ASA added the company to its list of non-compliant online advertisers for \"making unproven efficacy claims for CEASE therapy\". In July 2018 the ASA upheld an adjudication against Bubbling Life's website, determining that the claims relating to CEASE, vaccination, autism and ASD could discourage customers from seeking appropriate advice or treatment. \n\nIn British Columbia, Canada, the Board of the College of Naturopathic Physicians investigated three CEASE practitioners following complaints from the public and subsequently \"determined that naturopathic doctors in British Columbia must not advertise or offer CEASE therapy\". As well as this prohibition the College's updated position statements also clarify that naturopathic doctors in BC must not offer anti-vaccination materials or advice (including on social media) and must not imply that vaccination causes autism.\n\n"}
{"id": "22786710", "url": "https://en.wikipedia.org/wiki?curid=22786710", "title": "Carcel", "text": "Carcel\n\nThe Carcel is a former French unit for measuring the intensity of light. The unit was defined in 1860 as the intensity of a Carcel lamp with standard burner and chimney dimensions, which burnt colza oil\n\nIn modern terminology one carcel equals about 9.74 candelas.\n\n"}
{"id": "39935010", "url": "https://en.wikipedia.org/wiki?curid=39935010", "title": "Center for Open Science", "text": "Center for Open Science\n\nThe Center for Open Science is a non-profit technology organization based in Charlottesville, Virginia with a mission to \"increase the openness, integrity, and reproducibility of scientific research.\" Brian Nosek and Jeffrey Spies founded the organization in January 2013, funded mainly by the Laura and John Arnold Foundation and others, after implementation and use of the Open Science Framework (OSF).\n\nThe organization began with work in reproducibility of psychology research, with the large-scale \"\". A second reproducibility project for cancer biology research has also been started through a partnership with Science Exchange. In March 2017, the Center published a detailed strategic plan. Brian Nosek posted a letter outlining the history of the Center and future directions.\n\nThe Open Science Framework (OSF) is an open source software project that facilitates open collaboration in science research. This framework was used to work on a project in the reproducibility of psychology research. The current reproducibility project is a crowdsourced empirical investigation of the reproducibility of a variety of studies from psychological literature. The reproducibility project samples from three major journals: \"Journal of Personality and Social Psychology\", \"Psychological Science\", and \"\". Scientists from all over the world volunteer to replicate a study of their choosing from these journals, and follow a structured protocol for designing and conducting a high-powered replication of the key effect. The results were published in 2015. Whilst OSF initially focused on psychology, it has since broadened into any research field.\n\nIn 2016 the group released three new open source preprint services covering the fields of engineering, engrXiv, one that covers social sciences, SocArxiv, and one for psychology, psyArXiv. Currently partner repositories include: AgriXiv, arabixiv, BITSS, Earth ArXiv, engrXiv, FocUS Archive, Frenxiv, INA-Rxiv, LawArXiv, LIS Scholarship Archive (LISSA), MarXiv, MindRxiv, NutriXiv, Paleorxiv, PsyArXiv, SocArxiv, SportRxiv, and Thesis Commons (theses and dissertations). \n\n\n"}
{"id": "429171", "url": "https://en.wikipedia.org/wiki?curid=429171", "title": "Characterology", "text": "Characterology\n\nCharacterology (from Greek \"character\" and , \"-logia\") is a method of character reading that attempted to combine revised physiognomy, reconstructed phrenology and amplified pathognomy, with ethnology, sociology and anthropology. Developed by L. Hamilton McCormick in the 1920s, characterology was an attempt to produce a scientific, objective system to assess an individual's character.\n\nCharacterology attempted to resolve flaws in the phrenological systems of Franz Joseph Gall \nand Johann Spurzheim. McCormick tried to distance himself from those earlier systems, and wrote extensively about how his ideas improved upon them.\n\nMcCormick suggested possible applications for characterology, e.g., advice for parents and educators, guidance in military officer promotions, evaluating thinking patterns (i.e., reason-oriented or memory-oriented ), assessing business associates and competitors, career counseling, and selecting marital partners.\n\n"}
{"id": "49245321", "url": "https://en.wikipedia.org/wiki?curid=49245321", "title": "Chinese Chemical Society (Beijing)", "text": "Chinese Chemical Society (Beijing)\n\nThe Chinese Chemical Society (CCS; ) is a professional society of chemists headquartered in Beijing. It is part of the China Association for Science and Technology. Current membership is at around 55,000.\n\nThe CCS was founded in Nanjing on August 4, 1932. It merged with the Chinese Chemical Engineering Society in 1959. The organizations were separated again in 1963. CSS has been a member of the International Union of Pure and Applied Chemistry (IUPAC) since 1980 and of the Federation of Asian Chemical Societies (FACS) since 1984.\n\n\nThe CCS publishes many academic journals, including:\n\n\n"}
{"id": "7638", "url": "https://en.wikipedia.org/wiki?curid=7638", "title": "Consilience", "text": "Consilience\n\nIn science and history, consilience (also convergence of evidence or concordance of evidence) refers to the principle that evidence from independent, unrelated sources can \"converge\" on strong conclusions. That is, when multiple sources of evidence are in agreement, the conclusion can be very strong even when none of the individual sources of evidence is significantly so on its own. Most established scientific knowledge is supported by a convergence of evidence: if not, the evidence is comparatively weak, and there will not likely be a strong scientific consensus.\n\nThe principle is based on the unity of knowledge; measuring the same result by several different methods should lead to the same answer. For example, it should not matter whether one measures the distance between the Giza pyramid complex by laser rangefinding, by satellite imaging, or with a meter stick – in all three cases, the answer should be approximately the same. For the same reason, different dating methods in geochronology should concur, a result in chemistry should not contradict a result in geology, etc.\n\nThe word \"consilience\" was originally coined as the phrase \"consilience of inductions\" by William Whewell (\"consilience\" refers to a \"jumping together\" of knowledge). The word comes from Latin \"com-\" \"together\" and \"-siliens\" \"jumping\" (as in resilience).\n\nConsilience requires the use of independent methods of measurement, meaning that the methods have few shared characteristics. That is, the mechanism by which the measurement is made is different; each method is dependent on an unrelated natural phenomenon. For example, the accuracy of laser rangefinding measurements is based on the scientific understanding of lasers, while satellite pictures and meter sticks rely on different phenomena. Because the methods are independent, when one of several methods is in error, it is very unlikely to be in error in the \"same way\" as any of the other methods, and a difference between the measurements will be observed. If the scientific understanding of the properties of lasers were inaccurate, then the laser measurement would be inaccurate but the others would not.\n\nAs a result, when several different methods agree, this is strong evidence that \"none\" of the methods are in error and the conclusion is correct. This is because of a greatly reduced likelihood of errors: for a consensus estimate from multiple measurements to be wrong, the errors would have to be similar for all samples and all methods of measurement, which is extremely unlikely. Random errors will tend to cancel out as more measurements are made, due to regression to the mean; systematic errors will be detected by differences between the measurements (and will also tend to cancel out since the direction of the error will still be random). This is how scientific theories reach high confidence – over time, they build up a large degree of evidence which converges on the same conclusion.\n\nWhen results from different strong methods do appear to conflict, this is treated as a serious problem to be reconciled. For example, in the 19th century, the Sun appeared to be no more than 20 million years old, but the Earth appeared to be no less than 300 million years (resolved by the discovery of nuclear fusion and radioactivity, and the theory of quantum mechanics); or current attempts to resolve theoretical differences between quantum mechanics and general relativity.\n\nBecause of consilience, the strength of evidence for any particular conclusion is related to how many independent methods are supporting the conclusion, as well as how different these methods are. Those techniques with the fewest (or no) shared characteristics provide the strongest consilience and result in the strongest conclusions. This also means that confidence is usually strongest when considering evidence from different fields, because the techniques are usually very different.\n\nFor example, the theory of evolution is supported by a convergence of evidence from genetics, molecular biology, paleontology, geology, biogeography, comparative anatomy, comparative physiology, and many other fields. In fact, the evidence within each of these fields is itself a convergence providing evidence for the theory. (As a result, to disprove evolution, most or all of these independent lines of evidence would have to be found to be in error.) The strength of the evidence, considered together as a whole, results in the strong scientific consensus that the theory is correct. In a similar way, evidence about the history of the universe is drawn from astronomy, astrophysics, planetary geology, and physics.\n\nFinding similar conclusions from multiple independent methods is also evidence for the reliability of the methods themselves, because consilience eliminates the possibility of all potential errors that do not affect all the methods equally. This is also used for the validation of new techniques through comparison with the consilient ones. If only partial consilience is observed, this allows for the detection of errors in methodology; any weaknesses in one technique can be compensated for by the strengths of the others. Alternatively, if using more than one or two techniques for every experiment is infeasible, some of the benefits of consilience may still be obtained if it is well-established that these techniques usually give the same result.\n\nConsilience is important across all of science, including the social sciences, and is often used as an argument for scientific realism by philosophers of science. Each branch of science studies a subset of reality that depends on factors studied in other branches. Atomic physics underlies the workings of chemistry, which studies emergent properties that in turn are the basis of biology. Psychology is not separate from the study of properties emergent from the interaction of neurons and synapses. Sociology, economics, and anthropology are each, in turn, studies of properties emergent from the interaction of countless individual humans. The concept that all the different areas of research are studying one real, existing universe is an apparent explanation of why scientific knowledge determined in one field of inquiry has often helped in understanding other fields.\n\nConsilience does not forbid deviations: in fact, since not all experiments are perfect, some deviations from established knowledge are expected. However, when the convergence is strong enough, then new evidence inconsistent with the previous conclusion is not usually enough to outweigh that convergence. Without an equally strong convergence on the new result, the weight of evidence will still favor the established result. This means that the new evidence is most likely to be wrong.\n\nScience denialism (for example, AIDS denialism) is often based on a misunderstanding of this property of consilience. A denier may promote small gaps not yet accounted for by the consilient evidence, or small amounts of evidence contradicting a conclusion without accounting for the pre-existing strength resulting from consilience. More generally, to insist that all evidence converge precisely with no deviations would be naïve falsificationism, equivalent to considering a single contrary result to falsify a theory when another explanation, such as equipment malfunction or misinterpretation of results, is much more likely.\n\nHistorical evidence also converges in an analogous way. For example: if five ancient historians, none of whom knew each other, all claim that Julius Caesar seized power in Rome in 49 BCE, this is strong evidence in favor of that event occurring even if each individual historian is only partially reliable. By contrast, if the same historian had made the same claim five times in five different places (and no other types of evidence were available), the claim is much weaker because it originates from a single source. The evidence from the ancient historians could also converge with evidence from other fields, such as archaeology: for example, evidence that many senators fled Rome at the time, that the battles of Caesar’s civil war occurred, and so forth.\n\nConsilience has also been discussed in reference to Holocaust denial. \nThat is, individually the evidence may underdetermine the conclusion, but together they overdetermine it. A similar way to state this is that to ask for one \"particular\" piece of evidence in favor of a conclusion is a flawed question.\n\nIn addition to the sciences, consilience can be important to the arts, ethics and religion. Both artists and scientists have identified the importance of biology in the process of artistic innovation.\n\nConsilience has its roots in the ancient Greek concept of an intrinsic orderliness that governs our cosmos, inherently comprehensible by logical process, a vision at odds with mystical views in many cultures that surrounded the Hellenes. The rational view was recovered during the high Middle Ages, separated from theology during the Renaissance and found its apogee in the Age of Enlightenment.\n\nWhewell’s definition was that:\nMore recent descriptions include:\n\nAlthough the concept of consilience in Whewell's sense was widely discussed by philosophers of science, the term was unfamiliar to the broader public until the end of the 20th century, when it was revived in \"Consilience: The Unity of Knowledge,\" a 1998 book by the humanist biologist Edward Osborne Wilson, as an attempt to bridge the culture gap between the sciences and the humanities that was the subject of C. P. Snow's \"The Two Cultures and the Scientific Revolution\" (1959).\n\nWilson held that with the rise of the modern sciences, the sense of unity gradually was lost in the increasing fragmentation and specialization of knowledge in the last two centuries. He asserted that the sciences, humanities, and arts have a common goal: to give a purpose to understanding the details, to lend to all inquirers \"a conviction, far deeper than a mere working proposition, that the world is orderly and can be explained by a small number of natural laws.\" And important point made by Wilson is that hereditary human nature and evolution itself profoundly effect the evolution of culture, in essence a sociobiological concept. Wilson's concept is a much broader notion of consilience than that of Whewell, who was merely pointing out that generalizations invented to account for one set of phenomena often account for others as well.\n\nA parallel view lies in the term universology, which literally means \"the science of the universe.\" Universology was first promoted for the study of the interconnecting principles and truths of all domains of knowledge by Stephen Pearl Andrews, a 19th-century utopian futurist and anarchist.\n\n\n"}
{"id": "56206", "url": "https://en.wikipedia.org/wiki?curid=56206", "title": "Crop circle", "text": "Crop circle\n\nA crop circle or crop formation is a pattern created by flattening a crop, usually a cereal. The term was first coined in the early 1980s by Colin Andrews. Crop circles have been described as all falling \"within the range of the sort of thing done in hoaxes\" by Taner Edis, professor of physics at Truman State University. Although obscure natural causes or alien origins of crop circles are suggested by fringe theorists, there is no scientific evidence for such explanations, and all crop circles are consistent with human causation.\n\nThe number of crop circles has substantially increased from the 1970s to current times. There has been little scientific study of them. Circles in the United Kingdom are not distributed randomly across the landscape but appear near roads, areas of medium to dense population and cultural heritage monuments, such as Stonehenge or Avebury. In 1991, two hoaxers, Bower and Chorley, took credit for having created many circles throughout England after one of their circles was described by a circle investigator as impossible to be made by human hand.\n\nFormations are usually created overnight, although some are reported to have appeared during the day. In contrast to crop circles or crop formations, archaeological remains can cause cropmarks in the fields in the shapes of circles and squares, but they do not appear overnight, and they are always in the same places every year.\n\nThe concept of \"crop circles\" began with the original late-1970s hoaxes by Doug Bower and Dave Chorley (see Bower and Chorley, below). They said that they were inspired by the Tully \"saucer nest\" case in Australia, where a farmer claimed to first have seen a UFO, then found a flattened circle of swamp reeds.\n\nA 1678 news pamphlet \"The Mowing-Devil: or, Strange News Out of Hartfordshire\" is claimed by some cereologists to be the first depiction of a crop circle. Crop circle researcher Jim Schnabel does not consider it to be a historical precedent because it describes the stalks as being cut rather than bent (see folklore section).\n\nIn 1686, British naturalist Robert Plot reported on rings or arcs of mushrooms (see fairy rings) in \"The Natural History of Stafford-Shire\" and proposed air flows from the sky as a cause. In 1991 meteorologist Terence Meaden linked this report with modern crop circles, a claim that has been compared with those made by Erich von Däniken.\n\nAn 1880 letter to the editor of \"Nature\" by amateur scientist John Rand Capron describes how a recent storm had created several circles of flattened crops in a field.\n\nIn 1932, archaeologist E C Curwen observed four dark rings in a field at Stoughton Down near Chichester, but could examine only one: \"a circle in which the barley was 'lodged' or beaten down, while the interior area was very slightly mounded up.\"\n\nIn 1963, amateur astronomer Patrick Moore described a crater in a potato field in Wiltshire, which he considered was probably caused by an unknown meteoric body. In nearby wheat fields, there were several circular and elliptical areas where the wheat had been flattened. There was evidence of \"spiral flattening\". He thought they could be caused by air currents from the impact, since they led towards the crater. Astronomer Hugh Ernest Butler observed similar craters and said they were likely caused by lightning strikes.\n\nIn the 1960s, in Tully, Queensland, Australia, and in Canada, there were many reports of UFO sightings and circular formations in swamp reeds and sugar cane fields. For example, on 8 August 1967, three circles were found in a field in Duhamel, Alberta, Canada; Department of National Defence investigators concluded that it was artificial but couldn't say who made them or how. The most famous case is the 1966 Tully \"saucer nest\", when a farmer said he witnessed a saucer-shaped craft rise 30 or from a swamp and then fly away. On investigating he found a nearly circular area 32 feet long by 25 feet wide where the grass was flattened in clockwise curves to water level within the circle, and the reeds had been uprooted from the mud. The local police officer, the Royal Australian Air Force, and the University of Queensland concluded that it was most probably caused by natural causes, like a down draught, a willy-willy (dust devil), or a waterspout. In 1973, G.J. Odgers, Director of Public Relations, Department of Defence (Air Office), wrote to a journalist that the \"saucer\" was probably debris lifted by the causing willy-willy. Hoaxers Bower and Chorley said they were inspired by this case to start making the modern crop circles that appear today.\n\nSince the 1960s, there had been a surge of UFOlogists in Wiltshire, and there were rumours of \"saucer nests\" appearing in the area, but they were never photographed. There are other pre-1970s reports of circular formations, especially in Australia and Canada, but they were always simple circles, which could have been caused by whirlwinds. In \"Fortean Times\" David Wood reported that in 1940 he had already made crop circles near Gloucestershire using ropes. In 1997, the \"Oxford English Dictionary\" recorded the earliest usage of the term \"crop circles\" in a 1988 issue of \"Journal of Meteorology\", referring to a BBC film. The coining of the term \"crop circle\" is attributed to Colin Andrews in the late 1970s or early 1980s.\n\nThe majority of reports of crop circles have appeared in and spread since the late 1970s as many circles began appearing throughout the English countryside. This phenomenon became widely known in the late 1980s, after the media started to report crop circles in Hampshire and Wiltshire. After Bower's and Chorley's 1991 statement that they were responsible for many of them, circles started appearing all over the world. To date, approximately 10,000 crop circles have been reported internationally, from locations such as the former Soviet Union, the United Kingdom, Japan, the U.S., and Canada. Sceptics note a correlation between crop circles, recent media coverage, and the absence of fencing and/or anti-trespassing legislation.\n\nAlthough farmers expressed concern at the damage caused to their crops, local response to the appearance of crop circles was often enthusiastic, with locals taking advantage of the increase of tourism and visits from scientists, crop circle researchers, and individuals seeking spiritual experiences. The market for crop-circle interest consequently generated bus or helicopter tours of circle sites, walking tours, T-shirts, and book sales.\n\nSince the start of the 21st century, crop formations have increased in size and complexity, with some featuring as many as 2,000 different shapes and some incorporating complex mathematical and scientific characteristics.\n\nThe researcher Jeremy Northcote found that crop circles in the UK in 2002 were not spread randomly across the landscape. They tended to appear near roads, areas of medium-to-dense population, and cultural heritage monuments such as Stonehenge or Avebury. He found that they always appeared in areas that were easy to access. This suggests strongly that these crop circles were more likely to be caused by intentional human action than by paranormal activity. Another strong indication of that theory was that inhabitants of the zone with the most circles had a historical tendency for making large-scale formations, including stone circles such as Stonehenge, burial mounds such as Silbury Hill, long barrows such as West Kennet Long Barrow, and .\n\nIn 1991, self-professed pranksters Doug Bower and Dave Chorley made headlines claiming it was they who started the phenomenon in 1978 with the use of simple tools consisting of a plank of wood, rope, and a baseball cap fitted with a loop of wire to help them walk in a straight line. To prove their case they made a circle in front of journalists; a \"cereologist\" (advocate of paranormal explanations of crop circles), Pat Delgado, examined the circle and declared it authentic before it was revealed that it was a hoax. Inspired by Australian crop circle accounts from 1966, Bower and Chorley claimed to be responsible for all circles made prior to 1987, and for more than 200 crop circles in 1978–1991 (with 1000 other circles not being made by them). After their announcement, the two men demonstrated making a crop circle. According to Professor Richard Taylor, \"the pictographs they created inspired a second wave of crop artists. Far from fizzling out, crop circles have evolved into an international phenomenon, with hundreds of sophisticated pictographs now appearing annually around the globe.\"\n\n\"Smithsonian\" magazine wrote:\n\nSince the early 1990s, the UK arts collective \"Circlemakers,\" founded by artists Rod Dickinson and John Lundberg (and subsequently including artists Wil Russell and Rob Irving), have been creating crop circles in the UK and around the world as part of their art practice and for commercial clients.\n\nThe Led Zeppelin boxed set that was released on 7 September 1990, along with the remasters of the first boxed set, as well as the second boxed set, all feature an image of a crop circle that appeared in East Field in Alton Barnes, Wiltshire.\n\nOn the night of 11–12 July 1992, a crop-circle making competition with a prize of £3,000 (funded in part by the Arthur Koestler Foundation) was held in Berkshire. The winning entry was produced by three Westland Helicopters engineers, using rope, PVC pipe, a plank, string, a telescopic device and two stepladders. According to Rupert Sheldrake, the competition was organised by him and John Michell and \"co-sponsored by The Guardian and The Cerealogist\". The prize money came from \"PM\", a German magazine. Sheldrake wrote that \"The experiment was conclusive. Humans could indeed make all the features of state-of-the-art crop formations at that time. Eleven of the twelve teams made more or less impressive formations that followed the set design.\"\n\nIn 2002, Discovery Channel commissioned five aeronautics and astronautics graduate students from MIT to create crop circles of their own, aiming to duplicate some of the features claimed to distinguish \"real\" crop circles from the known fakes such as those created by Bower and Chorley. The creation of the circle was recorded and used in the Discovery Channel documentary \"Crop Circles: Mysteries in the Fields\".\n\nIn 2009, \"The Guardian\" reported that crop circle activity had been waning around Wiltshire, in part because makers preferred creating promotional crop circles for companies that paid well for their efforts.\n\nA video sequence used in connection with the opening of the 2012 Summer Olympics in London showed two crop circles in the shape of the Olympic rings. Another Olympic crop circle was visible to passengers landing at nearby Heathrow Airport before and during the Games.\n\nA crop circle depicting the emblem of the \"Star Wars\" Rebel Alliance was created in California in December 2017 by an 11-year-old boy as a spaceport for X-wing fighters.\n\nIn 1992, Hungarian youths Gábor Takács and Róbert Dallos, both then 17, were the first people to face legal action after creating a crop circle. Takács and Dallos, of the St. Stephen Agricultural Technicum, a high school in Hungary specializing in agriculture, created a diameter crop circle in a wheat field near Székesfehérvár, southwest of Budapest, on June 8, 1992. On September 3, the pair appeared on Hungarian TV and exposed the circle as a hoax, showing photos of the field before and after the circle was made. As a result, Aranykalász Co., the owners of the land, sued the teens for 630,000 Ft (~$3,000 USD) in damages. The presiding judge ruled that the students were only responsible for the damage caused in the circle itself, amounting to about 6,000 Ft (~$30 USD), and that 99% of the damage to the crops was caused by the thousands of visitors who flocked to Székesfehérvár following the media's promotion of the circle. The fine was eventually paid by the TV show, as were the students' legal fees.\n\nIn 2000, Matthew Williams became the first man in the UK to be arrested for causing criminal damage after making a crop circle near Devizes. In November 2000, he was fined £100 and £40 in costs. , no one else has been successfully prosecuted in the UK for criminal damage caused by creating crop circles.\n\nThe scientific consensus on crop circles is that they are constructed by human beings as hoaxes, advertising, or art. The most widely known method for a person or group to construct a crop formation is to tie one end of a rope to an anchor point and the other end to a board which is used to crush the plants. Sceptics of the paranormal point out that all characteristics of crop circles are fully compatible with their being made by hoaxers.\n\nBower and Chorley confessed in 1991 to making the first crop circles in southern England. When some people refused to believe them, they deliberately added straight lines and squares to show that they could not have natural causes. In a copycat effect, increasingly complex circles started appearing in many countries around the world, including fractal figures. Physicists have suggested that the most complex formations might be made with the help of GPS and lasers. In 2009, a circle formation was made over the course of three consecutive nights and was apparently left unfinished, with some half-made circles.\n\nThe main criticism of alleged non-human creation of crop circles is that while evidence of these origins, besides eyewitness testimonies, is essentially absent, some are definitely known to be the work of human pranksters, and others can be adequately explained as such. There have been cases in which researchers declared crop circles to be \"the real thing\", only to be confronted with the people who created the circle and documented the fraud, like Bower and Chorley and tabloid \"Today\" hoaxing Pat Delgado, the Wessex Sceptics and Channel 4's \"Equinox\" hoaxing Terence Meaden, or a friend of a Canadian farmer hoaxing a field researcher of the Canadian Crop Circle Research Network. In his 1997 book \"The Demon-Haunted World: Science as a Candle in the Dark\", Carl Sagan concludes that crop circles were created by Bower and Chorley and their copycats, and speculates that UFOlogists willingly ignore the evidence for hoaxing so they can keep believing in an extraterrestrial origin of the circles. Many others have demonstrated how complex crop circles can be created. \"Scientific American\" published an article by Matt Ridley, who started making crop circles in northern England in 1991. He wrote about how easy it is to develop techniques using simple tools that can easily fool later observers. He reported on \"expert\" sources such as \"The Wall Street Journal\", who had been easily fooled and mused about why people want to believe supernatural explanations for phenomena that are not yet explained. Methods of creating a crop circle are now well documented on the Internet.\n\nSome crop formations are paid for by companies who use them as advertising. Many crop circles show human symbols, like the heart and arrow symbol of love, stereotyped alien faces,\n\nHoaxers have been caught in the process of making new circles, such as in 2004 in the Netherlands for example (see more cases in \"legal implications\" section above).\n\nAdvocates of non-human causes discount on-site evidence of human involvement as attempts to discredit the phenomena. Some even argue a conspiracy theory, with governments planting evidence of hoaxing to muddle the origins of the circles. When Ridley wrote negative articles in newspapers, he was accused of spreading \"government disinformation\" and of working for the UK military intelligence service MI5. Ridley responded by noting that many cereologists make good livings from selling books and providing high-priced personal tours through crop fields, and he claimed that they have vested interests in rejecting what is by far the most likely explanation for the circles.\n\nIt has been suggested that crop circles may be the result of extraordinary meteorological phenomena ranging from freak tornadoes to ball lightning, but there is no evidence of any crop circle being created by any of these causes.\n\nIn 1880, an amateur scientist, John Rand Capron, wrote a letter to the editor of journal \"Nature\" about some circles in crops and blamed them on a recent storm, saying their shape was \"suggestive of some cyclonic wind action\".\n\nIn 1980, Terence Meaden, a meteorologist and physicist, proposed that the circles were caused by whirlwinds whose course was affected by southern England hills. As circles became more complex, Terence had to create increasingly complex theories, blaming an electromagneto-hydrodynamic \"plasma vortex\". The meteorological theory became popular, and it was even referenced in 1991 by physicist Stephen Hawking who said that, \"Corn circles are either hoaxes or formed by vortex movement of air\". The weather theory suffered a serious blow in 1991, but Hawking's point about hoaxes was supported when Bower and Chorley stated that they had been responsible for making all those circles. By the end of 1991 Meaden conceded that those circles that had complex designs were made by hoaxers.\n\nSince becoming the focus of widespread media attention in the 1980s, crop circles have become the subject of speculation by various paranormal, ufological, and anomalistic investigators ranging from proposals that they were created by bizarre meteorological phenomena to messages from extraterrestrial beings. There has also been speculation that crop circles have a relation to ley lines. Many New Age groups incorporate crop circles into their belief systems.\n\nSome paranormal advocates think that crop circles are caused by ball lighting and that the patterns are so complex that they have to be controlled by some entity. Some proposed entities are: Gaia asking to stop global warming and human pollution, God, supernatural beings (for example Indian devas), the collective minds of humanity through a proposed \"quantum field\", or extraterrestrial beings.\n\nResponding to local beliefs that \"extraterrestrial beings\" in UFOs were responsible for crop circles appearing, the Indonesian National Institute of Aeronautics and Space (LAPAN) described crop circles as \"man-made\". Thomas Djamaluddin, research professor of astronomy and astrophysics at LAPAN stated, \"We have come to agree that this 'thing' cannot be scientifically proven.\" Among others, paranormal enthusiasts, ufologists, and anomalistic investigators have offered hypothetical explanations that have been criticized as pseudoscientific by sceptical groups and scientists, including the Committee for Skeptical Inquiry. No credible evidence of extraterrestrial origin has been presented.\n\nIn 2009, the attorney general for the island state of Tasmania stated that Australian wallabies had been found creating crop circles in fields of opium poppies, which are grown legally for medicinal use, after consuming some of the opiate-laden poppies and running in circles.\n\nA small number of scientists (physicist Eltjo Haselhoff, the late biophysicist William Levengood) have found differences between the crops inside the circles and outside them, citing this as evidence they were not man-made.\n\nLevengood published papers in journal \"Physiologia Plantarum\" in 1994 and 1999. In his 1994 paper he found that certain deformities in the grain inside the circles were correlated to the position of the grain inside the circle. In 1996 sceptic Joe Nickell objected that correlation is not causation, raised several objections to the Levengood's methods and assumptions, and said \"Until his work is independently replicated by qualified scientists doing 'double-blind' studies and otherwise following stringent scientific protocols, there seems no need to take seriously the many dubious claims that Levengood makes, including his similar ones involving plants at alleged 'cattle mutilation' sites.\" (in reference to cattle mutilation).\n\nA study by Eltjo Haselhoff reported that the pulvini of wheat in 95% of the crop circles investigated were elongated in a pattern falling off with distance from the centre and that seeds from the bent-over plants grew much more slowly under controlled conditions. Furthermore, traces of crop circle patterns are sometimes found in the crop the following year, \"suggesting long-term damage to the crop field consistent with Levengood's observations of stunted seed growth.\"\n\nIn 2000, Colin Andrews, who had researched crop circles for 17 years, stated that while he believed 80% were man-made, he thought the remaining circles, with less elaborate designs, could be explained by a three-degree shift in the Earth's magnetic field, that creates a current that \"electrocutes\" the crops, causing them to flatten and form the circle.\n\nResearchers of crop circles have linked modern crop circles to old folkloric tales to support the claim that they are not artificially produced. Circle crops are culture-dependent: they appear mostly in developed and secularized Western countries where people are receptive to New Age beliefs, including Japan, but they don't appear at all in other zones, such as Muslim countries.\n\nFungi can cause circular areas of crop to die, probably the origin of tales of \"fairie rings\". Tales also mention balls of light many times but never in relation to crop circles.\n\nA 17th-century English woodcut called the \"Mowing-Devil\" depicts the devil with a scythe mowing (cutting) a circular design in a field of oats. The pamphlet containing the image states that the farmer, disgusted at the wage his mower was demanding for his work, insisted that he would rather have \"the devil himself\" perform the task. Crop circle researcher Jim Schnabel does not consider this to be a historical precedent for crop circles because the stalks were cut down, not bent. The circular form indicated to the farmer that it had been caused by the devil.\n\nIn the 1948 German story \"Die zwölf Schwäne\" (\"The Twelve Swans\"), a farmer every morning found a circular ring of flattened grain on his field. After several attempts, his son saw twelve princesses disguised as swans, who took off their disguises and danced in the field. Crop rings produced by fungi may have inspired such tales since folklore holds these rings are created by dancing wolves or fairies.\n\n\n\n"}
{"id": "47341258", "url": "https://en.wikipedia.org/wiki?curid=47341258", "title": "Data janitor", "text": "Data janitor\n\nA data janitor is a person who works to take big data and condense it into useful amounts of information. Also known as a \"data wrangler,\" a data janitor sifts through data for companies in the information technology industry. A multitude of start-ups rely on large amounts of data, so a data janitor works to help these businesses with this basic, but difficult process of interpreting data.\n\nWhile it is a commonly held belief that data janitor work is fully automated, many data scientists are employed primarily as data janitors. The Information technology industry has been increasingly turning towards new sources of data gathered on consumers, so data janitors have become more commonplace in recent years.\n\nData janitors work in a process that largely consists of four steps: selection and defining relationships, extraction and organization, loading, and interpretation. Data janitors identify sources of data before selecting which data is relevant and find the relationships between the data that will be useful to the company's projects. Next, they structure the data in an effort to extract the information and put it into a format that can be stored in a secure place for the business. Last, the data janitors work with other employees to create visual aids to present to managers and executives who will eventually benefit from the conclusions that can be made from them. In this way, the work of data janitors is integral to the functioning of businesses that rely on large amounts data to function.\n"}
{"id": "23167508", "url": "https://en.wikipedia.org/wiki?curid=23167508", "title": "Dustbin category", "text": "Dustbin category\n\nThe term \"dustbin category\" is sometimes used to describe a category that includes people or things that might be heterogeneous, only loosely related or poorly understood. It has been used in discussion of law, linguistics, medicine, sociology and other disciplines. For example:\nSome patients' symptoms do not fit well with any recognised category and there is a danger these may be forced into a 'dustbin' category such as 'depression, not otherwise specified.'\n"}
{"id": "744997", "url": "https://en.wikipedia.org/wiki?curid=744997", "title": "Electronic voice phenomenon", "text": "Electronic voice phenomenon\n\nWithin ghost hunting and parapsychology, electronic voice phenomena (EVP) are sounds found on electronic recordings that are interpreted as spirit voices that have been either unintentionally recorded or intentionally requested and recorded. Parapsychologist Konstantīns Raudive, who popularized the idea in the 1970s, described EVP as typically brief, usually the length of a word or short phrase.\n\nEnthusiasts consider EVP to be a form of paranormal phenomenon often found in recordings with static or other background noise. However, scientists regard EVP as a form of auditory pareidolia (interpreting random sounds as voices in one's own language) and a pseudoscience promulgated by popular culture. Prosaic explanations for EVP include apophenia (perceiving patterns in random information), equipment artifacts, and hoaxes.\n\nAs the Spiritualist religious movement became prominent in the 1840s–1920s with a distinguishing belief that the spirits of the dead can be contacted by mediums, new technologies of the era including photography were employed by spiritualists in an effort to demonstrate contact with a spirit world. So popular were such ideas that Thomas Edison was asked in an interview with \"Scientific American\" to comment on the possibility of using his inventions to communicate with spirits. He replied that if the spirits were only capable of subtle influences, a sensitive recording device would provide a better chance of spirit communication than the table tipping and ouija boards mediums employed at the time. However, there is no indication that Edison ever designed or constructed a device for such a purpose. As sound recording became widespread, mediums explored using this technology to demonstrate communication with the dead as well. Spiritualism declined in the latter part of the 20th century, but attempts to use portable recording devices and modern digital technologies to communicate with spirits continued.\n\nAmerican photographer Attila von Szalay was among the first to try recording what he believed to be voices of the dead as a way to augment his investigations in photographing ghosts. He began his attempts in 1941 using a 78 rpm record, but it wasn't until 1956 — after switching to a reel-to-reel tape recorder — that he believed he was successful. Working with Raymond Bayless, von Szalay conducted a number of recording sessions with a custom-made apparatus, consisting of a microphone in an insulated cabinet connected to an external recording device and speaker. Szalay reported finding many sounds on the tape that could not be heard on the speaker at the time of recording, some of which were recorded when there was no one in the cabinet. He believed these sounds to be the voices of discarnate spirits. Among the first recordings believed to be spirit voices were such messages as \"This is G!\", \"Hot dog, Art!\", and \"Merry Christmas and Happy New Year to you all\". Von Szalay and Raymond Bayless' work was published by the Journal of the American Society for Psychical Research in 1959. Bayless later went on to co-author the 1979 book, \"Phone Calls From the Dead\".\n\nIn 1959, Swedish painter and film producer Friedrich Jürgenson was recording bird songs. Upon playing the tape later, he heard what he interpreted to be his dead father's voice and then the spirit of his deceased wife calling his name. He went on to make several more recordings, including one that he said contained a message from his late mother.\n\nKonstantin Raudive, a Latvian psychologist who had taught at the Uppsala University, Sweden and who had worked in conjunction with Jürgenson, made over 100,000 recordings which he described as being communications with people. Some of these recordings were conducted in an RF-screened laboratory and contained words Raudive said were identifiable. In an attempt to confirm the content of his collection of recordings, Raudive invited listeners to hear and interpret them. He believed that the clarity of the voices heard in his recordings implied that they could not be readily explained by normal means. Raudive published his first book, \"Breakthrough: An Amazing Experiment in Electronic Communication with the Dead\" in 1968 and it was translated into English in 1971.\n\nIn 1980, William O'Neil constructed an electronic audio device called \"The Spiricom\". O'Neil claimed the device was built to specifications which he received psychically from George Mueller, a scientist who had died six years previously. At a Washington, DC press conference on April 6, 1982, O'Neil stated that he was able to hold two-way conversations with spirits through the Spiricom device, and provided the design specifications to researchers for free. However, nobody is known to have replicated the results O'Neil claimed using his own Spiricom devices. O'Neil's partner, retired industrialist George Meek, attributed O'Neil's success, and the inability of others to replicate it, to O'Neil's mediumistic abilities forming part of the loop that made the system work. \n\nAnother electronic device specifically constructed in an attempt to capture EVP is \"Frank's Box\" or the \"Ghost Box\", created in 2002 by EVP enthusiast Frank Sumption for supposed real-time communication with the dead. Sumption claims he received his design instructions from the spirit world. The device is described as a combination white noise generator and AM radio receiver modified to sweep back and forth through the AM band selecting split-second snippets of sound. Critics of the device say its effect is subjective and incapable of being replicated, and since it relies on radio noise, any meaningful response a user gets is purely coincidental, or simply the result of pareidolia. Paranormal researcher Ben Radford writes that Frank's Box is a \"modern version of the Ouija board... also known as the 'broken radio'\".\n\nIn 1982, Sarah Estep founded the American Association of Electronic Voice Phenomena (AA-EVP) in Severna Park, Maryland, a nonprofit organization with the purpose of increasing awareness of EVP, and of teaching standardized methods for capturing it. Estep began her exploration of EVP in 1976, and says she has made hundreds of recordings of messages from deceased friends, relatives, and extraterrestrials whom she speculated originated from other planets or dimensions.\n\nThe term Instrumental Trans-Communication (ITC) was coined by Ernst Senkowski in the 1970s to refer more generally to communication through any sort of electronic device such as tape recorders, fax machines, television sets or computers between spirits or other discarnate entities and the living. One particularly famous claimed incidence of ITC occurred when the image of EVP enthusiast Friedrich Jürgenson (whose funeral was held that day) was said to have appeared on a television in the home of a colleague, which had been purposefully tuned to a vacant channel. ITC enthusiasts also look at the TV and video camera feedback loop of the Droste effect.\n\nIn 1979, parapsychologist D. Scott Rogo described an alleged paranormal phenomenon in which people report that they receive simple, brief, and usually single-occurrence telephone calls from spirits of deceased relatives, friends, or strangers. Rosemary Guiley has written \"within the parapsychology establishment, Rogo was often faulted for poor scholarship, which, critics said, led to erroneous conclusions.\"\n\nIn 1995, the parapsychologist David Fontana proposed in an article that poltergeists could haunt tape recorders. He speculated that this may have happened to the parapsychologist Maurice Grosse who investigated the Enfield Poltergeist case. However, Tom Flynn a media expert for the Committee for Skeptical Inquiry examined Fontana's article and suggested an entirely naturalistic explanation for the phenomena. According to the skeptical investigator Joe Nickell \"Occasionally, especially with older tape and under humid conditions, as the tape travels it can adhere to one of the guide posts. When this happens on a deck where both supply and take-up spindles are powered, the tape continues to feed, creating a fold. It was such a loop of tape, Flynn theorizes, that threaded its way amid the works of Grosse’s recorder.\"\n\nIn 1997, Imants Barušs, of the Department of Psychology at the University of Western Ontario, conducted a series of experiments using the methods of EVP investigator Konstantin Raudive, and the work of \"instrumental transcommunication researcher\" Mark Macy, as a guide. A radio was tuned to an empty frequency, and over 81 sessions a total of 60 hours and 11 minutes of recordings were collected. During recordings, a person either sat in silence or attempted to make verbal contact with potential sources of EVP. Barušs stated that he did record several events that sounded like voices, but they were too few and too random to represent viable data and too open to interpretation to be described definitively as EVP. He concluded: \"While we did replicate EVP in the weak sense of finding voices on audio tapes, none of the phenomena found in our study was clearly anomalous, let alone attributable to discarnate beings. Hence we have failed to replicate EVP in the strong sense.\" The findings were published in the \"Journal of Scientific Exploration\" in 2001, and include a literature review.\n\nIn 2005, the \"Journal of the Society for Psychical Research\" published a report by paranormal investigator Alexander MacRae. MacRae conducted recording sessions using a device of his own design that generated EVP.\nIn an attempt to demonstrate that different individuals would interpret EVP in the recordings the same way, MacRae asked seven people to compare some selections to a list of five phrases he provided, and to choose the best match. MacRae said the results of the listening panels indicated that the selections were of paranormal origin.\n\nPortable digital voice recorders are currently the technology of choice for some EVP investigators. Since some of these devices are very susceptible to Radio Frequency (RF) contamination, EVP enthusiasts sometimes try to record EVP in RF- and sound-screened rooms.\n\nSome EVP enthusiasts describe hearing the words in EVP as an ability, much like learning a new language. Skeptics suggest that the claimed instances may be misinterpretations of natural phenomena, inadvertent influence of the electronic equipment by researchers, or deliberate influencing of the researchers and the equipment by third parties. EVP and ITC are seldom researched within the scientific community, so most research in the field is carried out by amateur researchers who lack training and resources to conduct scientific research, and who are motivated by subjective notions.\n\nParanormal claims for the origin of EVP include living humans imprinting thoughts directly on an electronic medium through psychokinesis and communication by discarnate entities such as spirits, nature energies, beings from other dimensions, or extraterrestrials. Paranormal explanations for EVP generally assume production of EVP by a communicating intelligence through means other than the typical functioning of communication technologies. Natural explanations for reported instances of EVP tend to dispute this assumption explicitly and provide explanations which do not require novel mechanisms that are not based on recognized scientific phenomena.\n\nOne study, by psychologist Imants Barušs, was unable to replicate suggested paranormal origins for EVP recorded under controlled conditions. Brian Regal in \"Pseudoscience: A Critical Encyclopedia\" (2009) has written \"A case can be made for the idea that many EVPs are artifacts of the recording process itself with which the operators are unfamiliar. The majority of EVPS have alternative, nonspiritual sources; anomalous ones have no clear proof they are of spiritual origin.\"\n\nThere are a number of simple scientific explanations that can account for why some listeners to the static on audio devices may believe they hear voices, including radio interference and the tendency of the human brain to recognize patterns in random stimuli. Some recordings may be hoaxes created by frauds or pranksters.\n\n\"Auditory pareidolia\" is a situation created when the brain incorrectly interprets random patterns as being familiar patterns. In the case of EVP it could result in an observer interpreting random noise on an audio recording as being the familiar sound of a human voice. The propensity for an apparent voice heard in white noise recordings to be in a language understood well by those researching it, rather than in an unfamiliar language, has been cited as evidence of this, and a broad class of phenomena referred to by author Joe Banks as \"Rorschach Audio\" has been described as a global explanation for all manifestations of EVP.\n\nSkeptics such as David Federlein, Chris French, Terence Hines and Michael Shermer say that EVP are usually recorded by raising the \"noise floor\" – the electrical noise created by all electrical devices – in order to create white noise. When this noise is filtered, it can be made to produce noises which sound like speech. Federlein says that this is no different from using a wah pedal on a guitar, which is a focused sweep filter which moves around the spectrum and creates open vowel sounds. This, according to Federlein, sounds exactly like some EVP. This, in combination with such things as cross modulation of radio stations or faulty ground loops can cause the impression of paranormal voices. The human brain evolved to recognize patterns, and if a person listens to enough noise the brain will detect words, even when there is no intelligent source for them. Expectation also plays an important part in making people believe they are hearing voices in random noise.\n\n\"Apophenia\" is related to, but distinct from pareidolia. Apophenia is defined as \"the spontaneous finding of connections or meaning in things which are random, unconnected or meaningless\", and has been put forward as a possible explanation. According to the psychologist James Alcock what people hear in EVP recordings can best be explained by apophenia, cross-modulation or expectation and wishful thinking. Alcock concluded \"Electronic Voice Phenomena are the products of hope and expectation; the claims wither away under the light of scientific scrutiny.\"\n\nInterference, for example, is seen in certain EVP recordings, especially those recorded on devices which contain RLC circuitry. These cases represent radio signals of voices or other sounds from broadcast sources. Interference from CB Radio transmissions and wireless baby monitors, or anomalies generated through cross modulation from other electronic devices, are all documented phenomena. It is even possible for circuits to resonate without any internal power source by means of radio reception.\n\n\"Capture errors\" are anomalies created by the method used to capture audio signals, such as noise generated through the over-amplification of a signal at the point of recording.\n\nArtifacts created during attempts to boost the clarity of an existing recording might explain some EVP. Methods include re-sampling, frequency isolation, and noise reduction or enhancement, which can cause recordings to take on qualities significantly different from those that were present in the original recording.\n\nThe very first EVP recordings may have originated from the use of tape recording equipment with poorly aligned erasure and recording heads, resulting in the incomplete erasure of previous audio recordings on the tape. This could allow a small percentage of previous content to be superimposed or mixed into a new 'silent' recording.\n\nFor all radio transmissions above 30 MHz (which are not reflected by the ionosphere) there is a possibility of meteor reflection of the radio signal. Meteors leave a trail of ionised particles and electrons as they pass through the upper atmosphere (a process called ablation) which reflect transmission radio waves which would usually flow into space. These reflected waves are from transmitters which are below the horizon of the received meteor reflection. In Europe this means the brief scattered wave may carry a foreign voice which can interfere with radio receivers. Meteor reflected radio waves last between 0.05 seconds and 1 second, depending on the size of the meteor.\n\nThere are a number of organizations dedicated to studying EVP and instrumental transcommunication, or which otherwise express interest in the subject. Individuals within these organizations may participate in investigations, author books or journal articles, deliver presentations, and hold conferences where they share experiences. In addition organizations exist which dispute the validity of the phenomena on scientific grounds.\n\nThe Association TransCommunication (ATransC), formerly the American Association of Electronic Voice Phenomena (AA-EVP), and the International Ghost Hunters Society conduct ongoing investigations of EVP and ITC including collecting examples of purported EVP available over the internet. The Rorschach Audio Project, initiated by sound artist Joe Banks, which presents EVP as a product of radio interference combined with auditory pareidolia and the Interdisciplinary Laboratory for Biopsychocybernetics Research, a non-profit organization dedicated to studying anomalous phenomena related to neurophysiological conditions. According to the AA-EVP it is \"the only organized group of researchers we know of specializing in the study of ITC\".\n\nParapsychologists and Spiritualists have an ongoing interest in EVP. Many Spiritualists experiment with a variety of techniques for spirit communication which they believe provide evidence of the continuation of life. According to the National Spiritualist Association of Churches, \"An important modern day development in mediumship is spirit communications via an electronic device. This is most commonly known as Electronic Voice Phenomena (EVP)\". An informal survey by the organization's Department Of Phenomenal Evidence cites that 1/3 of churches conduct sessions in which participants seek to communicate with spirit entities using EVP.\n\nThe James Randi Educational Foundation offers a million dollars for proof that any phenomena, including EVP, are caused paranormally.\n\nThe concept of EVP has influenced popular culture. It is popular as an entertaining pursuit, as in ghost hunting, and as a means of dealing with grief. It has influenced literature, radio, film, television, and music.\n\nInvestigation of EVP is the subject of hundreds of regional and national groups and Internet message boards. Paranormal investigator John Zaffis claims, \"There's been a boom in ghost hunting ever since the Internet took off.\" Investigators, equipped with electronic gear—like EMF meters, video cameras, and audio recorders—scour reportedly haunted venues, trying to uncover visual and audio evidence of ghosts. Many use portable recording devices in an attempt to capture EVP.\n\nFilms involving EVP include \"Poltergeist\", \"The Sixth Sense\", \"White Noise\", and \"The Changeling\"and \"Trace\"(2015)https://www.imdb.com/title/tt3733618/?ref_=nv_sr_8. It has also been featured on television series like \"Ghost Whisperer\", \"The Omega Factor\", \"A Haunting\", \"Ghost Hunters\", \"MonsterQuest\", \"Ghost Adventures\", \"The Secret Saturdays\", \"\", \"Supernatural\", \"Derren Brown Investigates\", and \"Ghost Lab\".\n\n\"Coast To Coast AM\" hosts George Noory and Art Bell have explored the topic of EVP with featured guests such as Brendan Cook and Barbara McBeath of the Ghost Investigators Society, and paranormal investigator and 'demonologist' Lou Gentile. \"The Spirit of John Lennon\", a pay-per-view seance broadcast in 2006, in which TV crew members, a psychic, and an \"expert in paranormal activity\" claim the spirit of former Beatle John Lennon made contact with them through what was described as \"an Electronic Voice Phenomenon (EVP).\"\n\n\"Legion\", a 1983 novel by William Peter Blatty, contains a subplot where Dr. Vincent Amfortas, a terminally ill neurologist, leaves a \"to-be-opened-upon-my-death\" letter for Lt. Kinderman detailing his accounts of contact with the dead, including the doctor's recently deceased wife, Ann, through EVP recordings. Amfortas' character and the EVP subplot do not appear in the film version of the novel, \"The Exorcist III\", although in Kinderman's dream dead people are seen trying to communicate with the living by radio.\n\nIn \"Pattern Recognition\", a 2003 novel by William Gibson, the main character's mother tries to convince her that her father is communicating with her from recordings after his death/disappearance in the September 11, 2001 attacks.'\n\nIn \"Nyctivoe\" a 2001 vampire-inspired play by Dimitris Lyacos the male character as well as his deceased companion are speaking from a recording device amidst a static/white noise background.\n\nIn \"With the people from the bridge\", a 2014 play by Dimitris Lyacos based on the idea of the return of the dead, the voice of the female character NCTV is transmitted from a television monitor amidst a static/white noise background.\n\nEVP is the subject of Vyktoria Pratt Keating's song \"Disembodied Voices on Tape\" from her 2003 album \"Things that Fall from the Sky\", produced by Andrew Giddings of Jethro Tull.\n\nLaurie Anderson's \"Example #22\", from her 1981 album \"Big Science,\" interposes spoken sentences and phrases in German with sung passages in English representing EVP.\n\nDuring the outro to \"Rubber Ring\" by The Smiths, a sample from an EVP recording is repeated. The phrase \"You are sleeping, you do not want to believe,\" is a 'translation' of the 'spirit voices' from a 1970s flexitape. The original recording is from the 1971 record which accompanied Raudive's book 'Breakthrough', and which was re-issued as a flexi-disc in the 1980s free with The Unexplained magazine.\n\nBass Communion's 2004 album Ghosts on Magnetic Tape was inspired by EVP.\n\nThe band Giles Corey, founded by Dan Barrett composed a song called 'Empty Churches' which features track 2 called 'Raymond Cass', track 36 called 'Justified Theft' and track 38 called 'Tramping' from the album An Introduction to EVP by The Ghost Orchid which features excerpts from different EVP experiments produced by many researchers, although most are unknown, some have been pointed out to be more known researchers who studied EVP recordings including Friedrich Jurgenson, Raymond Cass and Konstantin Raudive.\n\nIn 2017 in Poland was published music cd ′′′Katharsis (A Small Victory)′′′ of Teatr Tworzenia by Jarosław Pijarowski with background recorded used EVP recordings (second track - „Katharsis – Pandemonium”).\n\n"}
{"id": "57104312", "url": "https://en.wikipedia.org/wiki?curid=57104312", "title": "Haplogroup A-P305", "text": "Haplogroup A-P305\n\nHaplogroup A-P305 also known as A1 is a Human Y-chromosome DNA haplogroup. Like its parent haplogroup haplogroup A0-T (A-L1085), A1 includes the vast majority of living human males. It emerged in Africa approximately 161,300 years ago. By comparison, members of its sole sibling subclade, haplogroup A0 – the only other primary subclade of haplogroup A0-T – are found mostly in \n\nBasal, undivergent A-P305* is largely restricted to populations native to Africa, though a handful of cases have been reported in Europe and Western Asia. A-P305* is found at its highest rates in Bakola Pygmies (South Cameroon) at 8.3% and Berbers from Algeria at 1.5% and in Ghana. The clade also achieves high frequencies in the Bushmen hunter-gatherer populations of Southern Africa, followed closely by many Nilotic groups in Eastern Africa. However, haplogroup A's oldest sub-clades are exclusively found in Central-Northwest Africa, where it, and consequently Y-chromosomal Adam, is believed to have originated about 140,000 years ago. The clade has also been observed at notable frequencies in certain populations in Ethiopia, as well as some Pygmy groups in Central Africa.\n"}
{"id": "18877437", "url": "https://en.wikipedia.org/wiki?curid=18877437", "title": "History and naming of human leukocyte antigens", "text": "History and naming of human leukocyte antigens\n\nHuman leukocyte antigens (HLA) began as a list of antigens identified as a result of transplant rejection. The antigens were initially identified by categorizing and performing massive statistical analyses on interactions between blood types. This process is based upon the principle of serotypes. HLA are not typical antigens, like those found on surface of infectious agents. HLAs are \"allo\"antigens, they vary from individual to individual as a result of genetic differences.\nAn organ called the thymus is responsible for ensuring that any T-cells that attack self proteins are not allowed to live. In essence, every individual's immune system is tuned to the specific set of HLA and self proteins produced by that individual; where this goes awry is when tissues are transferred to another person. Since individuals almost always have different \"banks\" of HLAs, the immune system of the recipient recognizes the transplanted tissue as non-self and destroys the foreign tissue, leading to transplant rejection. It was through the realization of this that HLAs were discovered.\n\nThe thought that the mammalian body must have some way of identifying introduced foreign tissues first arose during World War II. It started with a plane crash in the height of the London Blitz. The pilot suffered severe burns requiring skin grafts; however, skin grafts were a risky business at the time, often being rejected for unknown reasons. Numerous theories were proposed and it wasn't until 1958 that the first of these \"identifying\" proteins was found. The first standardized naming system was established in 1968 by the WHO Nomenclature Committee for Factors of the HLA System. HLA research didn't heat up until the 1980s when a group of researchers finally elucidated the shape of the HLA-A*02 protein (just one of many specific HLA proteins). Even more recently, in 2010, the WHO committee responsible for naming all HLA proteins revised their standards for naming to introduce more clarity and specificity in the naming system.\n\nPeter Medawar was a zoologist turned clinician, who specialized in burn trauma. A plane crash near his home changed the path of his career, turning his work with burns from mere academia to a full on quest to save lives. Medawar and a Scottish surgeon, Tom Gibson, were tasked with working the Burns Unit of the Glasgow Royal Infirmary. The first insight came when the pair decided to experiment, and grafted part of a wound with the patient's skin, and another part with skin from the patient's brother. Within days the skin grafts from the brother were completely destroyed. Successive skin grafts from the brother were destroyed even faster, a fact that gave them the evidence they needed to implicate the immune system. Medawar later repeated this experiment on rabbits and 625 surgeries later validated their initial conclusions. Medawar then set out in search of the reason why rabbits rejected non-self grafts.\n\nMedawar continued his work, this time with a team of three at the University College London during the 1950s. Medawar's coworkers were Leslie Brent, a PhD student, and Rupert Billingham, Medawar's first graduate student at Oxford several years prior. Through carefully planned experimentation, the trio showed that mice exposed to cells of unrelated mice as fetuses did \"not\" reject skin grafts from those same mice. For this discovery, Medawar and Australian scientist Macfarlane Burnet earned the 1960 Nobel Prize.\n\nBurnet, independently of Medawar, came to the conclusion that the immune system must learn to tolerate any self cells, and hypothesized that this must occur during fetal development. For this, he jointly was awarded the Nobel Prize in 1960. Burnet's work continued and in 1957 along with Niels Jerne published a paper that modified and revolutionized antibody theory. \"Burnet speculated that one cell makes one particular shape of antibody and that all our antibody-making immune cells together make an unimaginably vast repertoire of 10 billion antibodies, each having a slightly different shape\". Thus, whenever a non-self molecule appears in the human body, one of these antibodies will have an accurate enough shape to bind to that molecule. This idea is known as Clonal Selection Theory. At the time, many leading scientists including Linus Pauling and James Watson completely rejected the idea, but repeated experimentation intended to disprove the theory actually served to build up a large body of evidence supporting Burnet and Jerne's theory.\n\nThe biggest weakness in Burnet's theory was that he had no explanation for how the body selected for immune cells that only identified non-self. In 1961, Jacques Miller published a paper offering an explanation. Miller was a PhD student at the Chester Beatty Research Institute in London. His discovery centered on the thymus. The thymus had long been regarded as nothing more than a repository for dead cells. Miller didn't buy this hypothesis. By removing the thymus of leukemic mice early in life, he found that the mice had a drastically weakened immune system. Taking inspiration from Medawar's skin transplant work, he performed a series of skin-graft experiments that showed that these immunocompromised mice didn't reject skin grafts from non-genetically identical mice. Miller then hypothesized that the thymus was essential in the construction and maintenance of the immune system. At this point Burnet came back into the picture, extending the hypothesis to specify that the dead cells found in the thymus are not any old immune cells, but instead the cells that are activated by self molecules. In other words, any molecule that binds to and hence \"recognizes\" a self molecule is killed before exiting the thymus. These cells were later found to be one of two types of immune cells, the T-cells (named for their origin, the thymus).\n\nThe discovery of the first HLA was very much a mystery. In 1958 Jean Dausset noticed that blood serum from one person could react with the white blood cells of another. He had no idea why, but he named the causative agent MAC. Around the same time other researchers were making similar discoveries. Rose Payne and Jon van Rood made an identical conclusion from observations of interactions between the blood of women who had been pregnant multiple times and the white blood cells of others. They hypothesized that this was because they had been \"sensitized\" (an immunological term meaning previously exposed to and thus more reactive towards) to the non-self proteins of the father through tissue damage during birth. At this point the researchers all realized that the sheer quantity of data they were capable of obtaining was vastly greater than that of any previous study and so collaboration would be essential. The first international meeting, in 1964, highlighted the difficulties of such massive collaborative work. Different experimental methods and inconsistency in the execution of the same tests and a non-homogeneity of naming systems added together to make collaboration incredibly difficult.\n\nIn 1967 the World Health Organization (WHO) decided that the HLA research needed an official naming system. This in turn would aid in organization and would more easily facilitate the unification of data being collected at numerous laboratories across the world. This committee is still in existence today and vastly accelerated the rate of HLA research. The first meeting of this committee in 1968 set forth guidelines and rules that govern HLAs. First, compatibility genes were divided into two types, class I and class II. Class I molecules were identified via reactions between blood serum and cells. Class II molecules were identified by mixtures of white blood cells. Second, the compatibility genes were renamed Human Leukocyte Antigens (HLA). Despite this clarification and the ever-increasing number of identified HLAs, nobody knew how they worked.\n\nLate in 1973 a pair of researchers in Australia, Rolf Zinkernagel and Peter Doherty made a revelatory discovery that altered the thinking of immunologists forever. The pair was doing research on viral infections in mice and noticed that T-cells that prevented viral infections in some mice wouldn't always prevent the same infection in other mice. After looking at the MHCs present in the mice, they realized that cytotoxic T-cells could only identify virus infections in cells with the right Class I compatibility gene. Traditional thinking was that the immune system identified infections directly but this discovery turned that theory on its head. Compatibility genes were essential in immune system mediated viral clearing. The pair coined the term \"MHC Restriction\" to describe this relationship between T-cells, specific MHC proteins, and viral detection. In 1975, in an article in the journal \"Lancet\", they introduced the idea of \"altered self\", meaning that viruses alter the MHC proteins and this alteration is detected by T-cells. For their work they won the 1996 Nobel Prize. It took the work of many others to determine how T-cells made this identification.\n\nNearly all important molecules in the body are proteins. Proteins work by each having a specific sequence of amino acids and a specific shape. Determining the order of amino acids is relatively simple. Finding the shape requires the use of x-ray crystallography and is anything but easy. It took a team of three researchers at Harvard, Don Wiley, Jack Strominger, and Pamela Bjorkman, eight years to ferret out the structure of the HLA protein. They worked specifically with HLA-A*02. Bjorkman did the majority of the leg work and in the seven years managed to piece together the structure of 90% of the protein. That last 10% was elusive though. It took another year of work to finally unveil the complete structure of HLA-A*02. They completed their work in the spring of 1987, discovering that the final 10% made a \"cup\" (of sorts) located on top of the molecule. It was the perfect size to hold peptides. Other researchers had previously determined that T-Cells can recognize cells infected with a virus, cells injected with a single protein from a virus, and even cells injected with pieces of protein from a virus. The discovery of the HLA protein structure made it starkly clear that the HLA proteins hold viral peptides in their binding groove. But the research team from Harvard wasn't done. They also observed that there was clearly a peptide in the binding groove of the HLA molecules they used to determine the shape. However, the cells they had extracted the protein from were definitely not infected by any disease causing viruses. The conclusion they made and the conclusion that has stuck to this day, is that HLA molecules can bind both self, and non-self peptides.\n\nThe most recent HLA naming system was developed in 2010 by the WHO Committee for Factors of the HLA System. There are two types of MHCs, Class I and Class II. Both are named using the same system. Currently there are 7,678 Class I alleles and 2,268 Class II alleles.\n\nHLA Naming can be quite confusing at first. All alleles start with \"HLA\", signifying they are part of the human MHC genes. The next portion (HLA-A or HLA-B) identifies which gene the allele is a modification of. The first two numbers (HLA-A*02) signifies what antigen type that particular allele is, which typically signifies the serological antigen present. In other words, HLAs with the same antigen type (HLA-A*02:101 and HLA-A*02:102) will not react with each other in serological tests. The next set of digits (HLA-A*02:101) indicates what protein the allele codes for, and these are numbered sequentially in the order they are discovered. Any HLA that has a different number here produces a different protein (AKA has a nucleotide change that replaces an amino acid with another). The third set of numbers (HLA-A*02:101:01) indicates an allele variant that has a different DNA sequence but produces the same protein as the normal gene. The final set of numbers (HLA-A*02:101:01:01) is used to designate a single or multiple nucleotide polymorphism in a non-coding region of the gene. The final aspect of HLA naming is a letter (HLA-A*02:101:01:01L). There are six letters, each with a different meaning.\n\nA person can have 2 antigen proteins per genetic-locus (one gene from each parent). When first discovered, identified antigens were clustered, creating groups in which no more than two antigens per cluster were found in a given person. Serotype group \"A\" consisted HL-A1, A2, A3, A9, A10, A11. Another cluster, \"B\", contained A7, A8, A12, A13, A14, A15. HL-A4 antigen was found to occur on lymphoid cells. Since the \"HL-Antigens\" no longer belonged to a single group, a new naming system was needed.\n\nIn 1968 the WHO Nomenclature Committee for Factors of the HLA System first met. They established a system that divided the HLAs into HLA-A and HLA-B, A and B corresponding to a group of reactive serotypes. For example, \"HL-A2\" became HLA-A2, \"HL-A7\" became HLA-B7 and \"HL-A8\" became HLA-B8.\n\nIn this arrangement there were cells that were 'blank' or had new specificities, these new antigens were called \"W\" antigens, and as they were reassigned to new groups, for example \"A\" serotypes, they became Aw or Bw antigens. It was found that some antigens that behaved like A and B antigens but could be excluded based on '2-type max' exclusion. Thus a new group, \"C\" was created. Classification of C antigens is still ongoing, and they have retained the name Cw as many serotypes have not been developed.\n\nThe classification of the \"A4\" antigens was complicated. The \"A4\" subset evolved to become D-region antigens, which was a large cluster of genes that encoded MHC class II. Several renamings occurred. The D-region has 8 major coding loci that combine to form 3 different protein groups; DP, DQ, and DR. DRw antigens were the first to be split, a process made easy by the virtue of having an invariant alpha chain, but complicated by 4 beta chain loci (DRB1, DRB3, DRB4, and DRB5). Serotypes to DQ reacted with alpha and beta chains, or both of certain isoforms. The proper classification was greatly aided by gene sequencing and PCR. Classification and description of DP antigens is ongoing.\n\nThe naming of human leukocyte antigens HLA \"antigens\" is deeply rooted in the discovery history of their serotypes and alleles. There is no doubt that HLA terminology can be bewildering, this terminology is a consequence of the complex genetics as well as the way these antigens were characterized.\n\nHistorical perspective is important to an understanding of how the HLA were systematized. In organ transplant the goal was to explain graft rejection for recipients, and of course, to prevent future rejection. From this perspective, the cause of rejections were found to be \"antigens\". In the same way bacterial antigens can cause inflammatory response, HLA antigens from the donor of the organ caused an inflammatory response when placed in a recipient. This is called allograft [allo = different, graft(medical) = transplant] rejection.\n\nTo explain rejection in a nutshell, certain immune system components are highly variable, the agents are called the Major histocompatibility (MHC) antigens. MHC antigens cause rejection of improperly matched organ transplants. The variability stems from genetics. From the perspective of human evolution, why are antigens of the MHC so variable when many other human proteins lack variability? The cause of host-versus-graft-disease may actually stem from the functions of the system.\n\nThe use of the word alloantigen actually masks the fact that HLA are infrequently autoantigens in the donor, and therefore their function is not as antigens, but something else. But the naming of these antigens is not borne out of function but the need to match organ donors with recipients.\n\nIn the early 1960s, some physicians began more aggressive attempts at organ transplantation. Knowing little about \"compatibility factors\", they attempted transplantation between humans and between non-humans and humans. Immunosuppressive drugs worked for a time, but transplanted organs would either always fail or the patients would die from infections. Patients received skin, white blood cell or kidney donations from other donors (called allografts, meaning 'of different genetics' grafts). If these allografts were rejected, it was found that the 'rejection' response was accompanied by an antibody mediated agglutination (biology) of red blood cells (See figure). The search for these cell surface antigens began. There are several processes by which antibodies can reduce function: \n\nIn the accompanying figure, two similar haplotypes (unknown to early clinicians) are identical, except for the one \"antigen\" in the top haplotype. The transplant may not be rejected, but if rejection does occur that allotypic protein, the allo\"antigen\", in the donor tissue may have induced the dominant allo-reactive antibody in the recipient.\n\nHemagglutination assay. In generating an immune response to an antigen, the B-cells go through a process of maturation, from surface IgM production, to serum IgM production, to maturation into a plasma cell producing IgG. Graft recipients who generate an immune response have both IgM and IgG. The IgM can be used directly in hemagglutination assays, depicted on the right. IgM has 10 antigen binding regions per molecule, allowing cross-linking of cells. An antiserum specific for HLA-A3 will then agglutinate HLA-A3 bearing red blood cells if the concentration of IgM in the antiserum is sufficiently high. Alternatively, a second antibody to the invariable (F) region of the IgG can be used to cross-link antibodies on different cells, causing agglutination.\n\nComplement fixation assay. The complement fixation test was modified to assay Antiserum mediated RBC lysis.\n\nChromium release assay. This assay measures the release of (biological) radioactive chromium from cells as a result of killer cell activity. These cells are attracted to class I antigens that either carry foreign antigens, or are foreign to the immune system.\n\nEach person has two HLA haplotypes, a cassette of genes passed on from each parent. The haplotype frequencies in Europeans are in strong linkage disequilibrium. This means there are much higher frequencies of certain haplotypes relative to the expectation based on random sorting of gene-alleles. This aided the discovery of HLA antigens, but was unknown to the pioneering researchers.\n\nIn the tables a fortuitous transplant between two unrelated individual has resulted in an antiserum to single alloantigen. By discovering these close-but-non-identical matches, the process with somewhat related haplotypes surface antigens were identified for HLA A, and in the table below, HLA B at the time however these were all grouped together as HL-Antigens. On the left the \"B\" and \"cw\" antigens are matched (B and C are close together so if B matches then C likely also matches), but A antigens are not matched. The antisera that is produced by the recipient is most likely to be A3, but if the direction of transplant is reversed A2 is the likely alloantigen. Two of the first three alloantigens are thus readily easy to detect because of the similarity and frequency of the A2-B7 and A3-B7 haplotypes (see example 1). \n\nIn these instances, the A1/A2, A2/A3, A1/A3 are matched, decreasing the probability of a rejection because many are linked to a given haplotype. Occasionally the 'recombinant' A1-Cw7-B7(rare), B7 becomes the alloantigen in a recipient with A1-Cw7-B8(common).\n\nThis linkage disequilibrium in Europeans explains why A1, A2, A3, \"A7\"[B7], and \"A8\"[B8] were identified, first. It would have taken substantially longer to identify other alleles because frequencies were lower, and haplotypes that migrated into the European population had undergone equilibration or were from multiple sources.\n\nThis is the genetic background against which scientists tried to uncover and understand the histocompatibility antigens.\n\nIn the late 1960s, scientist began reacting sera from patients with rejecting transplants to donor or 'third party' tissues. Their sera (the liquid part of the blood when blood clots) was sensitized to the cells from donors - it was \"alloreactive\". By testing different anti-sera from recipients they were able to uncover some with unique reactivities. As a result, scientists were able to identify a few antigens. At first the first antigens were called the Hu-1 antigens and tentatively tagged as gene products of the Human equivalent of the mouse histocompatibility locus (H2). In 1968, it was discovered that matching these antigens between kidney donor and recipient improved the likelihood of kidney survival in the recipient. The antigen list still exists, although it has been reorganized to fit what we have since learned about genetics, refined, and greatly expanded.\n\nAs the study of these 'rejection' sera and \"allo\"-antigens progressed, certain patterns in the antibody recognition were recognized. The first major observation, in 1969, was that an allotypic antibodies to \"4\" (\"Four\") was only found on lymphocytes, while most of the antigens, termed \"LA\", recognized most cells in the body.\n\nThis group \"4\" antigen on lymphocytes would expand into \"4a\", \"4b\" and so on, becoming the \"D\" series (HLA-D (Class II) antigens) DP, DQ, and DR. This is an interesting history in itself.\n\nThe Hu-1 antigens were renamed the Human-lymphoid (HL) allo-antigens (HL-As). Allo-antigen comes from the observation that a tolerated protein in the donor becomes antigenic in the recipient. This can be compared with an autoantigen, in which a person develops antibodies to one or more of their own proteins. This also suggested the donor and recipient have a different genetic makeup for these antigens. The \"LA\" group thereafter was composed of HL-A1, A2, A3, A5, A6, A7, A8, A9, A10, A11, A12, A13, A14 and A15 until further divisions and renaming were necessary. Some of the antigens above, for example HL-A1, are similar to HLA-A1, as they are the same serotype. Some of the above, like A5, are not mentioned within the last few years, as they have been renamed.\n\nDuring these early studies it became known that there were associations with many autoimmune diseases. And the HLA A1-B8 haplotype is linked to a very long piece of conserved chromosome 6 variant called AH8.1 haplotype. In these studies \"HL-A1,8\" were frequently found co-linked to disease. This linkage is not necessarily a function of either gene, but a consequence of the way AH8.1 evolved.\n\nA series of tests on cultured cells revealed that, within the \"LA\" group, a donor tissue might have some antigens but not others. For example, an antiserum may react with patterns (on a given tissue):\n\n\nBut fail to react in the following patterns:\n\n\nIf 2 members of the series (A1, 2, 3, 9, 10, 11) were typed, a reaction with a third member of the series to the donor was not observed. This 'exclusivity' identified series \"A\". One might notice the similarities of this numeric series with the , as series \"A\" antigens are the first six members of HLA-A. Inadvertently, the scientist had discovered an antibody set that recognized only gene products from one locus, HLA-A gene the \"antigens\" being the gene products. The implication is that an alloreactive anti-sera can be a tool for genetic identification.\n\nNot long after the series A antigens were separated from the (rapidly expanding) list of antigens, it was determined another group also could be separated along the same \"logical\" lines. This group included HL-A5, A7, A8, A12. This became the series \"B\".\nNote the similarity of Series \"B\" to the first few members . The names of these antigens were necessarily changed to fit the new putative series they were assigned to. From HL-A# to HLA-B#. The problem was that the literature was using \"A7\" and would soon be using \"B7\" as shorthand for HLA-B7.\n\nSince it was now certain, by the early 1970s, that the \"antigens\" were encoded by different series, implicit loci, numeric lists became somewhat cumbersome. Many groups were discovering antigens. In these instances an antigen was assigned a temporary name, like \"RoMa2\" and after discussion, the next open numeric slot could be assigned, but not to an \"A\" or \"B\" series until proper testing had been done. To work around this problem a 'workshop' number \"w#\" was often assigned while testing continued to determine which series the antigen belonged to.\n\nBefore too long, a series \"C\" was uncovered. Series C has proved difficult to serotype, and the alleles in the series still carry the \"w\" tag signifying that status; in addition, it reminds us that Series C were not assigned names the same way as Series A and B, it has its own numeric list Cw1, Cw2, Cw3.\n\nBy the mid 1970s, genetic research was finally beginning to make sense of the simple list of antigens, a new series \"C\" had been discovered and, in turn genetic research had determined the order of HLA-A, C, B and D encoding loci on the human 6p. With new series came new antigens; Cw1 and 2 were quickly populated, although Cw typing lagged. Almost half of the antigens could not be resolved by serotyping in the early 90s. Currently genetics defines 18 groups.\n\nAt this point, Dw was still being used to identify DR, DQ, and DP antigens. The ability to identify new antigens far exceeded the ability to characterize those new antigens.\n\nAs technology for transplantation was deployed around the world, it became clear that these antigens were far from a complete set, and in fact hardly useful in some areas of the world (e.g., Africa, or those descended from Africans). Some serotyping antibodies proved to be poor, with broad specificities, and new serotypes were found that identified a smaller set of antigens more precisely. These broad antigen groups, like A9 and B5, were subdivided into \"split\" antigen groups, A23 & A24 and B51 & B52, respectively. As the HL-A serotyping developed, so did identification of new antigens.\n\nIn the early 1980s, it was discovered that a restriction fragment segregates with individuals who bear the HLA-B8 serotype. By 1990, it was discovered that a single amino acid sequence difference between HLA-B44 (B*4401 versus B*4402) could result in allograft rejection. This revelation appeared to make serotyping based matching strategies problematic if many such differences existed. In the case of B44, the antigen had already been split from the B12 broad antigen group. In 1983, the cDNA sequences of HLA-A3 and Cw3 All three sequences compared well with mouse MHC class I antigens. The Western European HLA-B7 antigen had been sequenced (although the first sequence had errors and was replaced). In short order, many HLA class I alleles were sequenced\nincluding 2 Cw1 alleles.\n\nBy 1990, the full complexity of the HLA class I antigens was beginning to be understood. At the time new serotypes were being determined, the problem with multiple alleles for each serotype was becoming apparent by nucleotide sequencing. RFLP analysis helped determine new alleles, but sequencing was more thorough. Throughout the 1990s, PCR kits, called SSP-PCR kits were developed that allowed, at least under optimal conditions, the purification of DNA, PCR and Agarose Gel identification of alleles within an 8-hour day. Alleles that could not be clearly identified by serotype and PCR could be sequenced, allowing for the refinement of new PCR kits.\n\nSerotypes like B*4401, B*4402, B*4403, each abundant within those with B44 serotypes could be determined with unambiguous accuracy. The molecular genetics has advanced HLA technology markedly over serotyping technology, but serotyping still survives. Serotyping had identified the most similar antigens that now form the HLA subgroups. Serotyping can reveal whether an antigen coded by the relevant HLA gene is expressed. An HLA allele coding non-expressed gene is termed \"Null Allele\", for example: HLA-B*15:01:01:02N. The expression level can also detected by serotyping, an HLA gene coding for antigens which has low protein expression on the cell surface is termed \"Low Expresser\", for example: HLA-A*02:01:01:02L.\n\n\nThe scientific problem has been to explain the natural function of a molecule, such as a self cell-surface receptor involved in immunity. It also seeks to explain how variation developed (perhaps by evolutionary pressure), and how the genetic mechanisms works (dominant, codominant, semidominant, or recessive; purifying selection or balancing selection).\n"}
{"id": "1674353", "url": "https://en.wikipedia.org/wiki?curid=1674353", "title": "History of pseudoscience", "text": "History of pseudoscience\n\nThe history of pseudoscience is the study of pseudoscientific theories over time. A pseudoscience is a set of ideas that presents itself as science, while it does not meet the criteria to properly be called such.\n\nDistinguishing between proper science and pseudoscience is sometimes difficult. One popular proposal for demarcation between the two is the falsification criterion, most notably contributed to by the philosopher Karl Popper. In the history of pseudoscience it can be especially hard to separate the two, because some sciences developed from pseudosciences. An example of this is the science chemistry, which traces its origins from the protoscience of alchemy.\n\nThe vast diversity in pseudosciences further complicates the history of pseudoscience. Some pseudosciences originated in the pre-scientific era, such as astrology and acupuncture. Others developed as part of an ideology, such as Lysenkoism, or as a response to perceived threats to an ideology. An example of this is creationism, which was developed as a response to the scientific theory of evolution.\n\nDespite failing to meet proper scientific standards, many pseudosciences survive. This is usually due to a persistent core of devotees who refuse to accept scientific criticism of their beliefs, or due to popular misconceptions. Sheer popularity is also a factor, as is attested by astrology which remains popular despite being rejected by a large majority of scientists.\n\nAmong the most notable developments in the history of pseudoscience in the 19th century are the rise of Spiritualism (traced in America to 1848), homeopathy (first formulated in 1796), and phrenology (developed around 1800). Another popular pseudoscientific belief that arose during the 19th century was the idea that there were canals visible on Mars. A relatively mild Christian fundamentalist backlash against the scientific theory of evolution foreshadowed subsequent events in the 20th century.\n\nThe study of bumps and fissures in people's skulls to determine their character, phrenology, was originally considered a science. It influenced psychiatry and early studies into neuroscience. As science advanced, phrenology was increasingly viewed as a pseudoscience. Halfway through the 19th century, the scientific community had prevailingly abandoned it.\n\nHalfway through the century, iridology was invented by the Hungarian physician Ignaz von Peczely. The theory would remain popular throughout the 20th century as well.\n\nSpiritualism (sometimes referred to as \"Modern Spiritualism\" or \"Spiritism\") or \"Modern American Spiritualism\" grew phenomenally during the period. The American version of this movement has been traced to the Fox sisters who in 1848 began claiming the ability to communicate with the dead. The religious movement would remain popular until the 1920s, when renowned magician Harry Houdini began exposing famous mediums and other performers as frauds (see also Harry Houdini#Debunking spiritualists). While the religious beliefs of Spiritualism are not presented as science, and thus are not properly considered pseudoscientific, the movement did spawn numerous pseudoscientific phenomena such as ectoplasm and spirit photography.\n\nThe principles of homeopathy were first formulated in 1796, by German physician Samuel Hahnemann. At the time, mainstream medicine was a primitive affair and still made use of techniques such as bloodletting. Homeopathic medicine by contrast consisted of extremely diluted substances, which meant that patients basically received water. Compared to the damage often caused by conventional medicine, this was an improvement. During the 1830s homeopathic institutions and schools spread across the USA and Europe. Despite these early successes, homeopathy was not without its critics. Its popularity was on the decline before the end of the 19th century, though it has been revived in the 20th century.\n\nThe supposed Martian canals were first reported in 1877, by the Italian astronomer Giovanni Schiaparelli. The belief in them peaked in the late 19th century, but was widely discredited in the beginning of the 20th century.\n\nThe publication of \"\" by politician and author Ignatius L. Donnelly in 1882, renewed interest in the ancient idea of Atlantis. This highly advanced society supposedly existed several millennia before the rise of civilizations like Ancient Egypt. It was first mentioned by Plato, as a literary device in two of his dialogues. Other stories of lost continents, such as Mu and Lemuria also arose during the late 19th century.\n\nIn 1881 the Dutch Vereniging tegen de Kwakzalverij (English: \"Society against Quackery\") was formed to oppose pseudoscientific trends in medicine. It is still active.\n\nAmong the most notable developments to pseudoscience in the 20th century are the rise of Creationism, the demise of Spiritualism, and the first formulation of ancient astronaut theories.\n\nReflexology, the idea that an undetectable life force connects various parts of the body to the feet and sometimes the hands and ears, was introduced in the USA in 1913 as 'zone therapy'.\n\nCreationism arose during the 20th century as a result of various other historical developments. When the modern evolutionary synthesis overcame the eclipse of Darwinism in the first half of the 20th century, American fundamentalist Christians began opposing the teaching of the theory of evolution in public schools. They introduced numerous laws to this effect, one of which was notoriously upheld by the Scopes Trial.\nIn the second half of the century the Space Race caused a renewed interest in science and worry that the USA was falling behind on the Soviet Union. Stricter science standards were adopted and led to the re-introduction of the theory of evolution in the curriculum. The laws against teaching evolution were now ruled unconstitutional, because they violated the separation of church and state. Attempting to evade this ruling, the Christian fundamentalists produced a supposedly secular alternative to evolution, Creationism. Perhaps the most influential publication of this new pseudoscience was \"\" by young earth creationists John C. Whitcomb and Henry M. Morris.\n\nThe dawn of the space age also inspired various versions of ancient astronaut theories. While differences between the specific theories exists, they share the idea that intelligent extraterrestrials visited Earth in the distant past and made contact with then living humans. Popular authors, such as Erich von Däniken and Zecharia Sitchin, began publishing in the 1960s. Among the most notable publications in the genre is \"Chariots of the Gods?\", which appeared in 1968.\n\nThe Apollo Moon landings from the 1960s through the 70's gave rise to a number of Apollo Moon Landing hoax conspiracy theories. These conspiracy theories are universally ignored by the scientific community, but at the end of the century a Gallup poll showed 6 percent of the American population did not believe the landings were genuine.\n\nLate in the 20th century several prominent skeptical foundations were formed to counter the growth of pseudosciences. In the USA, the most notable of these are, in chronological order, the Center for Inquiry (1991), The Skeptics Society (1992), the James Randi Educational Foundation (1996), and the New England Skeptical Society (1996). The Committee for Skeptical Inquiry, which has similar goals, had already been founded in 1976. It became part of the Center for Inquiry as part of the foundation of the latter in 1991. In the Netherlands Stichting Skepsis was founded in 1987.\n\nAt the beginning of the 21st century, a variety of pseudoscientific theories remain popular.\n\nCreationism, in the form of Intelligent Design, suffered a major legal defeat in the Kitzmiller v. Dover Area School District trial. Judge John E. Jones III ruled that Intelligent Design is inseparable from Creationism, and its teaching in public schools violates the Establishment Clause of the First Amendment. The trial sparked much interest, and was the subject of several documentaries including the award-winning NOVA production \"\" (2007).\n\nThe pseudoscientific idea that vaccines cause autism originated in the 1990s, but became prominent in the media during the first decade of the 21st century. Despite a broad scientific consensus against the idea that there is a link between vaccination and autism, several celebrities have joined the debate. Most notable of these is Jenny McCarthy, whose son has autism.\nIn February 2009, surgeon Andrew Wakefield, who published the original research supposedly indicating a link between vaccines and autism, was reported to have fixed the data by The Sunday Times. A hearing by the General Medical Council had already begun in March 2007, examining charges of professional misconduct.\n\nThe most notable development in the ancient astronauts genre was the opening of Erich von Däniken's Mystery Park in 2003. While the park had a good first year, the number of visitors was much lower than the expected 500,000 a year. This caused financial difficulties, which led to the closure of the park in 2006.\n\n"}
{"id": "53950535", "url": "https://en.wikipedia.org/wiki?curid=53950535", "title": "How to Build a Dinosaur", "text": "How to Build a Dinosaur\n\nHow to Build a Dinosaur: Extinction Doesn't Have to Be Forever is a 2009 book by paleontologist Jack Horner and James Gorman. The book outlines Horner's theory for being able to resurrect a maniraptoran dinosaur by altering the genes of a chicken embryo. In 2010, a paperback version was published under the title How to Build a Dinosaur: The New Science of Reverse Evolution.\n\nPaleontologist Jack Horner describes evolutionary developmental biology (evo-devo) and outlines his theory for being able to resurrect a maniraptoran dinosaur from a chicken embryo, by activating and deactivating certain genes to restore dormant dinosaur characteristics such as a tail, claws, teeth, and a snout. Horner also discusses paleontology in the book.\n\nHorner's idea for the \"Chickenosaurus\" project came from \"a pretty good script\" that was written for \"Jurassic Park IV\" early in its development. The film's story, at that time, was expected to involve genetic engineering of dinosaurs. Horner was planning the book with co-author James Gorman in spring 2005. Gorman was deputy science editor for \"The New York Times\", and had previously co-written Horner's 1990 book, \"Digging Dinosaurs\".\n\nHorner and his publisher planned for the book to come out at the same time as \"Jurassic Park IV\", to serve as a scientific companion volume; however, the film was delayed. Horner's book, in hardcover form, was ultimately published by Dutton Penguin on March 19, 2009, without the accompaniment of the film. The book was initially published with the title \"How to Build a Dinosaur: Extinction Doesn't Have to Be Forever\". A paperback version was published by Plume on February 23, 2010, with the title \"How to Build a Dinosaur: The New Science of Reverse Evolution\".\n\n\"Publishers Weekly\" called the book \"provocative but frustrating\", writing that aside from the main concept, \"Much of the rest of the book offers background, but often digresses, for example, into hunting for DNA from 68-million-year-old dinosaur bones or the surfing habit of the man who discovered the polymerase chain reaction or how genetically close humans and Neanderthals are—none of which advances the book's central argument.\"\n\nKirkus Reviews wrote that the book \"has a comfortable, intelligent flow,\" but noted that Horner first \"wants to tell a story—and it's a good one, though at times meandering—about paleontology […]. Horner digresses about skinheads, Ted Kaczynski and chicken carcasses, but his main idea is reverse evolutionary engineering.\" Gilbert Taylor of Booklist wrote, \"Straight from the scientific frontier, Horner's work should excite anyone who's dreamed of walking with dinosaurs.\"\n\nBrian Switek of \"Smithsonian\" wrote, \"The importance of \"How to Build a Dinosaur\" does not lie in Horner's wish to create a dinochicken. That makes up only a small part of the book. Instead the slim volume indicates how paleontology is becoming more of an interdisciplinary science where studies of development and genetics are just as important as fossilized bones.\" Jeff Hecht of \"New Scientist\" wrote that Horner \"is at his best\" in the book, which he called \"provocative yet firmly grounded in science.\"\n"}
{"id": "1645", "url": "https://en.wikipedia.org/wiki?curid=1645", "title": "Ibn al-Haytham", "text": "Ibn al-Haytham\n\nHasan Ibn al-Haytham (Latinized Alhazen ; full name \"\" ; ) was an Arab mathematician, astronomer, and physicist of the Islamic Golden Age. Sometimes called \"the father of modern optics\", he made significant contributions to the principles of optics and visual perception in particular, his most influential work being his \"Kitāb al-Manāẓir\" (كتاب المناظر, \"Book of Optics\"), written during 1011–1021, which survived in the Latin edition. A polymath, he also wrote on philosophy, theology and medicine.\n\nIbn al-Haytham was the first to explain that vision occurs when light bounces on an object and then is directed to one's eyes. And he was the first to point out that vision occurs in the brain, rather than in the eyes. He was also an early proponent of the concept that a hypothesis must be proved by experiments based on confirmable procedures or mathematical evidence—hence understanding the scientific method five centuries before Renaissance scientists.\n\nBorn in Basra, he spent most of his productive period in the Fatimid capital of Cairo and earned his living authoring various treatises and tutoring members of the nobilities. Ibn al-Haytham is sometimes given the byname \"al-Baṣrī\" after his birthplace, or \"al-Miṣrī\" (\"of Egypt\"). Ibn al-Haytham was nicknamed the \"Second Ptolemy\" by Abu'l-Hasan Bayhaqi\n\nIn medieval Europe, Ibn al-Haytham was honored as \"The Physicist\". Ibn al-Haytham paved the way for the modern science of physical optics.\n\nIbn al-Haytham (Alhazen) was born c. 965 to an Arab family in Basra, Iraq, \nwhich was at the time part of the Buyid emirate. \nHe held a position with the title \"vizier\" in his native Basra, and made a name for himself for his knowledge of applied mathematics. \nAs he claimed to be able to regulate the flooding of the Nile, he was invited to by Fatimid Caliph al-Hakim in order to realise a hydraulic project at Aswan. However, Ibn al-Haytham was forced to concede the impracticability of his project.\nUpon his return to Cairo, he was given an administrative post. After he proved unable to fulfill this task as well, he contracted the ire of the caliph Al-Hakim bi-Amr Allah, and is said to have been forced into hiding until the caliph's death in 1021, after which his confiscated possessions were returned to him.\nLegend has it that Alhazen feigned madness and was kept under house arrest during this period. During this time, he wrote his influential \"Book of Optics\".\nAlhazen continued to live in Cairo, in the neighborhood of the famous University of al-Azhar, and lived from the proceeds of his literary production until his death in c. 1040. (A copy of Apollonius' \"Conics\", written in Ibn al-Haytham's own handwriting exists in Aya Sofya: (MS Aya Sofya 2762, 307 fob., dated Safar 415 a.h. [1024]).)\n\nAmong his students were Sorkhab (Sohrab), a Persian from Semnan, and Abu al-Wafa Mubashir ibn Fatek, an Egyptian prince.\n\nAlhazen's most famous work is his seven-volume treatise on optics \"Kitab al-Manazir\" (\"Book of Optics\"), written from 1011 to 1021.\n\n\"Optics\" was translated into Latin by an unknown scholar at the end of the 12th century or the beginning of the 13th century. It was printed by Friedrich Risner in 1572, with the title \"Opticae thesaurus: Alhazeni Arabis libri septem, nuncprimum editi; Eiusdem liber De Crepusculis et nubium ascensionibus\" (English : Thesaurus of Optics: seven books of the Arab Alhazeni, first edition: concerning twilight and the advancement of clouds). Risner is also the author of the name variant \"Alhazen\"; before Risner he was known in the west as Alhacen. This work enjoyed a great reputation during the Middle Ages. Works by Alhazen on geometric subjects were discovered in the Bibliothèque nationale in Paris in 1834 by E. A. Sedillot. In all, A. Mark Smith has accounted for 18 full or near-complete manuscripts, and five fragments, which are preserved in 14 locations, including one in the Bodleian Library at Oxford, and one in the library of Bruges.\n\nTwo major theories on vision prevailed in classical antiquity. The first theory, the emission theory, was supported by such thinkers as Euclid and Ptolemy, who believed that sight worked by the eye emitting rays of light. The second theory, the intromission theory supported by Aristotle and his followers, had physical forms entering the eye from an object. Previous Islamic writers (such as al-Kindi) had argued essentially on Euclidean, Galenist, or Aristotelian lines. The strongest influence on the \"Book of Optics\" was from Ptolemy's \"Optics\", while the description of the anatomy and physiology of the eye was based on Galen's account. Alhazen's achievement was to come up with a theory that successfully combined parts of the mathematical ray arguments of Euclid, the medical tradition of Galen, and the intromission theories of Aristotle. Alhazen's intromission theory followed al-Kindi (and broke with Aristotle) in asserting that \"from each point of every colored body, illuminated by any light, issue light and color along every straight line that can be drawn from that point\". This however left him with the problem of explaining how a coherent image was formed from many independent sources of radiation; in particular, every point of an object would send rays to every point on the eye. What Alhazen needed was for each point on an object to correspond to one point only on the eye. He attempted to resolve this by asserting that the eye would only perceive perpendicular rays from the object—for any one point on the eye only saw the ray that reached it directly, without being refracted by any other part of the eye, would be perceived. He argued using a physical analogy that perpendicular rays were stronger than oblique rays; in the same way that a ball thrown directly at a board might break the board, whereas a ball thrown obliquely at the board would glance off, perpendicular rays were stronger than refracted rays, and it was only perpendicular rays which were perceived by the eye. As there was only one perpendicular ray that would enter the eye at any one point, and all these rays would converge on the centre of the eye in a cone, this allowed him to resolve the problem of each point on an object sending many rays to the eye; if only the perpendicular ray mattered, then he had a one-to-one correspondence and the confusion could be resolved. He later asserted (in book seven of the \"Optics\") that other rays would be refracted through the eye and perceived \"as if\" perpendicular.\n\nHis arguments regarding perpendicular rays do not clearly explain why \"only\" perpendicular rays were perceived; why would the weaker oblique rays not be perceived more weakly? His later argument that refracted rays would be perceived as if perpendicular does not seem persuasive. However, despite its weaknesses, no other theory of the time was so comprehensive, and it was enormously influential, particularly in Western Europe: Directly or indirectly, his \"De Aspectibus\" (Book of Optics) inspired much activity in optics between the 13th and 17th centuries. Kepler's later theory of the retinal image (which resolved the problem of the correspondence of points on an object and points in the eye) built directly on the conceptual framework of Alhazen.\n\nAlhazen showed through experiment that light travels in straight lines, and carried out various experiments with lenses, mirrors, refraction, and reflection. His analyses of reflection and refraction considered the vertical and horizontal components of light rays separately.\n\nThe camera obscura was known to the ancient Chinese, and was described by the Han Chinese polymathic genius Shen Kuo in his scientific book \"Dream Pool Essays\", published in the year 1088 C.E.. Aristotle had discussed the basic principle behind it in his \"Problems\", however Alhazen's work also contained the first clear description, outside of China, of camera obscura in the areas of the middle east, Europe, Africa and India. and early analysis of the device.\n\nAlhazen studied the process of sight, the structure of the eye, image formation in the eye, and the visual system. Ian P. Howard argued in a 1996 \"Perception\" article that Alhazen should be credited with many discoveries and theories previously attributed to Western Europeans writing centuries later. For example, he described what became in the 19th century Hering's law of equal innervation. He wrote a description of vertical horopters 600 years before Aguilonius that is actually closer to the modern definition than Aguilonius's—and his work on binocular disparity was repeated by Panum in 1858. Craig Aaen-Stockdale, while agreeing that Alhazen should be credited with many advances, has expressed some caution, especially when considering Alhazen in isolation from Ptolemy, who Alhazen was extremely familiar with. Alhazen corrected a significant error of Ptolemy regarding binocular vision, but otherwise his account is very similar; Ptolemy also attempted to explain what is now called Hering's law. In general, Alhazen built on and expanded the optics of Ptolemy. In a more detailed account of Ibn al-Haytham's contribution to the study of binocular vision based on Lejeune and Sabra, Raynaud showed that the concepts of correspondence, homonymous and crossed diplopia were in place in Ibn al-Haytham's optics. But contrary to Howard, he explained why Ibn al-Haytham did not give the circular figure of the horopter and why, by reasoning experimentally, he was in fact closer to the discovery of Panum's fusional area than that of the Vieth-Müller circle. In this regard, Ibn al-Haytham's theory of binocular vision faced two main limits: the lack of recognition of the role of the retina, and obviously the lack of an experimental investigation of ocular tracts.\n\nAlhazen's most original contribution was that after describing how he thought the eye was anatomically constructed, he went on to consider how this anatomy would behave functionally as an optical system. His understanding of pinhole projection from his experiments appears to have influenced his consideration of image inversion in the eye, which he sought to avoid. He maintained that the rays that fell perpendicularly on the lens (or glacial humor as he called it) were further refracted outward as they left the glacial humor and the resulting image thus passed upright into the optic nerve at the back of the eye. He followed Galen in believing that the lens was the receptive organ of sight, although some of his work hints that he thought the retina was also involved.\n\nAlhazen's synthesis of light and vision adhered to the Aristotelian scheme, exhaustively describing the process of vision in a logical, complete fashion.\n\nAn aspect associated with Alhazen's optical research is related to systemic and methodological reliance on experimentation (\"i'tibar\")(Arabic: إعتبار) and controlled testing in his scientific inquiries. Moreover, his experimental directives rested on combining classical physics (\"ilm tabi'i\") with mathematics (\"ta'alim\"; geometry in particular). This mathematical-physical approach to experimental science supported most of his propositions in \"Kitab al-Manazir\" (\"The Optics\"; \"De aspectibus\" or \"Perspectivae\") and grounded his theories of vision, light and colour, as well as his research in catoptrics and dioptrics (the study of the reflection and refraction of light, respectively). \n\nAccording to Matthias Schramm, Alhazen \"was the first to make a systematic use of the method of varying the experimental conditions in a constant and uniform manner, in an experiment showing that the intensity of the light-spot formed by the projection of the moonlight through two small apertures onto a screen diminishes constantly as one of the apertures is gradually blocked up.\" G. J. Toomer expressed some skepticism regarding Schramm's view, arguing that caution is needed to avoid reading anachronistically particular passages in Alhazen's very large body of work, because at the time (1964), his \"Book of Optics\" had not yet been fully translated from Arabic. While acknowledging Alhazen's importance in developing experimental techniques, Toomer argued that Alhazen should not be considered in isolation from other Islamic and ancient thinkers. Toomer does concede that \"Schramm sums up [Alhazen's] achievement in the development of scientific method.\" Toomer 1964 lists, as a precondition, what is needed for historians to investigate Schramm's claim (1963) that Ibn al-Haytham was the true founder of modern physics, is translations of Ibn al-Haytham.\n\nMark Smith recounts Alhazen's elaboration of Ptolemy's experiments in double vision, reflection, and refraction: Alhazen's \"Optics\" book influenced the Perspectivists in Europe, Roger Bacon, Witelo, and Peckham. \"The Optics\" was incorporated into Risner's 1572 printing of \"Opticae Thesaurus\", through which Kepler finally resolved the contradictions inherent in Witelo's explanation of the imaging chain, from external object to the retina of the eye.\n\nHis work on catoptrics in Book V of the Book of Optics contains a discussion of what is now known as Alhazen's problem, first formulated by Ptolemy in 150 AD. It comprises drawing lines from two points in the plane of a circle meeting at a point on the circumference and making equal angles with the normal at that point. This is equivalent to finding the point on the edge of a circular billiard table at which a player must aim a cue ball at a given point to make it bounce off the table edge and hit another ball at a second given point. Thus, its main application in optics is to solve the problem, \"Given a light source and a spherical mirror, find the point on the mirror where the light will be reflected to the eye of an observer.\" This leads to an equation of the fourth degree. This eventually led Alhazen to derive a formula for the sum of fourth powers, where previously only the formulas for the sums of squares and cubes had been stated. His method can be readily generalized to find the formula for the sum of any integral powers, although he did not himself do this (perhaps because he only needed the fourth power to calculate the volume of the paraboloid he was interested in). He used his result on sums of integral powers to perform what would now be called an integration, where the formulas for the sums of integral squares and fourth powers allowed him to calculate the volume of a paraboloid. Alhazen eventually solved the problem using conic sections and a geometric proof. His solution was extremely long and complicated and may not have been understood by mathematicians reading him in Latin translation. Later mathematicians used Descartes' analytical methods to analyse the problem, with a new solution being found in 1997 by the Oxford mathematician Peter M. Neumann. Recently, Mitsubishi Electric Research Laboratories (MERL) researchers Amit Agrawal, Yuichi Taguchi and Srikumar Ramalingam solved the extension of Alhazen's problem to general rotationally symmetric quadric mirrors including hyperbolic, parabolic and elliptical mirrors. They showed that the mirror reflection point can be computed by solving an eighth degree equation in the most general case. If the camera (eye) is placed on the axis of the mirror, the degree of the equation reduces to six. Alhazen's problem can also be extended to multiple refractions from a spherical ball. Given a light source and a spherical ball of certain refractive index, the closest point on the spherical ball where the light is refracted to the eye of the observer can be obtained by solving a tenth degree equation.\n\n The Kitab al-Manazir (Book of Optics) describes several experimental observations that Alhazen made and how he used his results to explain certain optical phenomena using mechanical analogies. He conducted experiments with projectiles and concluded that only the impact of perpendicular projectiles on surfaces was forceful enough to make them penetrate, whereas surfaces tended to deflect oblique projectile strikes. For example, to explain refraction from a rare to a dense medium, he used the mechanical analogy of an iron ball thrown at a thin slate covering a wide hole in a metal sheet. A perpendicular throw breaks the slate and passes through, whereas an oblique one with equal force and from an equal distance does not. He also used this result to explain how intense, direct light hurts the eye, using a mechanical analogy: Alhazen associated 'strong' lights with perpendicular rays and 'weak' lights with oblique ones. The obvious answer to the problem of multiple rays and the eye was in the choice of the perpendicular ray, since only one such ray from each point on the surface of the object could penetrate the eye.\n\nSudanese psychologist Omar Khaleefa has argued that Alhazen should be considered the founder of experimental psychology, for his pioneering work on the psychology of visual perception and optical illusions. Khaleefa has also argued that Alhazen should also be considered the \"founder of psychophysics\", a sub-discipline and precursor to modern psychology. Although Alhazen made many subjective reports regarding vision, there is no evidence that he used quantitative psychophysical techniques and the claim has been rebuffed.\n\nAlhazen offered an explanation of the Moon illusion, an illusion that played an important role in the scientific tradition of medieval Europe. Many authors repeated explanations that attempted to solve the problem of the Moon appearing larger near the horizon than it does when higher up in the sky. Alhazen argued against Ptolemy's refraction theory, and defined the problem in terms of perceived, rather than real, enlargement. He said that judging the distance of an object depends on there being an uninterrupted sequence of intervening bodies between the object and the observer. When the Moon is high in the sky there are no intervening objects, so the Moon appears close. The perceived size of an object of constant angular size varies with its perceived distance. Therefore, the Moon appears closer and smaller high in the sky, and further and larger on the horizon. Through works by Roger Bacon, John Pecham and Witelo based on Alhazen's explanation, the Moon illusion gradually came to be accepted as a psychological phenomenon, with the refraction theory being rejected in the 17th century. Although Alhazen is often credited with the perceived distance explanation, he was not the first author to offer it. Cleomedes ( 2nd century) gave this account (in addition to refraction), and he credited it to Posidonius ( 135-50 BC). Ptolemy may also have offered this explanation in his \"Optics\", but the text is obscure. Alhazen's writings were more widely available in the Middle Ages than those of these earlier authors, and that probably explains why Alhazen received the credit.\n\nBesides the \"Book of Optics\", Alhazen wrote several other treatises on the same subject, including his \"Risala fi l-Daw’\" (\"Treatise on Light\"). He investigated the properties of luminance, the rainbow, eclipses, twilight, and moonlight. Experiments with mirrors and the refractive interfaces between air, water, and glass cubes, hemispheres, and quarter-spheres provided the foundation for his theories on catoptrics.\n\nAlhazen discussed the physics of the celestial region in his \"Epitome of Astronomy\", arguing that Ptolemaic models must be understood in terms of physical objects rather than abstract hypotheses—in other words that it should be possible to create physical models where (for example) none of the celestial bodies would collide with each other. The suggestion of mechanical models for the Earth centred Ptolemaic model \"greatly contributed to the eventual triumph of the Ptolemaic system among the Christians of the West\". Alhazen's determination to root astronomy in the realm of physical objects was important, however, because it meant astronomical hypotheses \"were accountable to the laws of physics\", and could be criticised and improved upon in those terms.\n\nHe also wrote \"Maqala fi daw al-qamar\" (\"On the Light of the Moon\").\n\nIn his work, Alhazen discussed theories on the motion of a body. In his \"Treatise on Place\", Alhazen disagreed with Aristotle's view that nature abhors a void, and he used geometry in an attempt to demonstrate that place (\"al-makan\") is the imagined three-dimensional void between the inner surfaces of a containing body.\n\nIn his \"On the Configuration of the World\" Alhazen presented a detailed description of the physical structure of the earth:\n\nThe book is a non-technical explanation of Ptolemy's Almagest, which was eventually translated into Hebrew and Latin in the 13th and 14th centuries and subsequently had an influence on astronomers such as Georg von Peuerbach during the European Middle Ages and Renaissance.\n\nIn his \"Al-Shukūk ‛alā Batlamyūs\", variously translated as \"Doubts Concerning Ptolemy\" or \"Aporias against Ptolemy\", published at some time between 1025 and 1028, Alhazen criticized Ptolemy's \"Almagest\", \"Planetary Hypotheses\", and \"Optics\", pointing out various contradictions he found in these works, particularly in astronomy. Ptolemy's \"Almagest\" concerned mathematical theories regarding the motion of the planets, whereas the \"Hypotheses\" concerned what Ptolemy thought was the actual configuration of the planets. Ptolemy himself acknowledged that his theories and configurations did not always agree with each other, arguing that this was not a problem provided it did not result in noticeable error, but Alhazen was particularly scathing in his criticism of the inherent contradictions in Ptolemy's works. He considered that some of the mathematical devices Ptolemy introduced into astronomy, especially the equant, failed to satisfy the physical requirement of uniform circular motion, and noted the absurdity of relating actual physical motions to imaginary mathematical points, lines and circles:\n\nHaving pointed out the problems, Alhazen appears to have intended to resolve the contradictions he pointed out in Ptolemy in a later work. Alhazen believed there was a \"true configuration\" of the planets that Ptolemy had failed to grasp. He intended to complete and repair Ptolemy's system, not to replace it completely. In the \"Doubts Concerning Ptolemy\" Alhazen set out his views on the difficulty of attaining scientific knowledge and the need to question existing authorities and theories:\n\nHe held that the criticism of existing theories—which dominated this book—holds a special place in the growth of scientific knowledge.\n\nAlhazen's \"The Model of the Motions of Each of the Seven Planets\" was written 1038. Only one damaged manuscript has been found, with only the introduction and the first section, on the theory of planetary motion, surviving. (There was also a second section on astronomical calculation, and a third section, on astronomical instruments.) Following on from his \"Doubts on Ptolemy\", Alhazen described a new, geometry-based planetary model, describing the motions of the planets in terms of spherical geometry, infinitesimal geometry and trigonometry. He kept a geocentric universe and assumed that celestial motions are uniformly circular, which required the inclusion of epicycles to explain observed motion, but he managed to eliminate Ptolemy's equant. In general, his model didn't try to provide a causal explanation of the motions, but concentrated on providing a complete, geometric description that could explain observed motions without the contradictions inherent in Ptolemy's model.\n\nAlhazen wrote a total of twenty-five astronomical works, some concerning technical issues such as \"Exact Determination of the Meridian\", a second group concerning accurate astronomical observation, a third group concerning various astronomical problems and questions such as the location of the Milky Way; Alhazen argued for a distant location, based on the fact that it does not move in relation to the fixed stars. The fourth group consists of ten works on astronomical theory, including the \"Doubts\" and \"Model of the Motions\" discussed above.\n\nIn mathematics, Alhazen built on the mathematical works of Euclid and Thabit ibn Qurra and worked on \"the beginnings of the link between algebra and geometry.\"\n\nHe developed a formula for summing the first 100 natural numbers, using a geometric proof to prove the formula.\n\nAlhazen explored what is now known as the Euclidean parallel postulate, the fifth postulate in Euclid's \"Elements\", using a proof by contradiction, and in effect introducing the concept of motion into geometry. He formulated the Lambert quadrilateral, which Boris Abramovich Rozenfeld names the \"Ibn al-Haytham–Lambert quadrilateral\".\n\nIn elementary geometry, Alhazen attempted to solve the problem of squaring the circle using the area of lunes (crescent shapes), but later gave up on the impossible task. The two lunes formed from a right triangle by erecting a semicircle on each of the triangle's sides, inward for the hypotenuse and outward for the other two sides, are known as the lunes of Alhazen; they have the same total area as the triangle itself.\n\nAlhazen's contributions to number theory include his work on perfect numbers. In his \"Analysis and Synthesis\", he may have been the first to state that every even perfect number is of the form 2(2 − 1) where 2 − 1 is prime, but he was not able to prove this result; Euler later proved it in the 18th century.\n\nAlhazen solved problems involving congruences using what is now called Wilson's theorem. In his \"Opuscula\", Alhazen considers the solution of a system of congruences, and gives two general methods of solution. His first method, the canonical method, involved Wilson's theorem, while his second method involved a version of the Chinese remainder theorem.\n\nAlhazen discovered the sum formula for the fourth power, using a method that could be generally used to determine the sum for any integral power. He used this to find the volume of a paraboloid. He could find the integral formula for any polynomial without having developed a general formula.\n\nAlhazen also wrote a \"Treatise on the Influence of Melodies on the Souls of Animals\", although no copies have survived. It appears to have been concerned with the question of whether animals could react to music, for example whether a camel would increase or decrease its pace.\n\nIn engineering, one account of his career as a civil engineer has him summoned to Egypt by the Fatimid Caliph, Al-Hakim bi-Amr Allah, to regulate the flooding of the Nile River. He carried out a detailed scientific study of the annual inundation of the Nile River, and he drew plans for building a dam, at the site of the modern-day Aswan Dam. His field work, however, later made him aware of the impracticality of this scheme, and he soon feigned madness so he could avoid punishment from the Caliph.\n\nIn his \"Treatise on Place\", Alhazen disagreed with Aristotle's view that nature abhors a void, and he used geometry in an attempt to demonstrate that place (\"al-makan\") is the imagined three-dimensional void between the inner surfaces of a containing body. Abd-el-latif, a supporter of Aristotle's philosophical view of place, later criticized the work in \"Fi al-Radd ‘ala Ibn al-Haytham fi al-makan\" (\"A refutation of Ibn al-Haytham’s place\") for its geometrization of place.\n\nAlhazen also discussed space perception and its epistemological implications in his \"Book of Optics\". In \"tying the visual perception of space to prior bodily experience, Alhazen unequivocally rejected the intuitiveness of spatial perception and, therefore, the autonomy of vision. Without tangible notions of distance and size for\ncorrelation, sight can tell us next to nothing about such things.\"\n\nAlhazen was a Muslim; it is not certain to which school of Islam he belonged. As a Sunni, he may have been either a follower of the Ash'ari school, or a follower of the Mu'tazili school.\nSabra (1978) even suggested he might have been an adherent of Shia Islam.\n\nAlhazen wrote a work on Islamic theology in which he discussed prophethood and developed a system of philosophical criteria to discern its false claimants in his time. \nHe also wrote a treatise entitled \"Finding the Direction of Qibla by Calculation\" in which he discussed finding the Qibla, where prayers (salat) are directed towards, mathematically.\n\nThere are occasional references to theology or religious sentiment in his technical works, e.g. \nin \"Doubts Concerning Ptolemy\":\n\nIn \"The Winding Motion\":\nRegarding the relation of objective truth and God:\n\nAlhazen made significant contributions to optics, number theory, geometry, astronomy and natural philosophy. Alhazen's work on optics is credited with contributing a new emphasis on experiment.\n\nHis main work, \"Kitab al-Manazir\" (\"Book of Optics\"), was known in the Muslim world mainly, but not exclusively, through the thirteenth-century commentary by Kamāl al-Dīn al-Fārisī, the \"Tanqīḥ \"al-Manāẓir\" li-dhawī l-abṣār wa l-baṣā'ir\". In al-Andalus, it was used by the eleventh-century prince of the Banu Hud dynasty of Zaragossa and author of an important mathematical text, al-Mu'taman ibn Hūd. A Latin translation of the \"Kitab al-Manazir\" was made probably in the late twelfth or early thirteenth century. This translation was read by and greatly influenced a number of scholars in Christian Europe including: Roger Bacon, Robert Grosseteste, Witelo, Giambattista della Porta, Leonardo Da Vinci, Galileo Galilei, Christiaan Huygens, René Descartes, and Johannes Kepler. His research in catoptrics (the study of optical systems using mirrors) centred on spherical and parabolic mirrors and spherical aberration. He made the observation that the ratio between the angle of incidence and refraction does not remain constant, and investigated the magnifying power of a lens. His work on catoptrics also contains the problem known as \"Alhazen's problem\". Meanwhile in the Islamic world, Alhazen's work influenced Averroes' writings on optics, and his legacy was further advanced through the 'reforming' of his \"Optics\" by Persian scientist Kamal al-Din al-Farisi (died ca. 1320) in the latter's \"Kitab Tanqih al-Manazir\" (\"The Revision of\" [Ibn al-Haytham's] \"Optics\"). Alhazen wrote as many as 200 books, although only 55 have survived. Some of his treatises on optics survived only through Latin translation. During the Middle Ages his books on cosmology were translated into Latin, Hebrew and other languages.\n\nThe impact crater Alhazen on the Moon is named in his honour, as was the asteroid 59239 Alhazen. In honour of Alhazen, the Aga Khan University (Pakistan) named its Ophthalmology endowed chair as \"The Ibn-e-Haitham Associate Professor and Chief of Ophthalmology\". Alhazen, by the name Ibn al-Haytham, is featured on the obverse of the Iraqi 10,000-dinar banknote issued in 2003, and on 10-dinar notes from 1982.\n\nThe 2015 International Year of Light celebrated the 1000th anniversary of the works on optics by Ibn Al-Haytham.\n\nIn 2014, the \"Hiding in the Light\" episode of \"\", presented by Neil deGrasse Tyson, focused on the accomplishments of Ibn al-Haytham. He was voiced by Alfred Molina in the episode.\n\nOver forty years previously, Jacob Bronowski presented Alhazen's work in a similar television documentary (and the corresponding book), \"The Ascent of Man\". In episode 5 (\"The Music of the Spheres\"), Bronowski remarked that in his view, Alhazen was \"the one really original scientific mind that Arab culture produced\", whose theory of optics was not improved on till the time of Newton and Leibniz.\n\nH. J. J. Winter, a British historian of science, summing up the importance of Ibn al-Haytham in the history of physics wrote:\nAfter the death of Archimedes no really great physicist appeared until Ibn al-Haytham. If, therefore, we confine our interest only to the history of physics, there is a long period of over twelve hundred years during which the Golden Age of Greece gave way to the era of Muslim Scholasticism, and the experimental spirit of the noblest physicist of Antiquity lived again in the Arab Scholar from Basra.\n\nUNESCO declared 2015 the International Year of Light and its Director-General Irina Bokova dubbed Ibn al-Haytham 'the father of optics'. Amongst others, this was to celebrate Ibn Al-Haytham's achievements in optics, mathematics and astronomy. An international campaign, created by the 1001 Inventions organisation, titled \"1001 Inventions and the World of Ibn Al-Haytham\" featuring a series of interactive exhibits, workshops and live shows about his work, partnering with science centers, science festivals, museums, and educational institutions, as well as digital and social media platforms. The campaign also produced and released the short educational film 1001 Inventions and the World of Ibn Al-Haytham.\n\n has noted that Alhazen's treatment of refraction describes an experimental setup without publication of data. Ptolemy published his experimental results for refraction, in contrast.\n\nAccording to medieval biographers, Alhazen wrote more than 200 works on a wide range of subjects, of which at least 96 of his scientific works are known. Most of his works are now lost, but more than 50 of them have survived to some extent. Nearly half of his surviving works are on mathematics, 23 of them are on astronomy, and 14 of them are on optics, with a few on other subjects. Not all his surviving works have yet been studied, but some of the ones that have are given below.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "379978", "url": "https://en.wikipedia.org/wiki?curid=379978", "title": "In situ", "text": "In situ\n\nIn situ (; often not italicized in English) is a Latin phrase that translates literally to \"on site\" or \"in position\". It means \"locally\", \"on site\", \"on the premises\" or \"in place\" to describe an event where it takes place, and is used in many different contexts. For example, in fields such as physics, chemistry, or biology, \"in situ\" may describe the way a measurement is taken, that is, in the same place the phenomenon is occurring without isolating it from other systems or altering the original conditions of the test.\n\nIn the aerospace industry, equipment on-board aircraft must be tested \"in situ\", or in place, to confirm everything functions properly as a system. Individually, each piece may work but interference from nearby equipment may create unanticipated problems. Special test equipment is available for this \"in situ\" testing.\n\nIn archaeology, \"in situ\" refers to an artifact that has not been moved from its original place of deposition. In other words, it is stationary, meaning \"still.\" An artifact being \"in situ\" is critical to the interpretation of that artifact and, consequently, of the culture which formed it. Once an artifact's 'find-site' has been recorded, the artifact can then be moved for conservation, further interpretation and display. An artifact that is not discovered \"in situ\" is considered out of context and as not providing an accurate picture of the associated culture. However, the out of context artifact can provide scientists with an example of types and locations of \"in situ\" artifacts yet to be discovered. When excavating a burial site or surface deposit \"in situ\" refers to cataloging, recording, mapping, photographing human remains in the position they are discovered.\n\nThe label \"in situ\" indicates only that the object has not been \"newly\" moved. Thus, an archaeological \"in situ\" find may be an object that was historically looted from another place, an item of \"booty\" of a past war, a traded item, or otherwise of foreign origin. Consequently, the \"in situ\" find site may still not reveal its provenance, but with further detective work may help uncover links that otherwise would remain unknown. It is also possible for archaeological layers to be reworked on purpose or by accident (by humans, natural forces or animals). For example, in a Tell mound, where layers are not typically uniform or horizontal, or in land cleared or tilled for farming.\n\nThe term \"in situ\" is often used to describe ancient sculpture that was carved in place such as the Sphinx or Petra. This distinguishes it from statues that were carved and moved like the Colossi of Memnon, which was moved in ancient times.\n\nIn art, \"in situ\" refers to a work of art made specifically for a host site, or that a work of art takes into account the site in which it is installed or exhibited. For a more detailed account see: Site-specific art. The term can also refer to a work of art created at the site where it is to be displayed, rather than one created in the artist's studio and then installed elsewhere (\"e.g.,\" a sculpture carved \"in situ\"). In architectural sculpture the term is frequently employed to describe sculpture that is carved on a building, frequently from scaffolds, after the building has been erected.\nAlso commonly used to describe the site specific dance festival “Insitu”. Held in Queens, New York.\n\nA fraction of the globular star clusters in our galaxy, as well as those in other massive galaxies, might have formed \"in situ\". The rest might have been accreted from now defunct dwarf galaxies.\n\nIn astronomy, \"in situ\" also refers to \"in situ\" planet formation, in which planets are hypothesized to have been formed in the orbit that they are currently observed to be in rather than migrating from a different orbit.\n\nIn biology and biomedical engineering, \"in situ\" means to examine the phenomenon exactly in place where it occurs (i.e., without moving it to some special medium).\n\nIn the case of observations or photographs of living animals, it means that the organism was observed (and photographed) in the wild, exactly as it was found and exactly where it was found. This means it was not taken out of the area. The organism had not been moved to another (perhaps more convenient) location such as an aquarium.\n\nThis phrase \"in situ\" when used in laboratory science such as cell science can mean something intermediate between \"in vivo\" and \"in vitro\". For example, examining a cell within a whole organ intact and under perfusion may be \"in situ\" investigation. This would not be \"in vivo\" as the donor is sacrificed by experimentation, but it would not be the same as working with the cell alone (a common scenario for \"in vitro\" experiments).\n\n\"In vitro\" was among the first attempts to qualitatively and quantitatively analyze natural occurrences in the lab. Eventually, the limitation of \"in vitro\" experimentation was that they were not conducted in natural environments. To compensate for this problem, \"in vivo\" experimentation allowed testing to occur in the original organism or environment. To bridge the dichotomy of benefits associated with both methodologies, \"in situ\" experimentation allowed the controlled aspects of \"in vitro\" to become coalesced with the natural environmental compositions of \"in vivo\" experimentation.\n\nIn conservation of genetic resources, \"\"in situ\" conservation\" (also \"on-site conservation\") is the process of protecting an endangered plant or animal species in its natural habitat, as opposed to \"ex situ\" conservation (also \"off-site conservation\").\n\nIn chemistry, \"in situ\" typically means \"in the reaction mixture.\"\n\nThere are numerous situations in which chemical intermediates are synthesized \"in situ\" in various processes. This may be done because the species is unstable, and cannot be isolated, or simply out of convenience. Examples of the former include the Corey-Chaykovsky reagent and adrenochrome.\n\nIn biomedical engineering, protein nanogels made by the in situ polymerization method provide a versatile platform for storage and release of therapeutic proteins. It has tremendous applications for cancer treatment, vaccination, diagnosis, regenerative medicine, and therapies for loss-of-function genetic diseases.\n\nIn chemical engineering, \"in situ\" often refers to industrial plant \"operations or procedures that are performed in place\". For example, aged catalysts in industrial reactors may be regenerated in place (\"in situ\") without being removed from the reactors.\n\nIn architecture and building, \"in situ\" refers to construction which is carried out at the building site using raw materials. Compare that with \"prefabricated\" construction, in which building components are made in a factory and then transported to the building site for assembly. For example, concrete slabs may be \"in situ\" (also \"cast-in-place\") or \"prefabricated\".\n\nIn situ techniques are often more labour-intensive, and take longer, but the materials are cheaper, and the work is versatile and adaptable. \"Prefabricated\" techniques are usually much quicker, therefore saving money on labour costs, but factory-made parts can be expensive. They are also inflexible, and must often be designed on a grid, with all details fully calculated in advance. Finished units may require special handling due to excessive dimensions.\n\nThe phrase may also refer to those assets which are present at or near a project site. In this case, it is used to designate the state of an unmodified sample taken from a given stockpile.\n\nSite construction usually involves grading the existing soil surface so that material is \"cut\" out of one area and \"filled\" in another area creating a flat pad on an existing slope. The term \"in situ\" distinguishes soil still in its existing condition from soil modified (filled) during construction. The differences in the soil properties for supporting building loads, accepting underground utilities, and infiltrating water persist indefinitely.\n\n. For example, a file backup may be restored over a running system, without needing to take the system down to perform the restore. In the context of a database, a restore would allow the database system to continue to be available to users while a restore happened. An \"in situ\" upgrade would allow an operating system, firmware or application to be upgraded while the system was still running, perhaps without the need to reboot it, depending on the sophistication of the system.\n\nAnother use of the term in-situ that appears in Computer Science focuses primarily on the use of technology and user interfaces to provide continuous access to situationally relevant information in various locations and contexts. Examples include athletes viewing biometric data on smartwatches to improve their performance , a presenter looking at tips on a smart glass to reduce their speaking rate during a speech , or technicians receiving online and stepwise instructions for repairing an engine. \n\n, that is, does not exceed a constant no matter how large the input ---except for space for recursive calls on the \"call stack\". Typically such an algorithm operates on data objects directly in place rather than making copies of them. \n\nFor example, heapsort is an \"in situ\" sorting algorithm, which sorts the elements of an array in place. Quicksort is an \"in situ\" sorting algorithm, but in the worst case it requires linear space on the call stack (this can be reduced to log space). Merge sort is generally not written as an \"in situ\" algorithm. \n\nIn designing user interfaces, , for example, if a word processor displays an image and allows the image to be edited without launching a separate image editor, this is called \"in situ editing.\"\n\nAJAX partial page data updates is another example of \"in situ\" in a Web UI/UX context. \"Web 2.0\" included AJAX and the concept of asynchronous requests to servers to replace a portion of a web page with new data, without reloading\nthe entire page, as the early HTML model dictated. Arguably, \"all\" asynchronous data transfers or \"any\" background task is \"in situ\" as the normal state is normally unaware of background tasks, usually notified on completion\nby a callback mechanism.\n\nIn Big Data space, in situ data would mean bringing the computation to where data is located, rather than the other way like in traditional RDBMS systems where data is moved to computational space.\n\nIn design and advertising the term typically means the superimposing of theoretical design elements onto photographs of real world locations. This is a pre-visualization tool to aid in illustrating a proof of concept.\n\nIn physical geography and the Earth sciences, \"in situ\" typically describes natural material or processes prior to transport. For example, \"in situ\" is used in relation to the distinction between weathering and erosion, the difference being that erosion requires a transport medium (such as wind, ice, or water), whereas weathering occurs \"in situ\". Geochemical processes are also often described as occurring to material \"in situ\".\n\nIn the atmospheric sciences, \"in situ\" refers to obtained through direct contact with the respective subject, such as a radiosonde measuring a parcel of air or an anemometer measuring wind, as opposed to remote sensing such as weather radar or satellites.\n\nIn economics, \"in situ\" is used when referring to the \"in place\" storage of a product, usually a natural resource. More generally, it refers to any situation where there is no out-of-pocket cost to store the product so that the only storage cost is the opportunity cost of waiting longer to get your money when the product is eventually sold. Examples of \"in situ\" storage would be oil and gas wells, all types of mineral and gem mines, stone quarries, timber that has reached an age where it could be harvested, and agricultural products that do not need a physical storage facility such as hay.\n\nIn electrochemistry, the phrase in situ refers to performing electrochemical experiments under operating conditions of the electrochemical cell, i.e., under potential control. This is opposed to doing ex situ experiments that are performed under the absence of potential control. Potential control preserves the electrochemical environment essential to maintain the double layer structure intact and the electron transfer reactions occurring at that particular potential in the electrode/electrolyte interphasial region.\n\n\"In situ\" can refer to where a clean up or remediation of a polluted site is performed using and simulating the natural processes in the soil, contrary to \"ex situ\" where contaminated soil is excavated and cleaned elsewhere, off site.\n\nIn experimental physics \"in situ\" typically refers to a method of data collection or manipulation of a sample without exposure to an external environment. For example, the Si(111) 7x7 surface reconstruction is visible using a scanning tunneling microscope when it is prepared and analyzed \"in situ\".\n\nIn psychology experiments, \"in situ\" typically refers to those experiments done in a field setting as opposed to a laboratory setting.\n\nIn gastronomy, \"in situ\" refers to the art of cooking with the different resources that are available at the site of the event. Here a person is not going to the restaurant, but the restaurant comes to the person's home.\n\nIn legal contexts, \"in situ\" is often used for its literal meaning. For example, in Hong Kong, \"\"in situ\" land exchange\" involves the government exchanging the original or expired lease of a piece of land with a new grant or re-grant with the same piece of land or a portion of that.\n\nIn the field of recognition of governments under public international law the term \"in situ\" is used to distinguish between an exiled government and a government with effective control over the territory, i.e. the government \"in situ\".\n\nIn linguistics, specifically syntax, an element may be said to be \"in situ\" if it is pronounced in the position where it is interpreted. For example, questions in languages such as Chinese have \"in situ\" wh-elements, with structures comparable to \"John bought what?\" with \"what\" in the same position in the sentence as the grammatical object would be in its affirmative counterpart (for example, \"John bought bread\"). An example of an English wh-element that is not \"in situ\" (see wh-movement): \"What did John buy?\"\n\nIn literature \"in situ\" is used to describe a condition. The Rosetta Stone, for example, was originally erected in a courtyard, for public viewing. Most pictures of the famous stone are not \"in situ\" pictures of it erected, as it would have been originally. The stone was uncovered as part of building material, within a wall. Its in situ condition today is that it is erected, vertically, on public display at the British Museum in London, England.\n\nIn oncology: for a carcinoma, \"in situ\" means that malignant cells are present as a tumor but have not metastasized, or invaded, beyond the basement membrane of where the tumor was discovered. This can happen anywhere in the body, such as the skin, breast tissue, or lung. This type of tumor can often, depending on where it is located, be removed by surgery.\n\nIn anatomy: \"in situ\" refers to viewing structures as they appear in normal healthy bodies. For example, one can open up a cadaver's abdominal cavity and view the liver \"in situ\" or one can look at an isolated liver that has been removed from the cadaver's body.\n\nIn nursing, \"in situ\" describes any devices or appliances on the patient's body that remain in their desired and optimal position.\n\nIn medical simulation, \"in situ\" refers to the practice of clinical professionals using high fidelity patient simulators to train for clinical practice in patient care environments, such as wards, operating rooms, and other settings, rather than in dedicated simulation training facilities.\n\nIn biomedical, protein nanogels made by the in situ polymerization method provide a versatile platform for storage and release of therapeutic proteins. It has tremendous applications for cancer treatment, vaccination, diagnosis, regenerative medicine, and therapies for loss-of-function genetic diseases.\n\n\"In situ leaching\" or \"in situ recovery\" refers to the mining technique of injecting water underground to dissolve ore and bringing the uranium-impregnated water to the surface for extraction.\n\n\"In situ\" refers to recovery techniques which apply heat or solvents to heavy crude oil or bitumen reservoirs beneath the earth's crust. There are several varieties of \"in situ\" techniques, but the ones which work best in the oil sands use heat (steam).\n\nThe most common type of \"in situ\" petroleum production is referred to as SAGD (steam-assisted gravity drainage) this is becoming very popular in the Alberta Oil Sands.\n\nIn radio frequency (RF) transmission systems, \"in situ\" is often used to describe the location of various components while the system is in its standard transmission mode, rather than operation in a test mode. For example, if an \"in situ\" wattmeter is used in a commercial broadcast transmission system, the wattmeter can accurately measure power while the station is \"on air\".\n\nFuture space exploration or terraforming may rely on obtaining supplies \"in situ\", such as previous plans to power the Orion space vehicle with fuel minable on the moon. The Mars Direct mission concept is based primarily on the \"in situ\" fuel production using Sabatier reaction.\n\nIn the space sciences, \"in situ\" refers to measurements of the particle and field environment that the satellite is embedded in, such as the detection of energetic particles in the solar wind, or magnetic field measurements from a magnetometer.\n\nIn urban planning, in-situ upgrading is an approach to and method of upgrading informal settlements.\n\nIn vacuum technology, \"in situ\" baking refers to heating parts of the vacuum system while they are under vacuum in order to drive off volatile substances that may be absorbed or adsorbed on the walls so they cannot cause outgassing.\n\nThe term \"in situ\", used as \"repair in situ\", means to repair a vehicle at the place where it has a breakdown.\n\n"}
{"id": "10903491", "url": "https://en.wikipedia.org/wiki?curid=10903491", "title": "In the Name of Science", "text": "In the Name of Science\n\nIn the Name of Science is a book written by Harold L. Nieburg in 1966 concerning the political uses of science. It focuses on American defense spending on science and the U.S. military-industrial complex, and was one of the first books to discuss this issue at length. \n\nA summary appears in the Bulletin of the Atomic Scientists 22 (March 1966), pp. 20–24, as \"R and D in the Contract State: Throwing Away the Yardstick\" in a review by Bernard L. Spinrad.\n"}
{"id": "52916384", "url": "https://en.wikipedia.org/wiki?curid=52916384", "title": "Ion interaction chromatography", "text": "Ion interaction chromatography\n\nIon interaction chromatography (ion-pair chromatography) is a laboratory technique for separating ions with chromatography. In this technique ions are mixed with ion pairing reagents (IPR) . The analyte combines with its reciprocal ion in the IRP, this corresponds to retention time. Often organic salts are selected to pair with solute(s). The formation of this pair affects the interaction of the pair with the mobile phase and the stationary phase. \n\n"}
{"id": "40319830", "url": "https://en.wikipedia.org/wiki?curid=40319830", "title": "Journal of Natural Philosophy, Chemistry, and the Arts", "text": "Journal of Natural Philosophy, Chemistry, and the Arts\n\nThe A Journal of Natural Philosophy, Chemistry, and the Arts, generally known as \"Nicholson's Journal\", was the first monthly scientific journal in Great Britain. William Nicholson began it in 1797 and was the editor until it merged with another journal at the end of 1813.\n\nNicholson's journal would accept short papers, written by new or anonymous authors, and decide whether to publish them relatively quickly. These attributes distinguished the new journal from the established scientific journal \"Philosophical Transactions of the Royal Society\". By one account this less-formal model was so appealing that the next year a similar startup launched, Alexander Tilloch's \"Philosophical Magazine\".\n\n\nBy one account, William Nicholson started the journal and made all editorial decisions in a \"pioneering and uncertain attempt\" to make a living from publishing it. Revenues came only from subscriptions. Tilloch's \"Philosophical Magazine\" was more successful as a popular science journal business than Nicholson's journal, according to one source, and another such journal appeared in 1813 (\"Annals of Philosophy\"). Possibly partly because of this competition, William Nicholson ended the journal. By some accounts Nicholson's journal simply ceased, and by others it merged in 1814 with the \"Philosophical Magazine\" to form \"The Philosophical Magazine and Journal\".\n\nThe \"Advertisement\", dated 31 December 1813, at the start of Volume 42 of \"The Philosophical Magazine\" states:\n\n\"Nearly seventeen years have elapsed since \"The Philosophical Journal\" was commenced by Mr. Nicholson, and sixteen since the appearance of the first number of \"The Philosophical Magazine\". [...] [T]he result of [...] deliberations [between the publishers of \"Nicholson's Philosophical Journal\" and \"The Philosophical Magazine\" in order to respond to readers' complaints regarding duplication of material in the two publications] has been that it would certainly be best that we should unite, and that the joint product of our exertions and our correspondence should be consolidated in one periodical work. [...] The Philosophical Journal will henceforth be discontinued; and The Philosophical Magazine will be conducted by William Nicholson and Alexander Tilloch, in the same manner as it has always been carried on.\"\n\nFor the duration of Volume 43 (January to June 1814) the joint publishers of the new merged journal provided duplicate title-pages for each number, ostensibly so that subscribers to \"Nicholson's Philosophical Magazine\" might be enabled to \"preserve their Series without a chasm.\" However, despite their intention to continue this scheme of two-fold numeration, they abandoned it at the end of this trial period in June 1814, because of the perceived \"confusion and risque of many errors\" when referring to future volumes; from July 1814 a single numeration was used, following the numbering of \"The Philosophical Magazine.\"\n\nComplete journal issues have been scanned and are available online at the Biodiversity Heritage Library and at archive.org thanks to the Natural History Museum Library, London, the New York Public Library and google books.\n\n"}
{"id": "28870072", "url": "https://en.wikipedia.org/wiki?curid=28870072", "title": "List of rectores magnifici of the Eindhoven University of Technology", "text": "List of rectores magnifici of the Eindhoven University of Technology\n\nA rector of a Dutch university is called a \"rector magnificus\". The following people have been rector magnificus of the Eindhoven University of Technology or its predecessor, the Technische Hogeschool Eindhoven (THE):\n"}
{"id": "41652083", "url": "https://en.wikipedia.org/wiki?curid=41652083", "title": "List of scientific demonstrations", "text": "List of scientific demonstrations\n\nThis is a list of scientific demonstrations used in educational demonstrations and popular science lectures.\n\n\n\n"}
{"id": "30234767", "url": "https://en.wikipedia.org/wiki?curid=30234767", "title": "Living Earth Simulator Project", "text": "Living Earth Simulator Project\n\nThe living Earth simulator is a proposed massive computer simulation system intended to simulate the interactions of all aspects of life, human economic activity, climate, and other physical processes on the planet Earth as part of the FuturICT project, in response to the European FP7 \"Future and Emerging Technologies Flagship\" initiative.\n\nThere are over 300 international teams seeking ~€1 billion for the 10-year Future and Emerging Technologies ‘flagship’ competition. The Earth Simulator was not selected since the two winners have been announced as of March 2013. The winners were Graphene and Human Brain.\n\n\n"}
{"id": "1965902", "url": "https://en.wikipedia.org/wiki?curid=1965902", "title": "Long-range locator", "text": "Long-range locator\n\nA long-range locator is a class of devices purported to be a type of metal detector, supposedly able to detect a variety of substances, including gold, drugs and explosives; most are said to operate on a principle of resonance with the material being detected.\n\nSkeptics have examined the internals of many such devices and found those that have been examined to be incapable of operating as advertised, and have dismissed them as overpriced dowsing rods or similarly useless devices. Virtually all such devices claim to operate on a resonant frequency principle where the device is said to emit an electromagnetic signal, either through an antenna or a probe, that will respond to a specific substance such as gold, silver, or sometimes even paper money, and that the device will indicate the presence of such material by indicating a change in direction relative to the operator.\n\nThis theory of operation is not supported by scientific theory; the devices have not been shown to work in blind testing, and the resonance principle invoked has not been shown to work in laboratories (and is not consistently employed by LRL manufacturers). In addition, the Inverse-Square Law limits the effective possible signal strength of any putative LRL; moreover, not only does this attenuation apply to the supposed emissions from the LRL devices, but the return signals from the sought-after targets are further attenuated by the same constraints. Since most of these LRL devices are powered by low voltage, low current AA, AAA or 9v cells, the resultant power available for emissions is quite minuscule at best, and the return signal would suffer even greater attenuation. Examples exist of LRL devices having no internal power source at all, and these are advertised as being self-powered or powered by ambient static electricity; these are indistinguishable from dowsing rods.\n\nMany such devices contain non-functional circuitry or naively constructed approximations of radio transmitters. A few do have functional circuitry, putting out a weak signal with a function generator or a simple timer circuit, but are still largely useless in comparison with a coil-based metal detector; others have been found to contain intentionally obfuscated or completely superfluous components (from individual components such as inductors or ribbon cables up to, in some cases, pocket calculators), often indicative of intentional fraud, incompetence, or both, by the designer. Such functioning circuitry as exists in such devices usually has no obvious way (motor, solenoid, etc.) to connect to any rotating joint in the device either, meaning the devices are often entirely dependent on the ideomotor effect to function.\n\nAuthor Tom Clancy came under fire for including the DKL Lifeguard, a long-range locator purported to be useful for detecting people, in critical passages of his novel \"Rainbow Six\". A study by Sandia National Laboratories proved the Lifeguard to be completely useless, and other designs by the Lifeguard's creator Thomas Afilani have been shown to contain numerous dummy components with no clear function.\n\nAccusing the manufacturers of fraud, the UK banned export of the GT 200, used by the government of Thailand, and the ADE 651, used by the government of Iraq, in January 2010.\n\n\n"}
{"id": "15522138", "url": "https://en.wikipedia.org/wiki?curid=15522138", "title": "Marine counterparts of land creatures", "text": "Marine counterparts of land creatures\n\nThe idea that there are specific marine counterparts to land creatures, inherited from the writers on natural history in Antiquity, was firmly believed in Islam and in Medieval Europe, and is exemplified by the creatures represented in the medieval animal encyclopedias called bestiaries and in the parallels drawn in the moralising attributes attached to each. \"The creation was a mathematical diagram drawn in parallel lines,\" T. H. White said a propos the bestiary he translated. \"Things did not only have a moral they often had physical counterparts in other strata. There was a horse in the land and a sea-horse in the sea. For that matter there was probably a Pegasus in heaven\". The idea of perfect analogies in the fauna of land and sea was considered part of the perfect symmetry of the Creator's plan, offered as the \"book of nature\" to mankind, for which a text could be found in \"Job\":\nBut ask the animals, and they will teach you, or the birds of the air, and they will tell you; or speak to the earth, and it will teach you, or let the fish of the sea inform you. Which of all these does not know that the hand of the Lord has done this? In his hand is the life of every creature and the breath of all mankind.\n\nThe idea appears in the Jewish Tannaic sources as well, as brought down in Babylonian Talmud, Chulin 127a. Rashi (Psalms 49:2) traces this to a biblical source – the land is referred to as \"Chaled\", from the weasel (chulda), because the weasel is the only animal on dry land that does not have its counterpart in the sea.\nAll of Creation was considered to reflect the Creator, and Man could learn about the Creator through studying the Creation, an assumption that underlies the \"watchmaker analogy\" offered as a proof of God's existence.\n\nThe correspondence between the realms of earth and sea, extending to its denizens, offers examples of the taste for allegory engendered by Christian and Islamic methods of exegesis, which also encouraged the doctrine of signatures, a \"key\" to the meaning and use of herbs.\n\nThe source text that was most influential in compiling the bestiaries of the 12th and 13th centuries was the \"Physiologus\", one of the most widely read and copied secular texts of the Middle Ages. Written in Greek in Alexandria the 2nd century CE and accumulating further \"exemplary\" beasts in the next three centuries and more, \"Physiologus\" was transmitted in the West in Latin, and eventually translated into many vernacular languages: many manuscripts in various languages survive.\nAelian, \"On the Characteristics of Animals\" (A. F. Scholfield, in Loeb Classical Library, 1958).\n\nChristian writers, trained in anagogical thinking and expecting to find spiritual instruction inherent in the processes of Nature, disregarded the caveat in Pliny's Natural History, where the idea is presented as a \"vulgar opinion\": \n\nHence it is that the vulgar notion may very possibly be true, that whatever is produced in any other department of Nature, is to be found in the sea as well; while, at the same time, many other productions are there to be found which nowhere else exist. That there are to be found in the sea the forms, not only of terrestrial animals, but of inanimate objects even, is easily to be understood by all who will take the trouble to examine the grape-fish, the sword-fish, the sawfish, and the cucumber-fish, which last so strongly resembles the real cucumber both in colour and in smell.\nPliny points out that many more things are found in the sea than on the land, and also mentions the correspondences that may be discovered between many non-living objects of the land and living creatures in the sea. \n\nSaint Augustine of Hippo reasons based on analogy, that since there is a serpent in the grass, there must be an eel in the sea; because there is a Leviathan in the sea, there must be a Behemoth on the land. (\"City of God\"? xi.15?)\nThe reaction to such anagogical thinking set in with the unfolding of critical scientific thought in the 17th century. Sir Thomas Browne devoted a chapter of his \"Pseudodoxia Epidemica\" to dispelling such a belief: Chapter XXIV: \"That all Animals in the land are in their kinde in the Sea.\" During the Enlightenment the ancient conception was given an innovative and rationalized cast by Benoît de Maillet in describing the transformations and metamorphoses undergone by creatures of the sea to render them fit for life on land, a proto-evolutionist concept, though it was based on superficial morphological similarities:\nThere are in the Sea, Fish of almost all the Figures of Land-Animals, and even of Birds. She includes Plants, Flowers, and some Fruits; the Nettle, the Rose, the Pink, the Melon and the Grape, are to be found there.<br>\n<br>\nAs for the Quadrupeds, we not only find in the Sea, Species of the same Figure and Inclinations, and in the Waves living on the same Aliments by which they are nourished on Land, we have also Examples of those Species living equally in the Air and in the Water. Have not the Sea-Apes precisely the same figure with those of the Land?\n\nThough in \"Moby-Dick\" Ishmael, with a nod to Sir Thomas Browne's wording, denies the claim that land animals find their counterparts in the sea,For though some old naturalists have maintained that all creatures of the land are of their kind in the sea; and though taking a broad general view of the thing, this may very well be; yet coming to specialties, where, for example, does the ocean furnish any fish that in disposition answers to the sagacious kindness of the dog? The accursed shark alone can in any generic respect be said to bear comparative analogy to him.\nin discussing dolphins trained to aid scuba divers, a 1967 \"Popular Mechanics\" article could still casually state: \"It's hoped that the marine counterparts of some land animals can be trained to become useful members of the Man-in-the-Sea program.\"\n"}
{"id": "39127306", "url": "https://en.wikipedia.org/wiki?curid=39127306", "title": "Mechanism (philosophy)", "text": "Mechanism (philosophy)\n\nMechanism is the belief that natural wholes (principally living things) are like complicated machines or artifacts, composed of parts lacking any intrinsic relationship to each other. Thus, the source of an apparent thing's activities is not the whole itself, but its parts or an external influence on the parts.\n\nThe doctrine of mechanism in philosophy comes in two different flavors. They are both doctrines of metaphysics, but they are different in scope and ambitions: the first is a global doctrine about nature; the second is a local doctrine about humans and their minds, which is hotly contested. For clarity, we might distinguish these two doctrines as universal mechanism and anthropic mechanism.\n\nThe older doctrine, here called universal mechanism, is the ancient philosophies closely linked with materialism and reductionism, especially that of the atomists and to a large extent, stoic physics. They held that the universe is reducible to completely mechanical principles—that is, the motion and collision of matter. Later mechanists believed the achievements of the scientific revolution had shown that all phenomena could eventually be explained in terms of 'mechanical' laws, natural laws governing the motion and collision of matter that implied a thorough going determinism: if \"all\" phenomena could be explained \"entirely\" through the motion of matter under the laws of classical physics, then even more surely than the gears of a clock determine that it must strike 2:00 an hour after striking 1:00, \"all\" phenomena must be completely determined: whether past, present or future. (One of the philosophical implications of modern quantum mechanics is that this view of determinism is not defensible.)\n\nThe French mechanist and determinist Pierre Simon de Laplace formulated the sweeping implications of this thesis by saying:\n\nOne of the first and most famous expositions of universal mechanism is found in the opening passages of \"Leviathan\" by Thomas Hobbes (1651). What is less frequently appreciated is that René Descartes was a staunch mechanist, though today, in the philosophy of mind, he is remembered for introducing the mind–body problem in terms of dualism and physicalism.\n\nDescartes was a substance dualist, and argued that reality was composed of two radically different types of substance: extended matter, on the one hand, and immaterial mind, on the other. Descartes argued that one cannot explain the conscious mind in terms of the spatial dynamics of mechanistic bits of matter cannoning off each other. Nevertheless, his understanding of biology was thoroughly mechanistic in nature:\n\nHis scientific work was based on the traditional mechanistic understanding that animals and humans are completely mechanistic automata. Descartes' dualism was motivated by the seeming impossibility that mechanical dynamics could yield mental experiences.\n\nIsaac Newton ushered in a much weaker acceptation of mechanism that tolerated the antithetical, and as yet inexplicable, action at a distance of gravity. However, his work seemed to successfully predict the motion of both celestial and terrestrial bodies according to that principle, and the generation of philosophers who were inspired by Newton's example carried the mechanist banner nonetheless. Chief among them were French philosophers such as Julien Offray de La Mettrie and Denis Diderot (see also: French materialism).\n\nThe thesis in anthropic mechanism is not that everything can be completely explained in mechanical terms (although some anthropic mechanists may \"also\" believe that), but rather that everything \"about human beings\" can be completely explained in mechanical terms, as surely as can everything about clocks or the internal combustion engine.\n\nOne of the chief obstacles that all mechanistic theories have faced is providing a mechanistic explanation of the human mind; Descartes, for one, endorsed dualism in spite of endorsing a completely mechanistic conception of the material world because he argued that mechanism and the notion of a mind were logically incompatible. Hobbes, on the other hand, conceived of the mind and the will as purely mechanistic, completely explicable in terms of the effects of perception and the pursuit of desire, which in turn he held to be completely explicable in terms of the materialistic operations of the nervous system. Following Hobbes, other mechanists argued for a thoroughly mechanistic explanation of the mind, with one of the most influential and controversial expositions of the doctrine being offered by Julien Offray de La Mettrie in his \"Man a Machine\" (1748).\n\nToday, as in the past, the main points of debate between anthropic mechanists and anti-mechanists are mainly occupied with two topics: the mind — and consciousness, in particular — and free will. Anti-mechanists argue that anthropic mechanism is incompatible with our commonsense intuitions: in philosophy of mind they argue that unconscious matter cannot completely explain the phenomenon of consciousness, and in metaphysics they argue that anthropic mechanism implies determinism about human action, which (they argue) is incompatible with our understanding of ourselves as creatures with free will. Contemporary philosophers who have argued for this position include Norman Malcolm and\nDavid Chalmers.\n\nAnthropic mechanists typically respond in one of two ways. In the first, they agree with anti-mechanists that mechanism conflicts with some of our commonsense intuitions, but go on to argue that our commonsense intuitions are simply mistaken and need to be revised. Down this path lies eliminative materialism in philosophy of mind, and hard determinism on the question of free will. This option is accepted by the eliminative materialist philosopher Paul Churchland. Some have questioned how eliminative materialism is compatible with the freedom of will apparently required for anyone (including its adherents) to make truth claims. The second option, common amongst philosophers who adopt anthropic mechanism, is to argue that the arguments given for incompatibility are specious: whatever it is we mean by \"consciousness\" and \"free will,\" they urge, it is fully compatible with a mechanistic understanding of the human mind and will. As a result, they tend to argue for one or another non-eliminativist physicalist theories of mind, and for compatibilism on the question of free will. Contemporary philosophers who have argued for this sort of account include J. J. C. Smart and Daniel Dennett.\n\nSome scholars have debated over what, if anything, Gödel's incompleteness theorems imply about anthropic mechanism. Much of the debate centers on whether the human mind is equivalent to a Turing machine, or by the Church-Turing thesis, any finite machine at all. If it is, and if the machine is consistent, then Gödel's incompleteness theorems would apply to it.\n\nGödelian arguments claim that a system of human mathematicians (or some idealization of human mathematicians) is both consistent and powerful enough to recognize its own consistency. Since this is impossible for a Turing machine, the Gödelian concludes that human reasoning must be non-mechanical.\n\nHowever, the modern consensus in the scientific and mathematical community is that actual human reasoning is inconsistent; that any consistent \"idealized version\" \"H\" of human reasoning would logically be forced to adopt a healthy but counter-intuitive open-minded skepticism about the consistency of \"H\" (otherwise \"H\" is provably inconsistent); and that Gödel's theorems do not lead to any valid argument against mechanism. This consensus that Gödelian anti-mechanist arguments are doomed to failure is laid out strongly in \"Artificial Intelligence\": \"\"any\" attempt to utilize (Gödel's incompleteness results) to attack the computationalist thesis is bound to be illegitimate, since these results are quite consistent with the computationalist thesis.\"\n\nOne of the earliest attempts to use incompleteness to reason about human intelligence was by Gödel himself in his 1951 Gibbs Lecture entitled \"Some basic theorems on the foundations of mathematics and their philosophical implications\". In this lecture, Gödel uses the incompleteness theorem to arrive at the following disjunction: (a) the human mind is not a consistent finite machine, or (b) there exist Diophantine equations for which it cannot decide whether solutions exist. Gödel finds (b) implausible, and thus seems to have believed the human mind was not equivalent to a finite machine, i.e., its power exceeded that of any finite machine. He recognized that this was only a conjecture, since one could never disprove (b). Yet he considered the disjunctive conclusion to be a \"certain fact\".\n\nIn subsequent years, more direct anti-mechanist lines of reasoning were apparently floating around the intellectual atmosphere. In 1960, Hilary Putnam published a paper entitled \"Minds and Machines,\" in which he points out the flaws of a typical anti-mechanist argument. Informally, this is the argument that the (alleged) difference between \"what can be mechanically proven\" and \"what can be seen to be true by humans\" shows that human intelligence is not mechanical in nature. Or, as Putnam puts it:\n\nLet T be a Turing machine which \"represents\" me in the sense that T can prove just the mathematical statements I prove. Then using Gödel's technique I can discover a proposition that T cannot prove, and moreover I can prove this proposition. This refutes the assumption that T \"represents\" me, hence I am not a Turing machine.\n\nHilary Putnam objects that this argument ignores the issue of consistency. Gödel's technique can only be applied to consistent systems. It is conceivable, argues Putnam, that the human mind is inconsistent. If one is to use Gödel's technique to prove the proposition that T cannot prove, one must first prove (the mathematical statement representing) the consistency of T, a daunting and perhaps impossible task. Later Putnam suggested that while Gödel's theorems cannot be applied to humans, since they make mistakes and are therefore inconsistent, it may be applied to the human faculty of science or mathematics in general. If we are to believe that it is consistent, then either we cannot prove its consistency, or it cannot be represented by a Turing machine.\n\nJ. R. Lucas in \"Minds, Machines and Gödel\" (1961), and later in his book \"The Freedom of the Will\" (1970), lays out an anti-mechanist argument closely following the one described by Putnam, including reasons for why the human mind can be considered consistent. Lucas admits that, by Gödel's second theorem, a human mind cannot formally prove its own consistency, and even says (perhaps facetiously) that women and politicians are inconsistent. Nevertheless, he sets out arguments for why a male non-politician can be considered consistent. These arguments are philosophical in nature and are the subject of much debate; Lucas provides references to responses on his own website.\n\nAnother work was done by Judson Webb in his 1968 paper \"Metamathematics and the Philosophy of Mind\". Webb claims that previous attempts have glossed over whether one truly can see that the Gödelian statement \"p\" pertaining to oneself, is true. Using a different formulation of Gödel's theorems, namely, that of Raymond Smullyan and Emil Post, Webb shows one can derive convincing arguments for oneself of both the truth and falsity of \"p\". He furthermore argues that all arguments about the philosophical implications of Gödel's theorems are really arguments about whether the Church-Turing thesis is true.\n\nLater, Roger Penrose entered the fray, providing somewhat novel anti-mechanist arguments in his books, \"The Emperor's New Mind\" (1989) [ENM] and \"Shadows of the Mind\" (1994) [SM]. These books have proved highly controversial. Martin Davis responded to ENM in his paper \"Is Mathematical Insight Algorithmic?\" (ps), where he argues that Penrose ignores the issue of consistency. Solomon Feferman gives a critical examination of SM in his paper \"Penrose's Gödelian argument\" (pdf). The response of the scientific community to Penrose's arguments has been negative, with one group of scholars calling Penrose's repeated attempts to form a persuasive Gödelian argument \"a kind of intellectual shell game, in which a precisely defined notion to which a mathematical result applies... is switched for a vaguer notion\".\n\nA Gödel-based anti-mechanism argument can be found in Douglas Hofstadter's book \"\", though Hofstadter is widely viewed as a known skeptic of such arguments:\nLooked at this way, Gödel's proof suggests – though by no means does it prove! – that there could be some high-level way of viewing the mind/brain, involving concepts which do not appear on lower levels, and that this level might have explanatory power that does not exist – not even in principle – on lower levels. It would mean that some facts could be explained on the high level quite easily, but not on lower levels at all. No matter how long and cumbersome a low-level statement were made, it would not explain the phenomena in question.\nIt is analogous to the fact that, if you make derivation after derivation in Peano arithmetic, no matter how long and cumbersome you make them, you will never come up with one for G – despite the fact that on a higher level, you can see that the Gödel sentence is true.\n\nWhat might such high-level concepts be? It has been proposed for eons, by various holistically or \"soulistically\" inclined scientists and humanists that consciousness is a phenomenon that escapes explanation in terms of brain components; so here is a candidate at least. There is also the ever-puzzling notion of free will. So perhaps these qualities could be \"emergent\" in the sense of requiring explanations which cannot be furnished by the physiology alone\n\n\n"}
{"id": "30355727", "url": "https://en.wikipedia.org/wiki?curid=30355727", "title": "NASA eClips", "text": "NASA eClips\n\nNASA eClips is a web-based video and educator resource repository which focuses on grades K-5, 6-8, 9-12 and the general public.\n\nNASA eClips is public outreach effort funded by the NASA Headquarters Strategic Communication Office. The NASA eClips website offers educational video segments and instructional materials, such as lesson plans, designed for use in the classroom.\n\nNASA eClips comprises four programs, which are produced for targeted audiences.\n\nIn total, there are more than two hundred and thirty videos exploring current applications of science, technology, engineering and mathematics, or STEM, topics. The videos are searchable by title, grade level, keyword, and description. RSS feeds are available for each of the programs.\n\nThe material offered by NASA eClips is selected based on national curriculum standards identified by the National Council of Teachers of Mathematics, the National Science Teachers Association, and the International Society for Technology in Education. NASA eClips supports the 5E constructivist learning cycle.\n\nNASA eClips has won numerous awards including an iParenting Media Award, and a regional Emmy award.\n\n\n"}
{"id": "19494116", "url": "https://en.wikipedia.org/wiki?curid=19494116", "title": "Neuralgia-inducing cavitational osteonecrosis", "text": "Neuralgia-inducing cavitational osteonecrosis\n\nNeuralgia-inducing cavitational osteonecrosis (NICO) is a controversial diagnosis whereby a putative jawbone cavitation causes chronic facial neuralgia; this is different from osteonecrosis of the jaw.. In NICO the pain is said to result from the degenerating nerve (\"neuralagia\"). The condition is probably rare, if it does exist.\n\nAlso called Ratner's bone cavity, a neuralgia-inducing cavitational osteonecrosis was first described in dental literature by G V Black in 1920. Several decades later, oral pathologist Jerry E Bouquot took especial interest in NICO. \n\nThe diagnostic criteria for NICO are imprecise, and the research offered to support it is flawed. The diagnosis is popular among holistic dentists who attempt to treat NICO by surgically removing the dead bone they say is causing the pain.\n\nIt has been rejected as quackery by some dentists and maxillofacial surgeons. In its position statement, dated 1996, the American Association of Endodontists asserted that although NICO occur and are treatable in toothless areas, NICO occurrence and treatment at endodontically treated teeth is generally implausible, that the diagnosis ought to be a last resort, and that routine extraction of endodontically treated teeth is misguided.\n\n\n"}
{"id": "3156313", "url": "https://en.wikipedia.org/wiki?curid=3156313", "title": "Open research", "text": "Open research\n\nOpen research is research conducted in the spirit of free and open-source software. Much like open-source schemes that are built around a source code that is made public, the central theme of open research is to make clear accounts of the methodology freely available via the internet, along with any data or results extracted or derived from them. This permits a massively distributed collaboration, and one in which anyone may participate at any level of the project.\n\nEspecially if the research is scientific in nature, it is frequently referred to as open science. \"Open research\" can also include social sciences, the humanities, mathematics, engineering and medicine.\n\nImportant distinctions exist between different types of open projects.\n\nProjects that provide open data but don't offer open collaboration are referred to as \"open access\" rather than open research. Providing open data is a necessary but not sufficient condition for open research, because although the data may be used by anyone, there is no requirement for subsequent research to take place openly. For example, though there have been many calls for more open collaborative research in drug discovery and the open deposition of large amounts of data, there are very few active, openly collaborative projects in this area.\n\nCrowdsourcing projects that recruit large numbers of participants to carry out small tasks which are then assembled into a larger project outcome have delivered significant research outcomes, but these projects are distinct from those in which participants are able to influence the overall direction of the research, or in which participants are expected to have creative input into the science behind the project.\n\nMost open research is conducted within existing research groups. Primary research data are posted which can be added to, or interpreted by, anyone who has the necessary expertise and who can therefore join the collaborative effort. Thus the \"end product\" of the project (which may still be subject to future expansion or modification) arises from many contributions across multiple research groups, rather than the effort of one group or individual. Open research is therefore distinct from open access in that the output of open research is prone to change with time.\n\nUnlike open access, true open research must demonstrate live, online collaboration. Project websites that demonstrate this capability have started to become available.\n\nIssues with copyright are dealt with by using either standard copyright (where applicable), releasing the content into the Public domain or by releasing the content under licenses such as one of the Creative Commons licenses or one of the GNU General Public Licenses.\n\nIn 2005, several examples arose in the area of the search for new/improved medical treatments of Neglected Diseases.\n\nScience and engineering research to support the creation of open-source appropriate technology for sustainable development has long used open research principles. Open source research for sustainable development is now becoming formalized with open access for literature reviews, research methods, data, results and summaries for laypeople.\n\nWiki-based examples include: Appropedia, , Citizendium, Scholarpedia.\n\nWhile first attempts towards opening research were primarily aimed at opening areas such as scientific data, methodologies, software and publications, now increasingly other artifacts of the scientific workflow are also tackled, such as scientific meta-data and funding ideas.\n\nIn 2013, open research became more mainstream with web based platforms such as figshare continuing to grow in terms of users and publicly available outputs.\n\nThe Transparency and Openness Promotion (TOP) Committee met in 2014 to address one key element of the incentive systems: journals' procedures and policies for publication. The committee consisted of disciplinary leaders, journal editors, funding agency representatives, and disciplinary experts largely from the social and behavioral sciences. By developing shared standards for open practices across journals, the committee said it hopes to translate scientific norms and values into concrete actions and change the current incentive structures to drive researchers' behavior toward more openness. The committee said it sought to produce guidelines that (a) focus on the commonalities across disciplines, and that (b) define what aspects of the research process should be made available to the community to evaluate, critique, reuse, and extend. The committee added that the guidelines aim to help improve journal policies in order to help transparency, openness, and reproducibility \"become more evident in daily practice and ultimately improve the public trust in science, and science itself.\"\n\n"}
{"id": "1217056", "url": "https://en.wikipedia.org/wiki?curid=1217056", "title": "Organicism", "text": "Organicism\n\nOrganicism is the philosophical perspective which views the universe and its parts as organic wholes and – either by analogy or literally – as living organisms. It can be synonymous with holism. Organicism is an important tradition within the history of natural philosophy where it has remained as a vital current alongside reductionism and mechanism, the approaches that have dominated science since the seventeenth century. Plato is among the earliest philosophers to have regarded the universe as an intelligent living being (see \"Timaeus\"). Organicism flourished for a period during the era of German romanticism during which time the new science of biology was first defined by Jean-Baptiste Lamarck. Within modern-day biological sciences organicism is the approach that stresses the organization (particularly the self-organizing properties), rather than the composition, of organisms. John Scott Haldane was the first biologist to use the term to describe his philosophical views in 1917, after which it was followed by certain other biologists in the 20th century.\n\nOrganicism as a doctrine rejects mechanism and reductionism (doctrines that claim that the smallest parts by themselves explain the behavior of larger organized systems of which they are a part). However, organicism also rejects vitalism, the doctrine that there is a vital force different from physical forces that accounts for living things. As Capra puts it, both schools, organicism and vitalism, were born from the quest for getting rid of the Cartesian picture of reality, a view that has been claimed to be the most destructive paradigm nowadays, from science to politics.\nA number of biologists in the early to mid-twentieth century embraced organicism. They wished to reject earlier vitalisms but to stress that whole organism biology was not fully explainable by atomic mechanism. The larger organization of an organic system has features that must be taken into account to explain its behavior.\n\nGilbert and Sarkar distinguish organicism from holism to avoid what they see as the vitalistic or spiritualistic connotations of holism. Dusek notes that holism contains a continuum of degrees of the top-down control of organization, ranging from monism (the doctrine that the only complete object is the whole universe, or that there is only one entity, the universe) to organicism, which allows relatively more independence of the parts from the whole, despite the whole being more than the sum of the parts, and/or the whole exerting some control on the behavior of the parts.\n\nStill more independence is present in relational holism. This doctrine does not assert top-down control of the whole over its parts, but does claim that the relations of the parts are essential to explanation of behavior of the system. Aristotle and early modern philosophers and scientists tended to describe reality as made of substances and their qualities, and to neglect relations. Gottfried Wilhelm Leibniz showed the bizarre conclusions to which a doctrine of the non-existence of relations led. Twentieth century philosophy has been characterized by the introduction of and emphasis on the importance of relations, whether in symbolic logic, in phenomenology, or in metaphysics.\n\nWilliam Wimsatt has suggested that the number of terms in the relations considered distinguishes reductionism from holism. Reductionistic explanations claim that two or at most three term relations are sufficient to account for the system's behavior. At the other extreme the system could be considered as a single ten to the twenty-sixth term relation, for instance.\n\nOrganicism has some intellectually and politically controversial or suspect associations. \"Holism,\" the doctrine that the whole is more than the sum of its parts, often used synonymously with organicism, or as a broader category under which organicism falls, has been co-opted in recent decades by \"holistic medicine\" and by New Age Thought. German Nazism appealed to organicist and holistic doctrines, discrediting for many in retrospect, the original organicist doctrines. (See Anne Harrington). Soviet Dialectical Materialism also made appeals to an holistic and organicist approach stemming from Hegel via Karl Marx's co-worker Friedrich Engels, again giving a controversial political association to organicism.\n\nOrganicism' has also been used to characterize notions put forth by various late 19th-century social scientists who considered human society to be analogous to an organism, and individual humans to be analogous to the cells of an organism. This sort of organicist sociology was articulated by Alfred Espinas, Paul von Lilienfeld, Jacques Novicow, Albert Schäffle, Herbert Spencer, and René Worms, among others.\n\nThomas Hobbes arguably put forward a form of organicism. In the \"Leviathan\", he argued that the state is like a secular God whose constituents (individual people) make up a larger organism.\n\nIn breathing entities, cells – i.e., the smallest unit of life – were first observed in the 17th century, when the multifaceted equipment microscope was conceived. Before that period, the individual organisms were studied as a whole in a field known as organismic biology; that area of research remains an important component of the biological sciences. Further, as Capra puts it, during the early 1900s, the quantum researchers struggled with the same paradigm shift from \"the parts to the whole\" that culminated into the scholars of organismic biology.\n\nIn biology organicism considers that the observable structures of life, its overall form and the properties and characteristics of its component parts are a result of the reciprocal play of all the components on each other.\nExamples of 20th century biologists who were organicists are Ross Harrison, Paul Weiss, and Joseph Needham. Donna Haraway discusses them in her first book \"Crystals, Fabrics, and Fields\". John Scott Haldane (father of J. B. S. Haldane), William Emerson Ritter, Edward Stuart Russell, Joseph Henry Woodger, Ludwig von Bertalanffy, and Ralph Stayner Lillie are other early twentieth century organicists. Robert Rosen, founder of \"Relational Biology\" provided a comprehensive mathematical and category-theoretic treatment of irreducible causal relations he believed to be responsible for life.\n\nIn the early 1930s Joseph Henry Woodger and Joseph Needham, together with Conrad Hal Waddington, John Desmond Bernal, Dorothy Needham, and Dorothy Wrinch, formed the Theoretical Biology Club, to promote the organicist approach to biology. The club was in opposition to mechanism, reductionism and the gene-centric view of evolution. Most of the members were influenced by the philosophy of Alfred North Whitehead. The club disbanded as the Rockefeller Foundation refused to fund their investigations.\n\n\nNotes\nCitations\n\n\n"}
{"id": "246066", "url": "https://en.wikipedia.org/wiki?curid=246066", "title": "Prediction", "text": "Prediction\n\nA prediction (Latin \"præ-\", \"before,\" and \"dicere\", \"to say\"), or forecast, is a statement about a future event. A prediction is often, but not always, based upon experience or knowledge. There is no universal agreement about the exact difference between the two terms; different authors and disciplines ascribe different connotations. (Contrast with estimation.)\n\nAlthough future events are necessarily uncertain, so guaranteed accurate information about the future is in many cases impossible, prediction can be useful to assist in making plans about possible developments; Howard H. Stevenson writes that prediction in business \"... is at least two things: Important and hard.\"\n\nIn a non-statistical sense, the term \"prediction\" is often used to refer to an informed guess or opinion.\n\nA prediction of this kind might be informed by a predicting person's abductive reasoning, inductive reasoning, deductive reasoning, and experience; and may be of useful — if the predicting person is a knowledgeable person in the field.\n\nThe Delphi method is a technique for eliciting such expert-judgement-based predictions in a controlled way. This type of prediction might be perceived as consistent with statistical techniques in the sense that, at minimum, the \"data\" being used is the predicting expert's cognitive experiences forming an intuitive \"probability curve.\"\n\nIn statistics, prediction is a part of statistical inference. One particular approach to such inference is known as predictive inference, but the prediction can be undertaken within any of the several approaches to statistical inference. Indeed, one possible description of statistics is that it provides a means of transferring knowledge about a sample of a population to the whole population, and to other related populations, which is not necessarily the same as prediction over time. When information is transferred across time, often to specific points in time, the process is known as forecasting. Forecasting usually requires time series methods, while prediction is often performed on cross-sectional data.\n\nStatistical techniques used for prediction include regression analysis and its various sub-categories such as linear regression, generalized linear models (logistic regression, Poisson regression, Probit regression), etc. In case of forecasting, autoregressive moving average models and vector autoregression models can be utilized. When these and/or related, generalized set of regression or machine learning methods are deployed in commercial usage, the field is known as predictive analytics.\n\nIn many applications, such as time series analysis, it is possible to estimate the models that generate the observations. If models can be expressed as transfer functions or in terms of state-space parameters then smoothed, filtered and predicted data estimates can be calculated. If the underlying generating models are linear then a minimum-variance Kalman filter and a minimum-variance smoother may be used to recover data of interest from noisy measurements. These techniques rely on one-step-ahead predictors (which minimise the variance of the prediction error). When the generating models are nonlinear then stepwise linearizations may be applied within Extended Kalman Filter and smoother recursions. However, in nonlinear cases, optimum minimum-variance performance guarantees no longer apply.\n\nTo use regression analysis for prediction, data are collected on the variable that is to be predicted, called the dependent variable or response variable, and on one or more variables whose values are hypothesized to influence it, called independent variables or explanatory variables. A functional form, often linear, is hypothesized for the postulated causal relationship, and the parameters of the function are estimated from the data—that is, are chosen so as to optimize is some way the fit of the function, thus parameterized, to the data. That is the estimation step. For the prediction step, explanatory variable values that are deemed relevant to future (or current but not yet observed) values of the dependent variable are input to the parameterized function to generate predictions for the dependent variable.\n\nIn science, a prediction is a rigorous, often quantitative, statement, forecasting what would happen under specific conditions; for example, if an apple fell from a tree it would be attracted towards the center of the earth by gravity with a specified and constant acceleration. The scientific method is built on testing statements that are logical consequences of scientific theories. This is done through repeatable experiments or observational studies.\n\nA scientific theory which is contradicted by observations and evidence will be rejected. New theories that generate many new predictions can more easily be supported or falsified (see predictive power). Notions that make no \"testable\" predictions are usually considered not to be part of science (protoscience or nescience) until testable predictions can be made.\n\nMathematical equations and models, and computer models, are frequently used to describe the past and future behaviour of a process within the boundaries of that model. In some cases the probability of an outcome, rather than a specific outcome, can be predicted, for example in much of quantum physics.\n\nIn microprocessors, branch prediction permits avoidance of pipeline emptying at branch instructions. In engineering, possible failure modes are predicted and avoided by correcting the mechanism causing the failure.\n\nAccurate prediction and forecasting are very difficult in some areas, such as natural disasters, pandemics, demography, population dynamics and meteorology. For example, it is possible to predict the occurrence of solar cycles, but their exact timing and magnitude is much more difficult (see picture to right).\n\nEstablished science makes useful predictions which are often extremely reliable and accurate; for example, eclipses are routinely predicted.\n\nNew theories make predictions which allow them to be disproved by reality. For example, predicting the structure of crystals at the atomic level is a current research challenge. In the early 20th century the scientific consensus was that there existed an absolute frame of reference, which was given the name \"luminiferous ether\". The existence of this absolute frame was deemed necessary for consistency with the established idea that the speed of light is constant. The famous Michelson-Morley experiment demonstrated that predictions deduced from this concept were not borne out in reality, thus disproving the theory of an absolute frame of reference. The special theory of relativity was proposed by Einstein as an explanation for the seeming inconsistency between the constancy of the speed of light and the non-existence of a special, preferred or absolute frame of reference.\n\nAlbert Einstein's theory of general relativity could not easily be tested as it did not produce any effects observable on a terrestrial scale. However, the theory predicted that large masses such as stars would bend light, in contradiction to accepted theory; this was observed in a 1919 eclipse.\n\nMathematical models of stock market behaviour (and economic behaviour in general) are also unreliable in predicting future behaviour. Among other reasons, this is because economic events may span several years, and the world is changing over a similar time frame, thus invalidating the relevance of past observations to the present. Thus there are an extremely small number (of the order of 1) of relevant past data points from which to project the future. In addition, it is generally believed that stock market prices already take into account all the information available to predict the future, and subsequent movements must therefore be the result of unforeseen events. Consequently, it is extremely difficult for a stock investor to anticipate or predict a stock market boom, or a stock market crash. In contrast to predicting the actual stock return, forecasting of broad economic trends tends to have better accuracy. Such analysis is provided by both non-profit groups as well as by for-profit private institutions, including brokerage housesand consulting companies.\n\nSome correlation has been seen between actual stock market movements and prediction data from large groups in surveys and prediction games.\n\nAn actuary uses actuarial science to assess and predict future business risk, such that the risk(s) can be mitigated. For example, in insurance an actuary would use a life table (which incorporates the historical experience of mortality rates and sometimes an estimate of future trends) to project life expectancy.\n\nPredicting the outcome of sporting events is a business which has grown in popularity in recent years. Handicappers predict the outcome of games using a variety of mathematical formulas, simulation models or qualitative analysis. Early, well known sports bettors, such as Jimmy the Greek, were believed to have access to information that gave them an edge. Information ranged from personal issues, such as gambling or drinking to undisclosed injuries; anything that may affect the performance of a player on the field.\n\nRecent times have changed the way sports are predicted. Predictions now typically consist of two distinct approaches: Situational plays and statistical based models. Situational plays are much more difficult to measure because they usually involve the motivation of a team. Dan Gordon, noted handicapper, wrote “Without an emotional edge in a game in addition to value in a line, I won’t put my money on it”. These types of plays consist of: Betting on the home underdog, betting against Monday Night winners if they are a favorite next week, betting the underdog in “look ahead” games etc. As situational plays become more widely known they become less useful because they will impact the way the line is set.\n\nThe widespread use of technology has brought with it more modern sports betting systems. These systems are typically algorithms and simulation models based on regression analysis. Jeff Sagarin, a sports statistician, has brought attention to sports by having the results of his models published in USA Today. He is currently paid as a consultant by the Dallas Mavericks for his advice on lineups and the use of his Winval system, which evaluates free agents. Brian Burke, a former Navy fighter pilot turned sports statistician, has published his results of using regression analysis to predict the outcome of NFL games. Ken Pomeroy is widely accepted as a leading authority on college basketball statistics. His website includes his College Basketball Ratings, a tempo based statistics system. Some statisticians have become very famous for having successful prediction systems. Dare wrote “the effective odds for sports betting and horse racing are a direct result of human decisions and can therefore potentially exhibit consistent error”. Unlike other games offered in a casino, prediction in sporting events can be both logical and consistent.\n\nIn politics it is common to attempt to predict the outcome of elections via political forecasting techniques (or assess the popularity of politicians) through the use of opinion polls. Prediction games have been used by many corporations and governments to learn about the most likely outcome of future events.\n\nPredictions have often been made, from antiquity until the present, by using paranormal or supernatural means such as prophecy or by observing omens. Methods including water divining, astrology, numerology, fortune telling, interpretation of dreams, and many other forms of divination, have been used for millennia to attempt to predict the future. These means of prediction have not been proven by scientific experiments.\n\nIn literature, vision and prophecy are literary devices used to present a possible timeline of future events. They can be distinguished by vision referring to what an individual sees happen. The New Testament book of Revelation (Bible) thus uses vision as a literary device in this regard. It is also prophecy or prophetic literature when it is related by an individual in a sermon or other public forum.\n\nDivination is the attempt to gain insight into a question or situation by way of an occultic standardized process or ritual. It is an integral part of witchcraft and has been used in various forms for thousands of years. Diviners ascertain their interpretations of how a querent should proceed by reading signs, events, or omens, or through alleged contact with a supernatural agency, most often describe as an angel or a god though viewed by Christians and Jews as a fallen angel or demon.\n\nFiction (especially fantasy, forecasting and science fiction) often features instances of prediction achieved by unconventional means.\n\n"}
{"id": "159735", "url": "https://en.wikipedia.org/wiki?curid=159735", "title": "Quasi-empirical method", "text": "Quasi-empirical method\n\nQuasi-empirical methods are methods applied in science and mathematics to achieve epistemology similar to that of empiricism (thus \"quasi- + empirical\") when experience cannot falsify the ideas involved. Empirical research relies on empirical evidence, and its empirical methods involve experimentation and disclosure of apparatus for reproducibility, by which scientific findings are validated by other scientists. Empirical methods are studied extensively in the philosophy of science, but they cannot be used directly in fields whose hypotheses cannot be falsified by real experiment (for example, mathematics, philosophy, theology, and ideology). Because of such empirical limits in science, the scientific method must rely not only on empirical methods but sometimes also on quasi-empirical ones. The prefix \"quasi-\" came to denote methods that are \"almost\" or \"socially approximate\" an ideal of truly empirical methods.\n\nIt is unnecessary to find all counterexamples to a theory; all that is required to disprove a theory logically is one counterexample. The converse does not prove a theory; Bayesian inference simply makes a theory more likely, by weight of evidence.\n\nOne can argue that no science is capable of finding all counter-examples to a theory, therefore, no science is strictly empirical, it's all quasi-empirical. But usually, the term \"quasi-empirical\" refers to the means of choosing problems to focus on (or ignore), selecting prior work on which to build an argument or proof, notations for informal claims, peer review and acceptance, and incentives to discover, ignore, or correct errors. These are common to both science and mathematics, and do not include experimental method.\n\nAlbert Einstein's discovery of the general relativity theory relied upon thought experiments and mathematics. Empirical methods only became relevant when confirmation was sought. Furthermore, some empirical confirmation was found only some time after the general acceptance of the theory.\n\nThought experiments are almost standard procedure in philosophy, where a conjecture is tested out in the imagination for possible effects on experience; when these are thought to be implausible, unlikely to occur, or not actually occurring, then the conjecture may be either rejected or amended. Logical positivism was a perhaps extreme version of this practice, though this claim is open to debate.\n\nPost-20th-century philosophy of mathematics is mostly concerned with quasi-empirical mathematical methods, especially as reflected in the actual mathematical practice of working mathematicians. \n\n"}
{"id": "30635101", "url": "https://en.wikipedia.org/wiki?curid=30635101", "title": "Regius Professor of Natural History (Aberdeen)", "text": "Regius Professor of Natural History (Aberdeen)\n\nThe Regius Professor of Natural History is a Regius Professorship at the University of Aberdeen in Scotland. It was originally called the Regius Professor of Civil and Natural History at Marischal College until in 1860 Marischal College and King's Colleges merged to form the University of Aberdeen, and the title changed to Natural History.\n"}
{"id": "495795", "url": "https://en.wikipedia.org/wiki?curid=495795", "title": "Scientific Integrity in Policymaking", "text": "Scientific Integrity in Policymaking\n\n\"Scientific Integrity in Policymaking: An Investigation into the Bush Administration's Misuse of Science\" is the title of a report published by the Union of Concerned Scientists in February, 2004. The report was the culmination of an investigation of the Bush administration's objectivity in science, and ultimately a criticism thereof. (After it was published, the report's existence was fairly well-publicized by the United States' mass media.)\n\nA central thesis of the report, according to the Executive Summary (on page 2 of the text), was that the Bush administration had behaved in ways considered to be consistent with the following three situations.\n\n\nIn \"Part III\", the text of the report posits that the aforementioned activities are unprecedented in the history of the United States. The report lists the following persons and organization who had supposedly acted or made statements to support this claim.\n\n\"This list is sorted first by category, then by the order in which the persons or organizations are mentioned in the report.\"\n\n\nPage 29 of the report states: \"This behavior by the administration violates the central premise of the scientific method, and is therefore of particularly grave concern to the scientific community.\" It then goes on, in a short section titled \"Conclusions and Recommendations: What's at Stake\" at the end of the report, to provide recommendations for \"restoring scientific integrity to federal policymaking\" (page 30). These recommendations (on pages 30–31) include a suggestion for the President of the United States to issue executive orders, and other actions, that would prevent further \"abuse\"; for the United States Congress to hold appropriate hearings, consider the consequences of statutory law under its influence, increase the amount of publicly available scientific information, and establish an organization to guide Congress in its deliberations in technical matters; for scientists to raise awareness of the aforementioned issues and provide public policy recommendations; for the public to exercise its political influence in a constructive manner.\n\nOn April 2, 2004, the White House Office of Science and Technology Policy issued a statement by Dr. John Marburger, the director of OSTP, that claims the descriptions of the incidents in the UCS report are all \"false,\" \"wrong,\" or \"a distortion.\" He said he was disappointed with the report and dismissed it as \"biased.\".\n\nThe following is a duplication of the report's table of contents.\n\n\nAt the time of issue of this report, the UCS released a statement supporting the criticisms detailed in the above report. This statement was originally signed by the 62 prominent scientists listed below. Since that time it has gathered support from more than 12,000 scientists.\n\nSignatories of the original statement include:\n\n"}
{"id": "2626554", "url": "https://en.wikipedia.org/wiki?curid=2626554", "title": "Social studies of finance", "text": "Social studies of finance\n\nSocial studies of finance is an interdisciplinary research area that combines perspectives from anthropology, economic sociology, science and technology studies, international political economy, behavioral finance, cultural studies and/or economics in the study of financial markets. Work in social studies of finance emphasises the social and cultural dimensions of financial activities, but focuses also on technical and economic dimensions such as pricing and trading.\n\nFinancial markets have been an object for sociological inquiry since, at least, Max Weber’s \"Die Börse\". The raise of quantitative financial theory in financial economics from the 1950s onwards has led to an academic specialization on financial markets rather focused on economic modeling, and poorly attentive to sociological aspects. In the 1980s, a number of economic sociologists developed empirical investigation on the social structure and cultural characteristics of financial markets, especially in the US. Such pioneering researcher included contributions from Wayne E. Baker, Mitchel Y. Abolafia and Charles W. Smith, and was based on methods such as ethnographic observation or social network analysis. In the 1990s, a number of researchers from the field of science and technology studies such as Karin Knorr-Cetina and Donald A. MacKenzie started also developing empirical research in this area, with close attention to the role of expert knowledge and technology in financial activities.\n\nResearch topics in social studies of finance include the cultural world and work habits of traders and other professionals in financial markets, the globalization and regulation of financial services, the processes of innovation in the financial industry and the problems of risk and uncertainty that characterize such processes.\n\n\n"}
{"id": "50535883", "url": "https://en.wikipedia.org/wiki?curid=50535883", "title": "THE GrEEK CAMPUS", "text": "THE GrEEK CAMPUS\n\nThe GrEEK Campus is Cairo's first technology and innovation park, offering state-of-the-art office spaces in Downtown Cairo, Egypt. In 1964, The GrEEK Campus was formed by former president Dr. Thomas A. Bartlett of the American University in Cairo.\n\nThe GrEEK CAMPUS was a part of American University for 50 years. In 2013, former president of AUC Lisa Anderson signed an agreement with Tahrir Alley Technology Park, a Cairo-based company, who leased the property to run a Technology Park. The concept and vision were crafted by Ahmed El Alfi and the technology park was officially launched in 2014. \n\nThe GrEEK CAMPUS offers technologically advanced office spaces and promotes innovation and entrepreneurship.\n\n"}
{"id": "47256663", "url": "https://en.wikipedia.org/wiki?curid=47256663", "title": "The Hunting Hypothesis", "text": "The Hunting Hypothesis\n\nThe Hunting Hypothesis: A Personal Conclusion Concerning the Evolutionary Nature of Man (commonly known as \"The Hunting Hypothesis\") is a 1976 work of paleoanthropology by Robert Ardrey. It is the final book in his widely read Nature of Man Series, which also includes \"African Genesis\" (1961) and \"The Territorial Imperative\" (1966).\n\nThe work deals with the ramifications of evolutionarily inherited traits in man, particularly those that developed through hunting. It was also one of the earliest books to warn about the possible dangers of climate change.\n\nArdrey's main focus in \"The Hunting Hypothesis\" was to examine the ways in which human evolution developed with and because of hunting behavior, and the effects on modern man of inherited traits related to this evolution.\n\nAt the time of the publication of \"The Hunting Hypothesis\" there was still significant controversy surrounding the thesis that early man hunted for food. Ardrey's work was often attacked for its focus on human aggression. In particular, Ashley Montagu, representing a camp known as the \"Blank State\" theorists, who believed that man's behavior was entirely socially determined, marshaled fourteen scientists to refute Ardrey and his predecessors (chiefly Konrad Lorenz) in two volumes.\n\nThough now generally accepted, the hypothesis that hunting behavior influenced the evolution of early man continued to inspire controversy. As late as 1997 PBS, in its series \"In Search of Human Origins\" cast aspersion on the notion that hunting was common in early man, asserting instead that early man was primarily a \"highly successful scavenger.\"\n\nToday, the theories propounded in \"The Hunting Hypothesis\" have come to be commonly accepted in the scientific community. In 2011 PBS reversed its earlier position. The special \"Becoming Human\" asserted:\nHomo erectus probably hunted with close-quarters weapons, with spears that were thrown at animals from a short distance, clubs, thrown rocks, weapons like that. They weren’t using long distance projectile weapons that we know of. The Homo erectus hunt was simple but effective. It fed not just their larger brains, but the growing complexity of that early human society.\n\n\"Scientific American\" wrote about the controversy:\nFor decades researchers have been locked in debate over how and when hunting began and how big a role it played in human evolution. Recent analyses of human anatomy, stone tools and animal bones are helping to fill in the details of this game-changing shift in subsistence strategy. This evidence indicates that hunting evolved far earlier than some scholars had envisioned – and profoundly impacted subsequent human evolution.\n\nReviews of \"The Hunting Hypothesis\" were mixed; popular reviews tended to be generally positive, and scientific reviews tended to be polarized.\n\nThe famed biologist and naturalist E. O. Wilson, who notably advocated for Ardrey against his critics, effusively praised the book.\nIn his excellent new book Robert Ardrey continues as the lyric poet of human evolution, capturing the Homeric quality of the subject that so many scientists by and large feel but are unable to put into words. His opinions, like those in his earlier works, are controversial but more open, squarely stated, and closer to the truth than the protests of his most scandalized critics.\n\nThe anthropologist Colin Turnbull reviewed the book for \"The New York Times\": \"This is a sober, well-reasoned plea for a sane appraisal of the human situation, of a re-evaluation of man's nature, of where he has come from and, much more important, where he is going.\" He went on to call it a profoundly hopeful book, dispelling notions that Ardrey's work was pessimistic. \"If there is any cause for pessimism it is not in the facts nor in Ardrey's account, but in man's demonstrated ability to ignore the lessons of history, and in his preference for short-term responses rather than long-term solutions.\"\n\n\"The Hunting Hypothesis\", which was the final book in Ardrey's \"Nature of Man\" series, was widely acknowledged as a fitting capstone to his work. Max Lerner, for instance, wrote that it was \"Easily the best of Robert Ardrey's books. It is brilliant in its summary of recent findings, it is wonderfully persuasive in its argument about our essential human nature, and it makes a satisfying unity out of Ardrey's thinking in all his books.\" Roger D. Masters wrote that \"The Hunting Hypothesis\" is probably Robert Ardrey's best book. ... His overall contribution to public understanding of an enormous range of scientific research is of the greatest importance.\" Antony Jay summarized the consensus:\nIf I believe that Robert Ardrey's books are the most important to be written since the war and arguably in the 20th century, it is because he has satisfied to a quite unbelievable degree the demands of the ignorant layman and the requirements of the responsible scientist. \"The Hunting Hypothesis\" is not so much a sequel to the three previous books as the culmination of them. He draws on twenty years of wide reading and deep thinking, of predictable objection and surprising corroboration, to produce a unique and beautiful account of the making of man.\n\n\"The Hunting Hypothesis\" found success with popular audiences, though it sold fewer copies than \"African Genesis\" or \"The Territorial Imperative\". In 2014 it was reissued in a new edition.\n\n\"The Hunting Hypothesis\" was also one of the first books to warn about the possible dangers of climate change for the continued existence of humanity. In particular, Ardrey argued that the changing climate could render inoperable vast swathes of wheat-producing land in the Northern United States, Canada and Russia. He advocated long-term action and respect for nature. \"One of Ardrey's major criticisms of modern man is precisely that since the inception of agriculture he has sought to dominate nature, separating himself from it until he is now coming to think of himself as nature's master.\"\n\n"}
{"id": "2139040", "url": "https://en.wikipedia.org/wiki?curid=2139040", "title": "The World (Descartes)", "text": "The World (Descartes)\n\nThe World, also called Treatise on the Light (French title: \"Traité du monde et de la lumière\"), is a book by René Descartes (1596–1650). Written between 1629 and 1633, it contains a nearly complete version of his philosophy, from method, to metaphysics, to physics and biology.\n\nDescartes espoused mechanical philosophy, a form of natural philosophy popular in the 17th century. He thought everything physical in the universe to be made of tiny \"corpuscles\" of matter. Corpuscularianism is closely related to atomism. The main difference was that Descartes maintained that there could be no vacuum, and all matter was constantly swirling to prevent a void as corpuscles moved through other matter. \"The World\" presents a corpuscularian cosmology in which swirling vortices explain, among other phenomena, the creation of the Solar System and the circular motion of planets around the Sun.\n\n\"The World\" rests on the heliocentric view, first explicated in Western Europe by Copernicus. Descartes delayed the book's release upon news of the Roman Inquisition's conviction of Galileo for \"suspicion of heresy\" and sentencing to house arrest. Descartes discussed his work on the book, and his decision not to release it, in letters with another philosopher, Marin Mersenne.\n\nSome material from \"The World\" was revised for publication as \"Principia philosophiae\" or \"Principles of Philosophy\" (1644), a Latin textbook at first intended by Descartes to replace the Aristotelian textbooks then used in universities. In the \"Principles\" the heliocentric tone was softened slightly with a relativist frame of reference. The last chapter of \"The World\" was published separately as \"De Homine\" (\"On Man\") in 1662. The rest of \"The World\" was finally published in 1664, and the entire text in 1677.\n\nBefore Descartes begins to describe his theories in physics, he introduces the reader to the idea that there is no relationship between our sensations and what creates these sensations, thereby casting doubt on the Aristotelian belief that such a relationship existed. Next he describes how fire is capable of breaking wood apart into its minuscule parts through the rapid motion of the particles of fire within the flames. This rapid motion of particles is what gives fire its heat, since Descartes claims heat is nothing more than just the motion of particles, and what causes it to produce light.\n\nAccording to Descartes, the motion, or agitation, of these particles is what gives substances their properties (i.e. their fluidity and hardness). Fire is the most fluid and has enough energy to render most other bodies fluid whereas the particles of air lack the force necessary to do the same. Hard bodies have particles that are all equally hard to separate from the whole.\n\nBased on his observations of how resistant nature is to a vacuum, Descartes deduced that all particles in nature are packed together such that there is no void or empty space in nature (however, Descartes makes it clear that he does not claim that a void cannot exist in nature, since he lacks the observations necessary to say this with certainty).\n\nDescartes describes substances as consisting only of three elementary elements: fire, air and earth, from which the properties of any substance can be characterized by its composition of these elements, the size and arrangement of the particles in the substance, and the motion of its particles.\n\nThe motion of these particles and all other objects in nature are subject to the laws of motion Descartes had observed:\n\n\nDescartes in \"Principles of Philosophy\" added to these his laws on elastic collision.\n\nDescartes elaborates on how the universe could have started from utter chaos and with these basic laws could have had its particles arranged so as to resemble the universe we observe today. Once the particles in the chaotic universe began to move, the overall motion would have been circular because there is no void in nature, so whenever a single particle moves, another particle must also move to occupy the space where the previous particle once was. This type of circular motion, or vortex, would have created what Descartes observed to be the orbits of the planets about the sun with the heavier objects spinning out towards the outside of the vortex and the lighter objects remaining closer to the center. To explain this, Descartes used the analogy of a river that carried both floating debris (leaves, feathers, etc.) and heavy boats. If the river abruptly arrived at a sharp bend, the boats would follow Descartes third law of motion and hit the shore of the river since the flow of the particles in the river would not have enough force to change the direction of the boat. However, the much lighter floating debris would follow the river since the particles in the river would have sufficient force to change the direction of the debris. In the heavens, it’s the circular flow of celestial particles, or aether, that causes the motion of the planets to be circular.\n\nAs to the reason why heavy objects on Earth fall, Descartes explained this through the agitation of the particles in the atmosphere. The particles of the aether have greater agitation than the particles of air, which in turn have greater agitation than the particles that compose terrestrial objects (e.g. stones). The greater agitation of the aether prevents the particles of air from escaping into the heavens, just as the agitation of air particles forces terrestrial bodies, whose particles have far less agitation than those of air, to descend towards the world.\n\nWith his laws of motion set forth and the universe operating under these laws, Descartes next begins to describe his theory on the nature of light. Descartes believed that light traveled instantaneously - a common belief at the time – as an impulse across all the adjacent particles in nature, since Descartes believed nature was without a void. To illustrate this, Descartes used the example of a stick being pushed against some body. Just as the force which is felt at one end of the stick is instantly transferred and felt at the other end, so is the impulse of light that is sent across the heavens and through the atmosphere from luminous bodies to our eyes. Descartes attributed light to have 12 distinct properties:\n\n\nAlso:\n\n\n"}
{"id": "25754129", "url": "https://en.wikipedia.org/wiki?curid=25754129", "title": "Theory of forms", "text": "Theory of forms\n\nThe theory of Forms or theory of Ideas is a viewpoint attributed to Plato, which holds that non-physical (but substantial) forms (or ideas) represent the most accurate reality. When used in this sense, the word \"form\" or \"idea\" is often capitalized. Plato speaks of these entities only through the characters (primarily Socrates) of his dialogues who sometimes suggest that these Forms are the only objects of study that can provide knowledge. The theory itself is contested from within Plato's dialogues, and it is a general point of controversy in philosophy. Even whether the theory represents Plato's own views is held in doubt by modern scholarship. However, the theory is considered a classical solution to the problem of universals.\n\nThe early Greek concept of form precedes attested philosophical usage and is represented by a number of words mainly having to do with vision, sight, and appearance. \n\nThe meaning of the term (\"eidos\"), \"visible form\", and related terms μορφή (\"morphē\"), \"shape\", and φαινόμενα (\"phainomena\"), \"appearances\", from φαίνω (\"phainō\"), \"shine\", Indo-European \"\"*bʰeh₂-\"\" or \"*bhā-\" remained stable over the centuries until the beginning of philosophy, when they became equivocal, acquiring additional specialized philosophic meanings. The pre-Socratic philosophers, starting with Thales, noted that appearances change, and began to ask what the thing that changes \"really\" is. The answer was substance, which stands under the changes and is the actually existing thing being seen. The status of appearances now came into question. What is the form really and how is that related to substance?\n\nThus, the theory of matter and form (today's hylomorphism) was born. Starting with at least Plato and possibly germinal in some of the presocratics the forms were considered as being \"in\" something else, which Plato called nature (\"physis\"). The latter seemed as carved \"wood\", ὕλη (\"hyle\") in Greek, corresponding to \"materia\" in Latin, from which the English word \"matter\" is derived, shaped by receiving (or exchanging) forms.\n\nThe Forms are expounded upon in Plato's dialogues and general speech, in that every object or quality in reality has a form: dogs, human beings, mountains, colors, courage, love, and goodness. Form answers the question, \"What is that?\" Plato was going a step further and asking what Form itself is. He supposed that the object was essentially or \"really\" the Form and that the phenomena were mere shadows mimicking the Form; that is, momentary portrayals of the Form under different circumstances. The problem of universals – how can one thing in general be many things in particular – was solved by presuming that Form was a distinct singular thing but caused plural representations of itself in particular objects. For example, Parmenides states, \"Nor, again, if a person were to show that all is one by partaking of one, and at the same time many by partaking of many, would that be very astonishing. But if he were to show me that the absolute one was many, or the absolute many one, I should be truly amazed.\" Matter is considered particular in itself. For Plato, forms, such as beauty, are more real than any objects that imitate them. Though the forms are timeless and unchanging, physical things are in a constant change of existence. Where forms are unqualified perfection, physical things are qualified and conditioned.\n\nThese Forms are the essences of various objects: they are that without which a thing would not be the kind of thing it is. For example, there are countless tables in the world but the Form of tableness is at the core; it is the essence of all of them. Plato's Socrates held that the world of Forms is transcendent to our own world (the world of substances) and also is the essential basis of reality. Super-ordinate to matter, Forms are the most pure of all things. Furthermore, he believed that true knowledge/intelligence is the ability to grasp the world of Forms with one's mind.\n\nA Form is \"aspatial\" (transcendent to space) and \"atemporal\" (transcendent to time). Atemporal means that it does not exist within any time period, rather it provides the formal basis for time. It therefore formally grounds beginning, persisting and ending. It is neither eternal in the sense of existing forever, nor mortal, of limited duration. It exists transcendent to time altogether. Forms are aspatial in that they have no spatial dimensions, and thus no orientation in space, nor do they even (like the point) have a location. They are non-physical, but they are not in the mind. Forms are extra-mental (i.e. real in the strictest sense of the word).\n\nA Form is an objective \"blueprint\" of perfection. The Forms are perfect themselves because they are unchanging. For example, say we have a triangle drawn on a blackboard. A triangle is a polygon with 3 sides. The triangle as it is on the blackboard is far from perfect. However, it is only the intelligibility of the Form \"triangle\" that allows us to know the drawing on the chalkboard is a triangle, and the Form \"triangle\" is perfect and unchanging. It is exactly the same whenever anyone chooses to consider it; however, the time is that of the observer and not of the triangle.\n\nThe words, εἶδος (\"eidos\") and ἰδέα (\"idea\") come from the Indo-European root or \"*weid-\" \"see\" (cognate with Sanskrit \"vétti\"). \"Eidos\" (though not \"idea\") is already attested in texts of the Homeric era, the earliest Greek literature. This transliteration and the translation tradition of German and Latin lead to the expression \"theory of Ideas.\" The word is however not the English \"idea,\" which is a mental concept only.\n\nThe English word \"form\" may be used to translate two distinct concepts that concerned Plato—the outward \"form\" or appearance of something, and \"Form\" in a new, technical nature, that never...assumes a form like that of any of the things which enter into her; ... But the forms which enter into and go out of her are the likenesses of real existences modelled after their patterns in a wonderful and inexplicable manner... The objects that are seen, according to Plato, are not real, but literally \"mimic\" the real Forms. In the Allegory of the Cave expressed in \"Republic\", the things that are ordinarily perceived in the world are characterized as shadows of the real things, which are not perceived directly. That which the observer understands when he views the world mimics the archetypes of the many types and properties (that is, of universals) of things observed.\n\nPlato often invokes, particularly in his dialogues \"Phaedo\", \"Republic\" and \"Phaedrus\", poetic language to illustrate the mode in which the Forms are said to exist. Near the end of the \"Phaedo\", for example, Plato describes the world of Forms as a pristine region of the physical universe located above the surface of the Earth (\"Phd.\" 109a-111c). In the \"Phaedrus\" the Forms are in a \"place beyond heaven\" (\"huperouranios topos\") (\"Phdr.\" 247c ff); and in the \"Republic\" the sensible world is contrasted with the intelligible realm (\"noēton topon\") in the famous Allegory of the Cave.\n\nIt would be a mistake to take Plato's imagery as positing the intelligible world as a literal physical space apart from this one. Plato emphasizes that the Forms are not beings that extend in space (or time), but subsist apart from any physical space whatsoever. Thus we read in the \"Symposium\" of the Form of Beauty: \"It is not anywhere in another thing, as in an animal, or in earth, or in heaven, or in anything else, but itself by itself with itself,\" (211b). And in the \"Timaeus\" Plato writes: \"Since these things are so, we must agree that that which keeps its own form unchangingly, which has not been brought into being and is not destroyed, which neither receives into itself anything else from anywhere else, \"nor itself enters into anything anywhere\", is one thing,\" (52a, emphasis added).\n\nAccording to Plato, Socrates postulated a world of ideal Forms, which he admitted were impossible to know. Nevertheless, he formulated a very specific description of that world, which did not match his metaphysical principles. Corresponding to the world of Forms is our world, that of the shadows, an imitation of the real one. Just as shadows exist only because of the light of a fire, our world exists as, \"the offspring of the good\". Our world is modeled after the patterns of the Forms. The function of humans in our world is therefore to imitate the ideal world as much as possible which, importantly, includes imitating the good, i.e. acting morally.\n\nPlato lays out much of this theory in the \"Republic\" where, in an attempt to define Justice, he considers many topics including the constitution of the ideal state. While this state, and the Forms, do not exist on earth, because their imitations do, Plato says we are able to form certain well-founded opinions about them, through a theory called recollection.\n\nThe republic is a greater imitation of Justice:Our aim in founding the state was not the disproportional happiness of any one class, but the greatest happiness of the whole; we thought that in a state ordered with a view to the good of the whole we should be most likely to find justice.\n\nThe key to not know how such a state might come into existence is the word \"founding\" (\"oikidzomen\"), which is used of colonization. It was customary in such instances to receive a constitution from an elected or appointed lawgiver; however in Athens, lawgivers were appointed to reform the constitution from time to time (for example, Draco, Solon). In speaking of reform, Socrates uses the word \"purge\" (\"diakathairountes\") in the same sense that Forms exist purged of matter.\n\nThe purged society is a regulated one presided over by philosophers educated by the state, who maintain three non-hereditary classes as required: the tradesmen (including merchants and professionals), the guardians (militia and police) and the philosophers (legislators, administrators and the philosopher-king). Class is assigned at the end of education, when the state institutes individuals in their occupation. Socrates expects class to be hereditary but he allows for mobility according to natural ability. The criteria for selection by the academics is ability to perceive forms (the analog of English \"intelligence\") and martial spirit as well as predisposition or aptitude.\n\nThe views of Socrates on the proper order of society are certainly contrary to Athenian values of the time and must have produced a shock effect, intentional or not, accounting for the animosity against him. For example, reproduction is much too important to be left in the hands of untrained individuals: \"... the possession of women and the procreation of children ... will ... follow the general principle that friends have all things in common, ...\" The family is therefore to be abolished and the children – whatever their parentage – to be raised by the appointed mentors of the state.\n\nTheir genetic fitness is to be monitored by the physicians: \"... he (Asclepius, a culture hero) did not want to lengthen out good-for-nothing lives, or have weak fathers begetting weaker sons – if a man was not able to live in the ordinary way he had no business to cure him ...\" Physicians minister to the healthy rather than cure the sick: \"... (Physicians) will minister to better natures, giving health both of soul and of body; but those who are diseased in their bodies they will leave to die, and the corrupt and incurable souls they will put an end to themselves.\" Nothing at all in Greek medicine so far as can be known supports the airy (in the Athenian view) propositions of Socrates. Yet it is hard to be sure of Socrates' real views considering that there are no works written by Socrates himself. There are two common ideas pertaining to the beliefs and character of Socrates: the first being the Mouthpiece Theory where writers use Socrates in dialogue as a mouthpiece to get their own views across. However, since most of what we know about Socrates comes from plays, most of the Platonic plays are accepted as the more accurate Socrates since Plato was a direct student of Socrates.\n\nPerhaps the most important principle is that just as the Good must be supreme so must its image, the state, take precedence over individuals in everything. For example, guardians \"... will have to be watched at every age in order that we may see whether they preserve their resolution and never, under the influence either of force or enchantment, forget or cast off their sense of duty to the state.\" This concept of requiring guardians of guardians perhaps suffers from the Third Man weakness (see below): guardians require guardians require guardians, ad infinitum. The ultimate trusty guardian is missing. Socrates does not hesitate to face governmental issues many later governors have found formidable: \"Then if anyone at all is to have the privilege of lying, the rulers of the state should be the persons, and they ... may be allowed to lie for the public good.\"\n\nPlato's conception of Forms actually differs from dialogue to dialogue, and in certain respects it is never fully explained, so many aspects of the theory are open to interpretation. Forms are first introduced in the Phaedo, but in that dialogue the concept is simply referred to as something the participants are already familiar with, and the theory itself is not developed. Similarly, in the Republic, Plato relies on the concept of Forms as the basis of many of his arguments but feels no need to argue for the validity of the theory itself or to explain precisely what Forms are. Commentators have been left with the task of explaining what Forms are and how visible objects participate in them, and there has been no shortage of disagreement. Some scholars advance the view that Forms are paradigms, perfect examples on which the imperfect world is modeled. Others interpret Forms as universals, so that the Form of Beauty, for example, is that quality that all beautiful things share. Yet others interpret Forms as \"stuffs,\" the conglomeration of all instances of a quality in the visible world. Under this interpretation, we could say there is a little beauty in one person, a little beauty in another—all the beauty in the world put together is the Form of Beauty. Plato himself was aware of the ambiguities and inconsistencies in his Theory of Forms, as is evident from the incisive criticism he makes of his own theory in the Parmenides.\n\nPlato's main evidence for the existence of Forms is intuitive only and is as follows.\n\nWe call both the sky and blue jeans by the same color, blue. However, clearly a pair of jeans and the sky are not the same color; moreover, the wavelengths of light reflected by the sky at every location and all the millions of blue jeans in every state of fading constantly change, and yet we somehow have a consensus of the basic form Blueness as it applies to them. Says Plato:But if the very nature of knowledge changes, at the time when the change occurs there will be no knowledge, and, according to this view, there will be no one to know and nothing to be known: but if that which knows and that which is known exist ever, and the beautiful and the good and every other thing also exist, then I do not think that they can resemble a process of flux, as we were just now supposing.\n\nPlato believed that long before our bodies ever existed, our souls existed and inhabited heaven, where they became directly acquainted with the forms themselves. Real knowledge, to him, was knowledge of the forms. But knowledge of the forms cannot be gained through sensory experience because the forms are not in the physical world. Therefore, our real knowledge of the forms must be the memory of our initial acquaintance with the forms in heaven. Therefore, what we seem to learn is in fact just remembering.\n\nNo one has ever seen a perfect circle, nor a perfectly straight line, yet everyone knows what a circle and a straight line are. Plato utilizes the tool-maker's blueprint as evidence that Forms are real:... when a man has discovered the instrument which is naturally adapted to each work, he must express this natural form, and not others which he fancies, in the material ...\n\nPerceived circles or lines are not exactly circular or straight, and true circles and lines could never be detected since by definition they are sets of infinitely small points. But if the perfect ones were not real, how could they direct the manufacturer?\n\nPlato was well aware of the limitations of the theory, as he offered his own criticisms of it in his dialogue \"Parmenides\". There Socrates is portrayed as a young philosopher acting as junior counterfoil to aged Parmenides. To a certain extent it is tongue-in-cheek as the older Socrates will have solutions to some of the problems that are made to puzzle the younger.\n\nThe dialogue does present a very real difficulty with the Theory of Forms, which Plato most likely only viewed as problems for later thought. These criticisms were later emphasized by Aristotle in rejecting an independently existing world of Forms. It is worth noting that Aristotle was a pupil and then a junior colleague of Plato; it is entirely possible that the presentation of \"Parmenides\" \"sets up\" for Aristotle; that is, they agreed to disagree.\n\nOne difficulty lies in the conceptualization of the \"participation\" of an object in a form (or Form). The young Socrates conceives of his solution to the problem of the universals in another metaphor, which though wonderfully apt, remains to be elucidated:\nNay, but the idea may be like the day which is one and the same in many places at once, and yet continuous with itself; in this way each idea may be one and the same in all at the same time.\n\nBut exactly how is a Form like the day in being everywhere at once? The solution calls for a distinct form, in which the particular instances, which are not identical to the form, participate; i.e., the form is shared out somehow like the day to many places. The concept of \"participate\", represented in Greek by more than one word, is as obscure in Greek as it is in English. Plato hypothesized that distinctness meant existence as an independent being, thus opening himself to the famous third man argument of Parmenides, which proves that forms cannot independently exist and be participated.\n\nIf universal and particulars – say man or greatness – all exist and are the same then the Form is not one but is multiple. If they are only like each other then they contain a form that is the same and others that are different. Thus if we presume that the Form and a particular are alike then there must be another, or third Form, man or greatness by possession of which they are alike. An infinite regression would then result; that is, an endless series of third men. The ultimate participant, greatness, rendering the entire series great, is missing. Moreover, any Form is not unitary but is composed of infinite parts, none of which is the proper Form.\n\nThe young Socrates (some may say the young Plato) did not give up the Theory of Forms over the Third Man but took another tack, that the particulars do not exist as such. Whatever they are, they \"mime\" the Forms, appearing to be particulars. This is a clear dip into representationalism, that we cannot observe the objects as they are in themselves but only their representations. That view has the weakness that if only the mimes can be observed then the real Forms cannot be known at all and the observer can have no idea of what the representations are supposed to represent or that they are representations.\n\nSocrates' later answer would be that men already know the Forms because they were in the world of Forms before birth. The mimes only recall these Forms to memory. The comedian Aristophanes wrote a play, \"The Clouds\", poking fun of Socrates with his head in the clouds.\n\nThe topic of Aristotle's criticism of Plato's Theory of Forms is a large one and continues to expand. Rather than quote Plato, Aristotle often summarized. Classical commentaries thus recommended Aristotle as an introduction to Plato. As a historian of prior thought, Aristotle was invaluable, however this was secondary to his own dialectic and in some cases he treats purported implications as if Plato had actually mentioned them, or even defended them. In examining Aristotle's criticism of The Forms, it is helpful to understand Aristotle's own hylomorphic forms, by which he intends to salvage much of Plato's theory.\n\nIn the summary passage quoted above Plato distinguishes between real and non-real \"existing things\", where the latter term is used of substance. The figures that the artificer places in the gold are not substance, but gold is. Aristotle stated that, for Plato, all things studied by the sciences have Form and asserted that Plato considered only substance to have Form. Uncharitably, this leads him to something like a contradiction: Forms existing as the objects of science, but not-existing as non-substance. Scottish philosopher W.D. Ross objects to this as a mischaracterization of Plato.\n\nPlato did not claim to know where the line between Form and non-Form is to be drawn. As Cornford points out, those things about which the young Socrates (and Plato) asserted \"I have often been puzzled about these things\" (in reference to Man, Fire and Water), appear as Forms in later works. However, others do not, such as Hair, Mud, Dirt. Of these, Socrates is made to assert, \"it would be too absurd to suppose that they have a Form.\"\n\nRoss also objects to Aristotle's criticism that Form Otherness accounts for the differences between Forms and purportedly leads to contradictory forms: the Not-tall, the Not-beautiful, etc. That particulars participate in a Form is for Aristotle much too vague to permit analysis. By one way in which he unpacks the concept, the Forms would cease to be of one essence due to any multiple participation. As Ross indicates, Plato didn't make that leap from \"A is not B\" to \"A is Not-B.\" Otherness would only apply to its own particulars and not to those of other Forms. For example, there is no Form Not-Greek, only \"particulars\" of Form Otherness that somehow \"suppress\" Form Greek.\n\nRegardless of whether Socrates meant the particulars of Otherness yield Not-Greek, Not-tall, Not-beautiful, etc., the particulars would operate specifically rather than generally, each somehow yielding only one exclusion.\n\nPlato had postulated that we know Forms through a remembrance of the soul's past lives and Aristotle's arguments against this treatment of epistemology are compelling. For Plato, particulars somehow do not exist, and, on the face of it, \"that which is non-existent cannot be known\". See \"Metaphysics\" III 3–4.\n\nThe theory is presented in the following dialogues:\n\n\n\n"}
{"id": "41248918", "url": "https://en.wikipedia.org/wiki?curid=41248918", "title": "University of Valencia Science Park", "text": "University of Valencia Science Park\n\nThe University of Valencia Science Park ( also known by the acronym \"PCUV\") provides spaces and services to companies resulting from university research, –spin-off–, and other companies and R & D departments with content related to the innovative nature of the PCUV.\n\nThe PCUV has a scientific area that includes six research institutes, two centres and services and facilities for research; and a business area that currently houses more than seventy young or already established companies, mainly from the sectors of biotechnology and information and communication technologies (ICT).\n\nIn addition, The University of Valencia Science Park houses the technical office of the Emprendia Network (Iberoamerican University Network of Business Incubation), which enables the expansion of businesses in the science parks of universities that make up the network. It is also a member of the rePCV (Network of Valencian Science Parks), APTE (Association of Science and Technology Parks of Spain) and the IASP (International Association of Science and Technology Parks).\n\nThe University of Valencia Science Park Foundation\n\nThe University of Valencia Science Park Foundation was established 9 March 2009 as a private organization with a general interest established under the aegis of the protectorate\nof the Generalitat Valenciana. The founding benefactors are Fundación Bancaja, Banco Santander, the Valencian Chamber of Commerce, the Valencian Business Confederation, and the\nUniversity of Valencia. Foundation manages the Science Park with the purpose of promoting technological development, knowledge transfer and industrial innovation, among other things.\n\nThe PCUV currently includes more than eighty companies generating close to 500 direct jobs, mainly from the ICT and biotechnology sectors.\n\nThe PCUV has six research institutes, four of them from the University of Valencia, one from the National Scientific Research Council (CSIC), and one a joint venture of the University of Valencia and CSIC. The Astronomical Observatory of the institution and the Image Processing Laboratory (IPL) are also housed at the park. Together they form the academic area of this framework for innovation that is the Science Park. They all stand out for their level of collaboration with companies and institutions or for their participation in projects implemented for the benefit of society.\n\nCreated in 1995, the Institute of Materials Science of the University of Valencia focuses on the development of different national and international projects and multiple contracts with industry. Among the lines of research of the ICMUV, the following stand out: the study of quantum semiconductor nanostructures and devices, nanomaterials for energy, high pressure physics, photonic crystals, synthesis and characterization of porous materials and zeotypes, alternative synthesis strategies, surface treatments for laser marking, functional nanomaterials, structured nanomaterials, catalysis, hybrid polymers and historical heritage.\n\nFounded in 2000, the Institute for Molecular Science of the University of Valencia is for chemistry and molecular nanoscience. Its scientific objectives are focused on areas such as the design and synthesis of functional molecules, supramolecular associations and molecular materials with physical or chemical properties of interest. The fields of application range from molecular magnetism and molecular electronics to nanotechnology and biomedicine.\n\nFounded in 1950, the Institute of Corpuscular Physics, a joint centre of the University of Valencia and CSIC, is dedicated to basic research in particle, astroparticle and nuclear physics. Its most direct fields of application are medical physics and GRID technology. Its main lines of research are experimental high energy physics based on accelerators, experimental neutrino and astroparticle physics, experimental nuclear physics, theoretical astroparticle physics, the phenomenology of high energy physics, and nuclear theory, among others.\n\nThe Astronomical Observatory of the University of Valencia is an institution dedicated to research and education, to the study of the Universe and the popularization of astronomy in society. Founded in 1909, it is dedicated to research topics as hot as the study of the nature of dark energy, the evolution of the Universe and its galaxies, the formation and evolution of stars, and the study of near-Earth asteroids.\n\nIRTIC is a research centre of the University of Valencia, founded in the early 90s. Consisting of four research groups associated with the area of information and communication technologies, they develop projects of information management systems, traffic and transport telematics, computer and virtual reality graphics, integration systems for the disabled, civil machinery simulation, network services, computer security and digital image processing.\n\nThe Institute of Agrochemistry and Food Technology (IATA) is a centre of the CSIC in Valencia. Its lines of research include food biotechnology and microbiology, development of processes and technology for food processing and packaging, technologies for food preservation, quality and functionality, and advanced techniques for food analysis.\n\nThe Image Processing Laboratory (IPL) of the University of Valencia consists of four research groups with a common area: imaging (the creation of actual images or of geo-biophysical parameters) from satellite and remote sensing data. The research groups are UCG (Global Change Unit), GPDS (Digital Processing of Signals Group), GACE (Astronomy and Space Sciences Group) and LEO (Laboratory for Earth Observation).\n\nFounded in 1998, the Cavanilles Institute of the University of Valencia is dedicated to the study of biodiversity and evolutionary biology with an integrative and multidisciplinary approach. It has the following research groups: evolutionary genetics, limnology, entomology, evolutionary ecology, plant conservation biology, marine zoology, paleontology, vertebrate ecology, bacteriology, ethology, evolutionary biology of plants, comparative neurobiology and plant biodiversity/ecophysiology.\n\nAt present, cooperation and investment in R&D are the most effective tools that the entrepreneur has to face growing competition and to increase competitiveness. For this purpose, the PCUV has the collaboration of the University of Valencia, whose aims and objectives are to promote university-industry cooperation and the transference of research results: Support organizations include the Technology Transfer Office of the University of Valencia (OTRI), the Valencia University-Enterprise Foundation (ADEIT), the Centre\nof Professional Integration and Employment Counselling (OPAL), and the Office of European Projects (OPER), among others.\n\nThe Central Service for the Support of Experimental Research (SCSIE) is a general service of technology resources whose mission is to provide centralized and comprehensive support for research carried out in the university community, businesses, and public and private institutions.\n\nThe PCUV also offers the following business support services:\n\n"}
