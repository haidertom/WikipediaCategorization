{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showcase\n",
    "\n",
    "Here is a fast visulization of our results.\n",
    "\n",
    "Run all cells and when promted, type in an article from the english Wikipedia you wish to categorize, e.g. *Football*. If the article exists, the article is downloaded in the background (you need an Internet connection for this). \n",
    "For each of the Wikipida main topic classifcations, the probability that the article belongs to that category is then calculated and shown in a graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'BloomFilter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c9b7e5578a31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mBloomClassify\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mBC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLSIsimilarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbaseline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlanguageProcess\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DTU/ComputationToolsForDataScience/finalProject/WikipediaCategorization/WikipediaCategorization/Scripts/BloomClassify.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlanguageProcess\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mBloomFilter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtfidf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTfIdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'BloomFilter'"
     ]
    }
   ],
   "source": [
    "import BloomClassify as BC\n",
    "import LSIsimilarity\n",
    "from baseline import Baseline\n",
    "import os\n",
    "import languageProcess as lp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LSIsimilarity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7d098049467c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mLSI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSIsimilarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSIsimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mCL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBloomClassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloadModels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mLSI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoOfTrainArticle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LSIsimilarity' is not defined"
     ]
    }
   ],
   "source": [
    "LSI = LSIsimilarity.LSIsimilarity()\n",
    "CL = BC.BloomClassify(prct = 40, art = 1000)\n",
    "\n",
    "def loadModels():\n",
    "    LSI.train(noOfTrainArticle=1000)\n",
    "    CL.load_BL()\n",
    "\n",
    "def checkArticle(title):\n",
    "    # check if Validationfolder exists\n",
    "    if not os.path.exists(\"../Validation\"): os.mkdir(\"../Validation\")\n",
    "\n",
    "    # get article from wikipedia API\n",
    "    Base = Baseline(folder=\"Validation\")\n",
    "    filename = \"../Validation/\"+title.replace(' ','')+\"_raw.txt\"\n",
    "    with open(filename, 'w') as the_file:\n",
    "        the_file.write(Base.get_dumptext([title]))\n",
    "\n",
    "    #convert to plain text\n",
    "    os.system(\"../wikiextractor/WikiExtractor.py \"+\"../Validation/\"+title.replace(' ','')+\"_raw.txt\"+\" -o\"+\" ../Validation/\"+title.replace(' ','')+\"/ --json\")\n",
    "\n",
    "    #housekeeping\n",
    "    category = os.listdir(\"../Validation\")\n",
    "    if '.DS_Store' in category: category.remove('.DS_Store')\n",
    "\n",
    "    #languageProcess\n",
    "    filepath = \"../Validation/\"+title.replace(' ','')+\"/AA/wiki_00\"\n",
    "    article = lp.languageProcess(filepath)\n",
    "    bfarticle = article.getHighFreqWords()\n",
    "    lsiarticle = article.getWords()\n",
    "    \n",
    "    assert (len(bfarticle)>= 1),\"No article with that name\"\n",
    "    \n",
    "    #BloomFilter\n",
    "    vali_dict = {}\n",
    "    numOfCheckWords = 100\n",
    "\n",
    "    for cat in CL.BFdict.keys():\n",
    "        vali_dict[cat] = sum([1 for word in bfarticle[0].most_common(numOfCheckWords) if CL.BFdict[cat].classify(word[0])])/numOfCheckWords\n",
    "\n",
    "    #Rewrite to return LSIres and BFres\n",
    "    return LSI.compare(lsiarticle), vali_dict\n",
    "\n",
    "def plotGraph(resLSI,resBF):\n",
    "    ind = np.arange(len(resLSI))    # the x locations for the groups\n",
    "    width = 0.2         # the width of the bars\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(11,5))\n",
    "\n",
    "    p1 = ax.bar(ind-width,list(resLSI.values()),width, align='center',color='dodgerblue')\n",
    "    p2 = ax.bar(ind,list(resBF.values()),width, align='center',color='darkorange')\n",
    "    \n",
    "    ax.set_xticks(ind + width/2)\n",
    "    ax.set_xticklabels(list(resLSI.keys()),rotation='vertical')\n",
    "    ax.legend((p1[0], p2[0]), ('LSI 1000','BF 1000'))\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.set_ylabel('right assigned articles')\n",
    "    ax.grid()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "loadModels()\n",
    "\n",
    "\n",
    "def main():\n",
    "    title = input(\"Insert Article name: \")\n",
    "    print(title)\n",
    "    resLSI, resBF = checkArticle(title)\n",
    "    plotGraph(resLSI,resBF)\n",
    "    \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'main' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'main' is not defined"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results shown in the graph above represent the probability that the given article is within each of the categories. The higher the difference from the highest value to the second highest value, the higher the certainty that the result is valid. Some articles are very differentiatied and clearly assignable to one single Category. E.g. *Football* or *Handball* can not clearly be assigned to any other category than Sport and therefore, the result for these articles is very clear. Other articles like *Facebook* or *Google* don't have a clear direction, as they cover multiple different topics at once. These articles could be assgined to multiple different categories and therefore, our reults are rather unclear on articles like these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
